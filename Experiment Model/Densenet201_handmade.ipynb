{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756bf2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10cdbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size=1\n",
    "learning_rate = 0.001\n",
    "layers = 100\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(48),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(root='emotion_FixedVer_TrainTest/train/', transform=transforms)\n",
    "test_dataset = datasets.ImageFolder(root='emotion_FixedVer_TrainTest/test/', transform=transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5c5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,dropRate = 0.0):\n",
    "        #input dimsnsion을 정하고, output dimension을 정하고(growh_rate임), dropRate를 정함.\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace = True) # inplace 하면 input으로 들어온 것 자체를 수정하겠다는 뜻. 메모리 usage가 좀 좋아짐. 하지만 input을 없앰.\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride = 1, padding = 1, bias = False)\n",
    "        self.droprate = dropRate\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate>0:\n",
    "            out = F.dropout (out,p=self.droprate,training = self.training)\n",
    "        return torch.cat([x,out],1)\n",
    "        \n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,dropRate=0.0):\n",
    "        #out_planes => growh_rate를 입력으로 받게 된다.\n",
    "        super(BottleneckBlock,self).__init__()\n",
    "        inter_planes = out_planes * 4 # bottleneck layer의 conv 1x1 filter chennel 수는 4*growh_rate이다.\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.conv1 = nn.Conv2d(in_planes,inter_planes,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(inter_planes)\n",
    "        self.conv2 = nn.Conv2d(inter_planes,out_planes,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.droprate = dropRate\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate>0:\n",
    "            out = F.dropout(out,p=self.droprate,inplace=False,training = self.training)\n",
    "        out = self.conv2(self.relu(self.bn2(out)))\n",
    "        if self.droprate>0:\n",
    "            out = F.dropout(out,p=self.droprate,inplace=False,training = self.training)\n",
    "        return torch.cat([x,out],1) # 입력으로 받은 x와 새로 만든 output을 합쳐서 내보낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8e0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self,nb_layers,in_planes,growh_rate,block,dropRate=0.0):\n",
    "        super(DenseBlock,self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, growh_rate, nb_layers, dropRate)\n",
    "    \n",
    "    def _make_layer(self,block,in_planes,growh_rate,nb_layers,dropRate):\n",
    "        layers=[]\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(in_planes + i*growh_rate ,growh_rate,dropRate))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6869af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionBlock(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,dropRate=0.0):\n",
    "        super(TransitionBlock,self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes,out_planes,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.droprate = dropRate\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.droprate>0:\n",
    "            out = F.dropout(out,p=self.droprate,inplace=False,training=self.training)\n",
    "        return F.avg_pool2d(out,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe947225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,depth,num_classes,growh_rate=12,reduction=0.5,bottleneck=True,dropRate=0.0):\n",
    "        super(DenseNet,self).__init__()\n",
    "        num_of_blocks = 3\n",
    "        in_planes = 16 # 2 * growh_rate\n",
    "        n = (depth - num_of_blocks - 1)/num_of_blocks # 총 depth에서 첫 conv , 2개의 transit , 마지막 linear 빼고 / num_of_blocks\n",
    "        if reduction != 1 :\n",
    "            in_planes = 2 * growh_rate\n",
    "        if bottleneck == True:\n",
    "            in_planes = 2 * growh_rate #논문에서 Bottleneck + Compression 할 경우 first layer은 2*growh_rate라고 했다.\n",
    "            n = n/2 # conv 1x1 레이어가 추가되니까 !\n",
    "            block = BottleneckBlock \n",
    "        else :\n",
    "            block = BasicBlock\n",
    "        \n",
    "        n = int(n) #n = DenseBlock에서 block layer 개수를 의미한다.\n",
    "        self.conv1 = nn.Conv2d(3,in_planes,kernel_size=3,stride=1,padding=1,bias=False) # input:RGB -> output:growhR*2\n",
    "        \n",
    "        \n",
    "        #1st block\n",
    "        # nb_layers,in_planes,growh_rate,block,dropRate\n",
    "        self.block1 = DenseBlock(n,in_planes,growh_rate,block,dropRate)\n",
    "        in_planes = int(in_planes+n*growh_rate) # 입력 + 레이어 만큼의 growh_rate\n",
    "        \n",
    "        # in_planes,out_planes,dropRate\n",
    "        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)),dropRate=dropRate)\n",
    "        in_planes = int(math.floor(in_planes*reduction))\n",
    "        \n",
    "        \n",
    "        #2nd block\n",
    "        # nb_layers,in_planes,growh_rate,block,dropRate\n",
    "        self.block2 = DenseBlock(n,in_planes,growh_rate,block,dropRate)\n",
    "        in_planes = int(in_planes+n*growh_rate) # 입력 + 레이어 만큼의 growh_rate\n",
    "        \n",
    "        # in_planes,out_planes,dropRate\n",
    "        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)),dropRate=dropRate)\n",
    "        in_planes = int(math.floor(in_planes*reduction))\n",
    "        \n",
    "        \n",
    "        #3rd block\n",
    "        # nb_layers,in_planes,growh_rate,block,dropRate\n",
    "        self.block3 = DenseBlock(n,in_planes,growh_rate,block,dropRate)\n",
    "        in_planes = int(in_planes+n*growh_rate) # 입력 + 레이어 만큼의 growh_rate\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        self.fc = nn.Linear(in_planes,num_classes) # 마지막에 ave_pool 후에 1x1 size의 결과만 남음.\n",
    "        \n",
    "        self.in_planes = in_planes\n",
    "        \n",
    "        # module 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Conv layer들은 필터에서 나오는 분산 root(2/n)로 normalize 함\n",
    "                # mean = 0 , 분산 = sqrt(2/n) // 이게 무슨 초기화 방법이었는지 기억이 안난다.\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d): # shifting param이랑 scaling param 초기화(?)\n",
    "                m.weight.data.fill_(1) # \n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):# linear layer 초기화.\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x : 32*32\n",
    "        out = self.conv1(x) # 32*32\n",
    "        out = self.block1(out) # 32*32\n",
    "        out = self.trans1(out) # 16*16\n",
    "        out = self.block2(out) # 16*16\n",
    "        out = self.trans2(out) # 8*8\n",
    "        out = self.block3(out) # 8*8\n",
    "        out = self.relu(self.bn1(out)) #8*8\n",
    "        out = F.avg_pool2d(out,8) #1*1\n",
    "        out = out.view(-1, self.in_planes) #channel수만 남기 때문에 Linear -> in_planes\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee58627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 769162\n"
     ]
    }
   ],
   "source": [
    "#model = torch.load('DenseNetModelSave.pt')\n",
    "model = DenseNet(layers,10,growh_rate=12,dropRate = 0.0)\n",
    "\n",
    "\n",
    "# get the number of model parameters\n",
    "# 재미있는 코드라서 들고와봄.\n",
    "print('Number of model parameters: {}'.format(\n",
    "    sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)#해보자 한번\n",
    "#optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate,\n",
    "                            momentum=0.9,nesterov=True,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57585211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer,epoch):\n",
    "    model.train()\n",
    "    for i, (input,target) in enumerate(train_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i%20 == 0):\n",
    "            print(\"loss in epoch %d , step %d : %f\" % (epoch, i,loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d097b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,model,criterion,epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    for i, (input,target) in enumerate(test_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n",
    "    \n",
    "    print(\"Accuracy in epoch %d : %f\" % (epoch,100.0*correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cce1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch, learning_rate):\n",
    "    if epoch==15 :\n",
    "        learning_rate*=0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0af231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 0 : 2.460646\n",
      "loss in epoch 0 , step 20 : 1.628861\n",
      "loss in epoch 0 , step 40 : 2.802648\n",
      "loss in epoch 0 , step 60 : 1.319558\n",
      "loss in epoch 0 , step 80 : 2.103217\n",
      "loss in epoch 0 , step 100 : 2.323822\n",
      "loss in epoch 0 , step 120 : 1.525142\n",
      "loss in epoch 0 , step 140 : 2.023942\n",
      "loss in epoch 0 , step 160 : 1.477506\n",
      "loss in epoch 0 , step 180 : 2.635135\n",
      "loss in epoch 0 , step 200 : 1.928623\n",
      "loss in epoch 0 , step 220 : 1.804159\n",
      "loss in epoch 0 , step 240 : 1.633147\n",
      "loss in epoch 0 , step 260 : 1.131948\n",
      "loss in epoch 0 , step 280 : 1.990479\n",
      "loss in epoch 0 , step 300 : 1.221726\n",
      "loss in epoch 0 , step 320 : 2.426719\n",
      "loss in epoch 0 , step 340 : 1.254447\n",
      "loss in epoch 0 , step 360 : 1.688887\n",
      "loss in epoch 0 , step 380 : 1.305776\n",
      "loss in epoch 0 , step 400 : 1.274635\n",
      "loss in epoch 0 , step 420 : 2.549459\n",
      "loss in epoch 0 , step 440 : 2.082726\n",
      "loss in epoch 0 , step 460 : 2.156009\n",
      "loss in epoch 0 , step 480 : 1.586052\n",
      "loss in epoch 0 , step 500 : 2.281213\n",
      "loss in epoch 0 , step 520 : 1.365393\n",
      "loss in epoch 0 , step 540 : 3.123518\n",
      "loss in epoch 0 , step 560 : 2.241378\n",
      "loss in epoch 0 , step 580 : 1.388109\n",
      "loss in epoch 0 , step 600 : 1.418564\n",
      "loss in epoch 0 , step 620 : 1.407349\n",
      "loss in epoch 0 , step 640 : 1.654873\n",
      "loss in epoch 0 , step 660 : 1.547264\n",
      "loss in epoch 0 , step 680 : 1.955358\n",
      "loss in epoch 0 , step 700 : 2.999701\n",
      "loss in epoch 0 , step 720 : 2.409560\n",
      "loss in epoch 0 , step 740 : 1.514281\n",
      "loss in epoch 0 , step 760 : 2.222932\n",
      "loss in epoch 0 , step 780 : 2.181077\n",
      "loss in epoch 0 , step 800 : 1.711318\n",
      "loss in epoch 0 , step 820 : 1.813513\n",
      "loss in epoch 0 , step 840 : 1.514705\n",
      "loss in epoch 0 , step 860 : 2.143687\n",
      "loss in epoch 0 , step 880 : 1.903073\n",
      "loss in epoch 0 , step 900 : 1.983257\n",
      "loss in epoch 0 , step 920 : 1.682505\n",
      "loss in epoch 0 , step 940 : 2.008955\n",
      "loss in epoch 0 , step 960 : 2.092137\n",
      "loss in epoch 0 , step 980 : 2.676570\n",
      "loss in epoch 0 , step 1000 : 1.741676\n",
      "loss in epoch 0 , step 1020 : 1.453612\n",
      "loss in epoch 0 , step 1040 : 2.024477\n",
      "loss in epoch 0 , step 1060 : 2.075855\n",
      "loss in epoch 0 , step 1080 : 2.055470\n",
      "loss in epoch 0 , step 1100 : 1.778215\n",
      "loss in epoch 0 , step 1120 : 1.488319\n",
      "loss in epoch 0 , step 1140 : 1.714304\n",
      "loss in epoch 0 , step 1160 : 2.787045\n",
      "loss in epoch 0 , step 1180 : 1.945531\n",
      "loss in epoch 0 , step 1200 : 2.139859\n",
      "loss in epoch 0 , step 1220 : 2.153201\n",
      "loss in epoch 0 , step 1240 : 2.222939\n",
      "loss in epoch 0 , step 1260 : 1.586647\n",
      "loss in epoch 0 , step 1280 : 3.036611\n",
      "loss in epoch 0 , step 1300 : 2.405403\n",
      "loss in epoch 0 , step 1320 : 1.399455\n",
      "loss in epoch 0 , step 1340 : 1.848459\n",
      "loss in epoch 0 , step 1360 : 1.788499\n",
      "loss in epoch 0 , step 1380 : 2.266764\n",
      "loss in epoch 0 , step 1400 : 1.143976\n",
      "loss in epoch 0 , step 1420 : 1.517419\n",
      "loss in epoch 0 , step 1440 : 1.643204\n",
      "loss in epoch 0 , step 1460 : 1.252142\n",
      "loss in epoch 0 , step 1480 : 1.660452\n",
      "loss in epoch 0 , step 1500 : 1.525680\n",
      "loss in epoch 0 , step 1520 : 1.113269\n",
      "loss in epoch 0 , step 1540 : 0.936125\n",
      "loss in epoch 0 , step 1560 : 2.002974\n",
      "loss in epoch 0 , step 1580 : 2.045300\n",
      "loss in epoch 0 , step 1600 : 1.502491\n",
      "loss in epoch 0 , step 1620 : 1.914711\n",
      "loss in epoch 0 , step 1640 : 1.581893\n",
      "loss in epoch 0 , step 1660 : 2.386651\n",
      "loss in epoch 0 , step 1680 : 1.650061\n",
      "loss in epoch 0 , step 1700 : 2.233680\n",
      "loss in epoch 0 , step 1720 : 1.473048\n",
      "loss in epoch 0 , step 1740 : 1.930224\n",
      "loss in epoch 0 , step 1760 : 1.295598\n",
      "loss in epoch 0 , step 1780 : 1.031895\n",
      "loss in epoch 0 , step 1800 : 2.085354\n",
      "loss in epoch 0 , step 1820 : 2.324153\n",
      "loss in epoch 0 , step 1840 : 0.596949\n",
      "loss in epoch 0 , step 1860 : 1.682281\n",
      "loss in epoch 0 , step 1880 : 1.525434\n",
      "loss in epoch 0 , step 1900 : 0.470988\n",
      "loss in epoch 0 , step 1920 : 1.151801\n",
      "loss in epoch 0 , step 1940 : 1.554361\n",
      "loss in epoch 0 , step 1960 : 2.017040\n",
      "loss in epoch 0 , step 1980 : 1.246817\n",
      "loss in epoch 0 , step 2000 : 1.314489\n",
      "loss in epoch 0 , step 2020 : 1.851386\n",
      "loss in epoch 0 , step 2040 : 1.519297\n",
      "loss in epoch 0 , step 2060 : 2.837142\n",
      "loss in epoch 0 , step 2080 : 1.415639\n",
      "loss in epoch 0 , step 2100 : 2.702723\n",
      "loss in epoch 0 , step 2120 : 1.331143\n",
      "loss in epoch 0 , step 2140 : 1.536162\n",
      "loss in epoch 0 , step 2160 : 2.236221\n",
      "loss in epoch 0 , step 2180 : 1.947302\n",
      "loss in epoch 0 , step 2200 : 2.005379\n",
      "loss in epoch 0 , step 2220 : 1.852244\n",
      "loss in epoch 0 , step 2240 : 1.224617\n",
      "loss in epoch 0 , step 2260 : 1.226948\n",
      "loss in epoch 0 , step 2280 : 1.594796\n",
      "loss in epoch 0 , step 2300 : 1.841475\n",
      "loss in epoch 0 , step 2320 : 1.784341\n",
      "loss in epoch 0 , step 2340 : 2.116581\n",
      "loss in epoch 0 , step 2360 : 2.205587\n",
      "loss in epoch 0 , step 2380 : 1.807926\n",
      "loss in epoch 0 , step 2400 : 1.752054\n",
      "loss in epoch 0 , step 2420 : 0.938347\n",
      "loss in epoch 0 , step 2440 : 0.831172\n",
      "loss in epoch 0 , step 2460 : 2.306945\n",
      "loss in epoch 0 , step 2480 : 1.974937\n",
      "loss in epoch 0 , step 2500 : 2.064097\n",
      "loss in epoch 0 , step 2520 : 1.979357\n",
      "loss in epoch 0 , step 2540 : 1.971381\n",
      "loss in epoch 0 , step 2560 : 1.535933\n",
      "loss in epoch 0 , step 2580 : 2.073290\n",
      "loss in epoch 0 , step 2600 : 2.041986\n",
      "loss in epoch 0 , step 2620 : 2.378800\n",
      "loss in epoch 0 , step 2640 : 2.999211\n",
      "loss in epoch 0 , step 2660 : 2.120258\n",
      "loss in epoch 0 , step 2680 : 1.540854\n",
      "loss in epoch 0 , step 2700 : 1.696722\n",
      "loss in epoch 0 , step 2720 : 0.900834\n",
      "loss in epoch 0 , step 2740 : 0.913538\n",
      "loss in epoch 0 , step 2760 : 1.564636\n",
      "loss in epoch 0 , step 2780 : 1.728178\n",
      "loss in epoch 0 , step 2800 : 1.099817\n",
      "loss in epoch 0 , step 2820 : 2.251505\n",
      "loss in epoch 0 , step 2840 : 2.048823\n",
      "loss in epoch 0 , step 2860 : 2.261625\n",
      "loss in epoch 0 , step 2880 : 1.502376\n",
      "loss in epoch 0 , step 2900 : 2.274138\n",
      "loss in epoch 0 , step 2920 : 1.343455\n",
      "loss in epoch 0 , step 2940 : 1.516007\n",
      "loss in epoch 0 , step 2960 : 1.430983\n",
      "loss in epoch 0 , step 2980 : 1.996657\n",
      "loss in epoch 0 , step 3000 : 1.224103\n",
      "loss in epoch 0 , step 3020 : 1.487020\n",
      "loss in epoch 0 , step 3040 : 2.616059\n",
      "loss in epoch 0 , step 3060 : 1.512873\n",
      "loss in epoch 0 , step 3080 : 2.618550\n",
      "loss in epoch 0 , step 3100 : 1.876165\n",
      "loss in epoch 0 , step 3120 : 1.409624\n",
      "loss in epoch 0 , step 3140 : 1.319474\n",
      "loss in epoch 0 , step 3160 : 1.518334\n",
      "loss in epoch 0 , step 3180 : 1.888143\n",
      "loss in epoch 0 , step 3200 : 2.657887\n",
      "loss in epoch 0 , step 3220 : 2.623510\n",
      "loss in epoch 0 , step 3240 : 2.369107\n",
      "loss in epoch 0 , step 3260 : 1.454112\n",
      "loss in epoch 0 , step 3280 : 1.038265\n",
      "loss in epoch 0 , step 3300 : 2.174858\n",
      "loss in epoch 0 , step 3320 : 2.323449\n",
      "loss in epoch 0 , step 3340 : 2.133862\n",
      "loss in epoch 0 , step 3360 : 1.466642\n",
      "loss in epoch 0 , step 3380 : 0.872183\n",
      "loss in epoch 0 , step 3400 : 1.680958\n",
      "loss in epoch 0 , step 3420 : 2.922607\n",
      "loss in epoch 0 , step 3440 : 1.901229\n",
      "loss in epoch 0 , step 3460 : 1.473145\n",
      "loss in epoch 0 , step 3480 : 1.271105\n",
      "loss in epoch 0 , step 3500 : 1.814019\n",
      "loss in epoch 0 , step 3520 : 2.242397\n",
      "loss in epoch 0 , step 3540 : 1.808741\n",
      "loss in epoch 0 , step 3560 : 2.132215\n",
      "loss in epoch 0 , step 3580 : 2.213952\n",
      "loss in epoch 0 , step 3600 : 1.290008\n",
      "loss in epoch 0 , step 3620 : 1.455581\n",
      "loss in epoch 0 , step 3640 : 2.706062\n",
      "loss in epoch 0 , step 3660 : 2.790649\n",
      "loss in epoch 0 , step 3680 : 2.776634\n",
      "loss in epoch 0 , step 3700 : 1.301053\n",
      "loss in epoch 0 , step 3720 : 2.511815\n",
      "loss in epoch 0 , step 3740 : 1.172058\n",
      "loss in epoch 0 , step 3760 : 1.584375\n",
      "loss in epoch 0 , step 3780 : 2.146956\n",
      "loss in epoch 0 , step 3800 : 1.646843\n",
      "loss in epoch 0 , step 3820 : 2.570063\n",
      "loss in epoch 0 , step 3840 : 0.911174\n",
      "loss in epoch 0 , step 3860 : 2.121201\n",
      "loss in epoch 0 , step 3880 : 2.176071\n",
      "loss in epoch 0 , step 3900 : 1.504318\n",
      "loss in epoch 0 , step 3920 : 2.133960\n",
      "loss in epoch 0 , step 3940 : 2.127817\n",
      "loss in epoch 0 , step 3960 : 1.497520\n",
      "loss in epoch 0 , step 3980 : 1.613703\n",
      "loss in epoch 0 , step 4000 : 0.914690\n",
      "loss in epoch 0 , step 4020 : 1.492989\n",
      "loss in epoch 0 , step 4040 : 2.062170\n",
      "loss in epoch 0 , step 4060 : 1.566435\n",
      "loss in epoch 0 , step 4080 : 1.883943\n",
      "loss in epoch 0 , step 4100 : 3.375175\n",
      "loss in epoch 0 , step 4120 : 1.956811\n",
      "loss in epoch 0 , step 4140 : 1.313441\n",
      "loss in epoch 0 , step 4160 : 2.980501\n",
      "loss in epoch 0 , step 4180 : 1.581506\n",
      "loss in epoch 0 , step 4200 : 1.884671\n",
      "loss in epoch 0 , step 4220 : 1.725721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 4240 : 1.408625\n",
      "loss in epoch 0 , step 4260 : 1.915622\n",
      "loss in epoch 0 , step 4280 : 0.987378\n",
      "loss in epoch 0 , step 4300 : 1.194398\n",
      "loss in epoch 0 , step 4320 : 1.493425\n",
      "loss in epoch 0 , step 4340 : 1.807475\n",
      "loss in epoch 0 , step 4360 : 2.748307\n",
      "loss in epoch 0 , step 4380 : 1.895328\n",
      "loss in epoch 0 , step 4400 : 1.334299\n",
      "loss in epoch 0 , step 4420 : 2.333988\n",
      "loss in epoch 0 , step 4440 : 2.169950\n",
      "loss in epoch 0 , step 4460 : 2.231863\n",
      "loss in epoch 0 , step 4480 : 3.220804\n",
      "loss in epoch 0 , step 4500 : 1.568775\n",
      "loss in epoch 0 , step 4520 : 1.902367\n",
      "loss in epoch 0 , step 4540 : 1.101636\n",
      "loss in epoch 0 , step 4560 : 1.688417\n",
      "loss in epoch 0 , step 4580 : 1.008453\n",
      "loss in epoch 0 , step 4600 : 1.158932\n",
      "loss in epoch 0 , step 4620 : 2.148693\n",
      "loss in epoch 0 , step 4640 : 2.053548\n",
      "loss in epoch 0 , step 4660 : 1.328503\n",
      "loss in epoch 0 , step 4680 : 1.538968\n",
      "loss in epoch 0 , step 4700 : 2.256471\n",
      "loss in epoch 0 , step 4720 : 1.468189\n",
      "loss in epoch 0 , step 4740 : 1.527617\n",
      "loss in epoch 0 , step 4760 : 1.212536\n",
      "loss in epoch 0 , step 4780 : 1.655231\n",
      "loss in epoch 0 , step 4800 : 1.953022\n",
      "loss in epoch 0 , step 4820 : 1.353399\n",
      "loss in epoch 0 , step 4840 : 1.989767\n",
      "loss in epoch 0 , step 4860 : 2.102356\n",
      "loss in epoch 0 , step 4880 : 1.194703\n",
      "loss in epoch 0 , step 4900 : 1.538238\n",
      "loss in epoch 0 , step 4920 : 1.759954\n",
      "loss in epoch 0 , step 4940 : 1.416648\n",
      "loss in epoch 0 , step 4960 : 1.749897\n",
      "loss in epoch 0 , step 4980 : 2.229139\n",
      "loss in epoch 0 , step 5000 : 1.616619\n",
      "loss in epoch 0 , step 5020 : 1.920519\n",
      "loss in epoch 0 , step 5040 : 1.192571\n",
      "loss in epoch 0 , step 5060 : 1.760610\n",
      "loss in epoch 0 , step 5080 : 1.233099\n",
      "loss in epoch 0 , step 5100 : 1.603400\n",
      "loss in epoch 0 , step 5120 : 2.116184\n",
      "loss in epoch 0 , step 5140 : 2.716029\n",
      "loss in epoch 0 , step 5160 : 2.509451\n",
      "loss in epoch 0 , step 5180 : 2.396507\n",
      "loss in epoch 0 , step 5200 : 2.559717\n",
      "loss in epoch 0 , step 5220 : 2.473221\n",
      "loss in epoch 0 , step 5240 : 1.953397\n",
      "loss in epoch 0 , step 5260 : 1.948992\n",
      "loss in epoch 0 , step 5280 : 2.040499\n",
      "loss in epoch 0 , step 5300 : 2.018660\n",
      "loss in epoch 0 , step 5320 : 1.207596\n",
      "loss in epoch 0 , step 5340 : 1.274351\n",
      "loss in epoch 0 , step 5360 : 1.236935\n",
      "loss in epoch 0 , step 5380 : 1.837396\n",
      "loss in epoch 0 , step 5400 : 2.289280\n",
      "loss in epoch 0 , step 5420 : 1.604188\n",
      "loss in epoch 0 , step 5440 : 1.157596\n",
      "loss in epoch 0 , step 5460 : 1.411124\n",
      "loss in epoch 0 , step 5480 : 1.617216\n",
      "loss in epoch 0 , step 5500 : 1.522777\n",
      "loss in epoch 0 , step 5520 : 1.532514\n",
      "loss in epoch 0 , step 5540 : 1.464049\n",
      "loss in epoch 0 , step 5560 : 2.109988\n",
      "loss in epoch 0 , step 5580 : 1.248350\n",
      "loss in epoch 0 , step 5600 : 1.773342\n",
      "loss in epoch 0 , step 5620 : 2.173847\n",
      "loss in epoch 0 , step 5640 : 1.844887\n",
      "loss in epoch 0 , step 5660 : 1.491375\n",
      "loss in epoch 0 , step 5680 : 1.645383\n",
      "loss in epoch 0 , step 5700 : 1.586362\n",
      "loss in epoch 0 , step 5720 : 2.175488\n",
      "loss in epoch 0 , step 5740 : 1.726865\n",
      "loss in epoch 0 , step 5760 : 1.208535\n",
      "loss in epoch 0 , step 5780 : 1.259782\n",
      "loss in epoch 0 , step 5800 : 1.804867\n",
      "loss in epoch 0 , step 5820 : 1.813683\n",
      "loss in epoch 0 , step 5840 : 1.343267\n",
      "loss in epoch 0 , step 5860 : 2.383525\n",
      "loss in epoch 0 , step 5880 : 1.513825\n",
      "loss in epoch 0 , step 5900 : 1.329825\n",
      "loss in epoch 0 , step 5920 : 1.882290\n",
      "loss in epoch 0 , step 5940 : 1.566752\n",
      "loss in epoch 0 , step 5960 : 1.532838\n",
      "loss in epoch 0 , step 5980 : 2.051645\n",
      "loss in epoch 0 , step 6000 : 2.248824\n",
      "loss in epoch 0 , step 6020 : 2.330690\n",
      "loss in epoch 0 , step 6040 : 2.208648\n",
      "loss in epoch 0 , step 6060 : 1.877412\n",
      "loss in epoch 0 , step 6080 : 2.222578\n",
      "loss in epoch 0 , step 6100 : 1.628582\n",
      "loss in epoch 0 , step 6120 : 2.035617\n",
      "loss in epoch 0 , step 6140 : 0.784855\n",
      "loss in epoch 0 , step 6160 : 1.412345\n",
      "loss in epoch 0 , step 6180 : 1.177071\n",
      "loss in epoch 0 , step 6200 : 1.038388\n",
      "loss in epoch 0 , step 6220 : 2.279728\n",
      "loss in epoch 0 , step 6240 : 1.877648\n",
      "loss in epoch 0 , step 6260 : 1.542530\n",
      "loss in epoch 0 , step 6280 : 1.700068\n",
      "loss in epoch 0 , step 6300 : 2.002265\n",
      "loss in epoch 0 , step 6320 : 1.842080\n",
      "loss in epoch 0 , step 6340 : 2.402832\n",
      "loss in epoch 0 , step 6360 : 1.625616\n",
      "loss in epoch 0 , step 6380 : 2.005203\n",
      "loss in epoch 0 , step 6400 : 2.034346\n",
      "loss in epoch 0 , step 6420 : 1.877872\n",
      "loss in epoch 0 , step 6440 : 1.378012\n",
      "loss in epoch 0 , step 6460 : 1.403987\n",
      "loss in epoch 0 , step 6480 : 1.153808\n",
      "loss in epoch 0 , step 6500 : 0.956729\n",
      "loss in epoch 0 , step 6520 : 1.957814\n",
      "loss in epoch 0 , step 6540 : 1.618189\n",
      "loss in epoch 0 , step 6560 : 1.653298\n",
      "loss in epoch 0 , step 6580 : 3.064855\n",
      "loss in epoch 0 , step 6600 : 1.005898\n",
      "loss in epoch 0 , step 6620 : 1.825037\n",
      "loss in epoch 0 , step 6640 : 1.613701\n",
      "loss in epoch 0 , step 6660 : 2.737270\n",
      "loss in epoch 0 , step 6680 : 2.380377\n",
      "loss in epoch 0 , step 6700 : 1.307031\n",
      "loss in epoch 0 , step 6720 : 0.692225\n",
      "loss in epoch 0 , step 6740 : 1.929173\n",
      "loss in epoch 0 , step 6760 : 1.248626\n",
      "loss in epoch 0 , step 6780 : 2.387058\n",
      "loss in epoch 0 , step 6800 : 1.375210\n",
      "loss in epoch 0 , step 6820 : 2.045334\n",
      "loss in epoch 0 , step 6840 : 2.248427\n",
      "loss in epoch 0 , step 6860 : 2.490353\n",
      "loss in epoch 0 , step 6880 : 2.082474\n",
      "loss in epoch 0 , step 6900 : 1.631310\n",
      "loss in epoch 0 , step 6920 : 1.849222\n",
      "loss in epoch 0 , step 6940 : 1.497716\n",
      "loss in epoch 0 , step 6960 : 1.331685\n",
      "loss in epoch 0 , step 6980 : 1.939921\n",
      "loss in epoch 0 , step 7000 : 1.913201\n",
      "loss in epoch 0 , step 7020 : 1.973263\n",
      "loss in epoch 0 , step 7040 : 2.206475\n",
      "loss in epoch 0 , step 7060 : 2.147662\n",
      "loss in epoch 0 , step 7080 : 0.827133\n",
      "loss in epoch 0 , step 7100 : 2.183741\n",
      "loss in epoch 0 , step 7120 : 1.922947\n",
      "loss in epoch 0 , step 7140 : 1.873942\n",
      "loss in epoch 0 , step 7160 : 1.494608\n",
      "loss in epoch 0 , step 7180 : 1.966977\n",
      "loss in epoch 0 , step 7200 : 1.790613\n",
      "loss in epoch 0 , step 7220 : 2.193249\n",
      "loss in epoch 0 , step 7240 : 1.726116\n",
      "loss in epoch 0 , step 7260 : 1.561736\n",
      "loss in epoch 0 , step 7280 : 1.068339\n",
      "loss in epoch 0 , step 7300 : 2.071678\n",
      "loss in epoch 0 , step 7320 : 1.414844\n",
      "loss in epoch 0 , step 7340 : 1.422336\n",
      "loss in epoch 0 , step 7360 : 1.855542\n",
      "loss in epoch 0 , step 7380 : 1.982964\n",
      "loss in epoch 0 , step 7400 : 2.147963\n",
      "loss in epoch 0 , step 7420 : 0.903068\n",
      "loss in epoch 0 , step 7440 : 2.086247\n",
      "loss in epoch 0 , step 7460 : 1.589307\n",
      "loss in epoch 0 , step 7480 : 3.128586\n",
      "loss in epoch 0 , step 7500 : 1.236412\n",
      "loss in epoch 0 , step 7520 : 2.649519\n",
      "loss in epoch 0 , step 7540 : 2.171591\n",
      "loss in epoch 0 , step 7560 : 1.461550\n",
      "loss in epoch 0 , step 7580 : 2.000192\n",
      "loss in epoch 0 , step 7600 : 1.496540\n",
      "loss in epoch 0 , step 7620 : 1.190012\n",
      "loss in epoch 0 , step 7640 : 2.349227\n",
      "loss in epoch 0 , step 7660 : 2.247952\n",
      "loss in epoch 0 , step 7680 : 1.416348\n",
      "loss in epoch 0 , step 7700 : 1.523527\n",
      "loss in epoch 0 , step 7720 : 2.625700\n",
      "loss in epoch 0 , step 7740 : 1.029131\n",
      "loss in epoch 0 , step 7760 : 1.566533\n",
      "loss in epoch 0 , step 7780 : 1.874770\n",
      "loss in epoch 0 , step 7800 : 1.706580\n",
      "loss in epoch 0 , step 7820 : 1.370310\n",
      "loss in epoch 0 , step 7840 : 1.592775\n",
      "loss in epoch 0 , step 7860 : 2.298998\n",
      "loss in epoch 0 , step 7880 : 2.279855\n",
      "loss in epoch 0 , step 7900 : 1.703559\n",
      "loss in epoch 0 , step 7920 : 1.708951\n",
      "loss in epoch 0 , step 7940 : 2.150321\n",
      "loss in epoch 0 , step 7960 : 1.679133\n",
      "loss in epoch 0 , step 7980 : 1.534116\n",
      "loss in epoch 0 , step 8000 : 2.218773\n",
      "loss in epoch 0 , step 8020 : 2.099521\n",
      "loss in epoch 0 , step 8040 : 1.800322\n",
      "loss in epoch 0 , step 8060 : 2.348033\n",
      "loss in epoch 0 , step 8080 : 2.180327\n",
      "loss in epoch 0 , step 8100 : 0.941934\n",
      "loss in epoch 0 , step 8120 : 2.583894\n",
      "loss in epoch 0 , step 8140 : 1.654980\n",
      "loss in epoch 0 , step 8160 : 1.872832\n",
      "loss in epoch 0 , step 8180 : 1.612721\n",
      "loss in epoch 0 , step 8200 : 1.360047\n",
      "loss in epoch 0 , step 8220 : 2.275743\n",
      "loss in epoch 0 , step 8240 : 2.104758\n",
      "loss in epoch 0 , step 8260 : 1.708301\n",
      "loss in epoch 0 , step 8280 : 1.976444\n",
      "loss in epoch 0 , step 8300 : 1.877092\n",
      "loss in epoch 0 , step 8320 : 2.232614\n",
      "loss in epoch 0 , step 8340 : 2.106897\n",
      "loss in epoch 0 , step 8360 : 1.603966\n",
      "loss in epoch 0 , step 8380 : 2.141942\n",
      "loss in epoch 0 , step 8400 : 1.813627\n",
      "loss in epoch 0 , step 8420 : 1.710804\n",
      "loss in epoch 0 , step 8440 : 1.843863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 8460 : 2.858404\n",
      "loss in epoch 0 , step 8480 : 1.844612\n",
      "loss in epoch 0 , step 8500 : 1.907733\n",
      "loss in epoch 0 , step 8520 : 1.291613\n",
      "loss in epoch 0 , step 8540 : 1.102414\n",
      "loss in epoch 0 , step 8560 : 0.861679\n",
      "loss in epoch 0 , step 8580 : 1.874113\n",
      "loss in epoch 0 , step 8600 : 1.879731\n",
      "loss in epoch 0 , step 8620 : 1.332223\n",
      "loss in epoch 0 , step 8640 : 2.172588\n",
      "loss in epoch 0 , step 8660 : 2.047453\n",
      "loss in epoch 0 , step 8680 : 1.974102\n",
      "loss in epoch 0 , step 8700 : 1.121273\n",
      "loss in epoch 0 , step 8720 : 2.199615\n",
      "loss in epoch 0 , step 8740 : 2.167726\n",
      "loss in epoch 0 , step 8760 : 1.545709\n",
      "loss in epoch 0 , step 8780 : 1.867905\n",
      "loss in epoch 0 , step 8800 : 2.303628\n",
      "loss in epoch 0 , step 8820 : 1.890254\n",
      "loss in epoch 0 , step 8840 : 2.150928\n",
      "loss in epoch 0 , step 8860 : 1.753917\n",
      "loss in epoch 0 , step 8880 : 0.998254\n",
      "loss in epoch 0 , step 8900 : 2.135320\n",
      "loss in epoch 0 , step 8920 : 1.450131\n",
      "loss in epoch 0 , step 8940 : 2.002392\n",
      "loss in epoch 0 , step 8960 : 1.776346\n",
      "loss in epoch 0 , step 8980 : 2.475960\n",
      "loss in epoch 0 , step 9000 : 2.093839\n",
      "loss in epoch 0 , step 9020 : 2.511369\n",
      "loss in epoch 0 , step 9040 : 3.056623\n",
      "loss in epoch 0 , step 9060 : 1.551542\n",
      "loss in epoch 0 , step 9080 : 1.941797\n",
      "loss in epoch 0 , step 9100 : 2.553773\n",
      "loss in epoch 0 , step 9120 : 1.727189\n",
      "loss in epoch 0 , step 9140 : 1.586427\n",
      "loss in epoch 0 , step 9160 : 1.530418\n",
      "loss in epoch 0 , step 9180 : 2.157511\n",
      "loss in epoch 0 , step 9200 : 2.072371\n",
      "loss in epoch 0 , step 9220 : 1.578606\n",
      "loss in epoch 0 , step 9240 : 2.011385\n",
      "loss in epoch 0 , step 9260 : 1.200635\n",
      "loss in epoch 0 , step 9280 : 1.030908\n",
      "loss in epoch 0 , step 9300 : 2.087694\n",
      "loss in epoch 0 , step 9320 : 1.408760\n",
      "loss in epoch 0 , step 9340 : 2.015810\n",
      "loss in epoch 0 , step 9360 : 1.921369\n",
      "loss in epoch 0 , step 9380 : 2.005142\n",
      "loss in epoch 0 , step 9400 : 1.600066\n",
      "loss in epoch 0 , step 9420 : 2.222221\n",
      "loss in epoch 0 , step 9440 : 1.372450\n",
      "loss in epoch 0 , step 9460 : 1.515352\n",
      "loss in epoch 0 , step 9480 : 2.335618\n",
      "loss in epoch 0 , step 9500 : 2.176064\n",
      "loss in epoch 0 , step 9520 : 1.895216\n",
      "loss in epoch 0 , step 9540 : 1.881823\n",
      "loss in epoch 0 , step 9560 : 2.274822\n",
      "loss in epoch 0 , step 9580 : 1.500254\n",
      "loss in epoch 0 , step 9600 : 1.447011\n",
      "loss in epoch 0 , step 9620 : 1.713145\n",
      "loss in epoch 0 , step 9640 : 1.092046\n",
      "loss in epoch 0 , step 9660 : 2.035184\n",
      "loss in epoch 0 , step 9680 : 2.412215\n",
      "loss in epoch 0 , step 9700 : 1.181864\n",
      "loss in epoch 0 , step 9720 : 2.055794\n",
      "loss in epoch 0 , step 9740 : 2.046507\n",
      "loss in epoch 0 , step 9760 : 1.424694\n",
      "loss in epoch 0 , step 9780 : 1.893200\n",
      "loss in epoch 0 , step 9800 : 2.368970\n",
      "loss in epoch 0 , step 9820 : 1.556720\n",
      "loss in epoch 0 , step 9840 : 2.125202\n",
      "loss in epoch 0 , step 9860 : 1.072273\n",
      "loss in epoch 0 , step 9880 : 0.993166\n",
      "loss in epoch 0 , step 9900 : 1.605499\n",
      "loss in epoch 0 , step 9920 : 1.296347\n",
      "loss in epoch 0 , step 9940 : 1.579240\n",
      "loss in epoch 0 , step 9960 : 2.091454\n",
      "loss in epoch 0 , step 9980 : 1.425514\n",
      "loss in epoch 0 , step 10000 : 1.222956\n",
      "loss in epoch 0 , step 10020 : 1.664470\n",
      "loss in epoch 0 , step 10040 : 1.979774\n",
      "loss in epoch 0 , step 10060 : 1.748333\n",
      "loss in epoch 0 , step 10080 : 1.827316\n",
      "loss in epoch 0 , step 10100 : 1.251377\n",
      "loss in epoch 0 , step 10120 : 2.367646\n",
      "loss in epoch 0 , step 10140 : 1.387670\n",
      "loss in epoch 0 , step 10160 : 2.284612\n",
      "loss in epoch 0 , step 10180 : 1.639422\n",
      "loss in epoch 0 , step 10200 : 1.607042\n",
      "loss in epoch 0 , step 10220 : 1.288015\n",
      "loss in epoch 0 , step 10240 : 0.961219\n",
      "loss in epoch 0 , step 10260 : 2.386683\n",
      "loss in epoch 0 , step 10280 : 1.000010\n",
      "loss in epoch 0 , step 10300 : 0.814899\n",
      "loss in epoch 0 , step 10320 : 2.286219\n",
      "loss in epoch 0 , step 10340 : 2.115228\n",
      "loss in epoch 0 , step 10360 : 2.207973\n",
      "loss in epoch 0 , step 10380 : 1.655307\n",
      "loss in epoch 0 , step 10400 : 1.949763\n",
      "loss in epoch 0 , step 10420 : 2.716636\n",
      "loss in epoch 0 , step 10440 : 2.724129\n",
      "loss in epoch 0 , step 10460 : 1.806572\n",
      "loss in epoch 0 , step 10480 : 1.924664\n",
      "loss in epoch 0 , step 10500 : 1.219163\n",
      "loss in epoch 0 , step 10520 : 1.444393\n",
      "loss in epoch 0 , step 10540 : 2.164594\n",
      "loss in epoch 0 , step 10560 : 1.064941\n",
      "loss in epoch 0 , step 10580 : 1.463995\n",
      "loss in epoch 0 , step 10600 : 2.241162\n",
      "loss in epoch 0 , step 10620 : 2.902524\n",
      "loss in epoch 0 , step 10640 : 1.733707\n",
      "loss in epoch 0 , step 10660 : 1.434258\n",
      "loss in epoch 0 , step 10680 : 1.593170\n",
      "loss in epoch 0 , step 10700 : 1.844059\n",
      "loss in epoch 0 , step 10720 : 1.283304\n",
      "loss in epoch 0 , step 10740 : 2.053075\n",
      "loss in epoch 0 , step 10760 : 1.693605\n",
      "loss in epoch 0 , step 10780 : 2.306819\n",
      "loss in epoch 0 , step 10800 : 2.167406\n",
      "loss in epoch 0 , step 10820 : 2.012478\n",
      "loss in epoch 0 , step 10840 : 1.947183\n",
      "loss in epoch 0 , step 10860 : 1.951168\n",
      "loss in epoch 0 , step 10880 : 1.221976\n",
      "loss in epoch 0 , step 10900 : 1.042832\n",
      "loss in epoch 0 , step 10920 : 1.328495\n",
      "loss in epoch 0 , step 10940 : 1.873960\n",
      "loss in epoch 0 , step 10960 : 1.939216\n",
      "loss in epoch 0 , step 10980 : 2.326222\n",
      "loss in epoch 0 , step 11000 : 2.078733\n",
      "loss in epoch 0 , step 11020 : 1.139587\n",
      "loss in epoch 0 , step 11040 : 1.780639\n",
      "loss in epoch 0 , step 11060 : 1.311413\n",
      "loss in epoch 0 , step 11080 : 1.008842\n",
      "loss in epoch 0 , step 11100 : 2.044105\n",
      "loss in epoch 0 , step 11120 : 0.852633\n",
      "loss in epoch 0 , step 11140 : 1.438021\n",
      "loss in epoch 0 , step 11160 : 1.651572\n",
      "loss in epoch 0 , step 11180 : 2.059011\n",
      "loss in epoch 0 , step 11200 : 2.018654\n",
      "loss in epoch 0 , step 11220 : 2.032709\n",
      "loss in epoch 0 , step 11240 : 2.557580\n",
      "loss in epoch 0 , step 11260 : 1.906323\n",
      "loss in epoch 0 , step 11280 : 2.160465\n",
      "loss in epoch 0 , step 11300 : 1.921484\n",
      "loss in epoch 0 , step 11320 : 1.923254\n",
      "loss in epoch 0 , step 11340 : 2.520126\n",
      "loss in epoch 0 , step 11360 : 1.627244\n",
      "loss in epoch 0 , step 11380 : 2.078732\n",
      "loss in epoch 0 , step 11400 : 1.175221\n",
      "loss in epoch 0 , step 11420 : 1.019321\n",
      "loss in epoch 0 , step 11440 : 1.066461\n",
      "loss in epoch 0 , step 11460 : 0.919093\n",
      "loss in epoch 0 , step 11480 : 2.134079\n",
      "loss in epoch 0 , step 11500 : 0.880692\n",
      "loss in epoch 0 , step 11520 : 2.345758\n",
      "loss in epoch 0 , step 11540 : 1.916249\n",
      "loss in epoch 0 , step 11560 : 1.285909\n",
      "loss in epoch 0 , step 11580 : 1.743217\n",
      "loss in epoch 0 , step 11600 : 1.688563\n",
      "loss in epoch 0 , step 11620 : 1.172704\n",
      "loss in epoch 0 , step 11640 : 1.278310\n",
      "loss in epoch 0 , step 11660 : 1.583821\n",
      "loss in epoch 0 , step 11680 : 1.494606\n",
      "loss in epoch 0 , step 11700 : 2.452969\n",
      "loss in epoch 0 , step 11720 : 2.231738\n",
      "loss in epoch 0 , step 11740 : 1.956246\n",
      "loss in epoch 0 , step 11760 : 3.030942\n",
      "loss in epoch 0 , step 11780 : 1.130727\n",
      "loss in epoch 0 , step 11800 : 2.282305\n",
      "loss in epoch 0 , step 11820 : 1.657276\n",
      "loss in epoch 0 , step 11840 : 2.500171\n",
      "loss in epoch 0 , step 11860 : 1.986729\n",
      "loss in epoch 0 , step 11880 : 1.527291\n",
      "loss in epoch 0 , step 11900 : 1.663227\n",
      "loss in epoch 0 , step 11920 : 1.047797\n",
      "loss in epoch 0 , step 11940 : 2.358905\n",
      "loss in epoch 0 , step 11960 : 2.128132\n",
      "loss in epoch 0 , step 11980 : 1.742210\n",
      "loss in epoch 0 , step 12000 : 1.318325\n",
      "loss in epoch 0 , step 12020 : 1.701254\n",
      "loss in epoch 0 , step 12040 : 1.972036\n",
      "loss in epoch 0 , step 12060 : 1.806065\n",
      "loss in epoch 0 , step 12080 : 1.737180\n",
      "loss in epoch 0 , step 12100 : 1.881968\n",
      "loss in epoch 0 , step 12120 : 2.384014\n",
      "loss in epoch 0 , step 12140 : 1.427656\n",
      "loss in epoch 0 , step 12160 : 1.840742\n",
      "loss in epoch 0 , step 12180 : 2.198528\n",
      "loss in epoch 0 , step 12200 : 1.682101\n",
      "loss in epoch 0 , step 12220 : 1.721668\n",
      "loss in epoch 0 , step 12240 : 1.672321\n",
      "loss in epoch 0 , step 12260 : 2.346351\n",
      "loss in epoch 0 , step 12280 : 1.745610\n",
      "loss in epoch 0 , step 12300 : 1.648262\n",
      "loss in epoch 0 , step 12320 : 1.640826\n",
      "loss in epoch 0 , step 12340 : 1.950372\n",
      "loss in epoch 0 , step 12360 : 2.054826\n",
      "loss in epoch 0 , step 12380 : 2.784231\n",
      "loss in epoch 0 , step 12400 : 1.964525\n",
      "loss in epoch 0 , step 12420 : 2.311189\n",
      "loss in epoch 0 , step 12440 : 1.518903\n",
      "loss in epoch 0 , step 12460 : 1.607611\n",
      "loss in epoch 0 , step 12480 : 1.355382\n",
      "loss in epoch 0 , step 12500 : 1.340755\n",
      "loss in epoch 0 , step 12520 : 1.902325\n",
      "loss in epoch 0 , step 12540 : 1.916155\n",
      "loss in epoch 0 , step 12560 : 2.145280\n",
      "loss in epoch 0 , step 12580 : 1.347678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 12600 : 1.769675\n",
      "loss in epoch 0 , step 12620 : 2.480384\n",
      "loss in epoch 0 , step 12640 : 1.588082\n",
      "loss in epoch 0 , step 12660 : 1.795255\n",
      "loss in epoch 0 , step 12680 : 1.778934\n",
      "loss in epoch 0 , step 12700 : 1.259963\n",
      "loss in epoch 0 , step 12720 : 1.531678\n",
      "loss in epoch 0 , step 12740 : 1.645630\n",
      "loss in epoch 0 , step 12760 : 1.461940\n",
      "loss in epoch 0 , step 12780 : 1.679114\n",
      "loss in epoch 0 , step 12800 : 1.508867\n",
      "loss in epoch 0 , step 12820 : 1.810031\n",
      "loss in epoch 0 , step 12840 : 2.472244\n",
      "loss in epoch 0 , step 12860 : 1.457730\n",
      "loss in epoch 0 , step 12880 : 1.450042\n",
      "loss in epoch 0 , step 12900 : 2.007078\n",
      "loss in epoch 0 , step 12920 : 2.044086\n",
      "loss in epoch 0 , step 12940 : 1.798537\n",
      "loss in epoch 0 , step 12960 : 2.025398\n",
      "loss in epoch 0 , step 12980 : 1.115930\n",
      "loss in epoch 0 , step 13000 : 2.137632\n",
      "loss in epoch 0 , step 13020 : 2.036578\n",
      "loss in epoch 0 , step 13040 : 1.683956\n",
      "loss in epoch 0 , step 13060 : 1.570574\n",
      "loss in epoch 0 , step 13080 : 1.763716\n",
      "loss in epoch 0 , step 13100 : 1.901166\n",
      "loss in epoch 0 , step 13120 : 2.352432\n",
      "loss in epoch 0 , step 13140 : 2.423138\n",
      "loss in epoch 0 , step 13160 : 2.247353\n",
      "loss in epoch 0 , step 13180 : 2.278135\n",
      "loss in epoch 0 , step 13200 : 2.080386\n",
      "loss in epoch 0 , step 13220 : 2.334191\n",
      "loss in epoch 0 , step 13240 : 1.977959\n",
      "loss in epoch 0 , step 13260 : 1.431797\n",
      "loss in epoch 0 , step 13280 : 1.761988\n",
      "loss in epoch 0 , step 13300 : 1.310466\n",
      "loss in epoch 0 , step 13320 : 2.325592\n",
      "loss in epoch 0 , step 13340 : 1.509934\n",
      "loss in epoch 0 , step 13360 : 2.150709\n",
      "loss in epoch 0 , step 13380 : 1.419122\n",
      "loss in epoch 0 , step 13400 : 2.187244\n",
      "loss in epoch 0 , step 13420 : 2.067636\n",
      "loss in epoch 0 , step 13440 : 2.112715\n",
      "loss in epoch 0 , step 13460 : 2.086269\n",
      "loss in epoch 0 , step 13480 : 1.710995\n",
      "loss in epoch 0 , step 13500 : 1.969765\n",
      "loss in epoch 0 , step 13520 : 1.764679\n",
      "loss in epoch 0 , step 13540 : 1.240966\n",
      "loss in epoch 0 , step 13560 : 1.404594\n",
      "loss in epoch 0 , step 13580 : 2.172485\n",
      "loss in epoch 0 , step 13600 : 1.086690\n",
      "loss in epoch 0 , step 13620 : 1.669478\n",
      "loss in epoch 0 , step 13640 : 1.999053\n",
      "loss in epoch 0 , step 13660 : 1.572648\n",
      "loss in epoch 0 , step 13680 : 2.321349\n",
      "loss in epoch 0 , step 13700 : 1.550922\n",
      "loss in epoch 0 , step 13720 : 2.123864\n",
      "loss in epoch 0 , step 13740 : 1.975092\n",
      "loss in epoch 0 , step 13760 : 1.236391\n",
      "loss in epoch 0 , step 13780 : 2.283078\n",
      "loss in epoch 0 , step 13800 : 2.332955\n",
      "loss in epoch 0 , step 13820 : 1.348537\n",
      "loss in epoch 0 , step 13840 : 1.629810\n",
      "loss in epoch 0 , step 13860 : 1.346383\n",
      "loss in epoch 0 , step 13880 : 1.506218\n",
      "loss in epoch 0 , step 13900 : 2.145895\n",
      "loss in epoch 0 , step 13920 : 1.748271\n",
      "loss in epoch 0 , step 13940 : 1.391671\n",
      "loss in epoch 0 , step 13960 : 1.456105\n",
      "loss in epoch 0 , step 13980 : 1.178028\n",
      "loss in epoch 0 , step 14000 : 1.214977\n",
      "loss in epoch 0 , step 14020 : 1.823712\n",
      "loss in epoch 0 , step 14040 : 1.741608\n",
      "loss in epoch 0 , step 14060 : 1.645603\n",
      "loss in epoch 0 , step 14080 : 1.576912\n",
      "loss in epoch 0 , step 14100 : 1.381938\n",
      "loss in epoch 0 , step 14120 : 1.863419\n",
      "loss in epoch 0 , step 14140 : 1.699506\n",
      "loss in epoch 0 , step 14160 : 2.511539\n",
      "loss in epoch 0 , step 14180 : 2.103135\n",
      "loss in epoch 0 , step 14200 : 2.740495\n",
      "loss in epoch 0 , step 14220 : 1.738757\n",
      "loss in epoch 0 , step 14240 : 2.070585\n",
      "loss in epoch 0 , step 14260 : 1.958400\n",
      "loss in epoch 0 , step 14280 : 1.028472\n",
      "loss in epoch 0 , step 14300 : 0.767568\n",
      "loss in epoch 0 , step 14320 : 1.785809\n",
      "loss in epoch 0 , step 14340 : 2.121479\n",
      "loss in epoch 0 , step 14360 : 1.945637\n",
      "loss in epoch 0 , step 14380 : 1.780290\n",
      "loss in epoch 0 , step 14400 : 2.102534\n",
      "loss in epoch 0 , step 14420 : 1.274714\n",
      "loss in epoch 0 , step 14440 : 1.625291\n",
      "loss in epoch 0 , step 14460 : 1.052669\n",
      "loss in epoch 0 , step 14480 : 1.936289\n",
      "loss in epoch 0 , step 14500 : 1.378635\n",
      "loss in epoch 0 , step 14520 : 1.190832\n",
      "loss in epoch 0 , step 14540 : 1.084882\n",
      "loss in epoch 0 , step 14560 : 0.869385\n",
      "loss in epoch 0 , step 14580 : 2.025716\n",
      "loss in epoch 0 , step 14600 : 2.710475\n",
      "loss in epoch 0 , step 14620 : 2.237805\n",
      "loss in epoch 0 , step 14640 : 1.982986\n",
      "loss in epoch 0 , step 14660 : 1.970909\n",
      "loss in epoch 0 , step 14680 : 2.208540\n",
      "loss in epoch 0 , step 14700 : 1.770683\n",
      "loss in epoch 0 , step 14720 : 1.947961\n",
      "loss in epoch 0 , step 14740 : 0.922354\n",
      "loss in epoch 0 , step 14760 : 2.045272\n",
      "loss in epoch 0 , step 14780 : 1.672029\n",
      "loss in epoch 0 , step 14800 : 2.050430\n",
      "loss in epoch 0 , step 14820 : 1.611187\n",
      "loss in epoch 0 , step 14840 : 2.296164\n",
      "loss in epoch 0 , step 14860 : 2.132392\n",
      "loss in epoch 0 , step 14880 : 2.154345\n",
      "loss in epoch 0 , step 14900 : 1.391631\n",
      "loss in epoch 0 , step 14920 : 2.146688\n",
      "loss in epoch 0 , step 14940 : 1.915394\n",
      "loss in epoch 0 , step 14960 : 1.319413\n",
      "loss in epoch 0 , step 14980 : 1.238234\n",
      "loss in epoch 0 , step 15000 : 2.119282\n",
      "loss in epoch 0 , step 15020 : 1.808154\n",
      "loss in epoch 0 , step 15040 : 1.844781\n",
      "loss in epoch 0 , step 15060 : 1.966278\n",
      "loss in epoch 0 , step 15080 : 1.890185\n",
      "loss in epoch 0 , step 15100 : 1.507510\n",
      "loss in epoch 0 , step 15120 : 1.033491\n",
      "loss in epoch 0 , step 15140 : 2.011464\n",
      "loss in epoch 0 , step 15160 : 1.657103\n",
      "loss in epoch 0 , step 15180 : 1.875738\n",
      "loss in epoch 0 , step 15200 : 1.345206\n",
      "loss in epoch 0 , step 15220 : 1.359425\n",
      "loss in epoch 0 , step 15240 : 1.336973\n",
      "loss in epoch 0 , step 15260 : 1.860330\n",
      "loss in epoch 0 , step 15280 : 1.348728\n",
      "loss in epoch 0 , step 15300 : 1.318560\n",
      "loss in epoch 0 , step 15320 : 1.412714\n",
      "loss in epoch 0 , step 15340 : 2.390655\n",
      "loss in epoch 0 , step 15360 : 1.958895\n",
      "loss in epoch 0 , step 15380 : 1.254925\n",
      "loss in epoch 0 , step 15400 : 1.975750\n",
      "loss in epoch 0 , step 15420 : 2.205239\n",
      "loss in epoch 0 , step 15440 : 1.519571\n",
      "loss in epoch 0 , step 15460 : 1.203754\n",
      "loss in epoch 0 , step 15480 : 1.843344\n",
      "loss in epoch 0 , step 15500 : 1.352257\n",
      "loss in epoch 0 , step 15520 : 2.009886\n",
      "loss in epoch 0 , step 15540 : 1.386305\n",
      "loss in epoch 0 , step 15560 : 2.117206\n",
      "loss in epoch 0 , step 15580 : 2.026944\n",
      "loss in epoch 0 , step 15600 : 2.869491\n",
      "loss in epoch 0 , step 15620 : 1.864846\n",
      "loss in epoch 0 , step 15640 : 1.801442\n",
      "loss in epoch 0 , step 15660 : 1.605457\n",
      "loss in epoch 0 , step 15680 : 1.775643\n",
      "loss in epoch 0 , step 15700 : 1.901841\n",
      "loss in epoch 0 , step 15720 : 1.502492\n",
      "loss in epoch 0 , step 15740 : 2.094858\n",
      "loss in epoch 0 , step 15760 : 2.534120\n",
      "loss in epoch 0 , step 15780 : 1.516406\n",
      "loss in epoch 0 , step 15800 : 1.232310\n",
      "loss in epoch 0 , step 15820 : 1.540865\n",
      "loss in epoch 0 , step 15840 : 1.148089\n",
      "loss in epoch 0 , step 15860 : 1.291846\n",
      "loss in epoch 0 , step 15880 : 1.510554\n",
      "loss in epoch 0 , step 15900 : 2.727725\n",
      "loss in epoch 0 , step 15920 : 1.385040\n",
      "loss in epoch 0 , step 15940 : 1.541213\n",
      "loss in epoch 0 , step 15960 : 2.008229\n",
      "loss in epoch 0 , step 15980 : 1.686030\n",
      "loss in epoch 0 , step 16000 : 1.177173\n",
      "loss in epoch 0 , step 16020 : 1.558162\n",
      "loss in epoch 0 , step 16040 : 1.204597\n",
      "loss in epoch 0 , step 16060 : 1.767085\n",
      "loss in epoch 0 , step 16080 : 1.768027\n",
      "loss in epoch 0 , step 16100 : 1.781324\n",
      "loss in epoch 0 , step 16120 : 2.159086\n",
      "loss in epoch 0 , step 16140 : 1.484681\n",
      "loss in epoch 0 , step 16160 : 1.496906\n",
      "loss in epoch 0 , step 16180 : 1.431476\n",
      "loss in epoch 0 , step 16200 : 1.847888\n",
      "loss in epoch 0 , step 16220 : 1.309175\n",
      "loss in epoch 0 , step 16240 : 0.798745\n",
      "loss in epoch 0 , step 16260 : 1.224597\n",
      "loss in epoch 0 , step 16280 : 2.036164\n",
      "loss in epoch 0 , step 16300 : 2.466052\n",
      "loss in epoch 0 , step 16320 : 1.543045\n",
      "loss in epoch 0 , step 16340 : 1.737952\n",
      "loss in epoch 0 , step 16360 : 1.734629\n",
      "loss in epoch 0 , step 16380 : 1.691154\n",
      "loss in epoch 0 , step 16400 : 1.511317\n",
      "loss in epoch 0 , step 16420 : 2.659922\n",
      "loss in epoch 0 , step 16440 : 1.386057\n",
      "loss in epoch 0 , step 16460 : 0.728309\n",
      "loss in epoch 0 , step 16480 : 1.946957\n",
      "loss in epoch 0 , step 16500 : 1.880655\n",
      "loss in epoch 0 , step 16520 : 1.529904\n",
      "loss in epoch 0 , step 16540 : 2.344936\n",
      "loss in epoch 0 , step 16560 : 2.655066\n",
      "loss in epoch 0 , step 16580 : 1.163609\n",
      "loss in epoch 0 , step 16600 : 1.507233\n",
      "loss in epoch 0 , step 16620 : 1.946944\n",
      "loss in epoch 0 , step 16640 : 1.755600\n",
      "loss in epoch 0 , step 16660 : 2.318181\n",
      "loss in epoch 0 , step 16680 : 1.710269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 0 , step 16700 : 1.398897\n",
      "loss in epoch 0 , step 16720 : 2.230672\n",
      "loss in epoch 0 , step 16740 : 1.576988\n",
      "loss in epoch 0 , step 16760 : 2.065333\n",
      "loss in epoch 0 , step 16780 : 1.750304\n",
      "loss in epoch 0 , step 16800 : 1.867079\n",
      "loss in epoch 0 , step 16820 : 2.065050\n",
      "loss in epoch 0 , step 16840 : 1.366978\n",
      "loss in epoch 0 , step 16860 : 2.052722\n",
      "loss in epoch 0 , step 16880 : 2.554487\n",
      "loss in epoch 0 , step 16900 : 2.191084\n",
      "loss in epoch 0 , step 16920 : 2.720558\n",
      "loss in epoch 0 , step 16940 : 1.964914\n",
      "loss in epoch 0 , step 16960 : 1.568431\n",
      "loss in epoch 0 , step 16980 : 2.326305\n",
      "loss in epoch 0 , step 17000 : 2.328448\n",
      "loss in epoch 0 , step 17020 : 1.159228\n",
      "loss in epoch 0 , step 17040 : 1.714211\n",
      "loss in epoch 0 , step 17060 : 1.600200\n",
      "loss in epoch 0 , step 17080 : 1.234033\n",
      "loss in epoch 0 , step 17100 : 2.409417\n",
      "loss in epoch 0 , step 17120 : 1.893511\n",
      "loss in epoch 0 , step 17140 : 1.641556\n",
      "loss in epoch 0 , step 17160 : 1.937340\n",
      "loss in epoch 0 , step 17180 : 2.036841\n",
      "loss in epoch 0 , step 17200 : 1.343126\n",
      "loss in epoch 0 , step 17220 : 1.604632\n",
      "loss in epoch 0 , step 17240 : 1.192128\n",
      "loss in epoch 0 , step 17260 : 1.483084\n",
      "loss in epoch 0 , step 17280 : 1.266198\n",
      "loss in epoch 0 , step 17300 : 2.437425\n",
      "loss in epoch 0 , step 17320 : 1.303824\n",
      "loss in epoch 0 , step 17340 : 1.646559\n",
      "loss in epoch 0 , step 17360 : 1.709434\n",
      "loss in epoch 0 , step 17380 : 3.193843\n",
      "loss in epoch 0 , step 17400 : 1.411496\n",
      "loss in epoch 0 , step 17420 : 2.798322\n",
      "loss in epoch 0 , step 17440 : 1.170587\n",
      "loss in epoch 0 , step 17460 : 1.330608\n",
      "loss in epoch 0 , step 17480 : 1.576571\n",
      "loss in epoch 0 , step 17500 : 0.658816\n",
      "loss in epoch 0 , step 17520 : 1.495063\n",
      "loss in epoch 0 , step 17540 : 1.900797\n",
      "loss in epoch 0 , step 17560 : 1.469805\n",
      "loss in epoch 0 , step 17580 : 1.267602\n",
      "loss in epoch 0 , step 17600 : 2.025340\n",
      "loss in epoch 0 , step 17620 : 1.706967\n",
      "loss in epoch 0 , step 17640 : 1.643406\n",
      "loss in epoch 0 , step 17660 : 1.368442\n",
      "loss in epoch 0 , step 17680 : 1.639602\n",
      "loss in epoch 0 , step 17700 : 1.794657\n",
      "loss in epoch 0 , step 17720 : 2.260973\n",
      "loss in epoch 0 , step 17740 : 1.616080\n",
      "loss in epoch 0 , step 17760 : 2.080424\n",
      "loss in epoch 0 , step 17780 : 1.626429\n",
      "loss in epoch 0 , step 17800 : 1.273786\n",
      "loss in epoch 0 , step 17820 : 1.938097\n",
      "loss in epoch 0 , step 17840 : 1.720780\n",
      "loss in epoch 0 , step 17860 : 1.448639\n",
      "loss in epoch 0 , step 17880 : 2.636113\n",
      "loss in epoch 0 , step 17900 : 1.797737\n",
      "loss in epoch 0 , step 17920 : 1.643687\n",
      "loss in epoch 0 , step 17940 : 1.247508\n",
      "loss in epoch 0 , step 17960 : 2.009511\n",
      "loss in epoch 0 , step 17980 : 1.479067\n",
      "loss in epoch 0 , step 18000 : 2.185416\n",
      "loss in epoch 0 , step 18020 : 1.695776\n",
      "loss in epoch 0 , step 18040 : 1.707309\n",
      "loss in epoch 0 , step 18060 : 1.347990\n",
      "loss in epoch 0 , step 18080 : 1.613763\n",
      "loss in epoch 0 , step 18100 : 2.374653\n",
      "loss in epoch 0 , step 18120 : 1.613817\n",
      "loss in epoch 0 , step 18140 : 2.724938\n",
      "loss in epoch 0 , step 18160 : 1.748017\n",
      "loss in epoch 0 , step 18180 : 1.771712\n",
      "loss in epoch 0 , step 18200 : 1.484539\n",
      "loss in epoch 0 , step 18220 : 1.550571\n",
      "loss in epoch 0 , step 18240 : 1.553701\n",
      "loss in epoch 0 , step 18260 : 1.731115\n",
      "loss in epoch 0 , step 18280 : 2.128813\n",
      "loss in epoch 0 , step 18300 : 1.713643\n",
      "loss in epoch 0 , step 18320 : 2.439353\n",
      "loss in epoch 0 , step 18340 : 1.364613\n",
      "loss in epoch 0 , step 18360 : 1.881364\n",
      "loss in epoch 0 , step 18380 : 1.604675\n",
      "loss in epoch 0 , step 18400 : 1.483035\n",
      "loss in epoch 0 , step 18420 : 1.662665\n",
      "loss in epoch 0 , step 18440 : 1.804710\n",
      "loss in epoch 0 , step 18460 : 2.511475\n",
      "loss in epoch 0 , step 18480 : 1.281734\n",
      "loss in epoch 0 , step 18500 : 1.670938\n",
      "loss in epoch 0 , step 18520 : 2.275805\n",
      "loss in epoch 0 , step 18540 : 1.605413\n",
      "loss in epoch 0 , step 18560 : 1.489402\n",
      "loss in epoch 0 , step 18580 : 1.700266\n",
      "loss in epoch 0 , step 18600 : 1.229553\n",
      "loss in epoch 0 , step 18620 : 2.019941\n",
      "loss in epoch 0 , step 18640 : 2.127127\n",
      "loss in epoch 0 , step 18660 : 1.481509\n",
      "loss in epoch 0 , step 18680 : 2.151181\n",
      "loss in epoch 0 , step 18700 : 2.004826\n",
      "loss in epoch 0 , step 18720 : 1.581732\n",
      "loss in epoch 0 , step 18740 : 1.893600\n",
      "loss in epoch 0 , step 18760 : 1.468631\n",
      "loss in epoch 0 , step 18780 : 2.059545\n",
      "loss in epoch 0 , step 18800 : 1.945893\n",
      "loss in epoch 0 , step 18820 : 1.590546\n",
      "loss in epoch 0 , step 18840 : 1.552301\n",
      "loss in epoch 0 , step 18860 : 1.771903\n",
      "loss in epoch 0 , step 18880 : 1.679539\n",
      "loss in epoch 0 , step 18900 : 1.715139\n",
      "loss in epoch 0 , step 18920 : 2.005290\n",
      "loss in epoch 0 , step 18940 : 1.132370\n",
      "loss in epoch 0 , step 18960 : 1.894069\n",
      "loss in epoch 0 , step 18980 : 1.755704\n",
      "loss in epoch 0 , step 19000 : 1.828586\n",
      "loss in epoch 0 , step 19020 : 1.556945\n",
      "loss in epoch 0 , step 19040 : 1.856771\n",
      "loss in epoch 0 , step 19060 : 1.701446\n",
      "loss in epoch 0 , step 19080 : 1.481207\n",
      "loss in epoch 0 , step 19100 : 1.121476\n",
      "loss in epoch 0 , step 19120 : 2.091464\n",
      "loss in epoch 0 , step 19140 : 1.931403\n",
      "loss in epoch 0 , step 19160 : 1.922548\n",
      "loss in epoch 0 , step 19180 : 1.389504\n",
      "loss in epoch 0 , step 19200 : 1.730977\n",
      "loss in epoch 0 , step 19220 : 1.606731\n",
      "loss in epoch 0 , step 19240 : 1.347878\n",
      "loss in epoch 0 , step 19260 : 1.934261\n",
      "loss in epoch 0 , step 19280 : 2.067105\n",
      "loss in epoch 0 , step 19300 : 2.216476\n",
      "loss in epoch 0 , step 19320 : 2.227871\n",
      "loss in epoch 0 , step 19340 : 1.451170\n",
      "loss in epoch 0 , step 19360 : 2.086169\n",
      "loss in epoch 0 , step 19380 : 1.622005\n",
      "loss in epoch 0 , step 19400 : 1.549830\n",
      "loss in epoch 0 , step 19420 : 1.884807\n",
      "loss in epoch 0 , step 19440 : 1.909009\n",
      "loss in epoch 0 , step 19460 : 2.143806\n",
      "loss in epoch 0 , step 19480 : 1.754480\n",
      "loss in epoch 0 , step 19500 : 1.135060\n",
      "loss in epoch 0 , step 19520 : 1.676428\n",
      "loss in epoch 0 , step 19540 : 1.550787\n",
      "loss in epoch 0 , step 19560 : 1.528650\n",
      "loss in epoch 0 , step 19580 : 1.335719\n",
      "loss in epoch 0 , step 19600 : 2.227234\n",
      "loss in epoch 0 , step 19620 : 1.642400\n",
      "loss in epoch 0 , step 19640 : 1.540342\n",
      "loss in epoch 0 , step 19660 : 2.125822\n",
      "loss in epoch 0 , step 19680 : 1.234891\n",
      "loss in epoch 0 , step 19700 : 1.819433\n",
      "loss in epoch 0 , step 19720 : 1.515210\n",
      "loss in epoch 0 , step 19740 : 1.590105\n",
      "loss in epoch 0 , step 19760 : 1.741682\n",
      "loss in epoch 0 , step 19780 : 1.737797\n",
      "loss in epoch 0 , step 19800 : 1.883221\n",
      "loss in epoch 0 , step 19820 : 1.441944\n",
      "loss in epoch 0 , step 19840 : 1.882389\n",
      "loss in epoch 0 , step 19860 : 1.209680\n",
      "loss in epoch 0 , step 19880 : 2.368285\n",
      "loss in epoch 0 , step 19900 : 1.828325\n",
      "loss in epoch 0 , step 19920 : 1.444216\n",
      "loss in epoch 0 , step 19940 : 1.569909\n",
      "Accuracy in epoch 0 : 21.282246\n",
      "loss in epoch 1 , step 0 : 1.713090\n",
      "loss in epoch 1 , step 20 : 1.792744\n",
      "loss in epoch 1 , step 40 : 1.464326\n",
      "loss in epoch 1 , step 60 : 2.048921\n",
      "loss in epoch 1 , step 80 : 1.390319\n",
      "loss in epoch 1 , step 100 : 1.864656\n",
      "loss in epoch 1 , step 120 : 1.933967\n",
      "loss in epoch 1 , step 140 : 1.485769\n",
      "loss in epoch 1 , step 160 : 1.442720\n",
      "loss in epoch 1 , step 180 : 1.810313\n",
      "loss in epoch 1 , step 200 : 1.781698\n",
      "loss in epoch 1 , step 220 : 1.502246\n",
      "loss in epoch 1 , step 240 : 2.153861\n",
      "loss in epoch 1 , step 260 : 1.551384\n",
      "loss in epoch 1 , step 280 : 2.123796\n",
      "loss in epoch 1 , step 300 : 1.853115\n",
      "loss in epoch 1 , step 320 : 1.762093\n",
      "loss in epoch 1 , step 340 : 2.382785\n",
      "loss in epoch 1 , step 360 : 1.251727\n",
      "loss in epoch 1 , step 380 : 1.460547\n",
      "loss in epoch 1 , step 400 : 1.046178\n",
      "loss in epoch 1 , step 420 : 1.541033\n",
      "loss in epoch 1 , step 440 : 1.422785\n",
      "loss in epoch 1 , step 460 : 1.315185\n",
      "loss in epoch 1 , step 480 : 1.986205\n",
      "loss in epoch 1 , step 500 : 0.991023\n",
      "loss in epoch 1 , step 520 : 1.684411\n",
      "loss in epoch 1 , step 540 : 1.717969\n",
      "loss in epoch 1 , step 560 : 2.114587\n",
      "loss in epoch 1 , step 580 : 1.275017\n",
      "loss in epoch 1 , step 600 : 1.442295\n",
      "loss in epoch 1 , step 620 : 1.210735\n",
      "loss in epoch 1 , step 640 : 2.658889\n",
      "loss in epoch 1 , step 660 : 1.649481\n",
      "loss in epoch 1 , step 680 : 1.495109\n",
      "loss in epoch 1 , step 700 : 2.255165\n",
      "loss in epoch 1 , step 720 : 1.468951\n",
      "loss in epoch 1 , step 740 : 1.716762\n",
      "loss in epoch 1 , step 760 : 2.266314\n",
      "loss in epoch 1 , step 780 : 1.517561\n",
      "loss in epoch 1 , step 800 : 1.679292\n",
      "loss in epoch 1 , step 820 : 1.463462\n",
      "loss in epoch 1 , step 840 : 2.203304\n",
      "loss in epoch 1 , step 860 : 1.926010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 , step 880 : 1.728444\n",
      "loss in epoch 1 , step 900 : 2.617552\n",
      "loss in epoch 1 , step 920 : 1.580474\n",
      "loss in epoch 1 , step 940 : 1.500597\n",
      "loss in epoch 1 , step 960 : 1.304971\n",
      "loss in epoch 1 , step 980 : 1.935431\n",
      "loss in epoch 1 , step 1000 : 1.458786\n",
      "loss in epoch 1 , step 1020 : 1.342290\n",
      "loss in epoch 1 , step 1040 : 2.053436\n",
      "loss in epoch 1 , step 1060 : 1.747373\n",
      "loss in epoch 1 , step 1080 : 1.982870\n",
      "loss in epoch 1 , step 1100 : 1.538667\n",
      "loss in epoch 1 , step 1120 : 1.376190\n",
      "loss in epoch 1 , step 1140 : 1.408177\n",
      "loss in epoch 1 , step 1160 : 2.126888\n",
      "loss in epoch 1 , step 1180 : 1.962526\n",
      "loss in epoch 1 , step 1200 : 1.689281\n",
      "loss in epoch 1 , step 1220 : 1.652871\n",
      "loss in epoch 1 , step 1240 : 1.724078\n",
      "loss in epoch 1 , step 1260 : 1.728831\n",
      "loss in epoch 1 , step 1280 : 2.230725\n",
      "loss in epoch 1 , step 1300 : 1.203486\n",
      "loss in epoch 1 , step 1320 : 1.523552\n",
      "loss in epoch 1 , step 1340 : 1.929313\n",
      "loss in epoch 1 , step 1360 : 1.766730\n",
      "loss in epoch 1 , step 1380 : 1.593411\n",
      "loss in epoch 1 , step 1400 : 1.819742\n",
      "loss in epoch 1 , step 1420 : 0.945882\n",
      "loss in epoch 1 , step 1440 : 2.093341\n",
      "loss in epoch 1 , step 1460 : 0.966766\n",
      "loss in epoch 1 , step 1480 : 1.592096\n",
      "loss in epoch 1 , step 1500 : 2.163372\n",
      "loss in epoch 1 , step 1520 : 1.872675\n",
      "loss in epoch 1 , step 1540 : 2.488681\n",
      "loss in epoch 1 , step 1560 : 1.605200\n",
      "loss in epoch 1 , step 1580 : 2.068283\n",
      "loss in epoch 1 , step 1600 : 1.989708\n",
      "loss in epoch 1 , step 1620 : 2.129282\n",
      "loss in epoch 1 , step 1640 : 2.141744\n",
      "loss in epoch 1 , step 1660 : 1.772895\n",
      "loss in epoch 1 , step 1680 : 1.083536\n",
      "loss in epoch 1 , step 1700 : 1.467373\n",
      "loss in epoch 1 , step 1720 : 1.521248\n",
      "loss in epoch 1 , step 1740 : 1.318962\n",
      "loss in epoch 1 , step 1760 : 2.345319\n",
      "loss in epoch 1 , step 1780 : 1.439599\n",
      "loss in epoch 1 , step 1800 : 1.690588\n",
      "loss in epoch 1 , step 1820 : 1.710309\n",
      "loss in epoch 1 , step 1840 : 1.661253\n",
      "loss in epoch 1 , step 1860 : 1.702690\n",
      "loss in epoch 1 , step 1880 : 1.988990\n",
      "loss in epoch 1 , step 1900 : 1.928588\n",
      "loss in epoch 1 , step 1920 : 2.294647\n",
      "loss in epoch 1 , step 1940 : 1.666776\n",
      "loss in epoch 1 , step 1960 : 2.413110\n",
      "loss in epoch 1 , step 1980 : 1.090694\n",
      "loss in epoch 1 , step 2000 : 1.144514\n",
      "loss in epoch 1 , step 2020 : 2.016529\n",
      "loss in epoch 1 , step 2040 : 1.354271\n",
      "loss in epoch 1 , step 2060 : 1.767314\n",
      "loss in epoch 1 , step 2080 : 2.032421\n",
      "loss in epoch 1 , step 2100 : 2.172292\n",
      "loss in epoch 1 , step 2120 : 1.888947\n",
      "loss in epoch 1 , step 2140 : 1.986667\n",
      "loss in epoch 1 , step 2160 : 2.176674\n",
      "loss in epoch 1 , step 2180 : 1.675092\n",
      "loss in epoch 1 , step 2200 : 1.044573\n",
      "loss in epoch 1 , step 2220 : 1.420793\n",
      "loss in epoch 1 , step 2240 : 1.824836\n",
      "loss in epoch 1 , step 2260 : 1.660510\n",
      "loss in epoch 1 , step 2280 : 1.881209\n",
      "loss in epoch 1 , step 2300 : 1.662480\n",
      "loss in epoch 1 , step 2320 : 1.467642\n",
      "loss in epoch 1 , step 2340 : 1.979997\n",
      "loss in epoch 1 , step 2360 : 2.293973\n",
      "loss in epoch 1 , step 2380 : 1.349691\n",
      "loss in epoch 1 , step 2400 : 1.696370\n",
      "loss in epoch 1 , step 2420 : 1.528960\n",
      "loss in epoch 1 , step 2440 : 1.410075\n",
      "loss in epoch 1 , step 2460 : 1.522645\n",
      "loss in epoch 1 , step 2480 : 2.099115\n",
      "loss in epoch 1 , step 2500 : 2.045567\n",
      "loss in epoch 1 , step 2520 : 1.872042\n",
      "loss in epoch 1 , step 2540 : 2.414989\n",
      "loss in epoch 1 , step 2560 : 1.686156\n",
      "loss in epoch 1 , step 2580 : 1.651609\n",
      "loss in epoch 1 , step 2600 : 1.752788\n",
      "loss in epoch 1 , step 2620 : 1.386709\n",
      "loss in epoch 1 , step 2640 : 1.685358\n",
      "loss in epoch 1 , step 2660 : 1.906868\n",
      "loss in epoch 1 , step 2680 : 1.214417\n",
      "loss in epoch 1 , step 2700 : 2.330232\n",
      "loss in epoch 1 , step 2720 : 1.358139\n",
      "loss in epoch 1 , step 2740 : 1.257022\n",
      "loss in epoch 1 , step 2760 : 2.035559\n",
      "loss in epoch 1 , step 2780 : 1.399937\n",
      "loss in epoch 1 , step 2800 : 1.279697\n",
      "loss in epoch 1 , step 2820 : 1.372568\n",
      "loss in epoch 1 , step 2840 : 1.733181\n",
      "loss in epoch 1 , step 2860 : 1.501078\n",
      "loss in epoch 1 , step 2880 : 1.934675\n",
      "loss in epoch 1 , step 2900 : 0.628582\n",
      "loss in epoch 1 , step 2920 : 0.932051\n",
      "loss in epoch 1 , step 2940 : 1.847135\n",
      "loss in epoch 1 , step 2960 : 1.598857\n",
      "loss in epoch 1 , step 2980 : 1.999985\n",
      "loss in epoch 1 , step 3000 : 1.543163\n",
      "loss in epoch 1 , step 3020 : 1.218714\n",
      "loss in epoch 1 , step 3040 : 2.212508\n",
      "loss in epoch 1 , step 3060 : 2.445379\n",
      "loss in epoch 1 , step 3080 : 0.912026\n",
      "loss in epoch 1 , step 3100 : 1.148165\n",
      "loss in epoch 1 , step 3120 : 1.230447\n",
      "loss in epoch 1 , step 3140 : 1.763977\n",
      "loss in epoch 1 , step 3160 : 1.680957\n",
      "loss in epoch 1 , step 3180 : 2.404650\n",
      "loss in epoch 1 , step 3200 : 2.419654\n",
      "loss in epoch 1 , step 3220 : 2.006444\n",
      "loss in epoch 1 , step 3240 : 1.412787\n",
      "loss in epoch 1 , step 3260 : 1.366852\n",
      "loss in epoch 1 , step 3280 : 1.697585\n",
      "loss in epoch 1 , step 3300 : 1.122127\n",
      "loss in epoch 1 , step 3320 : 1.752831\n",
      "loss in epoch 1 , step 3340 : 1.427813\n",
      "loss in epoch 1 , step 3360 : 1.703736\n",
      "loss in epoch 1 , step 3380 : 1.427296\n",
      "loss in epoch 1 , step 3400 : 1.865850\n",
      "loss in epoch 1 , step 3420 : 1.680026\n",
      "loss in epoch 1 , step 3440 : 1.310383\n",
      "loss in epoch 1 , step 3460 : 1.641560\n",
      "loss in epoch 1 , step 3480 : 2.434179\n",
      "loss in epoch 1 , step 3500 : 2.260669\n",
      "loss in epoch 1 , step 3520 : 2.697274\n",
      "loss in epoch 1 , step 3540 : 1.826453\n",
      "loss in epoch 1 , step 3560 : 1.607099\n",
      "loss in epoch 1 , step 3580 : 1.216046\n",
      "loss in epoch 1 , step 3600 : 1.115862\n",
      "loss in epoch 1 , step 3620 : 1.101997\n",
      "loss in epoch 1 , step 3640 : 1.949507\n",
      "loss in epoch 1 , step 3660 : 1.773239\n",
      "loss in epoch 1 , step 3680 : 1.336892\n",
      "loss in epoch 1 , step 3700 : 1.421006\n",
      "loss in epoch 1 , step 3720 : 1.489684\n",
      "loss in epoch 1 , step 3740 : 2.794067\n",
      "loss in epoch 1 , step 3760 : 2.577244\n",
      "loss in epoch 1 , step 3780 : 1.599105\n",
      "loss in epoch 1 , step 3800 : 2.174531\n",
      "loss in epoch 1 , step 3820 : 1.623981\n",
      "loss in epoch 1 , step 3840 : 1.891923\n",
      "loss in epoch 1 , step 3860 : 1.790774\n",
      "loss in epoch 1 , step 3880 : 1.848068\n",
      "loss in epoch 1 , step 3900 : 1.839752\n",
      "loss in epoch 1 , step 3920 : 2.429903\n",
      "loss in epoch 1 , step 3940 : 1.925975\n",
      "loss in epoch 1 , step 3960 : 2.247028\n",
      "loss in epoch 1 , step 3980 : 1.669892\n",
      "loss in epoch 1 , step 4000 : 2.279426\n",
      "loss in epoch 1 , step 4020 : 1.844312\n",
      "loss in epoch 1 , step 4040 : 1.800056\n",
      "loss in epoch 1 , step 4060 : 1.775057\n",
      "loss in epoch 1 , step 4080 : 2.268449\n",
      "loss in epoch 1 , step 4100 : 1.090955\n",
      "loss in epoch 1 , step 4120 : 1.459364\n",
      "loss in epoch 1 , step 4140 : 2.561322\n",
      "loss in epoch 1 , step 4160 : 1.911704\n",
      "loss in epoch 1 , step 4180 : 1.818292\n",
      "loss in epoch 1 , step 4200 : 1.933614\n",
      "loss in epoch 1 , step 4220 : 1.245895\n",
      "loss in epoch 1 , step 4240 : 1.837962\n",
      "loss in epoch 1 , step 4260 : 1.638497\n",
      "loss in epoch 1 , step 4280 : 0.990121\n",
      "loss in epoch 1 , step 4300 : 1.626260\n",
      "loss in epoch 1 , step 4320 : 2.075352\n",
      "loss in epoch 1 , step 4340 : 1.011904\n",
      "loss in epoch 1 , step 4360 : 2.004476\n",
      "loss in epoch 1 , step 4380 : 1.910955\n",
      "loss in epoch 1 , step 4400 : 1.637591\n",
      "loss in epoch 1 , step 4420 : 1.186502\n",
      "loss in epoch 1 , step 4440 : 2.208469\n",
      "loss in epoch 1 , step 4460 : 1.804006\n",
      "loss in epoch 1 , step 4480 : 1.725327\n",
      "loss in epoch 1 , step 4500 : 1.825250\n",
      "loss in epoch 1 , step 4520 : 1.270758\n",
      "loss in epoch 1 , step 4540 : 2.017298\n",
      "loss in epoch 1 , step 4560 : 2.695330\n",
      "loss in epoch 1 , step 4580 : 0.852723\n",
      "loss in epoch 1 , step 4600 : 1.000616\n",
      "loss in epoch 1 , step 4620 : 2.038623\n",
      "loss in epoch 1 , step 4640 : 1.482821\n",
      "loss in epoch 1 , step 4660 : 1.977137\n",
      "loss in epoch 1 , step 4680 : 1.794309\n",
      "loss in epoch 1 , step 4700 : 2.147237\n",
      "loss in epoch 1 , step 4720 : 2.450908\n",
      "loss in epoch 1 , step 4740 : 1.494003\n",
      "loss in epoch 1 , step 4760 : 2.535894\n",
      "loss in epoch 1 , step 4780 : 1.644451\n",
      "loss in epoch 1 , step 4800 : 1.168005\n",
      "loss in epoch 1 , step 4820 : 1.838012\n",
      "loss in epoch 1 , step 4840 : 1.334841\n",
      "loss in epoch 1 , step 4860 : 2.048870\n",
      "loss in epoch 1 , step 4880 : 3.604248\n",
      "loss in epoch 1 , step 4900 : 1.275331\n",
      "loss in epoch 1 , step 4920 : 1.991999\n",
      "loss in epoch 1 , step 4940 : 1.378536\n",
      "loss in epoch 1 , step 4960 : 1.498169\n",
      "loss in epoch 1 , step 4980 : 1.719381\n",
      "loss in epoch 1 , step 5000 : 1.070367\n",
      "loss in epoch 1 , step 5020 : 1.924704\n",
      "loss in epoch 1 , step 5040 : 2.333032\n",
      "loss in epoch 1 , step 5060 : 1.366037\n",
      "loss in epoch 1 , step 5080 : 1.447309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 , step 5100 : 1.354728\n",
      "loss in epoch 1 , step 5120 : 1.448033\n",
      "loss in epoch 1 , step 5140 : 1.378367\n",
      "loss in epoch 1 , step 5160 : 1.727359\n",
      "loss in epoch 1 , step 5180 : 2.314321\n",
      "loss in epoch 1 , step 5200 : 1.287998\n",
      "loss in epoch 1 , step 5220 : 1.785314\n",
      "loss in epoch 1 , step 5240 : 1.274787\n",
      "loss in epoch 1 , step 5260 : 1.880508\n",
      "loss in epoch 1 , step 5280 : 2.038670\n",
      "loss in epoch 1 , step 5300 : 2.102087\n",
      "loss in epoch 1 , step 5320 : 1.892275\n",
      "loss in epoch 1 , step 5340 : 1.626556\n",
      "loss in epoch 1 , step 5360 : 1.584393\n",
      "loss in epoch 1 , step 5380 : 1.822944\n",
      "loss in epoch 1 , step 5400 : 1.554172\n",
      "loss in epoch 1 , step 5420 : 1.545368\n",
      "loss in epoch 1 , step 5440 : 2.146767\n",
      "loss in epoch 1 , step 5460 : 2.019047\n",
      "loss in epoch 1 , step 5480 : 1.474388\n",
      "loss in epoch 1 , step 5500 : 1.976860\n",
      "loss in epoch 1 , step 5520 : 2.068845\n",
      "loss in epoch 1 , step 5540 : 1.681103\n",
      "loss in epoch 1 , step 5560 : 1.531104\n",
      "loss in epoch 1 , step 5580 : 1.766967\n",
      "loss in epoch 1 , step 5600 : 1.139294\n",
      "loss in epoch 1 , step 5620 : 2.378697\n",
      "loss in epoch 1 , step 5640 : 1.617527\n",
      "loss in epoch 1 , step 5660 : 1.114062\n",
      "loss in epoch 1 , step 5680 : 1.127976\n",
      "loss in epoch 1 , step 5700 : 2.026255\n",
      "loss in epoch 1 , step 5720 : 1.998185\n",
      "loss in epoch 1 , step 5740 : 1.483901\n",
      "loss in epoch 1 , step 5760 : 1.313311\n",
      "loss in epoch 1 , step 5780 : 2.436592\n",
      "loss in epoch 1 , step 5800 : 1.726391\n",
      "loss in epoch 1 , step 5820 : 2.067069\n",
      "loss in epoch 1 , step 5840 : 2.682274\n",
      "loss in epoch 1 , step 5860 : 1.861518\n",
      "loss in epoch 1 , step 5880 : 1.978939\n",
      "loss in epoch 1 , step 5900 : 1.946286\n",
      "loss in epoch 1 , step 5920 : 1.331090\n",
      "loss in epoch 1 , step 5940 : 1.461952\n",
      "loss in epoch 1 , step 5960 : 1.082917\n",
      "loss in epoch 1 , step 5980 : 1.167475\n",
      "loss in epoch 1 , step 6000 : 2.225787\n",
      "loss in epoch 1 , step 6020 : 2.035783\n",
      "loss in epoch 1 , step 6040 : 1.473261\n",
      "loss in epoch 1 , step 6060 : 1.946110\n",
      "loss in epoch 1 , step 6080 : 1.398153\n",
      "loss in epoch 1 , step 6100 : 1.721068\n",
      "loss in epoch 1 , step 6120 : 2.130606\n",
      "loss in epoch 1 , step 6140 : 1.482075\n",
      "loss in epoch 1 , step 6160 : 1.738765\n",
      "loss in epoch 1 , step 6180 : 1.738551\n",
      "loss in epoch 1 , step 6200 : 1.759534\n",
      "loss in epoch 1 , step 6220 : 2.105325\n",
      "loss in epoch 1 , step 6240 : 2.345390\n",
      "loss in epoch 1 , step 6260 : 1.743272\n",
      "loss in epoch 1 , step 6280 : 2.459746\n",
      "loss in epoch 1 , step 6300 : 2.022132\n",
      "loss in epoch 1 , step 6320 : 1.585069\n",
      "loss in epoch 1 , step 6340 : 2.133072\n",
      "loss in epoch 1 , step 6360 : 1.685455\n",
      "loss in epoch 1 , step 6380 : 1.559610\n",
      "loss in epoch 1 , step 6400 : 2.181830\n",
      "loss in epoch 1 , step 6420 : 1.791125\n",
      "loss in epoch 1 , step 6440 : 1.992225\n",
      "loss in epoch 1 , step 6460 : 1.600256\n",
      "loss in epoch 1 , step 6480 : 1.549856\n",
      "loss in epoch 1 , step 6500 : 1.829801\n",
      "loss in epoch 1 , step 6520 : 1.954133\n",
      "loss in epoch 1 , step 6540 : 2.033885\n",
      "loss in epoch 1 , step 6560 : 2.155317\n",
      "loss in epoch 1 , step 6580 : 1.289004\n",
      "loss in epoch 1 , step 6600 : 1.834837\n",
      "loss in epoch 1 , step 6620 : 1.879393\n",
      "loss in epoch 1 , step 6640 : 1.779411\n",
      "loss in epoch 1 , step 6660 : 1.700864\n",
      "loss in epoch 1 , step 6680 : 1.365498\n",
      "loss in epoch 1 , step 6700 : 1.714231\n",
      "loss in epoch 1 , step 6720 : 1.431389\n",
      "loss in epoch 1 , step 6740 : 1.732843\n",
      "loss in epoch 1 , step 6760 : 1.890595\n",
      "loss in epoch 1 , step 6780 : 2.341659\n",
      "loss in epoch 1 , step 6800 : 1.554781\n",
      "loss in epoch 1 , step 6820 : 1.001359\n",
      "loss in epoch 1 , step 6840 : 1.798802\n",
      "loss in epoch 1 , step 6860 : 1.131473\n",
      "loss in epoch 1 , step 6880 : 1.947603\n",
      "loss in epoch 1 , step 6900 : 1.786781\n",
      "loss in epoch 1 , step 6920 : 2.482385\n",
      "loss in epoch 1 , step 6940 : 1.717360\n",
      "loss in epoch 1 , step 6960 : 1.215587\n",
      "loss in epoch 1 , step 6980 : 1.248836\n",
      "loss in epoch 1 , step 7000 : 1.991733\n",
      "loss in epoch 1 , step 7020 : 2.201665\n",
      "loss in epoch 1 , step 7040 : 1.521641\n",
      "loss in epoch 1 , step 7060 : 1.938802\n",
      "loss in epoch 1 , step 7080 : 1.667072\n",
      "loss in epoch 1 , step 7100 : 1.771760\n",
      "loss in epoch 1 , step 7120 : 2.002213\n",
      "loss in epoch 1 , step 7140 : 1.324182\n",
      "loss in epoch 1 , step 7160 : 1.293740\n",
      "loss in epoch 1 , step 7180 : 2.254042\n",
      "loss in epoch 1 , step 7200 : 1.804961\n",
      "loss in epoch 1 , step 7220 : 2.573770\n",
      "loss in epoch 1 , step 7240 : 1.007530\n",
      "loss in epoch 1 , step 7260 : 1.212894\n",
      "loss in epoch 1 , step 7280 : 1.637109\n",
      "loss in epoch 1 , step 7300 : 1.740984\n",
      "loss in epoch 1 , step 7320 : 1.461594\n",
      "loss in epoch 1 , step 7340 : 1.846475\n",
      "loss in epoch 1 , step 7360 : 1.774137\n",
      "loss in epoch 1 , step 7380 : 1.827712\n",
      "loss in epoch 1 , step 7400 : 1.093922\n",
      "loss in epoch 1 , step 7420 : 2.452753\n",
      "loss in epoch 1 , step 7440 : 1.848365\n",
      "loss in epoch 1 , step 7460 : 1.675107\n",
      "loss in epoch 1 , step 7480 : 1.152004\n",
      "loss in epoch 1 , step 7500 : 1.994965\n",
      "loss in epoch 1 , step 7520 : 1.448094\n",
      "loss in epoch 1 , step 7540 : 1.131539\n",
      "loss in epoch 1 , step 7560 : 1.404539\n",
      "loss in epoch 1 , step 7580 : 1.727474\n",
      "loss in epoch 1 , step 7600 : 1.802769\n",
      "loss in epoch 1 , step 7620 : 1.474573\n",
      "loss in epoch 1 , step 7640 : 1.881154\n",
      "loss in epoch 1 , step 7660 : 1.608735\n",
      "loss in epoch 1 , step 7680 : 0.978413\n",
      "loss in epoch 1 , step 7700 : 1.946846\n",
      "loss in epoch 1 , step 7720 : 1.495342\n",
      "loss in epoch 1 , step 7740 : 2.213977\n",
      "loss in epoch 1 , step 7760 : 2.119237\n",
      "loss in epoch 1 , step 7780 : 1.198937\n",
      "loss in epoch 1 , step 7800 : 2.262820\n",
      "loss in epoch 1 , step 7820 : 2.201633\n",
      "loss in epoch 1 , step 7840 : 1.720976\n",
      "loss in epoch 1 , step 7860 : 2.079786\n",
      "loss in epoch 1 , step 7880 : 1.267627\n",
      "loss in epoch 1 , step 7900 : 1.406241\n",
      "loss in epoch 1 , step 7920 : 1.593616\n",
      "loss in epoch 1 , step 7940 : 1.162909\n",
      "loss in epoch 1 , step 7960 : 1.040483\n",
      "loss in epoch 1 , step 7980 : 1.900270\n",
      "loss in epoch 1 , step 8000 : 1.134185\n",
      "loss in epoch 1 , step 8020 : 2.632136\n",
      "loss in epoch 1 , step 8040 : 1.977831\n",
      "loss in epoch 1 , step 8060 : 2.072297\n",
      "loss in epoch 1 , step 8080 : 2.366024\n",
      "loss in epoch 1 , step 8100 : 2.012814\n",
      "loss in epoch 1 , step 8120 : 1.867967\n",
      "loss in epoch 1 , step 8140 : 1.870065\n",
      "loss in epoch 1 , step 8160 : 1.875659\n",
      "loss in epoch 1 , step 8180 : 1.968092\n",
      "loss in epoch 1 , step 8200 : 2.485145\n",
      "loss in epoch 1 , step 8220 : 2.757720\n",
      "loss in epoch 1 , step 8240 : 1.693655\n",
      "loss in epoch 1 , step 8260 : 1.411627\n",
      "loss in epoch 1 , step 8280 : 1.904995\n",
      "loss in epoch 1 , step 8300 : 2.372961\n",
      "loss in epoch 1 , step 8320 : 0.917987\n",
      "loss in epoch 1 , step 8340 : 2.227181\n",
      "loss in epoch 1 , step 8360 : 1.680070\n",
      "loss in epoch 1 , step 8380 : 2.383720\n",
      "loss in epoch 1 , step 8400 : 1.991962\n",
      "loss in epoch 1 , step 8420 : 1.382043\n",
      "loss in epoch 1 , step 8440 : 1.761976\n",
      "loss in epoch 1 , step 8460 : 1.742015\n",
      "loss in epoch 1 , step 8480 : 2.185809\n",
      "loss in epoch 1 , step 8500 : 1.676369\n",
      "loss in epoch 1 , step 8520 : 1.713796\n",
      "loss in epoch 1 , step 8540 : 1.061461\n",
      "loss in epoch 1 , step 8560 : 2.241144\n",
      "loss in epoch 1 , step 8580 : 1.612043\n",
      "loss in epoch 1 , step 8600 : 1.479071\n",
      "loss in epoch 1 , step 8620 : 1.284210\n",
      "loss in epoch 1 , step 8640 : 1.051374\n",
      "loss in epoch 1 , step 8660 : 0.977589\n",
      "loss in epoch 1 , step 8680 : 1.054892\n",
      "loss in epoch 1 , step 8700 : 1.496866\n",
      "loss in epoch 1 , step 8720 : 1.198468\n",
      "loss in epoch 1 , step 8740 : 1.408874\n",
      "loss in epoch 1 , step 8760 : 1.384458\n",
      "loss in epoch 1 , step 8780 : 1.890159\n",
      "loss in epoch 1 , step 8800 : 1.953142\n",
      "loss in epoch 1 , step 8820 : 1.587919\n",
      "loss in epoch 1 , step 8840 : 1.155525\n",
      "loss in epoch 1 , step 8860 : 1.707134\n",
      "loss in epoch 1 , step 8880 : 2.247975\n",
      "loss in epoch 1 , step 8900 : 2.005193\n",
      "loss in epoch 1 , step 8920 : 1.557133\n",
      "loss in epoch 1 , step 8940 : 1.414295\n",
      "loss in epoch 1 , step 8960 : 1.733840\n",
      "loss in epoch 1 , step 8980 : 1.206793\n",
      "loss in epoch 1 , step 9000 : 1.934739\n",
      "loss in epoch 1 , step 9020 : 1.146662\n",
      "loss in epoch 1 , step 9040 : 2.238103\n",
      "loss in epoch 1 , step 9060 : 1.430266\n",
      "loss in epoch 1 , step 9080 : 1.608899\n",
      "loss in epoch 1 , step 9100 : 1.975525\n",
      "loss in epoch 1 , step 9120 : 2.147357\n",
      "loss in epoch 1 , step 9140 : 1.263279\n",
      "loss in epoch 1 , step 9160 : 1.806823\n",
      "loss in epoch 1 , step 9180 : 1.831774\n",
      "loss in epoch 1 , step 9200 : 1.465487\n",
      "loss in epoch 1 , step 9220 : 1.475530\n",
      "loss in epoch 1 , step 9240 : 0.958508\n",
      "loss in epoch 1 , step 9260 : 1.391725\n",
      "loss in epoch 1 , step 9280 : 1.773781\n",
      "loss in epoch 1 , step 9300 : 2.245902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 , step 9320 : 1.959208\n",
      "loss in epoch 1 , step 9340 : 1.659152\n",
      "loss in epoch 1 , step 9360 : 1.474171\n",
      "loss in epoch 1 , step 9380 : 1.561506\n",
      "loss in epoch 1 , step 9400 : 1.980486\n",
      "loss in epoch 1 , step 9420 : 1.326124\n",
      "loss in epoch 1 , step 9440 : 1.435284\n",
      "loss in epoch 1 , step 9460 : 2.160824\n",
      "loss in epoch 1 , step 9480 : 2.102712\n",
      "loss in epoch 1 , step 9500 : 1.317461\n",
      "loss in epoch 1 , step 9520 : 0.822152\n",
      "loss in epoch 1 , step 9540 : 1.695562\n",
      "loss in epoch 1 , step 9560 : 1.761982\n",
      "loss in epoch 1 , step 9580 : 2.488520\n",
      "loss in epoch 1 , step 9600 : 1.450386\n",
      "loss in epoch 1 , step 9620 : 2.357539\n",
      "loss in epoch 1 , step 9640 : 1.554471\n",
      "loss in epoch 1 , step 9660 : 1.513445\n",
      "loss in epoch 1 , step 9680 : 1.493034\n",
      "loss in epoch 1 , step 9700 : 1.036685\n",
      "loss in epoch 1 , step 9720 : 2.058303\n",
      "loss in epoch 1 , step 9740 : 1.804766\n",
      "loss in epoch 1 , step 9760 : 1.190121\n",
      "loss in epoch 1 , step 9780 : 1.419661\n",
      "loss in epoch 1 , step 9800 : 2.032134\n",
      "loss in epoch 1 , step 9820 : 1.329850\n",
      "loss in epoch 1 , step 9840 : 1.920331\n",
      "loss in epoch 1 , step 9860 : 1.479088\n",
      "loss in epoch 1 , step 9880 : 1.661269\n",
      "loss in epoch 1 , step 9900 : 1.772689\n",
      "loss in epoch 1 , step 9920 : 1.248263\n",
      "loss in epoch 1 , step 9940 : 2.642595\n",
      "loss in epoch 1 , step 9960 : 2.311397\n",
      "loss in epoch 1 , step 9980 : 2.075434\n",
      "loss in epoch 1 , step 10000 : 1.623025\n",
      "loss in epoch 1 , step 10020 : 1.217234\n",
      "loss in epoch 1 , step 10040 : 1.031873\n",
      "loss in epoch 1 , step 10060 : 2.247517\n",
      "loss in epoch 1 , step 10080 : 2.221938\n",
      "loss in epoch 1 , step 10100 : 0.926617\n",
      "loss in epoch 1 , step 10120 : 2.123161\n",
      "loss in epoch 1 , step 10140 : 1.496466\n",
      "loss in epoch 1 , step 10160 : 1.776940\n",
      "loss in epoch 1 , step 10180 : 1.252331\n",
      "loss in epoch 1 , step 10200 : 1.807157\n",
      "loss in epoch 1 , step 10220 : 1.645030\n",
      "loss in epoch 1 , step 10240 : 1.554930\n",
      "loss in epoch 1 , step 10260 : 1.508003\n",
      "loss in epoch 1 , step 10280 : 1.412131\n",
      "loss in epoch 1 , step 10300 : 1.608831\n",
      "loss in epoch 1 , step 10320 : 1.649220\n",
      "loss in epoch 1 , step 10340 : 2.560930\n",
      "loss in epoch 1 , step 10360 : 1.039155\n",
      "loss in epoch 1 , step 10380 : 2.100519\n",
      "loss in epoch 1 , step 10400 : 1.940817\n",
      "loss in epoch 1 , step 10420 : 1.530289\n",
      "loss in epoch 1 , step 10440 : 1.359151\n",
      "loss in epoch 1 , step 10460 : 2.154958\n",
      "loss in epoch 1 , step 10480 : 0.871458\n",
      "loss in epoch 1 , step 10500 : 1.462060\n",
      "loss in epoch 1 , step 10520 : 1.988959\n",
      "loss in epoch 1 , step 10540 : 1.242861\n",
      "loss in epoch 1 , step 10560 : 2.037791\n",
      "loss in epoch 1 , step 10580 : 1.306001\n",
      "loss in epoch 1 , step 10600 : 1.514043\n",
      "loss in epoch 1 , step 10620 : 1.550580\n",
      "loss in epoch 1 , step 10640 : 1.402495\n",
      "loss in epoch 1 , step 10660 : 1.716861\n",
      "loss in epoch 1 , step 10680 : 2.133161\n",
      "loss in epoch 1 , step 10700 : 1.676953\n",
      "loss in epoch 1 , step 10720 : 1.667107\n",
      "loss in epoch 1 , step 10740 : 1.766564\n",
      "loss in epoch 1 , step 10760 : 1.535553\n",
      "loss in epoch 1 , step 10780 : 1.230811\n",
      "loss in epoch 1 , step 10800 : 2.292429\n",
      "loss in epoch 1 , step 10820 : 1.880022\n",
      "loss in epoch 1 , step 10840 : 1.803237\n",
      "loss in epoch 1 , step 10860 : 2.351683\n",
      "loss in epoch 1 , step 10880 : 1.508643\n",
      "loss in epoch 1 , step 10900 : 1.667506\n",
      "loss in epoch 1 , step 10920 : 1.162789\n",
      "loss in epoch 1 , step 10940 : 1.889450\n",
      "loss in epoch 1 , step 10960 : 1.764226\n",
      "loss in epoch 1 , step 10980 : 1.776906\n",
      "loss in epoch 1 , step 11000 : 1.442648\n",
      "loss in epoch 1 , step 11020 : 2.166572\n",
      "loss in epoch 1 , step 11040 : 1.321057\n",
      "loss in epoch 1 , step 11060 : 1.834846\n",
      "loss in epoch 1 , step 11080 : 1.869785\n",
      "loss in epoch 1 , step 11100 : 1.565495\n",
      "loss in epoch 1 , step 11120 : 0.790371\n",
      "loss in epoch 1 , step 11140 : 1.911130\n",
      "loss in epoch 1 , step 11160 : 1.691540\n",
      "loss in epoch 1 , step 11180 : 1.316383\n",
      "loss in epoch 1 , step 11200 : 1.156176\n",
      "loss in epoch 1 , step 11220 : 1.773638\n",
      "loss in epoch 1 , step 11240 : 1.426166\n",
      "loss in epoch 1 , step 11260 : 2.012723\n",
      "loss in epoch 1 , step 11280 : 1.823541\n",
      "loss in epoch 1 , step 11300 : 0.934439\n",
      "loss in epoch 1 , step 11320 : 1.449844\n",
      "loss in epoch 1 , step 11340 : 1.083199\n",
      "loss in epoch 1 , step 11360 : 2.178580\n",
      "loss in epoch 1 , step 11380 : 1.811178\n",
      "loss in epoch 1 , step 11400 : 1.308646\n",
      "loss in epoch 1 , step 11420 : 2.245068\n",
      "loss in epoch 1 , step 11440 : 1.934291\n",
      "loss in epoch 1 , step 11460 : 3.028802\n",
      "loss in epoch 1 , step 11480 : 1.924993\n",
      "loss in epoch 1 , step 11500 : 1.860278\n",
      "loss in epoch 1 , step 11520 : 1.965929\n",
      "loss in epoch 1 , step 11540 : 0.841234\n",
      "loss in epoch 1 , step 11560 : 1.767312\n",
      "loss in epoch 1 , step 11580 : 2.408174\n",
      "loss in epoch 1 , step 11600 : 1.694105\n",
      "loss in epoch 1 , step 11620 : 2.241143\n",
      "loss in epoch 1 , step 11640 : 1.753598\n",
      "loss in epoch 1 , step 11660 : 1.527413\n",
      "loss in epoch 1 , step 11680 : 1.729898\n",
      "loss in epoch 1 , step 11700 : 1.684881\n",
      "loss in epoch 1 , step 11720 : 1.706821\n",
      "loss in epoch 1 , step 11740 : 1.197030\n",
      "loss in epoch 1 , step 11760 : 1.175717\n",
      "loss in epoch 1 , step 11780 : 1.474189\n",
      "loss in epoch 1 , step 11800 : 1.413772\n",
      "loss in epoch 1 , step 11820 : 1.688000\n",
      "loss in epoch 1 , step 11840 : 2.078751\n",
      "loss in epoch 1 , step 11860 : 2.428935\n",
      "loss in epoch 1 , step 11880 : 1.879573\n",
      "loss in epoch 1 , step 11900 : 1.130358\n",
      "loss in epoch 1 , step 11920 : 1.877804\n",
      "loss in epoch 1 , step 11940 : 1.617676\n",
      "loss in epoch 1 , step 11960 : 2.200906\n",
      "loss in epoch 1 , step 11980 : 2.221877\n",
      "loss in epoch 1 , step 12000 : 1.725378\n",
      "loss in epoch 1 , step 12020 : 1.464644\n",
      "loss in epoch 1 , step 12040 : 1.287046\n",
      "loss in epoch 1 , step 12060 : 1.630242\n",
      "loss in epoch 1 , step 12080 : 1.507706\n",
      "loss in epoch 1 , step 12100 : 1.941203\n",
      "loss in epoch 1 , step 12120 : 1.863206\n",
      "loss in epoch 1 , step 12140 : 1.186175\n",
      "loss in epoch 1 , step 12160 : 1.358630\n",
      "loss in epoch 1 , step 12180 : 1.437986\n",
      "loss in epoch 1 , step 12200 : 1.695349\n",
      "loss in epoch 1 , step 12220 : 2.123619\n",
      "loss in epoch 1 , step 12240 : 1.621845\n",
      "loss in epoch 1 , step 12260 : 1.757751\n",
      "loss in epoch 1 , step 12280 : 2.725877\n",
      "loss in epoch 1 , step 12300 : 1.573381\n",
      "loss in epoch 1 , step 12320 : 2.236040\n",
      "loss in epoch 1 , step 12340 : 1.690550\n",
      "loss in epoch 1 , step 12360 : 1.816072\n",
      "loss in epoch 1 , step 12380 : 2.041708\n",
      "loss in epoch 1 , step 12400 : 1.810843\n",
      "loss in epoch 1 , step 12420 : 1.604410\n",
      "loss in epoch 1 , step 12440 : 1.692673\n",
      "loss in epoch 1 , step 12460 : 1.514769\n",
      "loss in epoch 1 , step 12480 : 1.560711\n",
      "loss in epoch 1 , step 12500 : 1.586356\n",
      "loss in epoch 1 , step 12520 : 1.797228\n",
      "loss in epoch 1 , step 12540 : 1.360825\n",
      "loss in epoch 1 , step 12560 : 2.006865\n",
      "loss in epoch 1 , step 12580 : 1.606165\n",
      "loss in epoch 1 , step 12600 : 1.874827\n",
      "loss in epoch 1 , step 12620 : 1.654438\n",
      "loss in epoch 1 , step 12640 : 2.027899\n",
      "loss in epoch 1 , step 12660 : 1.620496\n",
      "loss in epoch 1 , step 12680 : 1.680727\n",
      "loss in epoch 1 , step 12700 : 1.454284\n",
      "loss in epoch 1 , step 12720 : 1.671439\n",
      "loss in epoch 1 , step 12740 : 2.074247\n",
      "loss in epoch 1 , step 12760 : 1.626075\n",
      "loss in epoch 1 , step 12780 : 1.663647\n",
      "loss in epoch 1 , step 12800 : 1.758384\n",
      "loss in epoch 1 , step 12820 : 1.798105\n",
      "loss in epoch 1 , step 12840 : 1.802215\n",
      "loss in epoch 1 , step 12860 : 1.620805\n",
      "loss in epoch 1 , step 12880 : 1.587740\n",
      "loss in epoch 1 , step 12900 : 1.531388\n",
      "loss in epoch 1 , step 12920 : 1.388232\n",
      "loss in epoch 1 , step 12940 : 1.185204\n",
      "loss in epoch 1 , step 12960 : 1.864520\n",
      "loss in epoch 1 , step 12980 : 1.990999\n",
      "loss in epoch 1 , step 13000 : 1.345879\n",
      "loss in epoch 1 , step 13020 : 1.209965\n",
      "loss in epoch 1 , step 13040 : 2.896312\n",
      "loss in epoch 1 , step 13060 : 0.797961\n",
      "loss in epoch 1 , step 13080 : 2.474828\n",
      "loss in epoch 1 , step 13100 : 1.076973\n",
      "loss in epoch 1 , step 13120 : 0.907182\n",
      "loss in epoch 1 , step 13140 : 1.702868\n",
      "loss in epoch 1 , step 13160 : 2.037552\n",
      "loss in epoch 1 , step 13180 : 1.325271\n",
      "loss in epoch 1 , step 13200 : 1.666176\n",
      "loss in epoch 1 , step 13220 : 1.373758\n",
      "loss in epoch 1 , step 13240 : 1.666203\n",
      "loss in epoch 1 , step 13260 : 1.601783\n",
      "loss in epoch 1 , step 13280 : 1.628166\n",
      "loss in epoch 1 , step 13300 : 2.042462\n",
      "loss in epoch 1 , step 13320 : 2.406556\n",
      "loss in epoch 1 , step 13340 : 1.379882\n",
      "loss in epoch 1 , step 13360 : 1.393666\n",
      "loss in epoch 1 , step 13380 : 1.553779\n",
      "loss in epoch 1 , step 13400 : 1.874440\n",
      "loss in epoch 1 , step 13420 : 0.953490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 , step 13440 : 2.146586\n",
      "loss in epoch 1 , step 13460 : 1.786137\n",
      "loss in epoch 1 , step 13480 : 1.741094\n",
      "loss in epoch 1 , step 13500 : 1.936149\n",
      "loss in epoch 1 , step 13520 : 1.709060\n",
      "loss in epoch 1 , step 13540 : 1.491251\n",
      "loss in epoch 1 , step 13560 : 1.350082\n",
      "loss in epoch 1 , step 13580 : 1.622701\n",
      "loss in epoch 1 , step 13600 : 1.476973\n",
      "loss in epoch 1 , step 13620 : 2.682565\n",
      "loss in epoch 1 , step 13640 : 1.375178\n",
      "loss in epoch 1 , step 13660 : 1.618650\n",
      "loss in epoch 1 , step 13680 : 1.500264\n",
      "loss in epoch 1 , step 13700 : 2.076526\n",
      "loss in epoch 1 , step 13720 : 1.754593\n",
      "loss in epoch 1 , step 13740 : 1.692723\n",
      "loss in epoch 1 , step 13760 : 2.219126\n",
      "loss in epoch 1 , step 13780 : 2.140472\n",
      "loss in epoch 1 , step 13800 : 2.043367\n",
      "loss in epoch 1 , step 13820 : 2.047492\n",
      "loss in epoch 1 , step 13840 : 1.838584\n",
      "loss in epoch 1 , step 13860 : 1.467324\n",
      "loss in epoch 1 , step 13880 : 1.525401\n",
      "loss in epoch 1 , step 13900 : 1.734791\n",
      "loss in epoch 1 , step 13920 : 1.275293\n",
      "loss in epoch 1 , step 13940 : 2.109623\n",
      "loss in epoch 1 , step 13960 : 1.840382\n",
      "loss in epoch 1 , step 13980 : 1.418437\n",
      "loss in epoch 1 , step 14000 : 1.747526\n",
      "loss in epoch 1 , step 14020 : 2.128840\n",
      "loss in epoch 1 , step 14040 : 1.720471\n",
      "loss in epoch 1 , step 14060 : 1.700832\n",
      "loss in epoch 1 , step 14080 : 2.142545\n",
      "loss in epoch 1 , step 14100 : 1.213812\n",
      "loss in epoch 1 , step 14120 : 2.272459\n",
      "loss in epoch 1 , step 14140 : 0.947651\n",
      "loss in epoch 1 , step 14160 : 0.990132\n",
      "loss in epoch 1 , step 14180 : 2.091105\n",
      "loss in epoch 1 , step 14200 : 2.080073\n",
      "loss in epoch 1 , step 14220 : 2.224898\n",
      "loss in epoch 1 , step 14240 : 1.565690\n",
      "loss in epoch 1 , step 14260 : 1.331815\n",
      "loss in epoch 1 , step 14280 : 2.153360\n",
      "loss in epoch 1 , step 14300 : 1.771052\n",
      "loss in epoch 1 , step 14320 : 1.864488\n",
      "loss in epoch 1 , step 14340 : 1.129863\n",
      "loss in epoch 1 , step 14360 : 1.602031\n",
      "loss in epoch 1 , step 14380 : 2.046686\n",
      "loss in epoch 1 , step 14400 : 1.097502\n",
      "loss in epoch 1 , step 14420 : 2.467979\n",
      "loss in epoch 1 , step 14440 : 1.552687\n",
      "loss in epoch 1 , step 14460 : 1.735829\n",
      "loss in epoch 1 , step 14480 : 1.367028\n",
      "loss in epoch 1 , step 14500 : 2.124162\n",
      "loss in epoch 1 , step 14520 : 0.752979\n",
      "loss in epoch 1 , step 14540 : 1.369224\n",
      "loss in epoch 1 , step 14560 : 2.175225\n",
      "loss in epoch 1 , step 14580 : 1.330842\n",
      "loss in epoch 1 , step 14600 : 1.763563\n",
      "loss in epoch 1 , step 14620 : 1.742160\n",
      "loss in epoch 1 , step 14640 : 1.630208\n",
      "loss in epoch 1 , step 14660 : 1.541553\n",
      "loss in epoch 1 , step 14680 : 1.281280\n",
      "loss in epoch 1 , step 14700 : 1.744212\n",
      "loss in epoch 1 , step 14720 : 1.238666\n",
      "loss in epoch 1 , step 14740 : 1.348522\n",
      "loss in epoch 1 , step 14760 : 1.167950\n",
      "loss in epoch 1 , step 14780 : 1.359953\n",
      "loss in epoch 1 , step 14800 : 1.376408\n",
      "loss in epoch 1 , step 14820 : 1.373932\n",
      "loss in epoch 1 , step 14840 : 1.738994\n",
      "loss in epoch 1 , step 14860 : 1.671674\n",
      "loss in epoch 1 , step 14880 : 1.655530\n",
      "loss in epoch 1 , step 14900 : 1.436754\n",
      "loss in epoch 1 , step 14920 : 2.397805\n",
      "loss in epoch 1 , step 14940 : 1.658683\n",
      "loss in epoch 1 , step 14960 : 1.057052\n",
      "loss in epoch 1 , step 14980 : 1.705150\n",
      "loss in epoch 1 , step 15000 : 2.316826\n",
      "loss in epoch 1 , step 15020 : 1.103330\n",
      "loss in epoch 1 , step 15040 : 2.305258\n",
      "loss in epoch 1 , step 15060 : 1.453460\n",
      "loss in epoch 1 , step 15080 : 2.034779\n",
      "loss in epoch 1 , step 15100 : 1.604326\n",
      "loss in epoch 1 , step 15120 : 0.735622\n",
      "loss in epoch 1 , step 15140 : 1.433427\n",
      "loss in epoch 1 , step 15160 : 1.314645\n",
      "loss in epoch 1 , step 15180 : 2.554439\n",
      "loss in epoch 1 , step 15200 : 1.606356\n",
      "loss in epoch 1 , step 15220 : 2.821567\n",
      "loss in epoch 1 , step 15240 : 1.321217\n",
      "loss in epoch 1 , step 15260 : 2.144166\n",
      "loss in epoch 1 , step 15280 : 1.059030\n",
      "loss in epoch 1 , step 15300 : 1.923461\n",
      "loss in epoch 1 , step 15320 : 1.853714\n",
      "loss in epoch 1 , step 15340 : 2.334614\n",
      "loss in epoch 1 , step 15360 : 2.337213\n",
      "loss in epoch 1 , step 15380 : 2.463237\n",
      "loss in epoch 1 , step 15400 : 1.433132\n",
      "loss in epoch 1 , step 15420 : 1.078827\n",
      "loss in epoch 1 , step 15440 : 1.232136\n",
      "loss in epoch 1 , step 15460 : 1.335669\n",
      "loss in epoch 1 , step 15480 : 1.572806\n",
      "loss in epoch 1 , step 15500 : 3.194134\n",
      "loss in epoch 1 , step 15520 : 0.559565\n",
      "loss in epoch 1 , step 15540 : 2.272395\n",
      "loss in epoch 1 , step 15560 : 1.455712\n",
      "loss in epoch 1 , step 15580 : 1.949743\n",
      "loss in epoch 1 , step 15600 : 1.953965\n",
      "loss in epoch 1 , step 15620 : 1.201180\n",
      "loss in epoch 1 , step 15640 : 1.500706\n",
      "loss in epoch 1 , step 15660 : 2.140064\n",
      "loss in epoch 1 , step 15680 : 1.058595\n",
      "loss in epoch 1 , step 15700 : 1.316826\n",
      "loss in epoch 1 , step 15720 : 1.236312\n",
      "loss in epoch 1 , step 15740 : 1.970830\n",
      "loss in epoch 1 , step 15760 : 1.536566\n",
      "loss in epoch 1 , step 15780 : 2.094940\n",
      "loss in epoch 1 , step 15800 : 1.871202\n",
      "loss in epoch 1 , step 15820 : 2.009846\n",
      "loss in epoch 1 , step 15840 : 1.395218\n",
      "loss in epoch 1 , step 15860 : 2.052250\n",
      "loss in epoch 1 , step 15880 : 1.014048\n",
      "loss in epoch 1 , step 15900 : 1.193189\n",
      "loss in epoch 1 , step 15920 : 1.744951\n",
      "loss in epoch 1 , step 15940 : 2.075025\n",
      "loss in epoch 1 , step 15960 : 2.152498\n",
      "loss in epoch 1 , step 15980 : 1.481813\n",
      "loss in epoch 1 , step 16000 : 0.559530\n",
      "loss in epoch 1 , step 16020 : 1.570772\n",
      "loss in epoch 1 , step 16040 : 2.069278\n",
      "loss in epoch 1 , step 16060 : 2.481752\n",
      "loss in epoch 1 , step 16080 : 1.276379\n",
      "loss in epoch 1 , step 16100 : 1.614772\n",
      "loss in epoch 1 , step 16120 : 1.585508\n",
      "loss in epoch 1 , step 16140 : 1.605462\n",
      "loss in epoch 1 , step 16160 : 1.796308\n",
      "loss in epoch 1 , step 16180 : 1.852956\n",
      "loss in epoch 1 , step 16200 : 2.095304\n",
      "loss in epoch 1 , step 16220 : 2.030150\n",
      "loss in epoch 1 , step 16240 : 1.400698\n",
      "loss in epoch 1 , step 16260 : 1.884189\n",
      "loss in epoch 1 , step 16280 : 1.913326\n",
      "loss in epoch 1 , step 16300 : 1.609855\n",
      "loss in epoch 1 , step 16320 : 2.427930\n",
      "loss in epoch 1 , step 16340 : 1.260309\n",
      "loss in epoch 1 , step 16360 : 1.314623\n",
      "loss in epoch 1 , step 16380 : 1.319237\n",
      "loss in epoch 1 , step 16400 : 2.056395\n",
      "loss in epoch 1 , step 16420 : 1.242670\n",
      "loss in epoch 1 , step 16440 : 2.205975\n",
      "loss in epoch 1 , step 16460 : 1.535965\n",
      "loss in epoch 1 , step 16480 : 2.027832\n",
      "loss in epoch 1 , step 16500 : 1.778100\n",
      "loss in epoch 1 , step 16520 : 2.006752\n",
      "loss in epoch 1 , step 16540 : 2.040923\n",
      "loss in epoch 1 , step 16560 : 1.539480\n",
      "loss in epoch 1 , step 16580 : 1.407881\n",
      "loss in epoch 1 , step 16600 : 0.805850\n",
      "loss in epoch 1 , step 16620 : 1.449391\n",
      "loss in epoch 1 , step 16640 : 1.410106\n",
      "loss in epoch 1 , step 16660 : 0.929903\n",
      "loss in epoch 1 , step 16680 : 1.954156\n",
      "loss in epoch 1 , step 16700 : 2.646337\n",
      "loss in epoch 1 , step 16720 : 1.889474\n",
      "loss in epoch 1 , step 16740 : 1.793385\n",
      "loss in epoch 1 , step 16760 : 1.153629\n",
      "loss in epoch 1 , step 16780 : 2.241526\n",
      "loss in epoch 1 , step 16800 : 1.427358\n",
      "loss in epoch 1 , step 16820 : 1.544681\n",
      "loss in epoch 1 , step 16840 : 2.122711\n",
      "loss in epoch 1 , step 16860 : 2.114903\n",
      "loss in epoch 1 , step 16880 : 1.826016\n",
      "loss in epoch 1 , step 16900 : 1.747553\n",
      "loss in epoch 1 , step 16920 : 1.418304\n",
      "loss in epoch 1 , step 16940 : 2.217950\n",
      "loss in epoch 1 , step 16960 : 1.694202\n",
      "loss in epoch 1 , step 16980 : 2.201416\n",
      "loss in epoch 1 , step 17000 : 0.932544\n",
      "loss in epoch 1 , step 17020 : 0.839495\n",
      "loss in epoch 1 , step 17040 : 2.145052\n",
      "loss in epoch 1 , step 17060 : 2.318751\n",
      "loss in epoch 1 , step 17080 : 1.913697\n",
      "loss in epoch 1 , step 17100 : 1.283277\n",
      "loss in epoch 1 , step 17120 : 2.025228\n",
      "loss in epoch 1 , step 17140 : 1.244472\n",
      "loss in epoch 1 , step 17160 : 2.094020\n",
      "loss in epoch 1 , step 17180 : 1.771138\n",
      "loss in epoch 1 , step 17200 : 1.436409\n",
      "loss in epoch 1 , step 17220 : 1.104928\n",
      "loss in epoch 1 , step 17240 : 1.691544\n",
      "loss in epoch 1 , step 17260 : 1.548330\n",
      "loss in epoch 1 , step 17280 : 2.104348\n",
      "loss in epoch 1 , step 17300 : 1.644415\n",
      "loss in epoch 1 , step 17320 : 1.742828\n",
      "loss in epoch 1 , step 17340 : 1.957525\n",
      "loss in epoch 1 , step 17360 : 1.470322\n",
      "loss in epoch 1 , step 17380 : 1.845218\n",
      "loss in epoch 1 , step 17400 : 0.517631\n",
      "loss in epoch 1 , step 17420 : 1.771566\n",
      "loss in epoch 1 , step 17440 : 1.924564\n",
      "loss in epoch 1 , step 17460 : 1.646965\n",
      "loss in epoch 1 , step 17480 : 2.414977\n",
      "loss in epoch 1 , step 17500 : 1.981894\n",
      "loss in epoch 1 , step 17520 : 1.403233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 , step 17540 : 1.980335\n",
      "loss in epoch 1 , step 17560 : 1.864521\n",
      "loss in epoch 1 , step 17580 : 2.197903\n",
      "loss in epoch 1 , step 17600 : 1.520347\n",
      "loss in epoch 1 , step 17620 : 1.751697\n",
      "loss in epoch 1 , step 17640 : 1.899966\n",
      "loss in epoch 1 , step 17660 : 1.469639\n",
      "loss in epoch 1 , step 17680 : 1.600479\n",
      "loss in epoch 1 , step 17700 : 2.283043\n",
      "loss in epoch 1 , step 17720 : 1.859537\n",
      "loss in epoch 1 , step 17740 : 2.102993\n",
      "loss in epoch 1 , step 17760 : 1.660471\n",
      "loss in epoch 1 , step 17780 : 1.856757\n",
      "loss in epoch 1 , step 17800 : 1.500443\n",
      "loss in epoch 1 , step 17820 : 2.081386\n",
      "loss in epoch 1 , step 17840 : 1.378478\n",
      "loss in epoch 1 , step 17860 : 1.278848\n",
      "loss in epoch 1 , step 17880 : 1.938999\n",
      "loss in epoch 1 , step 17900 : 1.654318\n",
      "loss in epoch 1 , step 17920 : 1.772993\n",
      "loss in epoch 1 , step 17940 : 1.568449\n",
      "loss in epoch 1 , step 17960 : 2.155983\n",
      "loss in epoch 1 , step 17980 : 2.019862\n",
      "loss in epoch 1 , step 18000 : 2.937202\n",
      "loss in epoch 1 , step 18020 : 1.321933\n",
      "loss in epoch 1 , step 18040 : 1.368343\n",
      "loss in epoch 1 , step 18060 : 1.595717\n",
      "loss in epoch 1 , step 18080 : 1.431737\n",
      "loss in epoch 1 , step 18100 : 1.761458\n",
      "loss in epoch 1 , step 18120 : 1.098587\n",
      "loss in epoch 1 , step 18140 : 2.253824\n",
      "loss in epoch 1 , step 18160 : 1.781075\n",
      "loss in epoch 1 , step 18180 : 1.962480\n",
      "loss in epoch 1 , step 18200 : 1.403735\n",
      "loss in epoch 1 , step 18220 : 1.897086\n",
      "loss in epoch 1 , step 18240 : 1.710324\n",
      "loss in epoch 1 , step 18260 : 2.123413\n",
      "loss in epoch 1 , step 18280 : 1.931305\n",
      "loss in epoch 1 , step 18300 : 1.019379\n",
      "loss in epoch 1 , step 18320 : 2.028309\n",
      "loss in epoch 1 , step 18340 : 2.385578\n",
      "loss in epoch 1 , step 18360 : 3.245186\n",
      "loss in epoch 1 , step 18380 : 2.176177\n",
      "loss in epoch 1 , step 18400 : 1.563454\n",
      "loss in epoch 1 , step 18420 : 1.134405\n",
      "loss in epoch 1 , step 18440 : 1.757801\n",
      "loss in epoch 1 , step 18460 : 1.663854\n",
      "loss in epoch 1 , step 18480 : 1.263749\n",
      "loss in epoch 1 , step 18500 : 1.475178\n",
      "loss in epoch 1 , step 18520 : 1.319018\n",
      "loss in epoch 1 , step 18540 : 2.550496\n",
      "loss in epoch 1 , step 18560 : 1.439128\n",
      "loss in epoch 1 , step 18580 : 1.310249\n",
      "loss in epoch 1 , step 18600 : 1.829901\n",
      "loss in epoch 1 , step 18620 : 2.371298\n",
      "loss in epoch 1 , step 18640 : 2.103001\n",
      "loss in epoch 1 , step 18660 : 1.072685\n",
      "loss in epoch 1 , step 18680 : 3.116957\n",
      "loss in epoch 1 , step 18700 : 1.831900\n",
      "loss in epoch 1 , step 18720 : 1.509173\n",
      "loss in epoch 1 , step 18740 : 1.458040\n",
      "loss in epoch 1 , step 18760 : 1.490269\n",
      "loss in epoch 1 , step 18780 : 1.819479\n",
      "loss in epoch 1 , step 18800 : 1.517747\n",
      "loss in epoch 1 , step 18820 : 2.044433\n",
      "loss in epoch 1 , step 18840 : 1.485467\n",
      "loss in epoch 1 , step 18860 : 0.857724\n",
      "loss in epoch 1 , step 18880 : 1.257004\n",
      "loss in epoch 1 , step 18900 : 1.516484\n",
      "loss in epoch 1 , step 18920 : 1.650147\n",
      "loss in epoch 1 , step 18940 : 1.424148\n",
      "loss in epoch 1 , step 18960 : 2.088090\n",
      "loss in epoch 1 , step 18980 : 2.799531\n",
      "loss in epoch 1 , step 19000 : 1.439448\n",
      "loss in epoch 1 , step 19020 : 2.272131\n",
      "loss in epoch 1 , step 19040 : 2.282524\n",
      "loss in epoch 1 , step 19060 : 2.012670\n",
      "loss in epoch 1 , step 19080 : 1.937670\n",
      "loss in epoch 1 , step 19100 : 1.785574\n",
      "loss in epoch 1 , step 19120 : 2.063093\n",
      "loss in epoch 1 , step 19140 : 1.936842\n",
      "loss in epoch 1 , step 19160 : 2.166400\n",
      "loss in epoch 1 , step 19180 : 2.344748\n",
      "loss in epoch 1 , step 19200 : 1.662496\n",
      "loss in epoch 1 , step 19220 : 2.927277\n",
      "loss in epoch 1 , step 19240 : 1.511038\n",
      "loss in epoch 1 , step 19260 : 1.324051\n",
      "loss in epoch 1 , step 19280 : 1.927909\n",
      "loss in epoch 1 , step 19300 : 1.739160\n",
      "loss in epoch 1 , step 19320 : 1.678994\n",
      "loss in epoch 1 , step 19340 : 0.872921\n",
      "loss in epoch 1 , step 19360 : 2.072483\n",
      "loss in epoch 1 , step 19380 : 1.889474\n",
      "loss in epoch 1 , step 19400 : 2.050749\n",
      "loss in epoch 1 , step 19420 : 2.185055\n",
      "loss in epoch 1 , step 19440 : 2.004614\n",
      "loss in epoch 1 , step 19460 : 1.960378\n",
      "loss in epoch 1 , step 19480 : 1.734851\n",
      "loss in epoch 1 , step 19500 : 1.815300\n",
      "loss in epoch 1 , step 19520 : 1.370344\n",
      "loss in epoch 1 , step 19540 : 2.231905\n",
      "loss in epoch 1 , step 19560 : 1.473568\n",
      "loss in epoch 1 , step 19580 : 1.210161\n",
      "loss in epoch 1 , step 19600 : 1.050704\n",
      "loss in epoch 1 , step 19620 : 1.730005\n",
      "loss in epoch 1 , step 19640 : 1.316616\n",
      "loss in epoch 1 , step 19660 : 1.573317\n",
      "loss in epoch 1 , step 19680 : 1.466410\n",
      "loss in epoch 1 , step 19700 : 1.654150\n",
      "loss in epoch 1 , step 19720 : 1.977631\n",
      "loss in epoch 1 , step 19740 : 2.174609\n",
      "loss in epoch 1 , step 19760 : 1.325921\n",
      "loss in epoch 1 , step 19780 : 2.082670\n",
      "loss in epoch 1 , step 19800 : 1.866393\n",
      "loss in epoch 1 , step 19820 : 1.924851\n",
      "loss in epoch 1 , step 19840 : 2.185905\n",
      "loss in epoch 1 , step 19860 : 1.388023\n",
      "loss in epoch 1 , step 19880 : 1.412224\n",
      "loss in epoch 1 , step 19900 : 1.049594\n",
      "loss in epoch 1 , step 19920 : 1.428288\n",
      "loss in epoch 1 , step 19940 : 1.584405\n",
      "Accuracy in epoch 1 : 20.649975\n",
      "loss in epoch 2 , step 0 : 1.204509\n",
      "loss in epoch 2 , step 20 : 1.646203\n",
      "loss in epoch 2 , step 40 : 1.692750\n",
      "loss in epoch 2 , step 60 : 1.240443\n",
      "loss in epoch 2 , step 80 : 2.434373\n",
      "loss in epoch 2 , step 100 : 1.147057\n",
      "loss in epoch 2 , step 120 : 2.316214\n",
      "loss in epoch 2 , step 140 : 1.786135\n",
      "loss in epoch 2 , step 160 : 2.067382\n",
      "loss in epoch 2 , step 180 : 1.536145\n",
      "loss in epoch 2 , step 200 : 0.862937\n",
      "loss in epoch 2 , step 220 : 0.813584\n",
      "loss in epoch 2 , step 240 : 2.086822\n",
      "loss in epoch 2 , step 260 : 1.907351\n",
      "loss in epoch 2 , step 280 : 2.093672\n",
      "loss in epoch 2 , step 300 : 1.074102\n",
      "loss in epoch 2 , step 320 : 2.369328\n",
      "loss in epoch 2 , step 340 : 2.264160\n",
      "loss in epoch 2 , step 360 : 2.100849\n",
      "loss in epoch 2 , step 380 : 1.911026\n",
      "loss in epoch 2 , step 400 : 1.424868\n",
      "loss in epoch 2 , step 420 : 2.957142\n",
      "loss in epoch 2 , step 440 : 1.159194\n",
      "loss in epoch 2 , step 460 : 2.953440\n",
      "loss in epoch 2 , step 480 : 1.523182\n",
      "loss in epoch 2 , step 500 : 1.551764\n",
      "loss in epoch 2 , step 520 : 2.162308\n",
      "loss in epoch 2 , step 540 : 1.654661\n",
      "loss in epoch 2 , step 560 : 1.939609\n",
      "loss in epoch 2 , step 580 : 1.523024\n",
      "loss in epoch 2 , step 600 : 2.146966\n",
      "loss in epoch 2 , step 620 : 1.178079\n",
      "loss in epoch 2 , step 640 : 1.353183\n",
      "loss in epoch 2 , step 660 : 1.900602\n",
      "loss in epoch 2 , step 680 : 2.082949\n",
      "loss in epoch 2 , step 700 : 1.190686\n",
      "loss in epoch 2 , step 720 : 2.029078\n",
      "loss in epoch 2 , step 740 : 2.182766\n",
      "loss in epoch 2 , step 760 : 1.955284\n",
      "loss in epoch 2 , step 780 : 1.815020\n",
      "loss in epoch 2 , step 800 : 1.728363\n",
      "loss in epoch 2 , step 820 : 1.006537\n",
      "loss in epoch 2 , step 840 : 2.046163\n",
      "loss in epoch 2 , step 860 : 1.288696\n",
      "loss in epoch 2 , step 880 : 2.729334\n",
      "loss in epoch 2 , step 900 : 2.164228\n",
      "loss in epoch 2 , step 920 : 1.401126\n",
      "loss in epoch 2 , step 940 : 1.690811\n",
      "loss in epoch 2 , step 960 : 2.318469\n",
      "loss in epoch 2 , step 980 : 1.537995\n",
      "loss in epoch 2 , step 1000 : 2.484210\n",
      "loss in epoch 2 , step 1020 : 1.830732\n",
      "loss in epoch 2 , step 1040 : 2.091526\n",
      "loss in epoch 2 , step 1060 : 1.316514\n",
      "loss in epoch 2 , step 1080 : 1.471189\n",
      "loss in epoch 2 , step 1100 : 1.629538\n",
      "loss in epoch 2 , step 1120 : 1.826863\n",
      "loss in epoch 2 , step 1140 : 1.439289\n",
      "loss in epoch 2 , step 1160 : 1.335288\n",
      "loss in epoch 2 , step 1180 : 1.014942\n",
      "loss in epoch 2 , step 1200 : 2.081522\n",
      "loss in epoch 2 , step 1220 : 1.945199\n",
      "loss in epoch 2 , step 1240 : 2.224777\n",
      "loss in epoch 2 , step 1260 : 1.698406\n",
      "loss in epoch 2 , step 1280 : 1.653830\n",
      "loss in epoch 2 , step 1300 : 1.557960\n",
      "loss in epoch 2 , step 1320 : 2.431491\n",
      "loss in epoch 2 , step 1340 : 2.323758\n",
      "loss in epoch 2 , step 1360 : 1.522773\n",
      "loss in epoch 2 , step 1380 : 1.335774\n",
      "loss in epoch 2 , step 1400 : 1.760095\n",
      "loss in epoch 2 , step 1420 : 1.491600\n",
      "loss in epoch 2 , step 1440 : 1.572402\n",
      "loss in epoch 2 , step 1460 : 1.585555\n",
      "loss in epoch 2 , step 1480 : 1.540957\n",
      "loss in epoch 2 , step 1500 : 1.815682\n",
      "loss in epoch 2 , step 1520 : 1.001550\n",
      "loss in epoch 2 , step 1540 : 1.951831\n",
      "loss in epoch 2 , step 1560 : 1.791909\n",
      "loss in epoch 2 , step 1580 : 1.477382\n",
      "loss in epoch 2 , step 1600 : 1.345686\n",
      "loss in epoch 2 , step 1620 : 1.935499\n",
      "loss in epoch 2 , step 1640 : 1.817398\n",
      "loss in epoch 2 , step 1660 : 2.058959\n",
      "loss in epoch 2 , step 1680 : 1.125406\n",
      "loss in epoch 2 , step 1700 : 1.388066\n",
      "loss in epoch 2 , step 1720 : 1.373729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 2 , step 1740 : 1.661587\n",
      "loss in epoch 2 , step 1760 : 1.694700\n",
      "loss in epoch 2 , step 1780 : 2.346367\n",
      "loss in epoch 2 , step 1800 : 1.379995\n",
      "loss in epoch 2 , step 1820 : 1.635188\n",
      "loss in epoch 2 , step 1840 : 2.321251\n",
      "loss in epoch 2 , step 1860 : 2.053783\n",
      "loss in epoch 2 , step 1880 : 1.645998\n",
      "loss in epoch 2 , step 1900 : 1.196880\n",
      "loss in epoch 2 , step 1920 : 1.144414\n",
      "loss in epoch 2 , step 1940 : 0.924893\n",
      "loss in epoch 2 , step 1960 : 3.081310\n",
      "loss in epoch 2 , step 1980 : 2.189068\n",
      "loss in epoch 2 , step 2000 : 2.323022\n",
      "loss in epoch 2 , step 2020 : 1.261962\n",
      "loss in epoch 2 , step 2040 : 1.800060\n",
      "loss in epoch 2 , step 2060 : 1.705957\n",
      "loss in epoch 2 , step 2080 : 1.258129\n",
      "loss in epoch 2 , step 2100 : 2.083948\n",
      "loss in epoch 2 , step 2120 : 1.066571\n",
      "loss in epoch 2 , step 2140 : 2.643469\n",
      "loss in epoch 2 , step 2160 : 1.927195\n",
      "loss in epoch 2 , step 2180 : 2.324392\n",
      "loss in epoch 2 , step 2200 : 2.337602\n",
      "loss in epoch 2 , step 2220 : 1.763735\n",
      "loss in epoch 2 , step 2240 : 2.287010\n",
      "loss in epoch 2 , step 2260 : 1.259256\n",
      "loss in epoch 2 , step 2280 : 1.545667\n",
      "loss in epoch 2 , step 2300 : 2.479898\n",
      "loss in epoch 2 , step 2320 : 1.821524\n",
      "loss in epoch 2 , step 2340 : 1.497778\n",
      "loss in epoch 2 , step 2360 : 1.504444\n",
      "loss in epoch 2 , step 2380 : 1.397068\n",
      "loss in epoch 2 , step 2400 : 2.073681\n",
      "loss in epoch 2 , step 2420 : 1.966260\n",
      "loss in epoch 2 , step 2440 : 2.073712\n",
      "loss in epoch 2 , step 2460 : 1.643657\n",
      "loss in epoch 2 , step 2480 : 1.730726\n",
      "loss in epoch 2 , step 2500 : 2.040409\n",
      "loss in epoch 2 , step 2520 : 3.160770\n",
      "loss in epoch 2 , step 2540 : 1.650515\n",
      "loss in epoch 2 , step 2560 : 1.438445\n",
      "loss in epoch 2 , step 2580 : 1.345709\n",
      "loss in epoch 2 , step 2600 : 1.818910\n",
      "loss in epoch 2 , step 2620 : 1.867137\n",
      "loss in epoch 2 , step 2640 : 1.862575\n",
      "loss in epoch 2 , step 2660 : 1.379618\n",
      "loss in epoch 2 , step 2680 : 2.009240\n",
      "loss in epoch 2 , step 2700 : 1.762118\n",
      "loss in epoch 2 , step 2720 : 1.686439\n",
      "loss in epoch 2 , step 2740 : 1.686603\n",
      "loss in epoch 2 , step 2760 : 1.661686\n",
      "loss in epoch 2 , step 2780 : 1.541350\n",
      "loss in epoch 2 , step 2800 : 1.531261\n",
      "loss in epoch 2 , step 2820 : 1.109415\n",
      "loss in epoch 2 , step 2840 : 1.506303\n",
      "loss in epoch 2 , step 2860 : 0.593711\n",
      "loss in epoch 2 , step 2880 : 1.977075\n",
      "loss in epoch 2 , step 2900 : 1.981086\n",
      "loss in epoch 2 , step 2920 : 1.865238\n",
      "loss in epoch 2 , step 2940 : 1.860620\n",
      "loss in epoch 2 , step 2960 : 1.810820\n",
      "loss in epoch 2 , step 2980 : 1.259616\n",
      "loss in epoch 2 , step 3000 : 2.114331\n",
      "loss in epoch 2 , step 3020 : 2.929115\n",
      "loss in epoch 2 , step 3040 : 1.386186\n",
      "loss in epoch 2 , step 3060 : 1.666646\n",
      "loss in epoch 2 , step 3080 : 1.475831\n",
      "loss in epoch 2 , step 3100 : 2.364608\n",
      "loss in epoch 2 , step 3120 : 2.454365\n",
      "loss in epoch 2 , step 3140 : 1.206203\n",
      "loss in epoch 2 , step 3160 : 2.368882\n",
      "loss in epoch 2 , step 3180 : 2.117135\n",
      "loss in epoch 2 , step 3200 : 2.645218\n",
      "loss in epoch 2 , step 3220 : 2.228760\n",
      "loss in epoch 2 , step 3240 : 1.689678\n",
      "loss in epoch 2 , step 3260 : 1.170293\n",
      "loss in epoch 2 , step 3280 : 1.297978\n",
      "loss in epoch 2 , step 3300 : 2.458951\n",
      "loss in epoch 2 , step 3320 : 1.704236\n",
      "loss in epoch 2 , step 3340 : 1.735744\n",
      "loss in epoch 2 , step 3360 : 1.905756\n",
      "loss in epoch 2 , step 3380 : 1.582645\n",
      "loss in epoch 2 , step 3400 : 1.905240\n",
      "loss in epoch 2 , step 3420 : 1.173203\n",
      "loss in epoch 2 , step 3440 : 1.243137\n",
      "loss in epoch 2 , step 3460 : 1.242611\n",
      "loss in epoch 2 , step 3480 : 1.709139\n",
      "loss in epoch 2 , step 3500 : 1.671332\n",
      "loss in epoch 2 , step 3520 : 0.955972\n",
      "loss in epoch 2 , step 3540 : 1.608195\n",
      "loss in epoch 2 , step 3560 : 4.005073\n",
      "loss in epoch 2 , step 3580 : 1.525887\n",
      "loss in epoch 2 , step 3600 : 1.349091\n",
      "loss in epoch 2 , step 3620 : 1.986334\n",
      "loss in epoch 2 , step 3640 : 1.527084\n",
      "loss in epoch 2 , step 3660 : 1.842059\n",
      "loss in epoch 2 , step 3680 : 2.001447\n",
      "loss in epoch 2 , step 3700 : 2.216266\n",
      "loss in epoch 2 , step 3720 : 1.528910\n",
      "loss in epoch 2 , step 3740 : 1.607161\n",
      "loss in epoch 2 , step 3760 : 1.810102\n",
      "loss in epoch 2 , step 3780 : 1.571659\n",
      "loss in epoch 2 , step 3800 : 0.396812\n",
      "loss in epoch 2 , step 3820 : 1.347303\n",
      "loss in epoch 2 , step 3840 : 1.512368\n",
      "loss in epoch 2 , step 3860 : 1.494330\n",
      "loss in epoch 2 , step 3880 : 1.696199\n",
      "loss in epoch 2 , step 3900 : 1.483959\n",
      "loss in epoch 2 , step 3920 : 1.930242\n",
      "loss in epoch 2 , step 3940 : 2.237883\n",
      "loss in epoch 2 , step 3960 : 1.308707\n",
      "loss in epoch 2 , step 3980 : 1.557414\n",
      "loss in epoch 2 , step 4000 : 2.027378\n",
      "loss in epoch 2 , step 4020 : 1.376369\n",
      "loss in epoch 2 , step 4040 : 2.115127\n",
      "loss in epoch 2 , step 4060 : 1.121939\n",
      "loss in epoch 2 , step 4080 : 1.992288\n",
      "loss in epoch 2 , step 4100 : 2.008868\n",
      "loss in epoch 2 , step 4120 : 1.412256\n",
      "loss in epoch 2 , step 4140 : 2.434352\n",
      "loss in epoch 2 , step 4160 : 1.845190\n",
      "loss in epoch 2 , step 4180 : 1.496335\n",
      "loss in epoch 2 , step 4200 : 1.361276\n",
      "loss in epoch 2 , step 4220 : 2.132528\n",
      "loss in epoch 2 , step 4240 : 2.083323\n",
      "loss in epoch 2 , step 4260 : 1.457281\n",
      "loss in epoch 2 , step 4280 : 1.433357\n",
      "loss in epoch 2 , step 4300 : 1.701334\n",
      "loss in epoch 2 , step 4320 : 1.436326\n",
      "loss in epoch 2 , step 4340 : 1.601077\n",
      "loss in epoch 2 , step 4360 : 1.892924\n",
      "loss in epoch 2 , step 4380 : 1.048501\n",
      "loss in epoch 2 , step 4400 : 1.528259\n",
      "loss in epoch 2 , step 4420 : 1.912875\n",
      "loss in epoch 2 , step 4440 : 1.228492\n",
      "loss in epoch 2 , step 4460 : 1.124708\n",
      "loss in epoch 2 , step 4480 : 1.716286\n",
      "loss in epoch 2 , step 4500 : 1.571933\n",
      "loss in epoch 2 , step 4520 : 2.662694\n",
      "loss in epoch 2 , step 4540 : 2.009764\n",
      "loss in epoch 2 , step 4560 : 2.938344\n",
      "loss in epoch 2 , step 4580 : 1.724070\n",
      "loss in epoch 2 , step 4600 : 1.158170\n",
      "loss in epoch 2 , step 4620 : 1.956303\n",
      "loss in epoch 2 , step 4640 : 4.039802\n",
      "loss in epoch 2 , step 4660 : 1.898763\n",
      "loss in epoch 2 , step 4680 : 1.532398\n",
      "loss in epoch 2 , step 4700 : 1.602308\n",
      "loss in epoch 2 , step 4720 : 0.895447\n",
      "loss in epoch 2 , step 4740 : 2.432495\n",
      "loss in epoch 2 , step 4760 : 1.897501\n",
      "loss in epoch 2 , step 4780 : 1.703775\n",
      "loss in epoch 2 , step 4800 : 1.405338\n",
      "loss in epoch 2 , step 4820 : 1.549806\n",
      "loss in epoch 2 , step 4840 : 1.148149\n",
      "loss in epoch 2 , step 4860 : 1.310431\n",
      "loss in epoch 2 , step 4880 : 1.497334\n",
      "loss in epoch 2 , step 4900 : 1.345603\n",
      "loss in epoch 2 , step 4920 : 1.848675\n",
      "loss in epoch 2 , step 4940 : 1.686863\n",
      "loss in epoch 2 , step 4960 : 1.740350\n",
      "loss in epoch 2 , step 4980 : 0.938750\n",
      "loss in epoch 2 , step 5000 : 1.560428\n",
      "loss in epoch 2 , step 5020 : 1.907284\n",
      "loss in epoch 2 , step 5040 : 1.654071\n",
      "loss in epoch 2 , step 5060 : 1.862980\n",
      "loss in epoch 2 , step 5080 : 1.642637\n",
      "loss in epoch 2 , step 5100 : 1.972693\n",
      "loss in epoch 2 , step 5120 : 1.707112\n",
      "loss in epoch 2 , step 5140 : 1.177269\n",
      "loss in epoch 2 , step 5160 : 2.078329\n",
      "loss in epoch 2 , step 5180 : 1.456254\n",
      "loss in epoch 2 , step 5200 : 2.409139\n",
      "loss in epoch 2 , step 5220 : 2.011796\n",
      "loss in epoch 2 , step 5240 : 1.588061\n",
      "loss in epoch 2 , step 5260 : 1.729886\n",
      "loss in epoch 2 , step 5280 : 1.812183\n",
      "loss in epoch 2 , step 5300 : 1.518777\n",
      "loss in epoch 2 , step 5320 : 0.953418\n",
      "loss in epoch 2 , step 5340 : 1.655850\n",
      "loss in epoch 2 , step 5360 : 2.010463\n",
      "loss in epoch 2 , step 5380 : 2.354599\n",
      "loss in epoch 2 , step 5400 : 1.804243\n",
      "loss in epoch 2 , step 5420 : 2.116510\n",
      "loss in epoch 2 , step 5440 : 1.651352\n",
      "loss in epoch 2 , step 5460 : 1.554787\n",
      "loss in epoch 2 , step 5480 : 1.456736\n",
      "loss in epoch 2 , step 5500 : 0.521249\n",
      "loss in epoch 2 , step 5520 : 1.882600\n",
      "loss in epoch 2 , step 5540 : 1.879834\n",
      "loss in epoch 2 , step 5560 : 2.014901\n",
      "loss in epoch 2 , step 5580 : 1.451019\n",
      "loss in epoch 2 , step 5600 : 1.378890\n",
      "loss in epoch 2 , step 5620 : 1.262510\n",
      "loss in epoch 2 , step 5640 : 1.633069\n",
      "loss in epoch 2 , step 5660 : 1.230662\n",
      "loss in epoch 2 , step 5680 : 2.442580\n",
      "loss in epoch 2 , step 5700 : 2.016306\n",
      "loss in epoch 2 , step 5720 : 2.304998\n",
      "loss in epoch 2 , step 5740 : 2.209419\n",
      "loss in epoch 2 , step 5760 : 1.233855\n",
      "loss in epoch 2 , step 5780 : 2.172098\n",
      "loss in epoch 2 , step 5800 : 1.627357\n",
      "loss in epoch 2 , step 5820 : 1.824668\n",
      "loss in epoch 2 , step 5840 : 0.773058\n",
      "loss in epoch 2 , step 5860 : 1.985312\n",
      "loss in epoch 2 , step 5880 : 1.789459\n",
      "loss in epoch 2 , step 5900 : 1.324511\n",
      "loss in epoch 2 , step 5920 : 1.407546\n",
      "loss in epoch 2 , step 5940 : 1.434128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 2 , step 5960 : 1.853030\n",
      "loss in epoch 2 , step 5980 : 2.717786\n",
      "loss in epoch 2 , step 6000 : 0.722765\n",
      "loss in epoch 2 , step 6020 : 1.794132\n",
      "loss in epoch 2 , step 6040 : 1.876184\n",
      "loss in epoch 2 , step 6060 : 2.184354\n",
      "loss in epoch 2 , step 6080 : 2.074217\n",
      "loss in epoch 2 , step 6100 : 1.366775\n",
      "loss in epoch 2 , step 6120 : 1.159590\n",
      "loss in epoch 2 , step 6140 : 1.381760\n",
      "loss in epoch 2 , step 6160 : 2.150731\n",
      "loss in epoch 2 , step 6180 : 1.714040\n",
      "loss in epoch 2 , step 6200 : 1.395276\n",
      "loss in epoch 2 , step 6220 : 1.971514\n",
      "loss in epoch 2 , step 6240 : 1.342018\n",
      "loss in epoch 2 , step 6260 : 1.304313\n",
      "loss in epoch 2 , step 6280 : 1.917990\n",
      "loss in epoch 2 , step 6300 : 1.670613\n",
      "loss in epoch 2 , step 6320 : 1.520555\n",
      "loss in epoch 2 , step 6340 : 1.709320\n",
      "loss in epoch 2 , step 6360 : 2.431976\n",
      "loss in epoch 2 , step 6380 : 1.882971\n",
      "loss in epoch 2 , step 6400 : 1.380194\n",
      "loss in epoch 2 , step 6420 : 1.730556\n",
      "loss in epoch 2 , step 6440 : 1.385316\n",
      "loss in epoch 2 , step 6460 : 1.488011\n",
      "loss in epoch 2 , step 6480 : 1.770293\n",
      "loss in epoch 2 , step 6500 : 0.963666\n",
      "loss in epoch 2 , step 6520 : 1.367984\n",
      "loss in epoch 2 , step 6540 : 1.873281\n",
      "loss in epoch 2 , step 6560 : 1.389197\n",
      "loss in epoch 2 , step 6580 : 1.947603\n",
      "loss in epoch 2 , step 6600 : 1.673150\n",
      "loss in epoch 2 , step 6620 : 1.726806\n",
      "loss in epoch 2 , step 6640 : 1.235017\n",
      "loss in epoch 2 , step 6660 : 1.818788\n",
      "loss in epoch 2 , step 6680 : 2.157004\n",
      "loss in epoch 2 , step 6700 : 2.224802\n",
      "loss in epoch 2 , step 6720 : 0.295332\n",
      "loss in epoch 2 , step 6740 : 2.668703\n",
      "loss in epoch 2 , step 6760 : 1.354177\n",
      "loss in epoch 2 , step 6780 : 1.394312\n",
      "loss in epoch 2 , step 6800 : 1.856081\n",
      "loss in epoch 2 , step 6820 : 1.507064\n",
      "loss in epoch 2 , step 6840 : 1.279627\n",
      "loss in epoch 2 , step 6860 : 2.143206\n",
      "loss in epoch 2 , step 6880 : 2.444273\n",
      "loss in epoch 2 , step 6900 : 1.658250\n",
      "loss in epoch 2 , step 6920 : 0.288598\n",
      "loss in epoch 2 , step 6940 : 2.748365\n",
      "loss in epoch 2 , step 6960 : 0.948740\n",
      "loss in epoch 2 , step 6980 : 2.239855\n",
      "loss in epoch 2 , step 7000 : 2.080874\n",
      "loss in epoch 2 , step 7020 : 1.062715\n",
      "loss in epoch 2 , step 7040 : 1.042379\n",
      "loss in epoch 2 , step 7060 : 1.359654\n",
      "loss in epoch 2 , step 7080 : 1.180982\n",
      "loss in epoch 2 , step 7100 : 1.272219\n",
      "loss in epoch 2 , step 7120 : 1.919641\n",
      "loss in epoch 2 , step 7140 : 1.909180\n",
      "loss in epoch 2 , step 7160 : 1.132931\n",
      "loss in epoch 2 , step 7180 : 2.777165\n",
      "loss in epoch 2 , step 7200 : 2.323690\n",
      "loss in epoch 2 , step 7220 : 2.469287\n",
      "loss in epoch 2 , step 7240 : 1.941142\n",
      "loss in epoch 2 , step 7260 : 1.392701\n",
      "loss in epoch 2 , step 7280 : 1.820840\n",
      "loss in epoch 2 , step 7300 : 1.142494\n",
      "loss in epoch 2 , step 7320 : 1.026000\n",
      "loss in epoch 2 , step 7340 : 1.702013\n",
      "loss in epoch 2 , step 7360 : 0.924596\n",
      "loss in epoch 2 , step 7380 : 1.758274\n",
      "loss in epoch 2 , step 7400 : 1.658045\n",
      "loss in epoch 2 , step 7420 : 1.110729\n",
      "loss in epoch 2 , step 7440 : 2.062887\n",
      "loss in epoch 2 , step 7460 : 1.897480\n",
      "loss in epoch 2 , step 7480 : 1.972259\n",
      "loss in epoch 2 , step 7500 : 1.403604\n",
      "loss in epoch 2 , step 7520 : 1.732537\n",
      "loss in epoch 2 , step 7540 : 0.961604\n",
      "loss in epoch 2 , step 7560 : 1.831058\n",
      "loss in epoch 2 , step 7580 : 1.374125\n",
      "loss in epoch 2 , step 7600 : 2.798676\n",
      "loss in epoch 2 , step 7620 : 1.231655\n",
      "loss in epoch 2 , step 7640 : 1.027294\n",
      "loss in epoch 2 , step 7660 : 1.784707\n",
      "loss in epoch 2 , step 7680 : 0.809672\n",
      "loss in epoch 2 , step 7700 : 1.891058\n",
      "loss in epoch 2 , step 7720 : 1.879606\n",
      "loss in epoch 2 , step 7740 : 1.985520\n",
      "loss in epoch 2 , step 7760 : 2.021457\n",
      "loss in epoch 2 , step 7780 : 3.136294\n",
      "loss in epoch 2 , step 7800 : 3.460162\n",
      "loss in epoch 2 , step 7820 : 1.344306\n",
      "loss in epoch 2 , step 7840 : 1.729300\n",
      "loss in epoch 2 , step 7860 : 0.611543\n",
      "loss in epoch 2 , step 7880 : 1.387047\n",
      "loss in epoch 2 , step 7900 : 1.518858\n",
      "loss in epoch 2 , step 7920 : 1.631153\n",
      "loss in epoch 2 , step 7940 : 2.708683\n",
      "loss in epoch 2 , step 7960 : 1.529375\n",
      "loss in epoch 2 , step 7980 : 1.639527\n",
      "loss in epoch 2 , step 8000 : 1.993830\n",
      "loss in epoch 2 , step 8020 : 1.827557\n",
      "loss in epoch 2 , step 8040 : 1.888494\n",
      "loss in epoch 2 , step 8060 : 1.417256\n",
      "loss in epoch 2 , step 8080 : 1.559931\n",
      "loss in epoch 2 , step 8100 : 1.529208\n",
      "loss in epoch 2 , step 8120 : 1.027706\n",
      "loss in epoch 2 , step 8140 : 2.190173\n",
      "loss in epoch 2 , step 8160 : 1.909821\n",
      "loss in epoch 2 , step 8180 : 1.716766\n",
      "loss in epoch 2 , step 8200 : 1.435596\n",
      "loss in epoch 2 , step 8220 : 1.987062\n",
      "loss in epoch 2 , step 8240 : 1.618073\n",
      "loss in epoch 2 , step 8260 : 2.180652\n",
      "loss in epoch 2 , step 8280 : 1.435504\n",
      "loss in epoch 2 , step 8300 : 2.294924\n",
      "loss in epoch 2 , step 8320 : 1.112729\n",
      "loss in epoch 2 , step 8340 : 1.770058\n",
      "loss in epoch 2 , step 8360 : 2.222752\n",
      "loss in epoch 2 , step 8380 : 1.121028\n",
      "loss in epoch 2 , step 8400 : 1.107414\n",
      "loss in epoch 2 , step 8420 : 1.541859\n",
      "loss in epoch 2 , step 8440 : 1.387757\n",
      "loss in epoch 2 , step 8460 : 1.110249\n",
      "loss in epoch 2 , step 8480 : 2.156341\n",
      "loss in epoch 2 , step 8500 : 2.380584\n",
      "loss in epoch 2 , step 8520 : 1.818951\n",
      "loss in epoch 2 , step 8540 : 1.689991\n",
      "loss in epoch 2 , step 8560 : 2.262249\n",
      "loss in epoch 2 , step 8580 : 1.382130\n",
      "loss in epoch 2 , step 8600 : 1.014539\n",
      "loss in epoch 2 , step 8620 : 0.869393\n",
      "loss in epoch 2 , step 8640 : 2.163151\n",
      "loss in epoch 2 , step 8660 : 1.756225\n",
      "loss in epoch 2 , step 8680 : 4.114725\n",
      "loss in epoch 2 , step 8700 : 1.720355\n",
      "loss in epoch 2 , step 8720 : 1.210574\n",
      "loss in epoch 2 , step 8740 : 2.595154\n",
      "loss in epoch 2 , step 8760 : 1.519719\n",
      "loss in epoch 2 , step 8780 : 2.257443\n",
      "loss in epoch 2 , step 8800 : 1.119963\n",
      "loss in epoch 2 , step 8820 : 1.172894\n",
      "loss in epoch 2 , step 8840 : 1.758127\n",
      "loss in epoch 2 , step 8860 : 1.966102\n",
      "loss in epoch 2 , step 8880 : 2.668044\n",
      "loss in epoch 2 , step 8900 : 2.121836\n",
      "loss in epoch 2 , step 8920 : 0.778089\n",
      "loss in epoch 2 , step 8940 : 0.769683\n",
      "loss in epoch 2 , step 8960 : 0.780646\n",
      "loss in epoch 2 , step 8980 : 2.052921\n",
      "loss in epoch 2 , step 9000 : 1.992918\n",
      "loss in epoch 2 , step 9020 : 0.972989\n",
      "loss in epoch 2 , step 9040 : 0.941804\n",
      "loss in epoch 2 , step 9060 : 1.000761\n",
      "loss in epoch 2 , step 9080 : 1.004591\n",
      "loss in epoch 2 , step 9100 : 1.628177\n",
      "loss in epoch 2 , step 9120 : 1.378249\n",
      "loss in epoch 2 , step 9140 : 2.057092\n",
      "loss in epoch 2 , step 9160 : 1.972864\n",
      "loss in epoch 2 , step 9180 : 1.143074\n",
      "loss in epoch 2 , step 9200 : 1.776710\n",
      "loss in epoch 2 , step 9220 : 1.772838\n",
      "loss in epoch 2 , step 9240 : 1.035819\n",
      "loss in epoch 2 , step 9260 : 1.769640\n",
      "loss in epoch 2 , step 9280 : 1.842153\n",
      "loss in epoch 2 , step 9300 : 1.554346\n",
      "loss in epoch 2 , step 9320 : 0.861429\n",
      "loss in epoch 2 , step 9340 : 0.996247\n",
      "loss in epoch 2 , step 9360 : 1.206766\n",
      "loss in epoch 2 , step 9380 : 1.064071\n",
      "loss in epoch 2 , step 9400 : 1.501474\n",
      "loss in epoch 2 , step 9420 : 2.304199\n",
      "loss in epoch 2 , step 9440 : 1.708842\n",
      "loss in epoch 2 , step 9460 : 1.329954\n",
      "loss in epoch 2 , step 9480 : 1.281809\n",
      "loss in epoch 2 , step 9500 : 1.534663\n",
      "loss in epoch 2 , step 9520 : 1.965017\n",
      "loss in epoch 2 , step 9540 : 2.120710\n",
      "loss in epoch 2 , step 9560 : 1.616174\n",
      "loss in epoch 2 , step 9580 : 1.809555\n",
      "loss in epoch 2 , step 9600 : 1.988357\n",
      "loss in epoch 2 , step 9620 : 1.689938\n",
      "loss in epoch 2 , step 9640 : 1.515298\n",
      "loss in epoch 2 , step 9660 : 1.759410\n",
      "loss in epoch 2 , step 9680 : 1.667276\n",
      "loss in epoch 2 , step 9700 : 1.727112\n",
      "loss in epoch 2 , step 9720 : 0.635070\n",
      "loss in epoch 2 , step 9740 : 2.184802\n",
      "loss in epoch 2 , step 9760 : 1.592269\n",
      "loss in epoch 2 , step 9780 : 1.340220\n",
      "loss in epoch 2 , step 9800 : 1.659581\n",
      "loss in epoch 2 , step 9820 : 1.684573\n",
      "loss in epoch 2 , step 9840 : 2.324180\n",
      "loss in epoch 2 , step 9860 : 1.990002\n",
      "loss in epoch 2 , step 9880 : 1.346894\n",
      "loss in epoch 2 , step 9900 : 2.718542\n",
      "loss in epoch 2 , step 9920 : 1.265616\n",
      "loss in epoch 2 , step 9940 : 2.124238\n",
      "loss in epoch 2 , step 9960 : 1.482965\n",
      "loss in epoch 2 , step 9980 : 1.924123\n",
      "loss in epoch 2 , step 10000 : 1.429286\n",
      "loss in epoch 2 , step 10020 : 2.183135\n",
      "loss in epoch 2 , step 10040 : 1.612786\n",
      "loss in epoch 2 , step 10060 : 1.473265\n",
      "loss in epoch 2 , step 10080 : 1.711536\n",
      "loss in epoch 2 , step 10100 : 1.402184\n",
      "loss in epoch 2 , step 10120 : 1.363383\n",
      "loss in epoch 2 , step 10140 : 1.830678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 2 , step 10160 : 2.049009\n",
      "loss in epoch 2 , step 10180 : 1.424794\n",
      "loss in epoch 2 , step 10200 : 1.414728\n",
      "loss in epoch 2 , step 10220 : 1.531247\n",
      "loss in epoch 2 , step 10240 : 1.322999\n",
      "loss in epoch 2 , step 10260 : 1.706059\n",
      "loss in epoch 2 , step 10280 : 0.987902\n",
      "loss in epoch 2 , step 10300 : 1.879373\n",
      "loss in epoch 2 , step 10320 : 2.086563\n",
      "loss in epoch 2 , step 10340 : 1.728446\n",
      "loss in epoch 2 , step 10360 : 1.213688\n",
      "loss in epoch 2 , step 10380 : 2.503115\n",
      "loss in epoch 2 , step 10400 : 2.220480\n",
      "loss in epoch 2 , step 10420 : 1.212063\n",
      "loss in epoch 2 , step 10440 : 1.435674\n",
      "loss in epoch 2 , step 10460 : 1.734101\n",
      "loss in epoch 2 , step 10480 : 2.123251\n",
      "loss in epoch 2 , step 10500 : 1.515107\n",
      "loss in epoch 2 , step 10520 : 1.997267\n",
      "loss in epoch 2 , step 10540 : 1.542755\n",
      "loss in epoch 2 , step 10560 : 1.711257\n",
      "loss in epoch 2 , step 10580 : 1.914319\n",
      "loss in epoch 2 , step 10600 : 1.953817\n",
      "loss in epoch 2 , step 10620 : 1.714423\n",
      "loss in epoch 2 , step 10640 : 1.056589\n",
      "loss in epoch 2 , step 10660 : 1.731036\n",
      "loss in epoch 2 , step 10680 : 1.278070\n",
      "loss in epoch 2 , step 10700 : 1.410786\n",
      "loss in epoch 2 , step 10720 : 1.704847\n",
      "loss in epoch 2 , step 10740 : 1.913328\n",
      "loss in epoch 2 , step 10760 : 2.025685\n",
      "loss in epoch 2 , step 10780 : 1.820839\n",
      "loss in epoch 2 , step 10800 : 1.342716\n",
      "loss in epoch 2 , step 10820 : 2.051577\n",
      "loss in epoch 2 , step 10840 : 2.455375\n",
      "loss in epoch 2 , step 10860 : 1.389616\n",
      "loss in epoch 2 , step 10880 : 1.621376\n",
      "loss in epoch 2 , step 10900 : 1.420073\n",
      "loss in epoch 2 , step 10920 : 2.011700\n",
      "loss in epoch 2 , step 10940 : 1.477485\n",
      "loss in epoch 2 , step 10960 : 2.108635\n",
      "loss in epoch 2 , step 10980 : 2.028271\n",
      "loss in epoch 2 , step 11000 : 1.741770\n",
      "loss in epoch 2 , step 11020 : 1.490807\n",
      "loss in epoch 2 , step 11040 : 1.000085\n",
      "loss in epoch 2 , step 11060 : 0.636726\n",
      "loss in epoch 2 , step 11080 : 1.632304\n",
      "loss in epoch 2 , step 11100 : 1.520183\n",
      "loss in epoch 2 , step 11120 : 1.186892\n",
      "loss in epoch 2 , step 11140 : 2.172386\n",
      "loss in epoch 2 , step 11160 : 0.961751\n",
      "loss in epoch 2 , step 11180 : 2.041984\n",
      "loss in epoch 2 , step 11200 : 2.057047\n",
      "loss in epoch 2 , step 11220 : 1.966811\n",
      "loss in epoch 2 , step 11240 : 1.735605\n",
      "loss in epoch 2 , step 11260 : 1.319745\n",
      "loss in epoch 2 , step 11280 : 1.099497\n",
      "loss in epoch 2 , step 11300 : 1.849460\n",
      "loss in epoch 2 , step 11320 : 2.090111\n",
      "loss in epoch 2 , step 11340 : 1.066530\n",
      "loss in epoch 2 , step 11360 : 1.983935\n",
      "loss in epoch 2 , step 11380 : 3.195457\n",
      "loss in epoch 2 , step 11400 : 1.800146\n",
      "loss in epoch 2 , step 11420 : 1.734568\n",
      "loss in epoch 2 , step 11440 : 1.666999\n",
      "loss in epoch 2 , step 11460 : 1.665849\n",
      "loss in epoch 2 , step 11480 : 2.158201\n",
      "loss in epoch 2 , step 11500 : 1.009155\n",
      "loss in epoch 2 , step 11520 : 0.831311\n",
      "loss in epoch 2 , step 11540 : 1.660261\n",
      "loss in epoch 2 , step 11560 : 2.228673\n",
      "loss in epoch 2 , step 11580 : 2.087395\n",
      "loss in epoch 2 , step 11600 : 1.041967\n",
      "loss in epoch 2 , step 11620 : 1.032757\n",
      "loss in epoch 2 , step 11640 : 1.483865\n",
      "loss in epoch 2 , step 11660 : 1.725689\n",
      "loss in epoch 2 , step 11680 : 1.838529\n",
      "loss in epoch 2 , step 11700 : 1.158931\n",
      "loss in epoch 2 , step 11720 : 2.407899\n",
      "loss in epoch 2 , step 11740 : 2.028758\n",
      "loss in epoch 2 , step 11760 : 1.671957\n",
      "loss in epoch 2 , step 11780 : 1.614537\n",
      "loss in epoch 2 , step 11800 : 1.698151\n",
      "loss in epoch 2 , step 11820 : 2.666325\n",
      "loss in epoch 2 , step 11840 : 1.273884\n",
      "loss in epoch 2 , step 11860 : 1.846267\n",
      "loss in epoch 2 , step 11880 : 2.603670\n",
      "loss in epoch 2 , step 11900 : 0.925589\n",
      "loss in epoch 2 , step 11920 : 1.272585\n",
      "loss in epoch 2 , step 11940 : 1.264124\n",
      "loss in epoch 2 , step 11960 : 1.857929\n",
      "loss in epoch 2 , step 11980 : 0.844918\n",
      "loss in epoch 2 , step 12000 : 1.004613\n",
      "loss in epoch 2 , step 12020 : 2.612942\n",
      "loss in epoch 2 , step 12040 : 1.768949\n",
      "loss in epoch 2 , step 12060 : 1.386742\n",
      "loss in epoch 2 , step 12080 : 1.627321\n",
      "loss in epoch 2 , step 12100 : 1.498146\n",
      "loss in epoch 2 , step 12120 : 1.685065\n",
      "loss in epoch 2 , step 12140 : 1.267836\n",
      "loss in epoch 2 , step 12160 : 2.401025\n",
      "loss in epoch 2 , step 12180 : 0.957589\n",
      "loss in epoch 2 , step 12200 : 1.669746\n",
      "loss in epoch 2 , step 12220 : 1.461134\n",
      "loss in epoch 2 , step 12240 : 2.036971\n",
      "loss in epoch 2 , step 12260 : 1.893090\n",
      "loss in epoch 2 , step 12280 : 1.412320\n",
      "loss in epoch 2 , step 12300 : 1.559845\n",
      "loss in epoch 2 , step 12320 : 1.132968\n",
      "loss in epoch 2 , step 12340 : 1.422816\n",
      "loss in epoch 2 , step 12360 : 1.916183\n",
      "loss in epoch 2 , step 12380 : 0.846545\n",
      "loss in epoch 2 , step 12400 : 0.988101\n",
      "loss in epoch 2 , step 12420 : 1.493814\n",
      "loss in epoch 2 , step 12440 : 1.559463\n",
      "loss in epoch 2 , step 12460 : 2.751543\n",
      "loss in epoch 2 , step 12480 : 1.857295\n",
      "loss in epoch 2 , step 12500 : 1.713797\n",
      "loss in epoch 2 , step 12520 : 0.319498\n",
      "loss in epoch 2 , step 12540 : 1.254503\n",
      "loss in epoch 2 , step 12560 : 1.357288\n",
      "loss in epoch 2 , step 12580 : 1.424554\n",
      "loss in epoch 2 , step 12600 : 1.584855\n",
      "loss in epoch 2 , step 12620 : 2.119762\n",
      "loss in epoch 2 , step 12640 : 1.681526\n",
      "loss in epoch 2 , step 12660 : 2.355021\n",
      "loss in epoch 2 , step 12680 : 2.181607\n",
      "loss in epoch 2 , step 12700 : 1.529677\n",
      "loss in epoch 2 , step 12720 : 1.925721\n",
      "loss in epoch 2 , step 12740 : 0.584275\n",
      "loss in epoch 2 , step 12760 : 1.246751\n",
      "loss in epoch 2 , step 12780 : 1.611427\n",
      "loss in epoch 2 , step 12800 : 1.769839\n",
      "loss in epoch 2 , step 12820 : 1.373430\n",
      "loss in epoch 2 , step 12840 : 1.828121\n",
      "loss in epoch 2 , step 12860 : 2.171636\n",
      "loss in epoch 2 , step 12880 : 0.995064\n",
      "loss in epoch 2 , step 12900 : 1.283709\n",
      "loss in epoch 2 , step 12920 : 0.552730\n",
      "loss in epoch 2 , step 12940 : 1.789129\n",
      "loss in epoch 2 , step 12960 : 1.511416\n",
      "loss in epoch 2 , step 12980 : 2.320758\n",
      "loss in epoch 2 , step 13000 : 1.815650\n",
      "loss in epoch 2 , step 13020 : 1.908001\n",
      "loss in epoch 2 , step 13040 : 2.380805\n",
      "loss in epoch 2 , step 13060 : 1.988789\n",
      "loss in epoch 2 , step 13080 : 2.013193\n",
      "loss in epoch 2 , step 13100 : 1.100389\n",
      "loss in epoch 2 , step 13120 : 1.412227\n",
      "loss in epoch 2 , step 13140 : 1.713856\n",
      "loss in epoch 2 , step 13160 : 1.911305\n",
      "loss in epoch 2 , step 13180 : 0.452457\n",
      "loss in epoch 2 , step 13200 : 0.859110\n",
      "loss in epoch 2 , step 13220 : 1.202240\n",
      "loss in epoch 2 , step 13240 : 2.491733\n",
      "loss in epoch 2 , step 13260 : 2.058555\n",
      "loss in epoch 2 , step 13280 : 1.754137\n",
      "loss in epoch 2 , step 13300 : 1.620252\n",
      "loss in epoch 2 , step 13320 : 1.847973\n",
      "loss in epoch 2 , step 13340 : 1.584744\n",
      "loss in epoch 2 , step 13360 : 1.919437\n",
      "loss in epoch 2 , step 13380 : 2.209949\n",
      "loss in epoch 2 , step 13400 : 1.925954\n",
      "loss in epoch 2 , step 13420 : 1.495775\n",
      "loss in epoch 2 , step 13440 : 1.548595\n",
      "loss in epoch 2 , step 13460 : 1.297380\n",
      "loss in epoch 2 , step 13480 : 2.141809\n",
      "loss in epoch 2 , step 13500 : 1.473621\n",
      "loss in epoch 2 , step 13520 : 1.347294\n",
      "loss in epoch 2 , step 13540 : 2.755227\n",
      "loss in epoch 2 , step 13560 : 0.951151\n",
      "loss in epoch 2 , step 13580 : 2.029996\n",
      "loss in epoch 2 , step 13600 : 1.888058\n",
      "loss in epoch 2 , step 13620 : 1.891946\n",
      "loss in epoch 2 , step 13640 : 1.380711\n",
      "loss in epoch 2 , step 13660 : 1.312118\n",
      "loss in epoch 2 , step 13680 : 1.771703\n",
      "loss in epoch 2 , step 13700 : 1.849155\n",
      "loss in epoch 2 , step 13720 : 1.144984\n",
      "loss in epoch 2 , step 13740 : 1.941168\n",
      "loss in epoch 2 , step 13760 : 2.480041\n",
      "loss in epoch 2 , step 13780 : 1.211376\n",
      "loss in epoch 2 , step 13800 : 1.976272\n",
      "loss in epoch 2 , step 13820 : 1.672817\n",
      "loss in epoch 2 , step 13840 : 2.271982\n",
      "loss in epoch 2 , step 13860 : 1.638485\n",
      "loss in epoch 2 , step 13880 : 1.768795\n",
      "loss in epoch 2 , step 13900 : 1.091693\n",
      "loss in epoch 2 , step 13920 : 1.392490\n",
      "loss in epoch 2 , step 13940 : 2.052223\n",
      "loss in epoch 2 , step 13960 : 0.499295\n",
      "loss in epoch 2 , step 13980 : 1.877862\n",
      "loss in epoch 2 , step 14000 : 1.571212\n",
      "loss in epoch 2 , step 14020 : 2.089149\n",
      "loss in epoch 2 , step 14040 : 1.629531\n",
      "loss in epoch 2 , step 14060 : 2.289902\n",
      "loss in epoch 2 , step 14080 : 0.462936\n",
      "loss in epoch 2 , step 14100 : 1.612380\n",
      "loss in epoch 2 , step 14120 : 1.177814\n",
      "loss in epoch 2 , step 14140 : 3.701607\n",
      "loss in epoch 2 , step 14160 : 0.761017\n",
      "loss in epoch 2 , step 14180 : 0.696078\n",
      "loss in epoch 2 , step 14200 : 1.476752\n",
      "loss in epoch 2 , step 14220 : 2.173559\n",
      "loss in epoch 2 , step 14240 : 0.937766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 2 , step 14260 : 1.720047\n",
      "loss in epoch 2 , step 14280 : 2.060318\n",
      "loss in epoch 2 , step 14300 : 0.947344\n",
      "loss in epoch 2 , step 14320 : 1.502036\n",
      "loss in epoch 2 , step 14340 : 1.867945\n",
      "loss in epoch 2 , step 14360 : 1.620453\n",
      "loss in epoch 2 , step 14380 : 1.510002\n",
      "loss in epoch 2 , step 14400 : 2.009359\n",
      "loss in epoch 2 , step 14420 : 1.255248\n",
      "loss in epoch 2 , step 14440 : 2.145730\n",
      "loss in epoch 2 , step 14460 : 1.136165\n",
      "loss in epoch 2 , step 14480 : 1.285668\n",
      "loss in epoch 2 , step 14500 : 1.462399\n",
      "loss in epoch 2 , step 14520 : 1.681932\n",
      "loss in epoch 2 , step 14540 : 1.995345\n",
      "loss in epoch 2 , step 14560 : 1.205549\n",
      "loss in epoch 2 , step 14580 : 1.859239\n",
      "loss in epoch 2 , step 14600 : 1.738952\n",
      "loss in epoch 2 , step 14620 : 1.183841\n",
      "loss in epoch 2 , step 14640 : 1.494582\n",
      "loss in epoch 2 , step 14660 : 1.311431\n",
      "loss in epoch 2 , step 14680 : 0.602338\n",
      "loss in epoch 2 , step 14700 : 0.858233\n",
      "loss in epoch 2 , step 14720 : 1.424172\n",
      "loss in epoch 2 , step 14740 : 1.500784\n",
      "loss in epoch 2 , step 14760 : 1.999653\n",
      "loss in epoch 2 , step 14780 : 1.231789\n",
      "loss in epoch 2 , step 14800 : 1.433046\n",
      "loss in epoch 2 , step 14820 : 2.130070\n",
      "loss in epoch 2 , step 14840 : 2.042985\n",
      "loss in epoch 2 , step 14860 : 1.602024\n",
      "loss in epoch 2 , step 14880 : 1.681661\n",
      "loss in epoch 2 , step 14900 : 1.230973\n",
      "loss in epoch 2 , step 14920 : 1.248251\n",
      "loss in epoch 2 , step 14940 : 2.618731\n",
      "loss in epoch 2 , step 14960 : 1.052508\n",
      "loss in epoch 2 , step 14980 : 1.690481\n",
      "loss in epoch 2 , step 15000 : 1.400602\n",
      "loss in epoch 2 , step 15020 : 1.727190\n",
      "loss in epoch 2 , step 15040 : 1.717628\n",
      "loss in epoch 2 , step 15060 : 1.447948\n",
      "loss in epoch 2 , step 15080 : 1.367079\n",
      "loss in epoch 2 , step 15100 : 1.766336\n",
      "loss in epoch 2 , step 15120 : 1.794165\n",
      "loss in epoch 2 , step 15140 : 1.255589\n",
      "loss in epoch 2 , step 15160 : 1.776003\n",
      "loss in epoch 2 , step 15180 : 2.213536\n",
      "loss in epoch 2 , step 15200 : 1.688435\n",
      "loss in epoch 2 , step 15220 : 0.959504\n",
      "loss in epoch 2 , step 15240 : 1.590536\n",
      "loss in epoch 2 , step 15260 : 1.490870\n",
      "loss in epoch 2 , step 15280 : 1.381428\n",
      "loss in epoch 2 , step 15300 : 1.607563\n",
      "loss in epoch 2 , step 15320 : 2.112525\n",
      "loss in epoch 2 , step 15340 : 2.251913\n",
      "loss in epoch 2 , step 15360 : 1.015543\n",
      "loss in epoch 2 , step 15380 : 1.476881\n",
      "loss in epoch 2 , step 15400 : 2.021677\n",
      "loss in epoch 2 , step 15420 : 1.986293\n",
      "loss in epoch 2 , step 15440 : 1.855451\n",
      "loss in epoch 2 , step 15460 : 3.640686\n",
      "loss in epoch 2 , step 15480 : 1.998046\n",
      "loss in epoch 2 , step 15500 : 1.969653\n",
      "loss in epoch 2 , step 15520 : 1.929957\n",
      "loss in epoch 2 , step 15540 : 2.011814\n",
      "loss in epoch 2 , step 15560 : 1.863848\n",
      "loss in epoch 2 , step 15580 : 1.256602\n",
      "loss in epoch 2 , step 15600 : 2.116230\n",
      "loss in epoch 2 , step 15620 : 2.265332\n",
      "loss in epoch 2 , step 15640 : 1.138880\n",
      "loss in epoch 2 , step 15660 : 1.161200\n",
      "loss in epoch 2 , step 15680 : 2.347952\n",
      "loss in epoch 2 , step 15700 : 2.006520\n",
      "loss in epoch 2 , step 15720 : 1.632917\n",
      "loss in epoch 2 , step 15740 : 0.713996\n",
      "loss in epoch 2 , step 15760 : 1.737264\n",
      "loss in epoch 2 , step 15780 : 1.185554\n",
      "loss in epoch 2 , step 15800 : 2.593388\n",
      "loss in epoch 2 , step 15820 : 2.134718\n",
      "loss in epoch 2 , step 15840 : 1.702695\n",
      "loss in epoch 2 , step 15860 : 1.469420\n",
      "loss in epoch 2 , step 15880 : 2.312561\n",
      "loss in epoch 2 , step 15900 : 1.326804\n",
      "loss in epoch 2 , step 15920 : 2.076913\n",
      "loss in epoch 2 , step 15940 : 2.055135\n",
      "loss in epoch 2 , step 15960 : 1.933658\n",
      "loss in epoch 2 , step 15980 : 1.381730\n",
      "loss in epoch 2 , step 16000 : 1.305587\n",
      "loss in epoch 2 , step 16020 : 1.810562\n",
      "loss in epoch 2 , step 16040 : 0.266937\n",
      "loss in epoch 2 , step 16060 : 1.384566\n",
      "loss in epoch 2 , step 16080 : 0.735682\n",
      "loss in epoch 2 , step 16100 : 1.942438\n",
      "loss in epoch 2 , step 16120 : 1.446985\n",
      "loss in epoch 2 , step 16140 : 2.670515\n",
      "loss in epoch 2 , step 16160 : 2.264894\n",
      "loss in epoch 2 , step 16180 : 1.605112\n",
      "loss in epoch 2 , step 16200 : 1.355260\n",
      "loss in epoch 2 , step 16220 : 1.465874\n",
      "loss in epoch 2 , step 16240 : 1.661241\n",
      "loss in epoch 2 , step 16260 : 1.154640\n",
      "loss in epoch 2 , step 16280 : 1.168757\n",
      "loss in epoch 2 , step 16300 : 2.255102\n",
      "loss in epoch 2 , step 16320 : 1.446814\n",
      "loss in epoch 2 , step 16340 : 1.998990\n",
      "loss in epoch 2 , step 16360 : 1.473168\n",
      "loss in epoch 2 , step 16380 : 1.677774\n",
      "loss in epoch 2 , step 16400 : 1.568525\n",
      "loss in epoch 2 , step 16420 : 1.869545\n",
      "loss in epoch 2 , step 16440 : 2.161824\n",
      "loss in epoch 2 , step 16460 : 1.686482\n",
      "loss in epoch 2 , step 16480 : 1.664014\n",
      "loss in epoch 2 , step 16500 : 1.751699\n",
      "loss in epoch 2 , step 16520 : 2.192450\n",
      "loss in epoch 2 , step 16540 : 2.096824\n",
      "loss in epoch 2 , step 16560 : 1.826447\n",
      "loss in epoch 2 , step 16580 : 1.281235\n",
      "loss in epoch 2 , step 16600 : 1.850149\n",
      "loss in epoch 2 , step 16620 : 1.420603\n",
      "loss in epoch 2 , step 16640 : 2.830357\n",
      "loss in epoch 2 , step 16660 : 1.849411\n",
      "loss in epoch 2 , step 16680 : 1.856927\n",
      "loss in epoch 2 , step 16700 : 1.862169\n",
      "loss in epoch 2 , step 16720 : 1.808229\n",
      "loss in epoch 2 , step 16740 : 1.632352\n",
      "loss in epoch 2 , step 16760 : 1.382508\n",
      "loss in epoch 2 , step 16780 : 1.479165\n",
      "loss in epoch 2 , step 16800 : 1.978843\n",
      "loss in epoch 2 , step 16820 : 1.740635\n",
      "loss in epoch 2 , step 16840 : 1.491842\n",
      "loss in epoch 2 , step 16860 : 1.899439\n",
      "loss in epoch 2 , step 16880 : 2.484245\n",
      "loss in epoch 2 , step 16900 : 0.959529\n",
      "loss in epoch 2 , step 16920 : 1.855797\n",
      "loss in epoch 2 , step 16940 : 1.009644\n",
      "loss in epoch 2 , step 16960 : 1.607111\n",
      "loss in epoch 2 , step 16980 : 1.673752\n",
      "loss in epoch 2 , step 17000 : 0.972213\n",
      "loss in epoch 2 , step 17020 : 1.827651\n",
      "loss in epoch 2 , step 17040 : 1.773604\n",
      "loss in epoch 2 , step 17060 : 1.597022\n",
      "loss in epoch 2 , step 17080 : 1.596026\n",
      "loss in epoch 2 , step 17100 : 1.720954\n",
      "loss in epoch 2 , step 17120 : 1.849566\n",
      "loss in epoch 2 , step 17140 : 1.417301\n",
      "loss in epoch 2 , step 17160 : 1.922974\n",
      "loss in epoch 2 , step 17180 : 1.841493\n",
      "loss in epoch 2 , step 17200 : 1.257981\n",
      "loss in epoch 2 , step 17220 : 0.309919\n",
      "loss in epoch 2 , step 17240 : 1.640237\n",
      "loss in epoch 2 , step 17260 : 1.705610\n",
      "loss in epoch 2 , step 17280 : 1.294083\n",
      "loss in epoch 2 , step 17300 : 1.919920\n",
      "loss in epoch 2 , step 17320 : 1.641243\n",
      "loss in epoch 2 , step 17340 : 1.484987\n",
      "loss in epoch 2 , step 17360 : 1.348353\n",
      "loss in epoch 2 , step 17380 : 0.910910\n",
      "loss in epoch 2 , step 17400 : 1.765491\n",
      "loss in epoch 2 , step 17420 : 1.693485\n",
      "loss in epoch 2 , step 17440 : 1.518386\n",
      "loss in epoch 2 , step 17460 : 1.861392\n",
      "loss in epoch 2 , step 17480 : 0.618316\n",
      "loss in epoch 2 , step 17500 : 1.393619\n",
      "loss in epoch 2 , step 17520 : 2.926127\n",
      "loss in epoch 2 , step 17540 : 1.232306\n",
      "loss in epoch 2 , step 17560 : 1.449122\n",
      "loss in epoch 2 , step 17580 : 2.278618\n",
      "loss in epoch 2 , step 17600 : 0.715519\n",
      "loss in epoch 2 , step 17620 : 1.308228\n",
      "loss in epoch 2 , step 17640 : 3.540941\n",
      "loss in epoch 2 , step 17660 : 1.928420\n",
      "loss in epoch 2 , step 17680 : 1.909880\n",
      "loss in epoch 2 , step 17700 : 1.712947\n",
      "loss in epoch 2 , step 17720 : 1.500677\n",
      "loss in epoch 2 , step 17740 : 1.661947\n",
      "loss in epoch 2 , step 17760 : 1.516669\n",
      "loss in epoch 2 , step 17780 : 1.156938\n",
      "loss in epoch 2 , step 17800 : 1.343120\n",
      "loss in epoch 2 , step 17820 : 1.808052\n",
      "loss in epoch 2 , step 17840 : 1.136186\n",
      "loss in epoch 2 , step 17860 : 0.359861\n",
      "loss in epoch 2 , step 17880 : 2.213515\n",
      "loss in epoch 2 , step 17900 : 0.896378\n",
      "loss in epoch 2 , step 17920 : 1.512174\n",
      "loss in epoch 2 , step 17940 : 1.323922\n",
      "loss in epoch 2 , step 17960 : 2.075868\n",
      "loss in epoch 2 , step 17980 : 2.227132\n",
      "loss in epoch 2 , step 18000 : 1.759039\n",
      "loss in epoch 2 , step 18020 : 1.770413\n",
      "loss in epoch 2 , step 18040 : 1.676941\n",
      "loss in epoch 2 , step 18060 : 0.846115\n",
      "loss in epoch 2 , step 18080 : 1.806211\n",
      "loss in epoch 2 , step 18100 : 1.545455\n",
      "loss in epoch 2 , step 18120 : 1.365578\n",
      "loss in epoch 2 , step 18140 : 2.167277\n",
      "loss in epoch 2 , step 18160 : 1.308449\n",
      "loss in epoch 2 , step 18180 : 1.389048\n",
      "loss in epoch 2 , step 18200 : 1.348134\n",
      "loss in epoch 2 , step 18220 : 2.438658\n",
      "loss in epoch 2 , step 18240 : 1.829920\n",
      "loss in epoch 2 , step 18260 : 1.748689\n",
      "loss in epoch 2 , step 18280 : 1.508900\n",
      "loss in epoch 2 , step 18300 : 1.622404\n",
      "loss in epoch 2 , step 18320 : 1.950774\n",
      "loss in epoch 2 , step 18340 : 0.961682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 2 , step 18360 : 1.660063\n",
      "loss in epoch 2 , step 18380 : 2.510876\n",
      "loss in epoch 2 , step 18400 : 0.874780\n",
      "loss in epoch 2 , step 18420 : 1.675290\n",
      "loss in epoch 2 , step 18440 : 1.336518\n",
      "loss in epoch 2 , step 18460 : 1.460240\n",
      "loss in epoch 2 , step 18480 : 1.519002\n",
      "loss in epoch 2 , step 18500 : 2.457982\n",
      "loss in epoch 2 , step 18520 : 2.410114\n",
      "loss in epoch 2 , step 18540 : 1.360911\n",
      "loss in epoch 2 , step 18560 : 1.957696\n",
      "loss in epoch 2 , step 18580 : 1.368500\n",
      "loss in epoch 2 , step 18600 : 1.908625\n",
      "loss in epoch 2 , step 18620 : 2.225527\n",
      "loss in epoch 2 , step 18640 : 1.794998\n",
      "loss in epoch 2 , step 18660 : 0.714956\n",
      "loss in epoch 2 , step 18680 : 0.875301\n",
      "loss in epoch 2 , step 18700 : 1.858063\n",
      "loss in epoch 2 , step 18720 : 1.865034\n",
      "loss in epoch 2 , step 18740 : 1.235646\n",
      "loss in epoch 2 , step 18760 : 2.309448\n",
      "loss in epoch 2 , step 18780 : 1.998142\n",
      "loss in epoch 2 , step 18800 : 1.226004\n",
      "loss in epoch 2 , step 18820 : 1.426969\n",
      "loss in epoch 2 , step 18840 : 1.732472\n",
      "loss in epoch 2 , step 18860 : 1.758772\n",
      "loss in epoch 2 , step 18880 : 2.142678\n",
      "loss in epoch 2 , step 18900 : 1.955443\n",
      "loss in epoch 2 , step 18920 : 1.537462\n",
      "loss in epoch 2 , step 18940 : 1.304922\n",
      "loss in epoch 2 , step 18960 : 0.923265\n",
      "loss in epoch 2 , step 18980 : 2.332886\n",
      "loss in epoch 2 , step 19000 : 1.234087\n",
      "loss in epoch 2 , step 19020 : 1.481984\n",
      "loss in epoch 2 , step 19040 : 1.369923\n",
      "loss in epoch 2 , step 19060 : 1.398532\n",
      "loss in epoch 2 , step 19080 : 1.268671\n",
      "loss in epoch 2 , step 19100 : 1.459925\n",
      "loss in epoch 2 , step 19120 : 2.481900\n",
      "loss in epoch 2 , step 19140 : 2.046747\n",
      "loss in epoch 2 , step 19160 : 1.578304\n",
      "loss in epoch 2 , step 19180 : 2.122752\n",
      "loss in epoch 2 , step 19200 : 1.827589\n",
      "loss in epoch 2 , step 19220 : 1.178365\n",
      "loss in epoch 2 , step 19240 : 1.727533\n",
      "loss in epoch 2 , step 19260 : 1.788717\n",
      "loss in epoch 2 , step 19280 : 2.507907\n",
      "loss in epoch 2 , step 19300 : 1.309254\n",
      "loss in epoch 2 , step 19320 : 1.084624\n",
      "loss in epoch 2 , step 19340 : 1.232886\n",
      "loss in epoch 2 , step 19360 : 1.274427\n",
      "loss in epoch 2 , step 19380 : 1.562061\n",
      "loss in epoch 2 , step 19400 : 1.405089\n",
      "loss in epoch 2 , step 19420 : 1.899788\n",
      "loss in epoch 2 , step 19440 : 1.066630\n",
      "loss in epoch 2 , step 19460 : 1.335960\n",
      "loss in epoch 2 , step 19480 : 1.020767\n",
      "loss in epoch 2 , step 19500 : 1.747606\n",
      "loss in epoch 2 , step 19520 : 2.164603\n",
      "loss in epoch 2 , step 19540 : 2.594232\n",
      "loss in epoch 2 , step 19560 : 1.563764\n",
      "loss in epoch 2 , step 19580 : 1.989541\n",
      "loss in epoch 2 , step 19600 : 0.847145\n",
      "loss in epoch 2 , step 19620 : 1.544261\n",
      "loss in epoch 2 , step 19640 : 2.150331\n",
      "loss in epoch 2 , step 19660 : 1.283695\n",
      "loss in epoch 2 , step 19680 : 1.729701\n",
      "loss in epoch 2 , step 19700 : 1.212241\n",
      "loss in epoch 2 , step 19720 : 1.843467\n",
      "loss in epoch 2 , step 19740 : 1.259391\n",
      "loss in epoch 2 , step 19760 : 1.178000\n",
      "loss in epoch 2 , step 19780 : 2.417205\n",
      "loss in epoch 2 , step 19800 : 1.520636\n",
      "loss in epoch 2 , step 19820 : 1.936622\n",
      "loss in epoch 2 , step 19840 : 1.630169\n",
      "loss in epoch 2 , step 19860 : 0.935743\n",
      "loss in epoch 2 , step 19880 : 1.712903\n",
      "loss in epoch 2 , step 19900 : 1.951502\n",
      "loss in epoch 2 , step 19920 : 1.354406\n",
      "loss in epoch 2 , step 19940 : 1.286171\n",
      "Accuracy in epoch 2 : 17.147192\n",
      "loss in epoch 3 , step 0 : 1.851818\n",
      "loss in epoch 3 , step 20 : 1.447547\n",
      "loss in epoch 3 , step 40 : 2.081080\n",
      "loss in epoch 3 , step 60 : 1.899330\n",
      "loss in epoch 3 , step 80 : 1.519961\n",
      "loss in epoch 3 , step 100 : 1.304232\n",
      "loss in epoch 3 , step 120 : 1.679443\n",
      "loss in epoch 3 , step 140 : 2.087386\n",
      "loss in epoch 3 , step 160 : 0.602279\n",
      "loss in epoch 3 , step 180 : 2.039375\n",
      "loss in epoch 3 , step 200 : 0.928496\n",
      "loss in epoch 3 , step 220 : 0.789538\n",
      "loss in epoch 3 , step 240 : 1.920131\n",
      "loss in epoch 3 , step 260 : 1.678993\n",
      "loss in epoch 3 , step 280 : 0.966942\n",
      "loss in epoch 3 , step 300 : 2.057482\n",
      "loss in epoch 3 , step 320 : 1.844523\n",
      "loss in epoch 3 , step 340 : 1.186415\n",
      "loss in epoch 3 , step 360 : 2.223754\n",
      "loss in epoch 3 , step 380 : 1.070607\n",
      "loss in epoch 3 , step 400 : 1.795615\n",
      "loss in epoch 3 , step 420 : 1.490061\n",
      "loss in epoch 3 , step 440 : 1.984598\n",
      "loss in epoch 3 , step 460 : 1.415706\n",
      "loss in epoch 3 , step 480 : 2.175113\n",
      "loss in epoch 3 , step 500 : 1.315816\n",
      "loss in epoch 3 , step 520 : 0.846640\n",
      "loss in epoch 3 , step 540 : 1.383114\n",
      "loss in epoch 3 , step 560 : 1.562814\n",
      "loss in epoch 3 , step 580 : 1.737275\n",
      "loss in epoch 3 , step 600 : 1.695724\n",
      "loss in epoch 3 , step 620 : 1.826318\n",
      "loss in epoch 3 , step 640 : 1.661301\n",
      "loss in epoch 3 , step 660 : 1.442579\n",
      "loss in epoch 3 , step 680 : 1.676730\n",
      "loss in epoch 3 , step 700 : 1.369822\n",
      "loss in epoch 3 , step 720 : 1.234574\n",
      "loss in epoch 3 , step 740 : 1.525030\n",
      "loss in epoch 3 , step 760 : 1.836568\n",
      "loss in epoch 3 , step 780 : 1.531054\n",
      "loss in epoch 3 , step 800 : 1.008835\n",
      "loss in epoch 3 , step 820 : 2.196845\n",
      "loss in epoch 3 , step 840 : 1.935534\n",
      "loss in epoch 3 , step 860 : 1.917967\n",
      "loss in epoch 3 , step 880 : 0.886243\n",
      "loss in epoch 3 , step 900 : 2.507487\n",
      "loss in epoch 3 , step 920 : 1.173278\n",
      "loss in epoch 3 , step 940 : 0.621528\n",
      "loss in epoch 3 , step 960 : 0.823288\n",
      "loss in epoch 3 , step 980 : 1.273355\n",
      "loss in epoch 3 , step 1000 : 1.609212\n",
      "loss in epoch 3 , step 1020 : 0.808549\n",
      "loss in epoch 3 , step 1040 : 1.695868\n",
      "loss in epoch 3 , step 1060 : 1.640954\n",
      "loss in epoch 3 , step 1080 : 1.275866\n",
      "loss in epoch 3 , step 1100 : 1.585083\n",
      "loss in epoch 3 , step 1120 : 1.860770\n",
      "loss in epoch 3 , step 1140 : 1.640127\n",
      "loss in epoch 3 , step 1160 : 1.969247\n",
      "loss in epoch 3 , step 1180 : 1.189471\n",
      "loss in epoch 3 , step 1200 : 2.291135\n",
      "loss in epoch 3 , step 1220 : 1.566684\n",
      "loss in epoch 3 , step 1240 : 1.530817\n",
      "loss in epoch 3 , step 1260 : 0.455494\n",
      "loss in epoch 3 , step 1280 : 2.236890\n",
      "loss in epoch 3 , step 1300 : 1.506326\n",
      "loss in epoch 3 , step 1320 : 1.882859\n",
      "loss in epoch 3 , step 1340 : 1.726874\n",
      "loss in epoch 3 , step 1360 : 0.571973\n",
      "loss in epoch 3 , step 1380 : 1.840795\n",
      "loss in epoch 3 , step 1400 : 2.328402\n",
      "loss in epoch 3 , step 1420 : 1.087385\n",
      "loss in epoch 3 , step 1440 : 2.223823\n",
      "loss in epoch 3 , step 1460 : 1.580455\n",
      "loss in epoch 3 , step 1480 : 2.019126\n",
      "loss in epoch 3 , step 1500 : 2.199425\n",
      "loss in epoch 3 , step 1520 : 2.039487\n",
      "loss in epoch 3 , step 1540 : 2.045724\n",
      "loss in epoch 3 , step 1560 : 1.766425\n",
      "loss in epoch 3 , step 1580 : 1.605125\n",
      "loss in epoch 3 , step 1600 : 1.128721\n",
      "loss in epoch 3 , step 1620 : 1.712082\n",
      "loss in epoch 3 , step 1640 : 2.064052\n",
      "loss in epoch 3 , step 1660 : 1.570772\n",
      "loss in epoch 3 , step 1680 : 2.271165\n",
      "loss in epoch 3 , step 1700 : 1.193933\n",
      "loss in epoch 3 , step 1720 : 2.174022\n",
      "loss in epoch 3 , step 1740 : 1.861016\n",
      "loss in epoch 3 , step 1760 : 1.554261\n",
      "loss in epoch 3 , step 1780 : 0.946941\n",
      "loss in epoch 3 , step 1800 : 2.755167\n",
      "loss in epoch 3 , step 1820 : 1.780683\n",
      "loss in epoch 3 , step 1840 : 1.651868\n",
      "loss in epoch 3 , step 1860 : 1.840742\n",
      "loss in epoch 3 , step 1880 : 1.405244\n",
      "loss in epoch 3 , step 1900 : 1.061970\n",
      "loss in epoch 3 , step 1920 : 1.189552\n",
      "loss in epoch 3 , step 1940 : 2.666404\n",
      "loss in epoch 3 , step 1960 : 1.988289\n",
      "loss in epoch 3 , step 1980 : 1.722849\n",
      "loss in epoch 3 , step 2000 : 0.909880\n",
      "loss in epoch 3 , step 2020 : 2.309597\n",
      "loss in epoch 3 , step 2040 : 1.801624\n",
      "loss in epoch 3 , step 2060 : 1.843402\n",
      "loss in epoch 3 , step 2080 : 2.060794\n",
      "loss in epoch 3 , step 2100 : 1.404708\n",
      "loss in epoch 3 , step 2120 : 1.098159\n",
      "loss in epoch 3 , step 2140 : 1.788104\n",
      "loss in epoch 3 , step 2160 : 0.650633\n",
      "loss in epoch 3 , step 2180 : 2.444090\n",
      "loss in epoch 3 , step 2200 : 1.674323\n",
      "loss in epoch 3 , step 2220 : 1.581877\n",
      "loss in epoch 3 , step 2240 : 0.637728\n",
      "loss in epoch 3 , step 2260 : 2.091562\n",
      "loss in epoch 3 , step 2280 : 1.939232\n",
      "loss in epoch 3 , step 2300 : 1.279840\n",
      "loss in epoch 3 , step 2320 : 1.847647\n",
      "loss in epoch 3 , step 2340 : 1.503533\n",
      "loss in epoch 3 , step 2360 : 1.781250\n",
      "loss in epoch 3 , step 2380 : 2.398873\n",
      "loss in epoch 3 , step 2400 : 1.740844\n",
      "loss in epoch 3 , step 2420 : 1.395631\n",
      "loss in epoch 3 , step 2440 : 0.997097\n",
      "loss in epoch 3 , step 2460 : 1.705422\n",
      "loss in epoch 3 , step 2480 : 0.574205\n",
      "loss in epoch 3 , step 2500 : 1.478534\n",
      "loss in epoch 3 , step 2520 : 0.835094\n",
      "loss in epoch 3 , step 2540 : 1.805766\n",
      "loss in epoch 3 , step 2560 : 1.292265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 3 , step 2580 : 2.040175\n",
      "loss in epoch 3 , step 2600 : 0.968905\n",
      "loss in epoch 3 , step 2620 : 1.657992\n",
      "loss in epoch 3 , step 2640 : 2.041595\n",
      "loss in epoch 3 , step 2660 : 1.472276\n",
      "loss in epoch 3 , step 2680 : 1.833767\n",
      "loss in epoch 3 , step 2700 : 1.800171\n",
      "loss in epoch 3 , step 2720 : 2.037001\n",
      "loss in epoch 3 , step 2740 : 1.632744\n",
      "loss in epoch 3 , step 2760 : 1.739887\n",
      "loss in epoch 3 , step 2780 : 1.335166\n",
      "loss in epoch 3 , step 2800 : 1.279540\n",
      "loss in epoch 3 , step 2820 : 1.599239\n",
      "loss in epoch 3 , step 2840 : 1.727294\n",
      "loss in epoch 3 , step 2860 : 2.632458\n",
      "loss in epoch 3 , step 2880 : 1.727546\n",
      "loss in epoch 3 , step 2900 : 2.073901\n",
      "loss in epoch 3 , step 2920 : 1.399868\n",
      "loss in epoch 3 , step 2940 : 0.935194\n",
      "loss in epoch 3 , step 2960 : 1.967818\n",
      "loss in epoch 3 , step 2980 : 1.206624\n",
      "loss in epoch 3 , step 3000 : 0.608827\n",
      "loss in epoch 3 , step 3020 : 3.175704\n",
      "loss in epoch 3 , step 3040 : 0.909135\n",
      "loss in epoch 3 , step 3060 : 1.388133\n",
      "loss in epoch 3 , step 3080 : 1.882769\n",
      "loss in epoch 3 , step 3100 : 1.191124\n",
      "loss in epoch 3 , step 3120 : 2.026620\n",
      "loss in epoch 3 , step 3140 : 0.733898\n",
      "loss in epoch 3 , step 3160 : 1.087792\n",
      "loss in epoch 3 , step 3180 : 2.192211\n",
      "loss in epoch 3 , step 3200 : 1.460960\n",
      "loss in epoch 3 , step 3220 : 1.826226\n",
      "loss in epoch 3 , step 3240 : 1.896672\n",
      "loss in epoch 3 , step 3260 : 1.600466\n",
      "loss in epoch 3 , step 3280 : 2.383589\n",
      "loss in epoch 3 , step 3300 : 1.945629\n",
      "loss in epoch 3 , step 3320 : 1.825273\n",
      "loss in epoch 3 , step 3340 : 1.651978\n",
      "loss in epoch 3 , step 3360 : 2.290023\n",
      "loss in epoch 3 , step 3380 : 1.781553\n",
      "loss in epoch 3 , step 3400 : 1.359034\n",
      "loss in epoch 3 , step 3420 : 1.323609\n",
      "loss in epoch 3 , step 3440 : 1.585828\n",
      "loss in epoch 3 , step 3460 : 0.508558\n",
      "loss in epoch 3 , step 3480 : 0.306912\n",
      "loss in epoch 3 , step 3500 : 1.258588\n",
      "loss in epoch 3 , step 3520 : 1.971903\n",
      "loss in epoch 3 , step 3540 : 1.093502\n",
      "loss in epoch 3 , step 3560 : 3.030530\n",
      "loss in epoch 3 , step 3580 : 1.070627\n",
      "loss in epoch 3 , step 3600 : 2.669268\n",
      "loss in epoch 3 , step 3620 : 1.735116\n",
      "loss in epoch 3 , step 3640 : 2.478363\n",
      "loss in epoch 3 , step 3660 : 0.464736\n",
      "loss in epoch 3 , step 3680 : 1.511437\n",
      "loss in epoch 3 , step 3700 : 1.801170\n",
      "loss in epoch 3 , step 3720 : 0.905336\n",
      "loss in epoch 3 , step 3740 : 0.794688\n",
      "loss in epoch 3 , step 3760 : 1.245377\n",
      "loss in epoch 3 , step 3780 : 1.026737\n",
      "loss in epoch 3 , step 3800 : 1.878898\n",
      "loss in epoch 3 , step 3820 : 1.556661\n",
      "loss in epoch 3 , step 3840 : 1.349827\n",
      "loss in epoch 3 , step 3860 : 1.220847\n",
      "loss in epoch 3 , step 3880 : 1.018217\n",
      "loss in epoch 3 , step 3900 : 1.394093\n",
      "loss in epoch 3 , step 3920 : 0.657126\n",
      "loss in epoch 3 , step 3940 : 1.424558\n",
      "loss in epoch 3 , step 3960 : 0.690675\n",
      "loss in epoch 3 , step 3980 : 0.920022\n",
      "loss in epoch 3 , step 4000 : 1.196574\n",
      "loss in epoch 3 , step 4020 : 1.541129\n",
      "loss in epoch 3 , step 4040 : 2.153058\n",
      "loss in epoch 3 , step 4060 : 1.668078\n",
      "loss in epoch 3 , step 4080 : 2.527679\n",
      "loss in epoch 3 , step 4100 : 1.707368\n",
      "loss in epoch 3 , step 4120 : 1.256791\n",
      "loss in epoch 3 , step 4140 : 1.374619\n",
      "loss in epoch 3 , step 4160 : 1.580477\n",
      "loss in epoch 3 , step 4180 : 0.949567\n",
      "loss in epoch 3 , step 4200 : 2.280965\n",
      "loss in epoch 3 , step 4220 : 1.955102\n",
      "loss in epoch 3 , step 4240 : 1.116915\n",
      "loss in epoch 3 , step 4260 : 1.640435\n",
      "loss in epoch 3 , step 4280 : 2.280546\n",
      "loss in epoch 3 , step 4300 : 1.522914\n",
      "loss in epoch 3 , step 4320 : 1.782285\n",
      "loss in epoch 3 , step 4340 : 0.982349\n",
      "loss in epoch 3 , step 4360 : 0.852532\n",
      "loss in epoch 3 , step 4380 : 1.716373\n",
      "loss in epoch 3 , step 4400 : 1.071222\n",
      "loss in epoch 3 , step 4420 : 1.972613\n",
      "loss in epoch 3 , step 4440 : 2.193746\n",
      "loss in epoch 3 , step 4460 : 1.516668\n",
      "loss in epoch 3 , step 4480 : 1.791519\n",
      "loss in epoch 3 , step 4500 : 2.104049\n",
      "loss in epoch 3 , step 4520 : 0.871752\n",
      "loss in epoch 3 , step 4540 : 1.213097\n",
      "loss in epoch 3 , step 4560 : 1.346328\n",
      "loss in epoch 3 , step 4580 : 1.094422\n",
      "loss in epoch 3 , step 4600 : 1.194281\n",
      "loss in epoch 3 , step 4620 : 0.450015\n",
      "loss in epoch 3 , step 4640 : 1.771383\n",
      "loss in epoch 3 , step 4660 : 1.745542\n",
      "loss in epoch 3 , step 4680 : 0.880156\n",
      "loss in epoch 3 , step 4700 : 1.351702\n",
      "loss in epoch 3 , step 4720 : 2.955910\n",
      "loss in epoch 3 , step 4740 : 0.643223\n",
      "loss in epoch 3 , step 4760 : 2.042151\n",
      "loss in epoch 3 , step 4780 : 2.086827\n",
      "loss in epoch 3 , step 4800 : 1.007375\n",
      "loss in epoch 3 , step 4820 : 1.517101\n",
      "loss in epoch 3 , step 4840 : 1.943219\n",
      "loss in epoch 3 , step 4860 : 1.793372\n",
      "loss in epoch 3 , step 4880 : 0.286464\n",
      "loss in epoch 3 , step 4900 : 1.817207\n",
      "loss in epoch 3 , step 4920 : 1.964177\n",
      "loss in epoch 3 , step 4940 : 1.541899\n",
      "loss in epoch 3 , step 4960 : 0.879291\n",
      "loss in epoch 3 , step 4980 : 1.818467\n",
      "loss in epoch 3 , step 5000 : 1.250697\n",
      "loss in epoch 3 , step 5020 : 0.925680\n",
      "loss in epoch 3 , step 5040 : 2.269008\n",
      "loss in epoch 3 , step 5060 : 1.398587\n",
      "loss in epoch 3 , step 5080 : 1.367388\n",
      "loss in epoch 3 , step 5100 : 1.602619\n",
      "loss in epoch 3 , step 5120 : 2.099762\n",
      "loss in epoch 3 , step 5140 : 1.778016\n",
      "loss in epoch 3 , step 5160 : 1.568917\n",
      "loss in epoch 3 , step 5180 : 1.714638\n",
      "loss in epoch 3 , step 5200 : 1.513725\n",
      "loss in epoch 3 , step 5220 : 1.131540\n",
      "loss in epoch 3 , step 5240 : 1.506140\n",
      "loss in epoch 3 , step 5260 : 1.454056\n",
      "loss in epoch 3 , step 5280 : 1.043231\n",
      "loss in epoch 3 , step 5300 : 1.161156\n",
      "loss in epoch 3 , step 5320 : 2.591058\n",
      "loss in epoch 3 , step 5340 : 2.247848\n",
      "loss in epoch 3 , step 5360 : 1.708946\n",
      "loss in epoch 3 , step 5380 : 1.252070\n",
      "loss in epoch 3 , step 5400 : 0.978813\n",
      "loss in epoch 3 , step 5420 : 1.212425\n",
      "loss in epoch 3 , step 5440 : 1.625119\n",
      "loss in epoch 3 , step 5460 : 1.837818\n",
      "loss in epoch 3 , step 5480 : 1.820933\n",
      "loss in epoch 3 , step 5500 : 1.069405\n",
      "loss in epoch 3 , step 5520 : 0.850061\n",
      "loss in epoch 3 , step 5540 : 0.548833\n",
      "loss in epoch 3 , step 5560 : 1.803044\n",
      "loss in epoch 3 , step 5580 : 2.207490\n",
      "loss in epoch 3 , step 5600 : 1.121577\n",
      "loss in epoch 3 , step 5620 : 1.213446\n",
      "loss in epoch 3 , step 5640 : 2.458402\n",
      "loss in epoch 3 , step 5660 : 2.257403\n",
      "loss in epoch 3 , step 5680 : 1.932839\n",
      "loss in epoch 3 , step 5700 : 1.574260\n",
      "loss in epoch 3 , step 5720 : 1.416876\n",
      "loss in epoch 3 , step 5740 : 0.947995\n",
      "loss in epoch 3 , step 5760 : 1.103673\n",
      "loss in epoch 3 , step 5780 : 1.656215\n",
      "loss in epoch 3 , step 5800 : 1.529431\n",
      "loss in epoch 3 , step 5820 : 1.870932\n",
      "loss in epoch 3 , step 5840 : 1.995817\n",
      "loss in epoch 3 , step 5860 : 1.972619\n",
      "loss in epoch 3 , step 5880 : 1.696378\n",
      "loss in epoch 3 , step 5900 : 1.834524\n",
      "loss in epoch 3 , step 5920 : 1.703339\n",
      "loss in epoch 3 , step 5940 : 2.263756\n",
      "loss in epoch 3 , step 5960 : 1.900343\n",
      "loss in epoch 3 , step 5980 : 1.533799\n",
      "loss in epoch 3 , step 6000 : 1.978906\n",
      "loss in epoch 3 , step 6020 : 1.491863\n",
      "loss in epoch 3 , step 6040 : 1.595106\n",
      "loss in epoch 3 , step 6060 : 1.676524\n",
      "loss in epoch 3 , step 6080 : 0.815427\n",
      "loss in epoch 3 , step 6100 : 2.002446\n",
      "loss in epoch 3 , step 6120 : 0.823737\n",
      "loss in epoch 3 , step 6140 : 1.860368\n",
      "loss in epoch 3 , step 6160 : 1.359256\n",
      "loss in epoch 3 , step 6180 : 2.134861\n",
      "loss in epoch 3 , step 6200 : 1.127259\n",
      "loss in epoch 3 , step 6220 : 1.432618\n",
      "loss in epoch 3 , step 6240 : 2.038522\n",
      "loss in epoch 3 , step 6260 : 0.709766\n",
      "loss in epoch 3 , step 6280 : 2.037526\n",
      "loss in epoch 3 , step 6300 : 1.167475\n",
      "loss in epoch 3 , step 6320 : 1.939797\n",
      "loss in epoch 3 , step 6340 : 1.883665\n",
      "loss in epoch 3 , step 6360 : 1.331514\n",
      "loss in epoch 3 , step 6380 : 1.548149\n",
      "loss in epoch 3 , step 6400 : 1.271435\n",
      "loss in epoch 3 , step 6420 : 1.002934\n",
      "loss in epoch 3 , step 6440 : 1.445421\n",
      "loss in epoch 3 , step 6460 : 0.255799\n",
      "loss in epoch 3 , step 6480 : 2.124681\n",
      "loss in epoch 3 , step 6500 : 2.278933\n",
      "loss in epoch 3 , step 6520 : 0.412984\n",
      "loss in epoch 3 , step 6540 : 1.399401\n",
      "loss in epoch 3 , step 6560 : 1.877203\n",
      "loss in epoch 3 , step 6580 : 1.282472\n",
      "loss in epoch 3 , step 6600 : 2.081431\n",
      "loss in epoch 3 , step 6620 : 2.793527\n",
      "loss in epoch 3 , step 6640 : 1.901277\n",
      "loss in epoch 3 , step 6660 : 1.060996\n",
      "loss in epoch 3 , step 6680 : 2.335696\n",
      "loss in epoch 3 , step 6700 : 0.782218\n",
      "loss in epoch 3 , step 6720 : 1.168807\n",
      "loss in epoch 3 , step 6740 : 2.145123\n",
      "loss in epoch 3 , step 6760 : 1.557157\n",
      "loss in epoch 3 , step 6780 : 1.619943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 3 , step 6800 : 1.728413\n",
      "loss in epoch 3 , step 6820 : 2.291707\n",
      "loss in epoch 3 , step 6840 : 1.669113\n",
      "loss in epoch 3 , step 6860 : 1.597598\n",
      "loss in epoch 3 , step 6880 : 1.936468\n",
      "loss in epoch 3 , step 6900 : 0.924761\n",
      "loss in epoch 3 , step 6920 : 2.454184\n",
      "loss in epoch 3 , step 6940 : 1.584230\n",
      "loss in epoch 3 , step 6960 : 1.304176\n",
      "loss in epoch 3 , step 6980 : 1.076725\n",
      "loss in epoch 3 , step 7000 : 2.187280\n",
      "loss in epoch 3 , step 7020 : 1.100058\n",
      "loss in epoch 3 , step 7040 : 2.147213\n",
      "loss in epoch 3 , step 7060 : 2.291916\n",
      "loss in epoch 3 , step 7080 : 1.076283\n",
      "loss in epoch 3 , step 7100 : 1.215049\n",
      "loss in epoch 3 , step 7120 : 1.209239\n",
      "loss in epoch 3 , step 7140 : 1.818491\n",
      "loss in epoch 3 , step 7160 : 1.664529\n",
      "loss in epoch 3 , step 7180 : 2.064195\n",
      "loss in epoch 3 , step 7200 : 1.396039\n",
      "loss in epoch 3 , step 7220 : 1.684500\n",
      "loss in epoch 3 , step 7240 : 1.925728\n",
      "loss in epoch 3 , step 7260 : 1.295338\n",
      "loss in epoch 3 , step 7280 : 1.818729\n",
      "loss in epoch 3 , step 7300 : 1.333982\n",
      "loss in epoch 3 , step 7320 : 1.592510\n",
      "loss in epoch 3 , step 7340 : 1.312279\n",
      "loss in epoch 3 , step 7360 : 2.414176\n",
      "loss in epoch 3 , step 7380 : 0.322464\n",
      "loss in epoch 3 , step 7400 : 2.340061\n",
      "loss in epoch 3 , step 7420 : 1.471317\n",
      "loss in epoch 3 , step 7440 : 2.111384\n",
      "loss in epoch 3 , step 7460 : 1.612348\n",
      "loss in epoch 3 , step 7480 : 1.759641\n",
      "loss in epoch 3 , step 7500 : 1.434578\n",
      "loss in epoch 3 , step 7520 : 0.397583\n",
      "loss in epoch 3 , step 7540 : 1.193739\n",
      "loss in epoch 3 , step 7560 : 0.468191\n",
      "loss in epoch 3 , step 7580 : 0.766486\n",
      "loss in epoch 3 , step 7600 : 1.708174\n",
      "loss in epoch 3 , step 7620 : 1.892928\n",
      "loss in epoch 3 , step 7640 : 0.989095\n",
      "loss in epoch 3 , step 7660 : 2.259007\n",
      "loss in epoch 3 , step 7680 : 1.759086\n",
      "loss in epoch 3 , step 7700 : 1.490224\n",
      "loss in epoch 3 , step 7720 : 1.496171\n",
      "loss in epoch 3 , step 7740 : 2.358059\n",
      "loss in epoch 3 , step 7760 : 1.722553\n",
      "loss in epoch 3 , step 7780 : 1.593923\n",
      "loss in epoch 3 , step 7800 : 2.128702\n",
      "loss in epoch 3 , step 7820 : 1.730298\n",
      "loss in epoch 3 , step 7840 : 1.301745\n",
      "loss in epoch 3 , step 7860 : 1.743294\n",
      "loss in epoch 3 , step 7880 : 2.105569\n",
      "loss in epoch 3 , step 7900 : 1.917437\n",
      "loss in epoch 3 , step 7920 : 1.969266\n",
      "loss in epoch 3 , step 7940 : 1.629900\n",
      "loss in epoch 3 , step 7960 : 4.727437\n",
      "loss in epoch 3 , step 7980 : 1.909324\n",
      "loss in epoch 3 , step 8000 : 1.521664\n",
      "loss in epoch 3 , step 8020 : 2.152120\n",
      "loss in epoch 3 , step 8040 : 1.072019\n",
      "loss in epoch 3 , step 8060 : 0.862904\n",
      "loss in epoch 3 , step 8080 : 1.306942\n",
      "loss in epoch 3 , step 8100 : 1.962657\n",
      "loss in epoch 3 , step 8120 : 3.240586\n",
      "loss in epoch 3 , step 8140 : 1.593035\n",
      "loss in epoch 3 , step 8160 : 1.650643\n",
      "loss in epoch 3 , step 8180 : 0.507933\n",
      "loss in epoch 3 , step 8200 : 2.295995\n",
      "loss in epoch 3 , step 8220 : 2.103802\n",
      "loss in epoch 3 , step 8240 : 1.525033\n",
      "loss in epoch 3 , step 8260 : 2.427056\n",
      "loss in epoch 3 , step 8280 : 1.510776\n",
      "loss in epoch 3 , step 8300 : 1.518617\n",
      "loss in epoch 3 , step 8320 : 2.112358\n",
      "loss in epoch 3 , step 8340 : 2.301404\n",
      "loss in epoch 3 , step 8360 : 2.406919\n",
      "loss in epoch 3 , step 8380 : 2.017893\n",
      "loss in epoch 3 , step 8400 : 1.534073\n",
      "loss in epoch 3 , step 8420 : 0.309606\n",
      "loss in epoch 3 , step 8440 : 2.201585\n",
      "loss in epoch 3 , step 8460 : 3.107332\n",
      "loss in epoch 3 , step 8480 : 1.882152\n",
      "loss in epoch 3 , step 8500 : 2.000285\n",
      "loss in epoch 3 , step 8520 : 2.048063\n",
      "loss in epoch 3 , step 8540 : 1.718717\n",
      "loss in epoch 3 , step 8560 : 1.443174\n",
      "loss in epoch 3 , step 8580 : 1.955988\n",
      "loss in epoch 3 , step 8600 : 2.391051\n",
      "loss in epoch 3 , step 8620 : 0.373300\n",
      "loss in epoch 3 , step 8640 : 0.439981\n",
      "loss in epoch 3 , step 8660 : 1.818496\n",
      "loss in epoch 3 , step 8680 : 1.894810\n",
      "loss in epoch 3 , step 8700 : 2.006816\n",
      "loss in epoch 3 , step 8720 : 1.884632\n",
      "loss in epoch 3 , step 8740 : 2.807234\n",
      "loss in epoch 3 , step 8760 : 1.287042\n",
      "loss in epoch 3 , step 8780 : 1.228602\n",
      "loss in epoch 3 , step 8800 : 2.024957\n",
      "loss in epoch 3 , step 8820 : 2.126322\n",
      "loss in epoch 3 , step 8840 : 2.162228\n",
      "loss in epoch 3 , step 8860 : 2.361418\n",
      "loss in epoch 3 , step 8880 : 1.487661\n",
      "loss in epoch 3 , step 8900 : 1.413779\n",
      "loss in epoch 3 , step 8920 : 1.775041\n",
      "loss in epoch 3 , step 8940 : 1.491407\n",
      "loss in epoch 3 , step 8960 : 1.837180\n",
      "loss in epoch 3 , step 8980 : 2.028773\n",
      "loss in epoch 3 , step 9000 : 1.840376\n",
      "loss in epoch 3 , step 9020 : 0.794167\n",
      "loss in epoch 3 , step 9040 : 1.478672\n",
      "loss in epoch 3 , step 9060 : 0.749390\n",
      "loss in epoch 3 , step 9080 : 1.463445\n",
      "loss in epoch 3 , step 9100 : 1.282483\n",
      "loss in epoch 3 , step 9120 : 0.754845\n",
      "loss in epoch 3 , step 9140 : 1.808558\n",
      "loss in epoch 3 , step 9160 : 0.999215\n",
      "loss in epoch 3 , step 9180 : 1.820465\n",
      "loss in epoch 3 , step 9200 : 2.992112\n",
      "loss in epoch 3 , step 9220 : 2.436044\n",
      "loss in epoch 3 , step 9240 : 1.874752\n",
      "loss in epoch 3 , step 9260 : 0.533515\n",
      "loss in epoch 3 , step 9280 : 1.932469\n",
      "loss in epoch 3 , step 9300 : 1.915175\n",
      "loss in epoch 3 , step 9320 : 0.430075\n",
      "loss in epoch 3 , step 9340 : 1.965299\n",
      "loss in epoch 3 , step 9360 : 1.631511\n",
      "loss in epoch 3 , step 9380 : 1.346337\n",
      "loss in epoch 3 , step 9400 : 3.404456\n",
      "loss in epoch 3 , step 9420 : 2.117171\n",
      "loss in epoch 3 , step 9440 : 2.325304\n",
      "loss in epoch 3 , step 9460 : 1.159596\n",
      "loss in epoch 3 , step 9480 : 0.569316\n",
      "loss in epoch 3 , step 9500 : 0.865553\n",
      "loss in epoch 3 , step 9520 : 1.640283\n",
      "loss in epoch 3 , step 9540 : 1.748683\n",
      "loss in epoch 3 , step 9560 : 1.832782\n",
      "loss in epoch 3 , step 9580 : 1.650168\n",
      "loss in epoch 3 , step 9600 : 1.317569\n",
      "loss in epoch 3 , step 9620 : 1.195187\n",
      "loss in epoch 3 , step 9640 : 1.874565\n",
      "loss in epoch 3 , step 9660 : 1.477809\n",
      "loss in epoch 3 , step 9680 : 0.823110\n",
      "loss in epoch 3 , step 9700 : 2.039552\n",
      "loss in epoch 3 , step 9720 : 1.713208\n",
      "loss in epoch 3 , step 9740 : 2.197568\n",
      "loss in epoch 3 , step 9760 : 1.159339\n",
      "loss in epoch 3 , step 9780 : 2.089810\n",
      "loss in epoch 3 , step 9800 : 1.851071\n",
      "loss in epoch 3 , step 9820 : 2.030740\n",
      "loss in epoch 3 , step 9840 : 1.417139\n",
      "loss in epoch 3 , step 9860 : 1.388790\n",
      "loss in epoch 3 , step 9880 : 2.302974\n",
      "loss in epoch 3 , step 9900 : 1.564744\n",
      "loss in epoch 3 , step 9920 : 1.123787\n",
      "loss in epoch 3 , step 9940 : 1.388920\n",
      "loss in epoch 3 , step 9960 : 1.102278\n",
      "loss in epoch 3 , step 9980 : 2.024941\n",
      "loss in epoch 3 , step 10000 : 2.005131\n",
      "loss in epoch 3 , step 10020 : 1.992284\n",
      "loss in epoch 3 , step 10040 : 1.779287\n",
      "loss in epoch 3 , step 10060 : 1.713393\n",
      "loss in epoch 3 , step 10080 : 2.073612\n",
      "loss in epoch 3 , step 10100 : 2.189604\n",
      "loss in epoch 3 , step 10120 : 0.745311\n",
      "loss in epoch 3 , step 10140 : 2.093231\n",
      "loss in epoch 3 , step 10160 : 1.949093\n",
      "loss in epoch 3 , step 10180 : 1.775461\n",
      "loss in epoch 3 , step 10200 : 1.559809\n",
      "loss in epoch 3 , step 10220 : 1.722144\n",
      "loss in epoch 3 , step 10240 : 2.150993\n",
      "loss in epoch 3 , step 10260 : 1.356146\n",
      "loss in epoch 3 , step 10280 : 1.388351\n",
      "loss in epoch 3 , step 10300 : 1.403308\n",
      "loss in epoch 3 , step 10320 : 0.883102\n",
      "loss in epoch 3 , step 10340 : 2.026203\n",
      "loss in epoch 3 , step 10360 : 2.166272\n",
      "loss in epoch 3 , step 10380 : 1.770231\n",
      "loss in epoch 3 , step 10400 : 1.784389\n",
      "loss in epoch 3 , step 10420 : 1.275810\n",
      "loss in epoch 3 , step 10440 : 0.952878\n",
      "loss in epoch 3 , step 10460 : 1.543225\n",
      "loss in epoch 3 , step 10480 : 2.150723\n",
      "loss in epoch 3 , step 10500 : 1.298900\n",
      "loss in epoch 3 , step 10520 : 1.493739\n",
      "loss in epoch 3 , step 10540 : 3.943655\n",
      "loss in epoch 3 , step 10560 : 1.231079\n",
      "loss in epoch 3 , step 10580 : 1.834599\n",
      "loss in epoch 3 , step 10600 : 1.996805\n",
      "loss in epoch 3 , step 10620 : 1.839637\n",
      "loss in epoch 3 , step 10640 : 2.301736\n",
      "loss in epoch 3 , step 10660 : 2.065413\n",
      "loss in epoch 3 , step 10680 : 1.346931\n",
      "loss in epoch 3 , step 10700 : 1.950252\n",
      "loss in epoch 3 , step 10720 : 1.816772\n",
      "loss in epoch 3 , step 10740 : 1.549141\n",
      "loss in epoch 3 , step 10760 : 1.349063\n",
      "loss in epoch 3 , step 10780 : 1.774062\n",
      "loss in epoch 3 , step 10800 : 2.472557\n",
      "loss in epoch 3 , step 10820 : 1.222923\n",
      "loss in epoch 3 , step 10840 : 1.602326\n",
      "loss in epoch 3 , step 10860 : 1.178159\n",
      "loss in epoch 3 , step 10880 : 2.001093\n",
      "loss in epoch 3 , step 10900 : 1.541774\n",
      "loss in epoch 3 , step 10920 : 1.422272\n",
      "loss in epoch 3 , step 10940 : 1.470269\n",
      "loss in epoch 3 , step 10960 : 0.683523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 3 , step 10980 : 1.668357\n",
      "loss in epoch 3 , step 11000 : 1.733160\n",
      "loss in epoch 3 , step 11020 : 1.714800\n",
      "loss in epoch 3 , step 11040 : 3.513875\n",
      "loss in epoch 3 , step 11060 : 1.552983\n",
      "loss in epoch 3 , step 11080 : 1.851489\n",
      "loss in epoch 3 , step 11100 : 3.323244\n",
      "loss in epoch 3 , step 11120 : 1.154108\n",
      "loss in epoch 3 , step 11140 : 1.477005\n",
      "loss in epoch 3 , step 11160 : 0.425198\n",
      "loss in epoch 3 , step 11180 : 1.770796\n",
      "loss in epoch 3 , step 11200 : 0.952758\n",
      "loss in epoch 3 , step 11220 : 1.737819\n",
      "loss in epoch 3 , step 11240 : 2.000512\n",
      "loss in epoch 3 , step 11260 : 1.405987\n",
      "loss in epoch 3 , step 11280 : 1.581311\n",
      "loss in epoch 3 , step 11300 : 0.976059\n",
      "loss in epoch 3 , step 11320 : 1.542836\n",
      "loss in epoch 3 , step 11340 : 1.062016\n",
      "loss in epoch 3 , step 11360 : 0.868514\n",
      "loss in epoch 3 , step 11380 : 0.719957\n",
      "loss in epoch 3 , step 11400 : 1.730772\n",
      "loss in epoch 3 , step 11420 : 3.599315\n",
      "loss in epoch 3 , step 11440 : 1.803214\n",
      "loss in epoch 3 , step 11460 : 1.706181\n",
      "loss in epoch 3 , step 11480 : 0.470660\n",
      "loss in epoch 3 , step 11500 : 2.308611\n",
      "loss in epoch 3 , step 11520 : 0.876044\n",
      "loss in epoch 3 , step 11540 : 0.813420\n",
      "loss in epoch 3 , step 11560 : 1.144102\n",
      "loss in epoch 3 , step 11580 : 1.764072\n",
      "loss in epoch 3 , step 11600 : 0.735853\n",
      "loss in epoch 3 , step 11620 : 0.968233\n",
      "loss in epoch 3 , step 11640 : 1.864883\n",
      "loss in epoch 3 , step 11660 : 1.603042\n",
      "loss in epoch 3 , step 11680 : 1.924594\n",
      "loss in epoch 3 , step 11700 : 1.976081\n",
      "loss in epoch 3 , step 11720 : 0.982134\n",
      "loss in epoch 3 , step 11740 : 1.412413\n",
      "loss in epoch 3 , step 11760 : 2.011640\n",
      "loss in epoch 3 , step 11780 : 1.779916\n",
      "loss in epoch 3 , step 11800 : 1.063471\n",
      "loss in epoch 3 , step 11820 : 1.768369\n",
      "loss in epoch 3 , step 11840 : 1.469514\n",
      "loss in epoch 3 , step 11860 : 2.091670\n",
      "loss in epoch 3 , step 11880 : 0.943552\n",
      "loss in epoch 3 , step 11900 : 2.085507\n",
      "loss in epoch 3 , step 11920 : 1.818980\n",
      "loss in epoch 3 , step 11940 : 2.846236\n",
      "loss in epoch 3 , step 11960 : 2.077183\n",
      "loss in epoch 3 , step 11980 : 1.524232\n",
      "loss in epoch 3 , step 12000 : 1.457717\n",
      "loss in epoch 3 , step 12020 : 0.952320\n",
      "loss in epoch 3 , step 12040 : 1.763242\n",
      "loss in epoch 3 , step 12060 : 1.222951\n",
      "loss in epoch 3 , step 12080 : 1.528600\n",
      "loss in epoch 3 , step 12100 : 0.122560\n",
      "loss in epoch 3 , step 12120 : 1.747963\n",
      "loss in epoch 3 , step 12140 : 1.420924\n",
      "loss in epoch 3 , step 12160 : 2.242710\n",
      "loss in epoch 3 , step 12180 : 1.295047\n",
      "loss in epoch 3 , step 12200 : 0.331080\n",
      "loss in epoch 3 , step 12220 : 2.086751\n",
      "loss in epoch 3 , step 12240 : 2.346587\n",
      "loss in epoch 3 , step 12260 : 1.258796\n",
      "loss in epoch 3 , step 12280 : 1.271047\n",
      "loss in epoch 3 , step 12300 : 2.081567\n",
      "loss in epoch 3 , step 12320 : 0.647035\n",
      "loss in epoch 3 , step 12340 : 0.314875\n",
      "loss in epoch 3 , step 12360 : 1.189457\n",
      "loss in epoch 3 , step 12380 : 2.253023\n",
      "loss in epoch 3 , step 12400 : 2.012136\n",
      "loss in epoch 3 , step 12420 : 2.145658\n",
      "loss in epoch 3 , step 12440 : 1.290179\n",
      "loss in epoch 3 , step 12460 : 0.707233\n",
      "loss in epoch 3 , step 12480 : 2.164656\n",
      "loss in epoch 3 , step 12500 : 1.212299\n",
      "loss in epoch 3 , step 12520 : 1.682727\n",
      "loss in epoch 3 , step 12540 : 2.073979\n",
      "loss in epoch 3 , step 12560 : 0.342156\n",
      "loss in epoch 3 , step 12580 : 0.933121\n",
      "loss in epoch 3 , step 12600 : 2.236441\n",
      "loss in epoch 3 , step 12620 : 0.666634\n",
      "loss in epoch 3 , step 12640 : 1.949514\n",
      "loss in epoch 3 , step 12660 : 1.747894\n",
      "loss in epoch 3 , step 12680 : 1.265737\n",
      "loss in epoch 3 , step 12700 : 1.258247\n",
      "loss in epoch 3 , step 12720 : 2.031262\n",
      "loss in epoch 3 , step 12740 : 1.770697\n",
      "loss in epoch 3 , step 12760 : 0.798710\n",
      "loss in epoch 3 , step 12780 : 1.964833\n",
      "loss in epoch 3 , step 12800 : 1.478378\n",
      "loss in epoch 3 , step 12820 : 2.509273\n",
      "loss in epoch 3 , step 12840 : 2.543664\n",
      "loss in epoch 3 , step 12860 : 1.678507\n",
      "loss in epoch 3 , step 12880 : 2.526635\n",
      "loss in epoch 3 , step 12900 : 0.786128\n",
      "loss in epoch 3 , step 12920 : 2.550225\n",
      "loss in epoch 3 , step 12940 : 2.260483\n",
      "loss in epoch 3 , step 12960 : 1.752008\n",
      "loss in epoch 3 , step 12980 : 2.189896\n",
      "loss in epoch 3 , step 13000 : 2.035841\n",
      "loss in epoch 3 , step 13020 : 2.026907\n",
      "loss in epoch 3 , step 13040 : 1.515895\n",
      "loss in epoch 3 , step 13060 : 1.644566\n",
      "loss in epoch 3 , step 13080 : 1.804950\n",
      "loss in epoch 3 , step 13100 : 1.596816\n",
      "loss in epoch 3 , step 13120 : 0.942778\n",
      "loss in epoch 3 , step 13140 : 2.047949\n",
      "loss in epoch 3 , step 13160 : 1.741286\n",
      "loss in epoch 3 , step 13180 : 1.368405\n",
      "loss in epoch 3 , step 13200 : 0.533559\n",
      "loss in epoch 3 , step 13220 : 0.732906\n",
      "loss in epoch 3 , step 13240 : 1.319284\n",
      "loss in epoch 3 , step 13260 : 1.718996\n",
      "loss in epoch 3 , step 13280 : 1.369533\n",
      "loss in epoch 3 , step 13300 : 1.542703\n",
      "loss in epoch 3 , step 13320 : 1.372413\n",
      "loss in epoch 3 , step 13340 : 2.045402\n",
      "loss in epoch 3 , step 13360 : 1.849215\n",
      "loss in epoch 3 , step 13380 : 0.499217\n",
      "loss in epoch 3 , step 13400 : 1.296944\n",
      "loss in epoch 3 , step 13420 : 2.046168\n",
      "loss in epoch 3 , step 13440 : 1.890185\n",
      "loss in epoch 3 , step 13460 : 1.867493\n",
      "loss in epoch 3 , step 13480 : 1.674941\n",
      "loss in epoch 3 , step 13500 : 2.071473\n",
      "loss in epoch 3 , step 13520 : 1.743895\n",
      "loss in epoch 3 , step 13540 : 1.636957\n",
      "loss in epoch 3 , step 13560 : 0.488474\n",
      "loss in epoch 3 , step 13580 : 1.447953\n",
      "loss in epoch 3 , step 13600 : 0.544692\n",
      "loss in epoch 3 , step 13620 : 1.887319\n",
      "loss in epoch 3 , step 13640 : 1.855463\n",
      "loss in epoch 3 , step 13660 : 0.553356\n",
      "loss in epoch 3 , step 13680 : 0.716840\n",
      "loss in epoch 3 , step 13700 : 1.868671\n",
      "loss in epoch 3 , step 13720 : 1.457386\n",
      "loss in epoch 3 , step 13740 : 1.619783\n",
      "loss in epoch 3 , step 13760 : 0.997592\n",
      "loss in epoch 3 , step 13780 : 1.949444\n",
      "loss in epoch 3 , step 13800 : 0.567442\n",
      "loss in epoch 3 , step 13820 : 1.169003\n",
      "loss in epoch 3 , step 13840 : 1.393733\n",
      "loss in epoch 3 , step 13860 : 0.596428\n",
      "loss in epoch 3 , step 13880 : 0.691994\n",
      "loss in epoch 3 , step 13900 : 0.573204\n",
      "loss in epoch 3 , step 13920 : 0.961662\n",
      "loss in epoch 3 , step 13940 : 0.392279\n",
      "loss in epoch 3 , step 13960 : 0.351283\n",
      "loss in epoch 3 , step 13980 : 1.100796\n",
      "loss in epoch 3 , step 14000 : 1.585956\n",
      "loss in epoch 3 , step 14020 : 1.887399\n",
      "loss in epoch 3 , step 14040 : 1.367180\n",
      "loss in epoch 3 , step 14060 : 0.981013\n",
      "loss in epoch 3 , step 14080 : 2.074911\n",
      "loss in epoch 3 , step 14100 : 0.866439\n",
      "loss in epoch 3 , step 14120 : 0.594204\n",
      "loss in epoch 3 , step 14140 : 0.507420\n",
      "loss in epoch 3 , step 14160 : 2.201475\n",
      "loss in epoch 3 , step 14180 : 2.166464\n",
      "loss in epoch 3 , step 14200 : 1.535002\n",
      "loss in epoch 3 , step 14220 : 1.900085\n",
      "loss in epoch 3 , step 14240 : 0.440056\n",
      "loss in epoch 3 , step 14260 : 2.706578\n",
      "loss in epoch 3 , step 14280 : 0.638679\n",
      "loss in epoch 3 , step 14300 : 1.671442\n",
      "loss in epoch 3 , step 14320 : 2.501918\n",
      "loss in epoch 3 , step 14340 : 1.337645\n",
      "loss in epoch 3 , step 14360 : 0.741856\n",
      "loss in epoch 3 , step 14380 : 0.526436\n",
      "loss in epoch 3 , step 14400 : 2.052963\n",
      "loss in epoch 3 , step 14420 : 2.164918\n",
      "loss in epoch 3 , step 14440 : 1.318795\n",
      "loss in epoch 3 , step 14460 : 3.427824\n",
      "loss in epoch 3 , step 14480 : 0.946144\n",
      "loss in epoch 3 , step 14500 : 2.043954\n",
      "loss in epoch 3 , step 14520 : 1.723008\n",
      "loss in epoch 3 , step 14540 : 1.883689\n",
      "loss in epoch 3 , step 14560 : 1.490174\n",
      "loss in epoch 3 , step 14580 : 2.090221\n",
      "loss in epoch 3 , step 14600 : 1.737777\n",
      "loss in epoch 3 , step 14620 : 1.890747\n",
      "loss in epoch 3 , step 14640 : 1.020605\n",
      "loss in epoch 3 , step 14660 : 2.330215\n",
      "loss in epoch 3 , step 14680 : 3.394435\n",
      "loss in epoch 3 , step 14700 : 1.589981\n",
      "loss in epoch 3 , step 14720 : 1.620564\n",
      "loss in epoch 3 , step 14740 : 2.305819\n",
      "loss in epoch 3 , step 14760 : 1.415790\n",
      "loss in epoch 3 , step 14780 : 1.297026\n",
      "loss in epoch 3 , step 14800 : 2.974468\n",
      "loss in epoch 3 , step 14820 : 1.794186\n",
      "loss in epoch 3 , step 14840 : 0.664802\n",
      "loss in epoch 3 , step 14860 : 1.887070\n",
      "loss in epoch 3 , step 14880 : 0.389158\n",
      "loss in epoch 3 , step 14900 : 1.458697\n",
      "loss in epoch 3 , step 14920 : 1.567217\n",
      "loss in epoch 3 , step 14940 : 1.247398\n",
      "loss in epoch 3 , step 14960 : 0.310290\n",
      "loss in epoch 3 , step 14980 : 1.465843\n",
      "loss in epoch 3 , step 15000 : 0.697150\n",
      "loss in epoch 3 , step 15020 : 1.495096\n",
      "loss in epoch 3 , step 15040 : 1.217121\n",
      "loss in epoch 3 , step 15060 : 1.742905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 3 , step 15080 : 1.735965\n",
      "loss in epoch 3 , step 15100 : 2.250646\n",
      "loss in epoch 3 , step 15120 : 2.093577\n",
      "loss in epoch 3 , step 15140 : 1.384095\n",
      "loss in epoch 3 , step 15160 : 2.018526\n",
      "loss in epoch 3 , step 15180 : 0.683977\n",
      "loss in epoch 3 , step 15200 : 2.349005\n",
      "loss in epoch 3 , step 15220 : 1.259663\n",
      "loss in epoch 3 , step 15240 : 2.118713\n",
      "loss in epoch 3 , step 15260 : 1.333643\n",
      "loss in epoch 3 , step 15280 : 1.351847\n",
      "loss in epoch 3 , step 15300 : 1.184742\n",
      "loss in epoch 3 , step 15320 : 2.642342\n",
      "loss in epoch 3 , step 15340 : 1.935988\n",
      "loss in epoch 3 , step 15360 : 1.517882\n",
      "loss in epoch 3 , step 15380 : 0.941131\n",
      "loss in epoch 3 , step 15400 : 0.620608\n",
      "loss in epoch 3 , step 15420 : 2.139098\n",
      "loss in epoch 3 , step 15440 : 1.338989\n",
      "loss in epoch 3 , step 15460 : 2.046979\n",
      "loss in epoch 3 , step 15480 : 1.700511\n",
      "loss in epoch 3 , step 15500 : 1.715527\n",
      "loss in epoch 3 , step 15520 : 2.404744\n",
      "loss in epoch 3 , step 15540 : 1.579133\n",
      "loss in epoch 3 , step 15560 : 1.662124\n",
      "loss in epoch 3 , step 15580 : 1.573812\n",
      "loss in epoch 3 , step 15600 : 1.476118\n",
      "loss in epoch 3 , step 15620 : 1.944065\n",
      "loss in epoch 3 , step 15640 : 1.044727\n",
      "loss in epoch 3 , step 15660 : 0.868590\n",
      "loss in epoch 3 , step 15680 : 1.166169\n",
      "loss in epoch 3 , step 15700 : 1.821738\n",
      "loss in epoch 3 , step 15720 : 1.750250\n",
      "loss in epoch 3 , step 15740 : 1.736990\n",
      "loss in epoch 3 , step 15760 : 1.709705\n",
      "loss in epoch 3 , step 15780 : 1.625648\n",
      "loss in epoch 3 , step 15800 : 2.735386\n",
      "loss in epoch 3 , step 15820 : 0.947946\n",
      "loss in epoch 3 , step 15840 : 0.993923\n",
      "loss in epoch 3 , step 15860 : 1.437228\n",
      "loss in epoch 3 , step 15880 : 1.248403\n",
      "loss in epoch 3 , step 15900 : 1.910416\n",
      "loss in epoch 3 , step 15920 : 2.026050\n",
      "loss in epoch 3 , step 15940 : 1.757705\n",
      "loss in epoch 3 , step 15960 : 1.503218\n",
      "loss in epoch 3 , step 15980 : 1.376346\n",
      "loss in epoch 3 , step 16000 : 3.083010\n",
      "loss in epoch 3 , step 16020 : 1.367181\n",
      "loss in epoch 3 , step 16040 : 1.249516\n",
      "loss in epoch 3 , step 16060 : 1.400236\n",
      "loss in epoch 3 , step 16080 : 0.292580\n",
      "loss in epoch 3 , step 16100 : 1.572830\n",
      "loss in epoch 3 , step 16120 : 1.921252\n",
      "loss in epoch 3 , step 16140 : 1.893159\n",
      "loss in epoch 3 , step 16160 : 1.525399\n",
      "loss in epoch 3 , step 16180 : 2.513857\n",
      "loss in epoch 3 , step 16200 : 0.490405\n",
      "loss in epoch 3 , step 16220 : 0.894581\n",
      "loss in epoch 3 , step 16240 : 2.923950\n",
      "loss in epoch 3 , step 16260 : 1.577291\n",
      "loss in epoch 3 , step 16280 : 1.297226\n",
      "loss in epoch 3 , step 16300 : 2.418047\n",
      "loss in epoch 3 , step 16320 : 0.638020\n",
      "loss in epoch 3 , step 16340 : 2.694410\n",
      "loss in epoch 3 , step 16360 : 2.673470\n",
      "loss in epoch 3 , step 16380 : 1.535382\n",
      "loss in epoch 3 , step 16400 : 0.355028\n",
      "loss in epoch 3 , step 16420 : 2.065418\n",
      "loss in epoch 3 , step 16440 : 2.016287\n",
      "loss in epoch 3 , step 16460 : 1.784442\n",
      "loss in epoch 3 , step 16480 : 1.793452\n",
      "loss in epoch 3 , step 16500 : 1.297435\n",
      "loss in epoch 3 , step 16520 : 1.191802\n",
      "loss in epoch 3 , step 16540 : 1.871921\n",
      "loss in epoch 3 , step 16560 : 1.706959\n",
      "loss in epoch 3 , step 16580 : 1.445820\n",
      "loss in epoch 3 , step 16600 : 2.031720\n",
      "loss in epoch 3 , step 16620 : 1.904271\n",
      "loss in epoch 3 , step 16640 : 1.424822\n",
      "loss in epoch 3 , step 16660 : 1.414258\n",
      "loss in epoch 3 , step 16680 : 1.126743\n",
      "loss in epoch 3 , step 16700 : 1.474100\n",
      "loss in epoch 3 , step 16720 : 1.843643\n",
      "loss in epoch 3 , step 16740 : 1.389110\n",
      "loss in epoch 3 , step 16760 : 1.210304\n",
      "loss in epoch 3 , step 16780 : 1.807421\n",
      "loss in epoch 3 , step 16800 : 1.606549\n",
      "loss in epoch 3 , step 16820 : 2.475362\n",
      "loss in epoch 3 , step 16840 : 0.314487\n",
      "loss in epoch 3 , step 16860 : 1.890764\n",
      "loss in epoch 3 , step 16880 : 2.112745\n",
      "loss in epoch 3 , step 16900 : 1.782752\n",
      "loss in epoch 3 , step 16920 : 1.865485\n",
      "loss in epoch 3 , step 16940 : 0.996409\n",
      "loss in epoch 3 , step 16960 : 0.775107\n",
      "loss in epoch 3 , step 16980 : 2.012397\n",
      "loss in epoch 3 , step 17000 : 1.863013\n",
      "loss in epoch 3 , step 17020 : 1.334524\n",
      "loss in epoch 3 , step 17040 : 1.840671\n",
      "loss in epoch 3 , step 17060 : 2.419534\n",
      "loss in epoch 3 , step 17080 : 1.516336\n",
      "loss in epoch 3 , step 17100 : 0.390857\n",
      "loss in epoch 3 , step 17120 : 1.656435\n",
      "loss in epoch 3 , step 17140 : 0.457411\n",
      "loss in epoch 3 , step 17160 : 1.811620\n",
      "loss in epoch 3 , step 17180 : 1.763322\n",
      "loss in epoch 3 , step 17200 : 1.597731\n",
      "loss in epoch 3 , step 17220 : 1.810594\n",
      "loss in epoch 3 , step 17240 : 1.747011\n",
      "loss in epoch 3 , step 17260 : 1.391375\n",
      "loss in epoch 3 , step 17280 : 1.015434\n",
      "loss in epoch 3 , step 17300 : 0.842801\n",
      "loss in epoch 3 , step 17320 : 3.432408\n",
      "loss in epoch 3 , step 17340 : 1.616600\n",
      "loss in epoch 3 , step 17360 : 1.366290\n",
      "loss in epoch 3 , step 17380 : 1.810318\n",
      "loss in epoch 3 , step 17400 : 0.747511\n",
      "loss in epoch 3 , step 17420 : 1.547615\n",
      "loss in epoch 3 , step 17440 : 1.547210\n",
      "loss in epoch 3 , step 17460 : 0.795252\n",
      "loss in epoch 3 , step 17480 : 1.981637\n",
      "loss in epoch 3 , step 17500 : 1.722267\n",
      "loss in epoch 3 , step 17520 : 0.820513\n",
      "loss in epoch 3 , step 17540 : 1.420791\n",
      "loss in epoch 3 , step 17560 : 1.966679\n",
      "loss in epoch 3 , step 17580 : 1.833741\n",
      "loss in epoch 3 , step 17600 : 0.852208\n",
      "loss in epoch 3 , step 17620 : 0.417367\n",
      "loss in epoch 3 , step 17640 : 2.856626\n",
      "loss in epoch 3 , step 17660 : 0.769410\n",
      "loss in epoch 3 , step 17680 : 1.444859\n",
      "loss in epoch 3 , step 17700 : 1.312377\n",
      "loss in epoch 3 , step 17720 : 2.462155\n",
      "loss in epoch 3 , step 17740 : 1.276595\n",
      "loss in epoch 3 , step 17760 : 1.611608\n",
      "loss in epoch 3 , step 17780 : 1.468159\n",
      "loss in epoch 3 , step 17800 : 1.903370\n",
      "loss in epoch 3 , step 17820 : 1.914544\n",
      "loss in epoch 3 , step 17840 : 1.657456\n",
      "loss in epoch 3 , step 17860 : 0.946849\n",
      "loss in epoch 3 , step 17880 : 0.780421\n",
      "loss in epoch 3 , step 17900 : 1.987745\n",
      "loss in epoch 3 , step 17920 : 1.297148\n",
      "loss in epoch 3 , step 17940 : 1.934883\n",
      "loss in epoch 3 , step 17960 : 1.008986\n",
      "loss in epoch 3 , step 17980 : 1.802090\n",
      "loss in epoch 3 , step 18000 : 0.566150\n",
      "loss in epoch 3 , step 18020 : 0.205305\n",
      "loss in epoch 3 , step 18040 : 2.367174\n",
      "loss in epoch 3 , step 18060 : 1.706525\n",
      "loss in epoch 3 , step 18080 : 1.647389\n",
      "loss in epoch 3 , step 18100 : 1.922698\n",
      "loss in epoch 3 , step 18120 : 1.787870\n",
      "loss in epoch 3 , step 18140 : 1.889590\n",
      "loss in epoch 3 , step 18160 : 0.873493\n",
      "loss in epoch 3 , step 18180 : 2.273405\n",
      "loss in epoch 3 , step 18200 : 1.244471\n",
      "loss in epoch 3 , step 18220 : 0.959183\n",
      "loss in epoch 3 , step 18240 : 0.950827\n",
      "loss in epoch 3 , step 18260 : 1.032155\n",
      "loss in epoch 3 , step 18280 : 1.821871\n",
      "loss in epoch 3 , step 18300 : 1.156238\n",
      "loss in epoch 3 , step 18320 : 2.007223\n",
      "loss in epoch 3 , step 18340 : 0.307769\n",
      "loss in epoch 3 , step 18360 : 3.446254\n",
      "loss in epoch 3 , step 18380 : 1.880720\n",
      "loss in epoch 3 , step 18400 : 1.862514\n",
      "loss in epoch 3 , step 18420 : 1.787784\n",
      "loss in epoch 3 , step 18440 : 1.757080\n",
      "loss in epoch 3 , step 18460 : 1.394499\n",
      "loss in epoch 3 , step 18480 : 2.488032\n",
      "loss in epoch 3 , step 18500 : 1.545053\n",
      "loss in epoch 3 , step 18520 : 2.264301\n",
      "loss in epoch 3 , step 18540 : 1.962010\n",
      "loss in epoch 3 , step 18560 : 0.353572\n",
      "loss in epoch 3 , step 18580 : 2.223519\n",
      "loss in epoch 3 , step 18600 : 1.510923\n",
      "loss in epoch 3 , step 18620 : 1.021418\n",
      "loss in epoch 3 , step 18640 : 1.957886\n",
      "loss in epoch 3 , step 18660 : 1.078932\n",
      "loss in epoch 3 , step 18680 : 1.292814\n",
      "loss in epoch 3 , step 18700 : 1.113835\n",
      "loss in epoch 3 , step 18720 : 1.478490\n",
      "loss in epoch 3 , step 18740 : 0.962119\n",
      "loss in epoch 3 , step 18760 : 1.982612\n",
      "loss in epoch 3 , step 18780 : 2.069874\n",
      "loss in epoch 3 , step 18800 : 1.257128\n",
      "loss in epoch 3 , step 18820 : 2.000241\n",
      "loss in epoch 3 , step 18840 : 1.604008\n",
      "loss in epoch 3 , step 18860 : 1.949710\n",
      "loss in epoch 3 , step 18880 : 1.498927\n",
      "loss in epoch 3 , step 18900 : 2.304287\n",
      "loss in epoch 3 , step 18920 : 2.486971\n",
      "loss in epoch 3 , step 18940 : 2.228256\n",
      "loss in epoch 3 , step 18960 : 1.472571\n",
      "loss in epoch 3 , step 18980 : 0.883065\n",
      "loss in epoch 3 , step 19000 : 0.667283\n",
      "loss in epoch 3 , step 19020 : 2.072235\n",
      "loss in epoch 3 , step 19040 : 1.700045\n",
      "loss in epoch 3 , step 19060 : 1.425828\n",
      "loss in epoch 3 , step 19080 : 1.372061\n",
      "loss in epoch 3 , step 19100 : 1.551764\n",
      "loss in epoch 3 , step 19120 : 1.289517\n",
      "loss in epoch 3 , step 19140 : 1.580449\n",
      "loss in epoch 3 , step 19160 : 2.082508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 3 , step 19180 : 1.296305\n",
      "loss in epoch 3 , step 19200 : 1.761159\n",
      "loss in epoch 3 , step 19220 : 1.594470\n",
      "loss in epoch 3 , step 19240 : 1.530391\n",
      "loss in epoch 3 , step 19260 : 1.385985\n",
      "loss in epoch 3 , step 19280 : 1.568506\n",
      "loss in epoch 3 , step 19300 : 2.041780\n",
      "loss in epoch 3 , step 19320 : 1.827869\n",
      "loss in epoch 3 , step 19340 : 1.460107\n",
      "loss in epoch 3 , step 19360 : 1.077614\n",
      "loss in epoch 3 , step 19380 : 1.036716\n",
      "loss in epoch 3 , step 19400 : 0.607053\n",
      "loss in epoch 3 , step 19420 : 2.322902\n",
      "loss in epoch 3 , step 19440 : 1.066570\n",
      "loss in epoch 3 , step 19460 : 0.964163\n",
      "loss in epoch 3 , step 19480 : 0.216417\n",
      "loss in epoch 3 , step 19500 : 1.085629\n",
      "loss in epoch 3 , step 19520 : 2.301503\n",
      "loss in epoch 3 , step 19540 : 1.156430\n",
      "loss in epoch 3 , step 19560 : 2.289346\n",
      "loss in epoch 3 , step 19580 : 2.501112\n",
      "loss in epoch 3 , step 19600 : 2.252431\n",
      "loss in epoch 3 , step 19620 : 1.815918\n",
      "loss in epoch 3 , step 19640 : 1.214204\n",
      "loss in epoch 3 , step 19660 : 1.111373\n",
      "loss in epoch 3 , step 19680 : 0.396975\n",
      "loss in epoch 3 , step 19700 : 0.784146\n",
      "loss in epoch 3 , step 19720 : 2.495204\n",
      "loss in epoch 3 , step 19740 : 1.639974\n",
      "loss in epoch 3 , step 19760 : 1.405609\n",
      "loss in epoch 3 , step 19780 : 1.882420\n",
      "loss in epoch 3 , step 19800 : 1.666998\n",
      "loss in epoch 3 , step 19820 : 1.350839\n",
      "loss in epoch 3 , step 19840 : 2.077168\n",
      "loss in epoch 3 , step 19860 : 0.556143\n",
      "loss in epoch 3 , step 19880 : 2.192752\n",
      "loss in epoch 3 , step 19900 : 1.755246\n",
      "loss in epoch 3 , step 19920 : 1.606836\n",
      "loss in epoch 3 , step 19940 : 2.189574\n",
      "Accuracy in epoch 3 : 20.422358\n",
      "loss in epoch 4 , step 0 : 1.403194\n",
      "loss in epoch 4 , step 20 : 1.604764\n",
      "loss in epoch 4 , step 40 : 2.143357\n",
      "loss in epoch 4 , step 60 : 1.966325\n",
      "loss in epoch 4 , step 80 : 0.487543\n",
      "loss in epoch 4 , step 100 : 0.980308\n",
      "loss in epoch 4 , step 120 : 0.912876\n",
      "loss in epoch 4 , step 140 : 0.461920\n",
      "loss in epoch 4 , step 160 : 1.130615\n",
      "loss in epoch 4 , step 180 : 0.731597\n",
      "loss in epoch 4 , step 200 : 1.754558\n",
      "loss in epoch 4 , step 220 : 0.976950\n",
      "loss in epoch 4 , step 240 : 1.835967\n",
      "loss in epoch 4 , step 260 : 2.900232\n",
      "loss in epoch 4 , step 280 : 1.882880\n",
      "loss in epoch 4 , step 300 : 0.336541\n",
      "loss in epoch 4 , step 320 : 2.003904\n",
      "loss in epoch 4 , step 340 : 1.225567\n",
      "loss in epoch 4 , step 360 : 1.444606\n",
      "loss in epoch 4 , step 380 : 1.512321\n",
      "loss in epoch 4 , step 400 : 1.274131\n",
      "loss in epoch 4 , step 420 : 0.324911\n",
      "loss in epoch 4 , step 440 : 1.041258\n",
      "loss in epoch 4 , step 460 : 1.673774\n",
      "loss in epoch 4 , step 480 : 1.937900\n",
      "loss in epoch 4 , step 500 : 1.591085\n",
      "loss in epoch 4 , step 520 : 0.770685\n",
      "loss in epoch 4 , step 540 : 2.167550\n",
      "loss in epoch 4 , step 560 : 2.430384\n",
      "loss in epoch 4 , step 580 : 2.042493\n",
      "loss in epoch 4 , step 600 : 0.324419\n",
      "loss in epoch 4 , step 620 : 1.148910\n",
      "loss in epoch 4 , step 640 : 1.200706\n",
      "loss in epoch 4 , step 660 : 2.015357\n",
      "loss in epoch 4 , step 680 : 1.467783\n",
      "loss in epoch 4 , step 700 : 1.884010\n",
      "loss in epoch 4 , step 720 : 2.128295\n",
      "loss in epoch 4 , step 740 : 1.887199\n",
      "loss in epoch 4 , step 760 : 1.253371\n",
      "loss in epoch 4 , step 780 : 1.553028\n",
      "loss in epoch 4 , step 800 : 1.525067\n",
      "loss in epoch 4 , step 820 : 1.515659\n",
      "loss in epoch 4 , step 840 : 1.835673\n",
      "loss in epoch 4 , step 860 : 1.647746\n",
      "loss in epoch 4 , step 880 : 1.610183\n",
      "loss in epoch 4 , step 900 : 0.244378\n",
      "loss in epoch 4 , step 920 : 1.872061\n",
      "loss in epoch 4 , step 940 : 0.993252\n",
      "loss in epoch 4 , step 960 : 1.733852\n",
      "loss in epoch 4 , step 980 : 1.712454\n",
      "loss in epoch 4 , step 1000 : 2.152009\n",
      "loss in epoch 4 , step 1020 : 2.192586\n",
      "loss in epoch 4 , step 1040 : 2.332951\n",
      "loss in epoch 4 , step 1060 : 2.317098\n",
      "loss in epoch 4 , step 1080 : 3.028220\n",
      "loss in epoch 4 , step 1100 : 2.036389\n",
      "loss in epoch 4 , step 1120 : 0.335752\n",
      "loss in epoch 4 , step 1140 : 2.153798\n",
      "loss in epoch 4 , step 1160 : 2.438787\n",
      "loss in epoch 4 , step 1180 : 1.666374\n",
      "loss in epoch 4 , step 1200 : 1.493066\n",
      "loss in epoch 4 , step 1220 : 2.094320\n",
      "loss in epoch 4 , step 1240 : 1.564705\n",
      "loss in epoch 4 , step 1260 : 1.144271\n",
      "loss in epoch 4 , step 1280 : 0.992934\n",
      "loss in epoch 4 , step 1300 : 1.405607\n",
      "loss in epoch 4 , step 1320 : 1.439546\n",
      "loss in epoch 4 , step 1340 : 1.831255\n",
      "loss in epoch 4 , step 1360 : 1.774531\n",
      "loss in epoch 4 , step 1380 : 3.900755\n",
      "loss in epoch 4 , step 1400 : 1.974344\n",
      "loss in epoch 4 , step 1420 : 2.036289\n",
      "loss in epoch 4 , step 1440 : 2.107648\n",
      "loss in epoch 4 , step 1460 : 1.071105\n",
      "loss in epoch 4 , step 1480 : 0.898860\n",
      "loss in epoch 4 , step 1500 : 1.418109\n",
      "loss in epoch 4 , step 1520 : 1.553931\n",
      "loss in epoch 4 , step 1540 : 2.273702\n",
      "loss in epoch 4 , step 1560 : 0.422073\n",
      "loss in epoch 4 , step 1580 : 1.679612\n",
      "loss in epoch 4 , step 1600 : 1.897545\n",
      "loss in epoch 4 , step 1620 : 1.793100\n",
      "loss in epoch 4 , step 1640 : 1.078546\n",
      "loss in epoch 4 , step 1660 : 1.526728\n",
      "loss in epoch 4 , step 1680 : 1.507311\n",
      "loss in epoch 4 , step 1700 : 0.633745\n",
      "loss in epoch 4 , step 1720 : 1.932500\n",
      "loss in epoch 4 , step 1740 : 1.068405\n",
      "loss in epoch 4 , step 1760 : 3.195960\n",
      "loss in epoch 4 , step 1780 : 1.287450\n",
      "loss in epoch 4 , step 1800 : 1.467437\n",
      "loss in epoch 4 , step 1820 : 1.590272\n",
      "loss in epoch 4 , step 1840 : 1.980845\n",
      "loss in epoch 4 , step 1860 : 0.753632\n",
      "loss in epoch 4 , step 1880 : 2.023225\n",
      "loss in epoch 4 , step 1900 : 0.968789\n",
      "loss in epoch 4 , step 1920 : 2.061425\n",
      "loss in epoch 4 , step 1940 : 2.390932\n",
      "loss in epoch 4 , step 1960 : 0.873160\n",
      "loss in epoch 4 , step 1980 : 1.425100\n",
      "loss in epoch 4 , step 2000 : 2.674803\n",
      "loss in epoch 4 , step 2020 : 2.355903\n",
      "loss in epoch 4 , step 2040 : 0.928954\n",
      "loss in epoch 4 , step 2060 : 0.446711\n",
      "loss in epoch 4 , step 2080 : 2.422743\n",
      "loss in epoch 4 , step 2100 : 0.623897\n",
      "loss in epoch 4 , step 2120 : 3.811163\n",
      "loss in epoch 4 , step 2140 : 0.650623\n",
      "loss in epoch 4 , step 2160 : 1.558585\n",
      "loss in epoch 4 , step 2180 : 2.638733\n",
      "loss in epoch 4 , step 2200 : 2.222669\n",
      "loss in epoch 4 , step 2220 : 1.852533\n",
      "loss in epoch 4 , step 2240 : 1.576460\n",
      "loss in epoch 4 , step 2260 : 1.348911\n",
      "loss in epoch 4 , step 2280 : 1.989822\n",
      "loss in epoch 4 , step 2300 : 0.990676\n",
      "loss in epoch 4 , step 2320 : 0.712146\n",
      "loss in epoch 4 , step 2340 : 1.218218\n",
      "loss in epoch 4 , step 2360 : 2.209138\n",
      "loss in epoch 4 , step 2380 : 0.972152\n",
      "loss in epoch 4 , step 2400 : 2.602278\n",
      "loss in epoch 4 , step 2420 : 1.024687\n",
      "loss in epoch 4 , step 2440 : 0.106935\n",
      "loss in epoch 4 , step 2460 : 2.352760\n",
      "loss in epoch 4 , step 2480 : 2.223866\n",
      "loss in epoch 4 , step 2500 : 1.971935\n",
      "loss in epoch 4 , step 2520 : 1.513341\n",
      "loss in epoch 4 , step 2540 : 1.404527\n",
      "loss in epoch 4 , step 2560 : 1.864387\n",
      "loss in epoch 4 , step 2580 : 1.052925\n",
      "loss in epoch 4 , step 2600 : 0.216680\n",
      "loss in epoch 4 , step 2620 : 1.922059\n",
      "loss in epoch 4 , step 2640 : 0.237391\n",
      "loss in epoch 4 , step 2660 : 0.145488\n",
      "loss in epoch 4 , step 2680 : 1.183437\n",
      "loss in epoch 4 , step 2700 : 1.682912\n",
      "loss in epoch 4 , step 2720 : 0.854073\n",
      "loss in epoch 4 , step 2740 : 1.435608\n",
      "loss in epoch 4 , step 2760 : 1.187794\n",
      "loss in epoch 4 , step 2780 : 0.387146\n",
      "loss in epoch 4 , step 2800 : 1.988127\n",
      "loss in epoch 4 , step 2820 : 1.459597\n",
      "loss in epoch 4 , step 2840 : 1.251148\n",
      "loss in epoch 4 , step 2860 : 1.261025\n",
      "loss in epoch 4 , step 2880 : 1.634524\n",
      "loss in epoch 4 , step 2900 : 0.369303\n",
      "loss in epoch 4 , step 2920 : 1.209478\n",
      "loss in epoch 4 , step 2940 : 1.624057\n",
      "loss in epoch 4 , step 2960 : 0.383211\n",
      "loss in epoch 4 , step 2980 : 2.589909\n",
      "loss in epoch 4 , step 3000 : 2.042929\n",
      "loss in epoch 4 , step 3020 : 2.142038\n",
      "loss in epoch 4 , step 3040 : 2.112981\n",
      "loss in epoch 4 , step 3060 : 4.189219\n",
      "loss in epoch 4 , step 3080 : 2.363459\n",
      "loss in epoch 4 , step 3100 : 1.702037\n",
      "loss in epoch 4 , step 3120 : 0.605213\n",
      "loss in epoch 4 , step 3140 : 2.131669\n",
      "loss in epoch 4 , step 3160 : 2.210952\n",
      "loss in epoch 4 , step 3180 : 1.695454\n",
      "loss in epoch 4 , step 3200 : 1.235363\n",
      "loss in epoch 4 , step 3220 : 1.192857\n",
      "loss in epoch 4 , step 3240 : 1.075418\n",
      "loss in epoch 4 , step 3260 : 2.292471\n",
      "loss in epoch 4 , step 3280 : 2.042369\n",
      "loss in epoch 4 , step 3300 : 2.047499\n",
      "loss in epoch 4 , step 3320 : 1.093228\n",
      "loss in epoch 4 , step 3340 : 0.563922\n",
      "loss in epoch 4 , step 3360 : 1.834442\n",
      "loss in epoch 4 , step 3380 : 2.041697\n",
      "loss in epoch 4 , step 3400 : 1.515693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 4 , step 3420 : 1.133742\n",
      "loss in epoch 4 , step 3440 : 1.000099\n",
      "loss in epoch 4 , step 3460 : 1.331447\n",
      "loss in epoch 4 , step 3480 : 2.265665\n",
      "loss in epoch 4 , step 3500 : 1.839697\n",
      "loss in epoch 4 , step 3520 : 1.421052\n",
      "loss in epoch 4 , step 3540 : 1.346286\n",
      "loss in epoch 4 , step 3560 : 0.873539\n",
      "loss in epoch 4 , step 3580 : 1.055846\n",
      "loss in epoch 4 , step 3600 : 1.745858\n",
      "loss in epoch 4 , step 3620 : 0.279412\n",
      "loss in epoch 4 , step 3640 : 1.749466\n",
      "loss in epoch 4 , step 3660 : 0.448171\n",
      "loss in epoch 4 , step 3680 : 0.297621\n",
      "loss in epoch 4 , step 3700 : 1.003956\n",
      "loss in epoch 4 , step 3720 : 1.847489\n",
      "loss in epoch 4 , step 3740 : 1.725208\n",
      "loss in epoch 4 , step 3760 : 0.762775\n",
      "loss in epoch 4 , step 3780 : 1.890792\n",
      "loss in epoch 4 , step 3800 : 1.565633\n",
      "loss in epoch 4 , step 3820 : 1.386917\n",
      "loss in epoch 4 , step 3840 : 0.314196\n",
      "loss in epoch 4 , step 3860 : 1.542997\n",
      "loss in epoch 4 , step 3880 : 2.100371\n",
      "loss in epoch 4 , step 3900 : 2.058274\n",
      "loss in epoch 4 , step 3920 : 1.358396\n",
      "loss in epoch 4 , step 3940 : 1.844740\n",
      "loss in epoch 4 , step 3960 : 3.619757\n",
      "loss in epoch 4 , step 3980 : 2.485591\n",
      "loss in epoch 4 , step 4000 : 1.930430\n",
      "loss in epoch 4 , step 4020 : 1.783706\n",
      "loss in epoch 4 , step 4040 : 1.127259\n",
      "loss in epoch 4 , step 4060 : 1.319203\n",
      "loss in epoch 4 , step 4080 : 1.567790\n",
      "loss in epoch 4 , step 4100 : 1.874274\n",
      "loss in epoch 4 , step 4120 : 1.581465\n",
      "loss in epoch 4 , step 4140 : 1.004919\n",
      "loss in epoch 4 , step 4160 : 1.565064\n",
      "loss in epoch 4 , step 4180 : 2.379372\n",
      "loss in epoch 4 , step 4200 : 1.396632\n",
      "loss in epoch 4 , step 4220 : 1.932004\n",
      "loss in epoch 4 , step 4240 : 2.057061\n",
      "loss in epoch 4 , step 4260 : 2.042516\n",
      "loss in epoch 4 , step 4280 : 1.516986\n",
      "loss in epoch 4 , step 4300 : 1.953293\n",
      "loss in epoch 4 , step 4320 : 1.812637\n",
      "loss in epoch 4 , step 4340 : 0.233366\n",
      "loss in epoch 4 , step 4360 : 1.892432\n",
      "loss in epoch 4 , step 4380 : 3.269133\n",
      "loss in epoch 4 , step 4400 : 2.018076\n",
      "loss in epoch 4 , step 4420 : 1.042449\n",
      "loss in epoch 4 , step 4440 : 1.319684\n",
      "loss in epoch 4 , step 4460 : 2.094973\n",
      "loss in epoch 4 , step 4480 : 1.201537\n",
      "loss in epoch 4 , step 4500 : 0.424440\n",
      "loss in epoch 4 , step 4520 : 1.941382\n",
      "loss in epoch 4 , step 4540 : 0.838213\n",
      "loss in epoch 4 , step 4560 : 2.133940\n",
      "loss in epoch 4 , step 4580 : 2.782619\n",
      "loss in epoch 4 , step 4600 : 0.676576\n",
      "loss in epoch 4 , step 4620 : 1.297504\n",
      "loss in epoch 4 , step 4640 : 2.538303\n",
      "loss in epoch 4 , step 4660 : 1.281873\n",
      "loss in epoch 4 , step 4680 : 1.650587\n",
      "loss in epoch 4 , step 4700 : 1.679031\n",
      "loss in epoch 4 , step 4720 : 1.267098\n",
      "loss in epoch 4 , step 4740 : 2.995273\n",
      "loss in epoch 4 , step 4760 : 2.757364\n",
      "loss in epoch 4 , step 4780 : 1.637017\n",
      "loss in epoch 4 , step 4800 : 2.744096\n",
      "loss in epoch 4 , step 4820 : 1.881508\n",
      "loss in epoch 4 , step 4840 : 1.867637\n",
      "loss in epoch 4 , step 4860 : 1.505182\n",
      "loss in epoch 4 , step 4880 : 2.114217\n",
      "loss in epoch 4 , step 4900 : 1.473372\n",
      "loss in epoch 4 , step 4920 : 1.820488\n",
      "loss in epoch 4 , step 4940 : 1.456139\n",
      "loss in epoch 4 , step 4960 : 1.796987\n",
      "loss in epoch 4 , step 4980 : 1.701045\n",
      "loss in epoch 4 , step 5000 : 1.738412\n",
      "loss in epoch 4 , step 5020 : 1.883487\n",
      "loss in epoch 4 , step 5040 : 1.198106\n",
      "loss in epoch 4 , step 5060 : 0.917848\n",
      "loss in epoch 4 , step 5080 : 0.633076\n",
      "loss in epoch 4 , step 5100 : 2.094857\n",
      "loss in epoch 4 , step 5120 : 2.499520\n",
      "loss in epoch 4 , step 5140 : 1.246249\n",
      "loss in epoch 4 , step 5160 : 1.321709\n",
      "loss in epoch 4 , step 5180 : 1.667346\n",
      "loss in epoch 4 , step 5200 : 1.681601\n",
      "loss in epoch 4 , step 5220 : 0.357620\n",
      "loss in epoch 4 , step 5240 : 2.163042\n",
      "loss in epoch 4 , step 5260 : 1.831343\n",
      "loss in epoch 4 , step 5280 : 1.928752\n",
      "loss in epoch 4 , step 5300 : 2.159228\n",
      "loss in epoch 4 , step 5320 : 1.528404\n",
      "loss in epoch 4 , step 5340 : 0.197697\n",
      "loss in epoch 4 , step 5360 : 0.346747\n",
      "loss in epoch 4 , step 5380 : 1.099010\n",
      "loss in epoch 4 , step 5400 : 2.102860\n",
      "loss in epoch 4 , step 5420 : 2.733844\n",
      "loss in epoch 4 , step 5440 : 0.263844\n",
      "loss in epoch 4 , step 5460 : 2.081229\n",
      "loss in epoch 4 , step 5480 : 1.993068\n",
      "loss in epoch 4 , step 5500 : 1.347716\n",
      "loss in epoch 4 , step 5520 : 1.456879\n",
      "loss in epoch 4 , step 5540 : 0.948363\n",
      "loss in epoch 4 , step 5560 : 1.668328\n",
      "loss in epoch 4 , step 5580 : 2.104514\n",
      "loss in epoch 4 , step 5600 : 1.562473\n",
      "loss in epoch 4 , step 5620 : 1.724128\n",
      "loss in epoch 4 , step 5640 : 2.020663\n",
      "loss in epoch 4 , step 5660 : 2.513890\n",
      "loss in epoch 4 , step 5680 : 1.345114\n",
      "loss in epoch 4 , step 5700 : 1.412089\n",
      "loss in epoch 4 , step 5720 : 1.589271\n",
      "loss in epoch 4 , step 5740 : 0.328293\n",
      "loss in epoch 4 , step 5760 : 1.599040\n",
      "loss in epoch 4 , step 5780 : 1.816973\n",
      "loss in epoch 4 , step 5800 : 1.394025\n",
      "loss in epoch 4 , step 5820 : 1.889067\n",
      "loss in epoch 4 , step 5840 : 1.662501\n",
      "loss in epoch 4 , step 5860 : 1.386290\n",
      "loss in epoch 4 , step 5880 : 0.989496\n",
      "loss in epoch 4 , step 5900 : 0.941842\n",
      "loss in epoch 4 , step 5920 : 1.227758\n",
      "loss in epoch 4 , step 5940 : 1.819762\n",
      "loss in epoch 4 , step 5960 : 1.748028\n",
      "loss in epoch 4 , step 5980 : 2.503558\n",
      "loss in epoch 4 , step 6000 : 0.937957\n",
      "loss in epoch 4 , step 6020 : 1.903952\n",
      "loss in epoch 4 , step 6040 : 1.408753\n",
      "loss in epoch 4 , step 6060 : 1.084769\n",
      "loss in epoch 4 , step 6080 : 1.376377\n",
      "loss in epoch 4 , step 6100 : 1.908431\n",
      "loss in epoch 4 , step 6120 : 1.324523\n",
      "loss in epoch 4 , step 6140 : 0.192242\n",
      "loss in epoch 4 , step 6160 : 1.784382\n",
      "loss in epoch 4 , step 6180 : 1.774043\n",
      "loss in epoch 4 , step 6200 : 2.707864\n",
      "loss in epoch 4 , step 6220 : 0.343472\n",
      "loss in epoch 4 , step 6240 : 1.434832\n",
      "loss in epoch 4 , step 6260 : 1.194968\n",
      "loss in epoch 4 , step 6280 : 0.229774\n",
      "loss in epoch 4 , step 6300 : 1.542671\n",
      "loss in epoch 4 , step 6320 : 1.368431\n",
      "loss in epoch 4 , step 6340 : 2.488573\n",
      "loss in epoch 4 , step 6360 : 1.365396\n",
      "loss in epoch 4 , step 6380 : 1.567048\n",
      "loss in epoch 4 , step 6400 : 1.623224\n",
      "loss in epoch 4 , step 6420 : 0.976579\n",
      "loss in epoch 4 , step 6440 : 2.204091\n",
      "loss in epoch 4 , step 6460 : 3.576264\n",
      "loss in epoch 4 , step 6480 : 1.667793\n",
      "loss in epoch 4 , step 6500 : 2.306502\n",
      "loss in epoch 4 , step 6520 : 0.355454\n",
      "loss in epoch 4 , step 6540 : 1.540649\n",
      "loss in epoch 4 , step 6560 : 1.829431\n",
      "loss in epoch 4 , step 6580 : 2.315555\n",
      "loss in epoch 4 , step 6600 : 1.082963\n",
      "loss in epoch 4 , step 6620 : 2.237245\n",
      "loss in epoch 4 , step 6640 : 1.286900\n",
      "loss in epoch 4 , step 6660 : 1.802773\n",
      "loss in epoch 4 , step 6680 : 2.135945\n",
      "loss in epoch 4 , step 6700 : 1.982678\n",
      "loss in epoch 4 , step 6720 : 1.037662\n",
      "loss in epoch 4 , step 6740 : 2.492738\n",
      "loss in epoch 4 , step 6760 : 1.606764\n",
      "loss in epoch 4 , step 6780 : 1.109485\n",
      "loss in epoch 4 , step 6800 : 1.481517\n",
      "loss in epoch 4 , step 6820 : 1.806074\n",
      "loss in epoch 4 , step 6840 : 0.803820\n",
      "loss in epoch 4 , step 6860 : 1.700794\n",
      "loss in epoch 4 , step 6880 : 2.138161\n",
      "loss in epoch 4 , step 6900 : 1.701361\n",
      "loss in epoch 4 , step 6920 : 0.912715\n",
      "loss in epoch 4 , step 6940 : 1.206455\n",
      "loss in epoch 4 , step 6960 : 1.232003\n",
      "loss in epoch 4 , step 6980 : 1.368712\n",
      "loss in epoch 4 , step 7000 : 1.330296\n",
      "loss in epoch 4 , step 7020 : 1.359271\n",
      "loss in epoch 4 , step 7040 : 1.893948\n",
      "loss in epoch 4 , step 7060 : 1.840465\n",
      "loss in epoch 4 , step 7080 : 1.591226\n",
      "loss in epoch 4 , step 7100 : 1.526610\n",
      "loss in epoch 4 , step 7120 : 2.157652\n",
      "loss in epoch 4 , step 7140 : 1.295951\n",
      "loss in epoch 4 , step 7160 : 1.580050\n",
      "loss in epoch 4 , step 7180 : 0.967058\n",
      "loss in epoch 4 , step 7200 : 2.313967\n",
      "loss in epoch 4 , step 7220 : 0.309640\n",
      "loss in epoch 4 , step 7240 : 1.408213\n",
      "loss in epoch 4 , step 7260 : 2.107542\n",
      "loss in epoch 4 , step 7280 : 0.369547\n",
      "loss in epoch 4 , step 7300 : 3.205515\n",
      "loss in epoch 4 , step 7320 : 2.167403\n",
      "loss in epoch 4 , step 7340 : 1.377172\n",
      "loss in epoch 4 , step 7360 : 2.569562\n",
      "loss in epoch 4 , step 7380 : 2.030739\n",
      "loss in epoch 4 , step 7400 : 0.171005\n",
      "loss in epoch 4 , step 7420 : 1.013138\n",
      "loss in epoch 4 , step 7440 : 1.873171\n",
      "loss in epoch 4 , step 7460 : 1.608514\n",
      "loss in epoch 4 , step 7480 : 1.874248\n",
      "loss in epoch 4 , step 7500 : 1.386638\n",
      "loss in epoch 4 , step 7520 : 1.649692\n",
      "loss in epoch 4 , step 7540 : 1.798169\n",
      "loss in epoch 4 , step 7560 : 2.045094\n",
      "loss in epoch 4 , step 7580 : 1.703176\n",
      "loss in epoch 4 , step 7600 : 1.690558\n",
      "loss in epoch 4 , step 7620 : 1.921532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 4 , step 7640 : 1.769060\n",
      "loss in epoch 4 , step 7660 : 1.605875\n",
      "loss in epoch 4 , step 7680 : 2.366024\n",
      "loss in epoch 4 , step 7700 : 3.062996\n",
      "loss in epoch 4 , step 7720 : 3.768757\n",
      "loss in epoch 4 , step 7740 : 0.283680\n",
      "loss in epoch 4 , step 7760 : 1.401293\n",
      "loss in epoch 4 , step 7780 : 1.326659\n",
      "loss in epoch 4 , step 7800 : 1.952036\n",
      "loss in epoch 4 , step 7820 : 1.723120\n",
      "loss in epoch 4 , step 7840 : 0.629555\n",
      "loss in epoch 4 , step 7860 : 0.786988\n",
      "loss in epoch 4 , step 7880 : 2.242930\n",
      "loss in epoch 4 , step 7900 : 1.663400\n",
      "loss in epoch 4 , step 7920 : 1.647149\n",
      "loss in epoch 4 , step 7940 : 1.352200\n",
      "loss in epoch 4 , step 7960 : 1.436033\n",
      "loss in epoch 4 , step 7980 : 1.238120\n",
      "loss in epoch 4 , step 8000 : 0.179893\n",
      "loss in epoch 4 , step 8020 : 1.466089\n",
      "loss in epoch 4 , step 8040 : 0.554981\n",
      "loss in epoch 4 , step 8060 : 1.510576\n",
      "loss in epoch 4 , step 8080 : 1.531026\n",
      "loss in epoch 4 , step 8100 : 0.620681\n",
      "loss in epoch 4 , step 8120 : 0.388745\n",
      "loss in epoch 4 , step 8140 : 1.790294\n",
      "loss in epoch 4 , step 8160 : 2.118785\n",
      "loss in epoch 4 , step 8180 : 0.345839\n",
      "loss in epoch 4 , step 8200 : 4.000053\n",
      "loss in epoch 4 , step 8220 : 1.274700\n",
      "loss in epoch 4 , step 8240 : 2.230769\n",
      "loss in epoch 4 , step 8260 : 2.404222\n",
      "loss in epoch 4 , step 8280 : 2.037990\n",
      "loss in epoch 4 , step 8300 : 1.623213\n",
      "loss in epoch 4 , step 8320 : 1.908913\n",
      "loss in epoch 4 , step 8340 : 2.161256\n",
      "loss in epoch 4 , step 8360 : 0.180174\n",
      "loss in epoch 4 , step 8380 : 1.822987\n",
      "loss in epoch 4 , step 8400 : 3.494656\n",
      "loss in epoch 4 , step 8420 : 1.697123\n",
      "loss in epoch 4 , step 8440 : 1.249307\n",
      "loss in epoch 4 , step 8460 : 2.030151\n",
      "loss in epoch 4 , step 8480 : 0.550067\n",
      "loss in epoch 4 , step 8500 : 1.420539\n",
      "loss in epoch 4 , step 8520 : 2.147059\n",
      "loss in epoch 4 , step 8540 : 0.203858\n",
      "loss in epoch 4 , step 8560 : 2.599780\n",
      "loss in epoch 4 , step 8580 : 1.063883\n",
      "loss in epoch 4 , step 8600 : 1.256658\n",
      "loss in epoch 4 , step 8620 : 1.512086\n",
      "loss in epoch 4 , step 8640 : 2.521201\n",
      "loss in epoch 4 , step 8660 : 2.380882\n",
      "loss in epoch 4 , step 8680 : 1.152718\n",
      "loss in epoch 4 , step 8700 : 0.367251\n",
      "loss in epoch 4 , step 8720 : 1.758296\n",
      "loss in epoch 4 , step 8740 : 1.875662\n",
      "loss in epoch 4 , step 8760 : 1.061077\n",
      "loss in epoch 4 , step 8780 : 1.780694\n",
      "loss in epoch 4 , step 8800 : 0.611708\n",
      "loss in epoch 4 , step 8820 : 0.328802\n",
      "loss in epoch 4 , step 8840 : 1.051865\n",
      "loss in epoch 4 , step 8860 : 1.105322\n",
      "loss in epoch 4 , step 8880 : 2.053203\n",
      "loss in epoch 4 , step 8900 : 1.952705\n",
      "loss in epoch 4 , step 8920 : 0.439158\n",
      "loss in epoch 4 , step 8940 : 1.782360\n",
      "loss in epoch 4 , step 8960 : 0.380146\n",
      "loss in epoch 4 , step 8980 : 1.256036\n",
      "loss in epoch 4 , step 9000 : 1.707878\n",
      "loss in epoch 4 , step 9020 : 1.749566\n",
      "loss in epoch 4 , step 9040 : 1.916797\n",
      "loss in epoch 4 , step 9060 : 1.461156\n",
      "loss in epoch 4 , step 9080 : 1.827297\n",
      "loss in epoch 4 , step 9100 : 1.190144\n",
      "loss in epoch 4 , step 9120 : 1.320803\n",
      "loss in epoch 4 , step 9140 : 1.711746\n",
      "loss in epoch 4 , step 9160 : 2.113823\n",
      "loss in epoch 4 , step 9180 : 0.360944\n",
      "loss in epoch 4 , step 9200 : 1.668358\n",
      "loss in epoch 4 , step 9220 : 1.434767\n",
      "loss in epoch 4 , step 9240 : 2.062450\n",
      "loss in epoch 4 , step 9260 : 0.661998\n",
      "loss in epoch 4 , step 9280 : 1.723358\n",
      "loss in epoch 4 , step 9300 : 1.868909\n",
      "loss in epoch 4 , step 9320 : 1.625736\n",
      "loss in epoch 4 , step 9340 : 1.641054\n",
      "loss in epoch 4 , step 9360 : 1.091403\n",
      "loss in epoch 4 , step 9380 : 1.572994\n",
      "loss in epoch 4 , step 9400 : 2.383063\n",
      "loss in epoch 4 , step 9420 : 2.800002\n",
      "loss in epoch 4 , step 9440 : 1.461673\n",
      "loss in epoch 4 , step 9460 : 0.801154\n",
      "loss in epoch 4 , step 9480 : 1.563689\n",
      "loss in epoch 4 , step 9500 : 1.152903\n",
      "loss in epoch 4 , step 9520 : 2.571396\n",
      "loss in epoch 4 , step 9540 : 1.434903\n",
      "loss in epoch 4 , step 9560 : 1.963695\n",
      "loss in epoch 4 , step 9580 : 0.137166\n",
      "loss in epoch 4 , step 9600 : 1.606050\n",
      "loss in epoch 4 , step 9620 : 1.330302\n",
      "loss in epoch 4 , step 9640 : 1.363444\n",
      "loss in epoch 4 , step 9660 : 2.960809\n",
      "loss in epoch 4 , step 9680 : 1.289295\n",
      "loss in epoch 4 , step 9700 : 1.860712\n",
      "loss in epoch 4 , step 9720 : 1.438699\n",
      "loss in epoch 4 , step 9740 : 0.735542\n",
      "loss in epoch 4 , step 9760 : 2.366152\n",
      "loss in epoch 4 , step 9780 : 0.685044\n",
      "loss in epoch 4 , step 9800 : 1.751166\n",
      "loss in epoch 4 , step 9820 : 1.526421\n",
      "loss in epoch 4 , step 9840 : 2.833317\n",
      "loss in epoch 4 , step 9860 : 4.630460\n",
      "loss in epoch 4 , step 9880 : 1.843982\n",
      "loss in epoch 4 , step 9900 : 0.870208\n",
      "loss in epoch 4 , step 9920 : 1.918276\n",
      "loss in epoch 4 , step 9940 : 1.842420\n",
      "loss in epoch 4 , step 9960 : 1.229553\n",
      "loss in epoch 4 , step 9980 : 1.351369\n",
      "loss in epoch 4 , step 10000 : 1.818834\n",
      "loss in epoch 4 , step 10020 : 1.835621\n",
      "loss in epoch 4 , step 10040 : 0.397401\n",
      "loss in epoch 4 , step 10060 : 1.692839\n",
      "loss in epoch 4 , step 10080 : 0.588758\n",
      "loss in epoch 4 , step 10100 : 1.964496\n",
      "loss in epoch 4 , step 10120 : 1.673993\n",
      "loss in epoch 4 , step 10140 : 0.143105\n",
      "loss in epoch 4 , step 10160 : 1.735528\n",
      "loss in epoch 4 , step 10180 : 1.181910\n",
      "loss in epoch 4 , step 10200 : 1.031550\n",
      "loss in epoch 4 , step 10220 : 1.251848\n",
      "loss in epoch 4 , step 10240 : 2.042534\n",
      "loss in epoch 4 , step 10260 : 1.295902\n",
      "loss in epoch 4 , step 10280 : 1.508325\n",
      "loss in epoch 4 , step 10300 : 1.138774\n",
      "loss in epoch 4 , step 10320 : 1.434447\n",
      "loss in epoch 4 , step 10340 : 2.137657\n",
      "loss in epoch 4 , step 10360 : 0.295566\n",
      "loss in epoch 4 , step 10380 : 2.080184\n",
      "loss in epoch 4 , step 10400 : 1.042702\n",
      "loss in epoch 4 , step 10420 : 1.741930\n",
      "loss in epoch 4 , step 10440 : 1.935163\n",
      "loss in epoch 4 , step 10460 : 1.634391\n",
      "loss in epoch 4 , step 10480 : 0.967154\n",
      "loss in epoch 4 , step 10500 : 1.488631\n",
      "loss in epoch 4 , step 10520 : 1.042082\n",
      "loss in epoch 4 , step 10540 : 1.119072\n",
      "loss in epoch 4 , step 10560 : 0.293532\n",
      "loss in epoch 4 , step 10580 : 1.945561\n",
      "loss in epoch 4 , step 10600 : 1.454614\n",
      "loss in epoch 4 , step 10620 : 1.620271\n",
      "loss in epoch 4 , step 10640 : 1.768610\n",
      "loss in epoch 4 , step 10660 : 2.311464\n",
      "loss in epoch 4 , step 10680 : 1.826865\n",
      "loss in epoch 4 , step 10700 : 1.227157\n",
      "loss in epoch 4 , step 10720 : 2.094154\n",
      "loss in epoch 4 , step 10740 : 1.585670\n",
      "loss in epoch 4 , step 10760 : 0.925937\n",
      "loss in epoch 4 , step 10780 : 0.807465\n",
      "loss in epoch 4 , step 10800 : 0.114056\n",
      "loss in epoch 4 , step 10820 : 2.230301\n",
      "loss in epoch 4 , step 10840 : 2.344968\n",
      "loss in epoch 4 , step 10860 : 1.720339\n",
      "loss in epoch 4 , step 10880 : 2.220602\n",
      "loss in epoch 4 , step 10900 : 1.342370\n",
      "loss in epoch 4 , step 10920 : 1.811691\n",
      "loss in epoch 4 , step 10940 : 4.452412\n",
      "loss in epoch 4 , step 10960 : 2.006979\n",
      "loss in epoch 4 , step 10980 : 1.633359\n",
      "loss in epoch 4 , step 11000 : 0.904822\n",
      "loss in epoch 4 , step 11020 : 2.247167\n",
      "loss in epoch 4 , step 11040 : 1.799236\n",
      "loss in epoch 4 , step 11060 : 1.584523\n",
      "loss in epoch 4 , step 11080 : 1.043490\n",
      "loss in epoch 4 , step 11100 : 0.068729\n",
      "loss in epoch 4 , step 11120 : 1.203022\n",
      "loss in epoch 4 , step 11140 : 1.326305\n",
      "loss in epoch 4 , step 11160 : 1.767467\n",
      "loss in epoch 4 , step 11180 : 3.364679\n",
      "loss in epoch 4 , step 11200 : 1.021694\n",
      "loss in epoch 4 , step 11220 : 2.212264\n",
      "loss in epoch 4 , step 11240 : 1.309461\n",
      "loss in epoch 4 , step 11260 : 2.147254\n",
      "loss in epoch 4 , step 11280 : 1.848280\n",
      "loss in epoch 4 , step 11300 : 1.476541\n",
      "loss in epoch 4 , step 11320 : 0.381482\n",
      "loss in epoch 4 , step 11340 : 1.829185\n",
      "loss in epoch 4 , step 11360 : 2.501406\n",
      "loss in epoch 4 , step 11380 : 1.972502\n",
      "loss in epoch 4 , step 11400 : 2.120672\n",
      "loss in epoch 4 , step 11420 : 0.734709\n",
      "loss in epoch 4 , step 11440 : 1.970146\n",
      "loss in epoch 4 , step 11460 : 2.700416\n",
      "loss in epoch 4 , step 11480 : 2.295121\n",
      "loss in epoch 4 , step 11500 : 1.426653\n",
      "loss in epoch 4 , step 11520 : 1.134706\n",
      "loss in epoch 4 , step 11540 : 1.288843\n",
      "loss in epoch 4 , step 11560 : 3.873646\n",
      "loss in epoch 4 , step 11580 : 1.707480\n",
      "loss in epoch 4 , step 11600 : 1.680508\n",
      "loss in epoch 4 , step 11620 : 1.800146\n",
      "loss in epoch 4 , step 11640 : 1.118176\n",
      "loss in epoch 4 , step 11660 : 1.928151\n",
      "loss in epoch 4 , step 11680 : 1.969049\n",
      "loss in epoch 4 , step 11700 : 1.535223\n",
      "loss in epoch 4 , step 11720 : 1.752599\n",
      "loss in epoch 4 , step 11740 : 1.872387\n",
      "loss in epoch 4 , step 11760 : 1.995078\n",
      "loss in epoch 4 , step 11780 : 1.464486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 4 , step 11800 : 1.974215\n",
      "loss in epoch 4 , step 11820 : 1.192605\n",
      "loss in epoch 4 , step 11840 : 2.054084\n",
      "loss in epoch 4 , step 11860 : 2.402814\n",
      "loss in epoch 4 , step 11880 : 1.081491\n",
      "loss in epoch 4 , step 11900 : 0.168729\n",
      "loss in epoch 4 , step 11920 : 1.686948\n",
      "loss in epoch 4 , step 11940 : 1.949925\n",
      "loss in epoch 4 , step 11960 : 1.630218\n",
      "loss in epoch 4 , step 11980 : 1.487168\n",
      "loss in epoch 4 , step 12000 : 1.320116\n",
      "loss in epoch 4 , step 12020 : 0.739729\n",
      "loss in epoch 4 , step 12040 : 0.069870\n",
      "loss in epoch 4 , step 12060 : 1.700355\n",
      "loss in epoch 4 , step 12080 : 1.333068\n",
      "loss in epoch 4 , step 12100 : 2.330348\n",
      "loss in epoch 4 , step 12120 : 0.501341\n",
      "loss in epoch 4 , step 12140 : 1.805222\n",
      "loss in epoch 4 , step 12160 : 1.110281\n",
      "loss in epoch 4 , step 12180 : 1.877805\n",
      "loss in epoch 4 , step 12200 : 0.794951\n",
      "loss in epoch 4 , step 12220 : 2.309003\n",
      "loss in epoch 4 , step 12240 : 0.692174\n",
      "loss in epoch 4 , step 12260 : 1.570539\n",
      "loss in epoch 4 , step 12280 : 2.327479\n",
      "loss in epoch 4 , step 12300 : 0.310935\n",
      "loss in epoch 4 , step 12320 : 0.905361\n",
      "loss in epoch 4 , step 12340 : 0.243786\n",
      "loss in epoch 4 , step 12360 : 1.086338\n",
      "loss in epoch 4 , step 12380 : 1.071932\n",
      "loss in epoch 4 , step 12400 : 1.896118\n",
      "loss in epoch 4 , step 12420 : 1.510993\n",
      "loss in epoch 4 , step 12440 : 3.573513\n",
      "loss in epoch 4 , step 12460 : 0.600382\n",
      "loss in epoch 4 , step 12480 : 1.559420\n",
      "loss in epoch 4 , step 12500 : 1.895054\n",
      "loss in epoch 4 , step 12520 : 2.140373\n",
      "loss in epoch 4 , step 12540 : 2.198033\n",
      "loss in epoch 4 , step 12560 : 1.533896\n",
      "loss in epoch 4 , step 12580 : 1.867941\n",
      "loss in epoch 4 , step 12600 : 1.505855\n",
      "loss in epoch 4 , step 12620 : 1.905987\n",
      "loss in epoch 4 , step 12640 : 0.791207\n",
      "loss in epoch 4 , step 12660 : 1.888568\n",
      "loss in epoch 4 , step 12680 : 2.320804\n",
      "loss in epoch 4 , step 12700 : 1.919647\n",
      "loss in epoch 4 , step 12720 : 2.202607\n",
      "loss in epoch 4 , step 12740 : 0.181545\n",
      "loss in epoch 4 , step 12760 : 1.052472\n",
      "loss in epoch 4 , step 12780 : 1.277484\n",
      "loss in epoch 4 , step 12800 : 1.718028\n",
      "loss in epoch 4 , step 12820 : 1.688881\n",
      "loss in epoch 4 , step 12840 : 1.423802\n",
      "loss in epoch 4 , step 12860 : 0.656575\n",
      "loss in epoch 4 , step 12880 : 1.913248\n",
      "loss in epoch 4 , step 12900 : 1.861819\n",
      "loss in epoch 4 , step 12920 : 2.192988\n",
      "loss in epoch 4 , step 12940 : 0.827988\n",
      "loss in epoch 4 , step 12960 : 1.713680\n",
      "loss in epoch 4 , step 12980 : 0.845321\n",
      "loss in epoch 4 , step 13000 : 1.978991\n",
      "loss in epoch 4 , step 13020 : 1.746756\n",
      "loss in epoch 4 , step 13040 : 1.738423\n",
      "loss in epoch 4 , step 13060 : 1.916426\n",
      "loss in epoch 4 , step 13080 : 1.793668\n",
      "loss in epoch 4 , step 13100 : 1.135234\n",
      "loss in epoch 4 , step 13120 : 1.528471\n",
      "loss in epoch 4 , step 13140 : 1.375471\n",
      "loss in epoch 4 , step 13160 : 1.628286\n",
      "loss in epoch 4 , step 13180 : 0.169500\n",
      "loss in epoch 4 , step 13200 : 1.614160\n",
      "loss in epoch 4 , step 13220 : 1.687131\n",
      "loss in epoch 4 , step 13240 : 2.331210\n",
      "loss in epoch 4 , step 13260 : 0.882210\n",
      "loss in epoch 4 , step 13280 : 1.481249\n",
      "loss in epoch 4 , step 13300 : 1.065135\n",
      "loss in epoch 4 , step 13320 : 1.452338\n",
      "loss in epoch 4 , step 13340 : 1.978707\n",
      "loss in epoch 4 , step 13360 : 0.912243\n",
      "loss in epoch 4 , step 13380 : 2.221791\n",
      "loss in epoch 4 , step 13400 : 2.366820\n",
      "loss in epoch 4 , step 13420 : 0.859022\n",
      "loss in epoch 4 , step 13440 : 0.457322\n",
      "loss in epoch 4 , step 13460 : 1.083214\n",
      "loss in epoch 4 , step 13480 : 1.396705\n",
      "loss in epoch 4 , step 13500 : 2.026575\n",
      "loss in epoch 4 , step 13520 : 3.065716\n",
      "loss in epoch 4 , step 13540 : 0.302418\n",
      "loss in epoch 4 , step 13560 : 1.496127\n",
      "loss in epoch 4 , step 13580 : 1.163288\n",
      "loss in epoch 4 , step 13600 : 1.673008\n",
      "loss in epoch 4 , step 13620 : 1.656809\n",
      "loss in epoch 4 , step 13640 : 2.711304\n",
      "loss in epoch 4 , step 13660 : 1.921804\n",
      "loss in epoch 4 , step 13680 : 1.002505\n",
      "loss in epoch 4 , step 13700 : 1.704954\n",
      "loss in epoch 4 , step 13720 : 1.434946\n",
      "loss in epoch 4 , step 13740 : 1.678544\n",
      "loss in epoch 4 , step 13760 : 1.523956\n",
      "loss in epoch 4 , step 13780 : 1.866556\n",
      "loss in epoch 4 , step 13800 : 1.319490\n",
      "loss in epoch 4 , step 13820 : 3.197044\n",
      "loss in epoch 4 , step 13840 : 1.378708\n",
      "loss in epoch 4 , step 13860 : 0.689798\n",
      "loss in epoch 4 , step 13880 : 1.873942\n",
      "loss in epoch 4 , step 13900 : 1.749976\n",
      "loss in epoch 4 , step 13920 : 1.660615\n",
      "loss in epoch 4 , step 13940 : 1.765722\n",
      "loss in epoch 4 , step 13960 : 2.240250\n",
      "loss in epoch 4 , step 13980 : 1.524884\n",
      "loss in epoch 4 , step 14000 : 1.613771\n",
      "loss in epoch 4 , step 14020 : 2.205226\n",
      "loss in epoch 4 , step 14040 : 1.796202\n",
      "loss in epoch 4 , step 14060 : 1.154456\n",
      "loss in epoch 4 , step 14080 : 1.727414\n",
      "loss in epoch 4 , step 14100 : 1.380175\n",
      "loss in epoch 4 , step 14120 : 1.589461\n",
      "loss in epoch 4 , step 14140 : 0.292391\n",
      "loss in epoch 4 , step 14160 : 1.445084\n",
      "loss in epoch 4 , step 14180 : 0.417718\n",
      "loss in epoch 4 , step 14200 : 2.112930\n",
      "loss in epoch 4 , step 14220 : 1.934109\n",
      "loss in epoch 4 , step 14240 : 1.579375\n",
      "loss in epoch 4 , step 14260 : 1.279960\n",
      "loss in epoch 4 , step 14280 : 2.299777\n",
      "loss in epoch 4 , step 14300 : 2.113172\n",
      "loss in epoch 4 , step 14320 : 2.137499\n",
      "loss in epoch 4 , step 14340 : 1.458919\n",
      "loss in epoch 4 , step 14360 : 1.375744\n",
      "loss in epoch 4 , step 14380 : 1.667257\n",
      "loss in epoch 4 , step 14400 : 1.631666\n",
      "loss in epoch 4 , step 14420 : 1.870054\n",
      "loss in epoch 4 , step 14440 : 1.512422\n",
      "loss in epoch 4 , step 14460 : 2.051224\n",
      "loss in epoch 4 , step 14480 : 1.500612\n",
      "loss in epoch 4 , step 14500 : 1.719965\n",
      "loss in epoch 4 , step 14520 : 1.662260\n",
      "loss in epoch 4 , step 14540 : 1.343554\n",
      "loss in epoch 4 , step 14560 : 1.022109\n",
      "loss in epoch 4 , step 14580 : 0.444484\n",
      "loss in epoch 4 , step 14600 : 1.571074\n",
      "loss in epoch 4 , step 14620 : 1.412642\n",
      "loss in epoch 4 , step 14640 : 1.312530\n",
      "loss in epoch 4 , step 14660 : 2.305419\n",
      "loss in epoch 4 , step 14680 : 2.181474\n",
      "loss in epoch 4 , step 14700 : 2.130409\n",
      "loss in epoch 4 , step 14720 : 1.505566\n",
      "loss in epoch 4 , step 14740 : 0.702238\n",
      "loss in epoch 4 , step 14760 : 1.741822\n",
      "loss in epoch 4 , step 14780 : 1.676702\n",
      "loss in epoch 4 , step 14800 : 1.069603\n",
      "loss in epoch 4 , step 14820 : 2.104947\n",
      "loss in epoch 4 , step 14840 : 1.893439\n",
      "loss in epoch 4 , step 14860 : 1.207563\n",
      "loss in epoch 4 , step 14880 : 1.961817\n",
      "loss in epoch 4 , step 14900 : 1.013862\n",
      "loss in epoch 4 , step 14920 : 1.383103\n",
      "loss in epoch 4 , step 14940 : 0.477038\n",
      "loss in epoch 4 , step 14960 : 1.497685\n",
      "loss in epoch 4 , step 14980 : 1.371332\n",
      "loss in epoch 4 , step 15000 : 0.907387\n",
      "loss in epoch 4 , step 15020 : 2.547336\n",
      "loss in epoch 4 , step 15040 : 0.440822\n",
      "loss in epoch 4 , step 15060 : 1.086901\n",
      "loss in epoch 4 , step 15080 : 1.218884\n",
      "loss in epoch 4 , step 15100 : 1.339383\n",
      "loss in epoch 4 , step 15120 : 2.247710\n",
      "loss in epoch 4 , step 15140 : 2.744162\n",
      "loss in epoch 4 , step 15160 : 0.758312\n",
      "loss in epoch 4 , step 15180 : 2.228903\n",
      "loss in epoch 4 , step 15200 : 1.880286\n",
      "loss in epoch 4 , step 15220 : 1.658379\n",
      "loss in epoch 4 , step 15240 : 0.352225\n",
      "loss in epoch 4 , step 15260 : 0.324288\n",
      "loss in epoch 4 , step 15280 : 0.302970\n",
      "loss in epoch 4 , step 15300 : 0.998146\n",
      "loss in epoch 4 , step 15320 : 1.320558\n",
      "loss in epoch 4 , step 15340 : 3.864712\n",
      "loss in epoch 4 , step 15360 : 2.130865\n",
      "loss in epoch 4 , step 15380 : 1.967750\n",
      "loss in epoch 4 , step 15400 : 0.756673\n",
      "loss in epoch 4 , step 15420 : 1.340640\n",
      "loss in epoch 4 , step 15440 : 1.510872\n",
      "loss in epoch 4 , step 15460 : 1.571008\n",
      "loss in epoch 4 , step 15480 : 1.091923\n",
      "loss in epoch 4 , step 15500 : 0.093105\n",
      "loss in epoch 4 , step 15520 : 2.724645\n",
      "loss in epoch 4 , step 15540 : 1.896675\n",
      "loss in epoch 4 , step 15560 : 0.721580\n",
      "loss in epoch 4 , step 15580 : 2.780456\n",
      "loss in epoch 4 , step 15600 : 1.947050\n",
      "loss in epoch 4 , step 15620 : 1.297535\n",
      "loss in epoch 4 , step 15640 : 1.827786\n",
      "loss in epoch 4 , step 15660 : 1.575443\n",
      "loss in epoch 4 , step 15680 : 1.147600\n",
      "loss in epoch 4 , step 15700 : 1.578299\n",
      "loss in epoch 4 , step 15720 : 1.701520\n",
      "loss in epoch 4 , step 15740 : 1.108381\n",
      "loss in epoch 4 , step 15760 : 0.734002\n",
      "loss in epoch 4 , step 15780 : 1.218290\n",
      "loss in epoch 4 , step 15800 : 2.371823\n",
      "loss in epoch 4 , step 15820 : 2.721569\n",
      "loss in epoch 4 , step 15840 : 0.806045\n",
      "loss in epoch 4 , step 15860 : 2.843210\n",
      "loss in epoch 4 , step 15880 : 1.774572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 4 , step 15900 : 1.945893\n",
      "loss in epoch 4 , step 15920 : 1.851349\n",
      "loss in epoch 4 , step 15940 : 2.227804\n",
      "loss in epoch 4 , step 15960 : 3.225606\n",
      "loss in epoch 4 , step 15980 : 1.240993\n",
      "loss in epoch 4 , step 16000 : 0.402386\n",
      "loss in epoch 4 , step 16020 : 1.468249\n",
      "loss in epoch 4 , step 16040 : 1.934689\n",
      "loss in epoch 4 , step 16060 : 1.809444\n",
      "loss in epoch 4 , step 16080 : 0.386226\n",
      "loss in epoch 4 , step 16100 : 0.516355\n",
      "loss in epoch 4 , step 16120 : 1.244807\n",
      "loss in epoch 4 , step 16140 : 1.321331\n",
      "loss in epoch 4 , step 16160 : 0.479110\n",
      "loss in epoch 4 , step 16180 : 2.251232\n",
      "loss in epoch 4 , step 16200 : 0.586049\n",
      "loss in epoch 4 , step 16220 : 2.118262\n",
      "loss in epoch 4 , step 16240 : 0.271697\n",
      "loss in epoch 4 , step 16260 : 1.587906\n",
      "loss in epoch 4 , step 16280 : 2.256144\n",
      "loss in epoch 4 , step 16300 : 0.212905\n",
      "loss in epoch 4 , step 16320 : 2.261977\n",
      "loss in epoch 4 , step 16340 : 2.114130\n",
      "loss in epoch 4 , step 16360 : 1.364414\n",
      "loss in epoch 4 , step 16380 : 2.025163\n",
      "loss in epoch 4 , step 16400 : 1.344142\n",
      "loss in epoch 4 , step 16420 : 0.776841\n",
      "loss in epoch 4 , step 16440 : 1.196409\n",
      "loss in epoch 4 , step 16460 : 2.051980\n",
      "loss in epoch 4 , step 16480 : 1.600211\n",
      "loss in epoch 4 , step 16500 : 1.949937\n",
      "loss in epoch 4 , step 16520 : 0.471109\n",
      "loss in epoch 4 , step 16540 : 0.619282\n",
      "loss in epoch 4 , step 16560 : 1.117822\n",
      "loss in epoch 4 , step 16580 : 1.948859\n",
      "loss in epoch 4 , step 16600 : 1.083381\n",
      "loss in epoch 4 , step 16620 : 2.308545\n",
      "loss in epoch 4 , step 16640 : 0.593901\n",
      "loss in epoch 4 , step 16660 : 1.962697\n",
      "loss in epoch 4 , step 16680 : 2.607230\n",
      "loss in epoch 4 , step 16700 : 1.757258\n",
      "loss in epoch 4 , step 16720 : 0.845590\n",
      "loss in epoch 4 , step 16740 : 1.557082\n",
      "loss in epoch 4 , step 16760 : 1.192806\n",
      "loss in epoch 4 , step 16780 : 0.880744\n",
      "loss in epoch 4 , step 16800 : 0.748913\n",
      "loss in epoch 4 , step 16820 : 0.711612\n",
      "loss in epoch 4 , step 16840 : 1.244265\n",
      "loss in epoch 4 , step 16860 : 1.567873\n",
      "loss in epoch 4 , step 16880 : 1.853650\n",
      "loss in epoch 4 , step 16900 : 0.424618\n",
      "loss in epoch 4 , step 16920 : 1.384431\n",
      "loss in epoch 4 , step 16940 : 1.526162\n",
      "loss in epoch 4 , step 16960 : 0.318969\n",
      "loss in epoch 4 , step 16980 : 1.807498\n",
      "loss in epoch 4 , step 17000 : 0.406325\n",
      "loss in epoch 4 , step 17020 : 1.765416\n",
      "loss in epoch 4 , step 17040 : 0.617394\n",
      "loss in epoch 4 , step 17060 : 0.194465\n",
      "loss in epoch 4 , step 17080 : 1.780331\n",
      "loss in epoch 4 , step 17100 : 1.880067\n",
      "loss in epoch 4 , step 17120 : 1.019437\n",
      "loss in epoch 4 , step 17140 : 1.720296\n",
      "loss in epoch 4 , step 17160 : 1.600935\n",
      "loss in epoch 4 , step 17180 : 2.233934\n",
      "loss in epoch 4 , step 17200 : 1.507810\n",
      "loss in epoch 4 , step 17220 : 1.109151\n",
      "loss in epoch 4 , step 17240 : 2.075585\n",
      "loss in epoch 4 , step 17260 : 2.400397\n",
      "loss in epoch 4 , step 17280 : 0.357798\n",
      "loss in epoch 4 , step 17300 : 1.329690\n",
      "loss in epoch 4 , step 17320 : 1.552791\n",
      "loss in epoch 4 , step 17340 : 1.811736\n",
      "loss in epoch 4 , step 17360 : 2.246611\n",
      "loss in epoch 4 , step 17380 : 0.176090\n",
      "loss in epoch 4 , step 17400 : 0.263506\n",
      "loss in epoch 4 , step 17420 : 1.778177\n",
      "loss in epoch 4 , step 17440 : 0.540859\n",
      "loss in epoch 4 , step 17460 : 0.188175\n",
      "loss in epoch 4 , step 17480 : 1.215933\n",
      "loss in epoch 4 , step 17500 : 1.502936\n",
      "loss in epoch 4 , step 17520 : 0.170660\n",
      "loss in epoch 4 , step 17540 : 0.787529\n",
      "loss in epoch 4 , step 17560 : 0.417080\n",
      "loss in epoch 4 , step 17580 : 1.524165\n",
      "loss in epoch 4 , step 17600 : 1.995969\n",
      "loss in epoch 4 , step 17620 : 2.109141\n",
      "loss in epoch 4 , step 17640 : 2.991861\n",
      "loss in epoch 4 , step 17660 : 1.373512\n",
      "loss in epoch 4 , step 17680 : 2.488599\n",
      "loss in epoch 4 , step 17700 : 2.276873\n",
      "loss in epoch 4 , step 17720 : 1.925436\n",
      "loss in epoch 4 , step 17740 : 0.869385\n",
      "loss in epoch 4 , step 17760 : 1.758551\n",
      "loss in epoch 4 , step 17780 : 1.503119\n",
      "loss in epoch 4 , step 17800 : 1.419069\n",
      "loss in epoch 4 , step 17820 : 1.414435\n",
      "loss in epoch 4 , step 17840 : 1.425802\n",
      "loss in epoch 4 , step 17860 : 0.925523\n",
      "loss in epoch 4 , step 17880 : 0.084285\n",
      "loss in epoch 4 , step 17900 : 0.827919\n",
      "loss in epoch 4 , step 17920 : 1.236620\n",
      "loss in epoch 4 , step 17940 : 1.444495\n",
      "loss in epoch 4 , step 17960 : 1.531725\n",
      "loss in epoch 4 , step 17980 : 1.099797\n",
      "loss in epoch 4 , step 18000 : 1.745656\n",
      "loss in epoch 4 , step 18020 : 1.251803\n",
      "loss in epoch 4 , step 18040 : 0.854683\n",
      "loss in epoch 4 , step 18060 : 2.037398\n",
      "loss in epoch 4 , step 18080 : 1.052968\n",
      "loss in epoch 4 , step 18100 : 1.801891\n",
      "loss in epoch 4 , step 18120 : 0.886746\n",
      "loss in epoch 4 , step 18140 : 3.231091\n",
      "loss in epoch 4 , step 18160 : 1.855461\n",
      "loss in epoch 4 , step 18180 : 1.370136\n",
      "loss in epoch 4 , step 18200 : 1.271609\n",
      "loss in epoch 4 , step 18220 : 0.105554\n",
      "loss in epoch 4 , step 18240 : 1.104636\n",
      "loss in epoch 4 , step 18260 : 1.222068\n",
      "loss in epoch 4 , step 18280 : 1.323573\n",
      "loss in epoch 4 , step 18300 : 1.635411\n",
      "loss in epoch 4 , step 18320 : 2.299092\n",
      "loss in epoch 4 , step 18340 : 2.117831\n",
      "loss in epoch 4 , step 18360 : 0.623372\n",
      "loss in epoch 4 , step 18380 : 1.522191\n",
      "loss in epoch 4 , step 18400 : 1.112684\n",
      "loss in epoch 4 , step 18420 : 1.867787\n",
      "loss in epoch 4 , step 18440 : 1.870988\n",
      "loss in epoch 4 , step 18460 : 2.111045\n",
      "loss in epoch 4 , step 18480 : 1.661939\n",
      "loss in epoch 4 , step 18500 : 2.593403\n",
      "loss in epoch 4 , step 18520 : 1.872413\n",
      "loss in epoch 4 , step 18540 : 2.204693\n",
      "loss in epoch 4 , step 18560 : 1.268033\n",
      "loss in epoch 4 , step 18580 : 0.179808\n",
      "loss in epoch 4 , step 18600 : 1.762030\n",
      "loss in epoch 4 , step 18620 : 2.394080\n",
      "loss in epoch 4 , step 18640 : 2.196721\n",
      "loss in epoch 4 , step 18660 : 1.456638\n",
      "loss in epoch 4 , step 18680 : 1.964805\n",
      "loss in epoch 4 , step 18700 : 1.745142\n",
      "loss in epoch 4 , step 18720 : 1.815168\n",
      "loss in epoch 4 , step 18740 : 0.793184\n",
      "loss in epoch 4 , step 18760 : 0.872849\n",
      "loss in epoch 4 , step 18780 : 1.740917\n",
      "loss in epoch 4 , step 18800 : 1.036027\n",
      "loss in epoch 4 , step 18820 : 1.962799\n",
      "loss in epoch 4 , step 18840 : 0.586623\n",
      "loss in epoch 4 , step 18860 : 2.783016\n",
      "loss in epoch 4 , step 18880 : 0.237441\n",
      "loss in epoch 4 , step 18900 : 2.352040\n",
      "loss in epoch 4 , step 18920 : 1.313885\n",
      "loss in epoch 4 , step 18940 : 1.206706\n",
      "loss in epoch 4 , step 18960 : 2.208841\n",
      "loss in epoch 4 , step 18980 : 0.841567\n",
      "loss in epoch 4 , step 19000 : 1.435878\n",
      "loss in epoch 4 , step 19020 : 2.052884\n",
      "loss in epoch 4 , step 19040 : 1.194972\n",
      "loss in epoch 4 , step 19060 : 1.474776\n",
      "loss in epoch 4 , step 19080 : 0.214301\n",
      "loss in epoch 4 , step 19100 : 1.323051\n",
      "loss in epoch 4 , step 19120 : 1.622029\n",
      "loss in epoch 4 , step 19140 : 1.449952\n",
      "loss in epoch 4 , step 19160 : 2.337896\n",
      "loss in epoch 4 , step 19180 : 1.695948\n",
      "loss in epoch 4 , step 19200 : 1.059951\n",
      "loss in epoch 4 , step 19220 : 1.327039\n",
      "loss in epoch 4 , step 19240 : 1.820077\n",
      "loss in epoch 4 , step 19260 : 1.577888\n",
      "loss in epoch 4 , step 19280 : 2.408986\n",
      "loss in epoch 4 , step 19300 : 1.566444\n",
      "loss in epoch 4 , step 19320 : 0.156562\n",
      "loss in epoch 4 , step 19340 : 0.493695\n",
      "loss in epoch 4 , step 19360 : 2.073048\n",
      "loss in epoch 4 , step 19380 : 0.297865\n",
      "loss in epoch 4 , step 19400 : 2.336470\n",
      "loss in epoch 4 , step 19420 : 0.660216\n",
      "loss in epoch 4 , step 19440 : 0.306318\n",
      "loss in epoch 4 , step 19460 : 0.451602\n",
      "loss in epoch 4 , step 19480 : 0.138091\n",
      "loss in epoch 4 , step 19500 : 2.196602\n",
      "loss in epoch 4 , step 19520 : 1.301569\n",
      "loss in epoch 4 , step 19540 : 1.340431\n",
      "loss in epoch 4 , step 19560 : 2.305763\n",
      "loss in epoch 4 , step 19580 : 2.046671\n",
      "loss in epoch 4 , step 19600 : 1.969935\n",
      "loss in epoch 4 , step 19620 : 1.292078\n",
      "loss in epoch 4 , step 19640 : 1.623600\n",
      "loss in epoch 4 , step 19660 : 2.176256\n",
      "loss in epoch 4 , step 19680 : 0.124656\n",
      "loss in epoch 4 , step 19700 : 1.108809\n",
      "loss in epoch 4 , step 19720 : 1.831868\n",
      "loss in epoch 4 , step 19740 : 0.963718\n",
      "loss in epoch 4 , step 19760 : 1.909605\n",
      "loss in epoch 4 , step 19780 : 1.016910\n",
      "loss in epoch 4 , step 19800 : 1.202661\n",
      "loss in epoch 4 , step 19820 : 1.389855\n",
      "loss in epoch 4 , step 19840 : 1.343446\n",
      "loss in epoch 4 , step 19860 : 1.683592\n",
      "loss in epoch 4 , step 19880 : 2.930219\n",
      "loss in epoch 4 , step 19900 : 1.979494\n",
      "loss in epoch 4 , step 19920 : 2.302060\n",
      "loss in epoch 4 , step 19940 : 1.672352\n",
      "Accuracy in epoch 4 : 21.535154\n",
      "loss in epoch 5 , step 0 : 0.129203\n",
      "loss in epoch 5 , step 20 : 2.965961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 5 , step 40 : 1.294414\n",
      "loss in epoch 5 , step 60 : 0.909317\n",
      "loss in epoch 5 , step 80 : 2.314019\n",
      "loss in epoch 5 , step 100 : 1.460899\n",
      "loss in epoch 5 , step 120 : 0.759823\n",
      "loss in epoch 5 , step 140 : 2.559116\n",
      "loss in epoch 5 , step 160 : 0.396677\n",
      "loss in epoch 5 , step 180 : 0.879449\n",
      "loss in epoch 5 , step 200 : 1.632612\n",
      "loss in epoch 5 , step 220 : 1.837350\n",
      "loss in epoch 5 , step 240 : 0.184654\n",
      "loss in epoch 5 , step 260 : 0.154290\n",
      "loss in epoch 5 , step 280 : 0.567121\n",
      "loss in epoch 5 , step 300 : 0.840518\n",
      "loss in epoch 5 , step 320 : 0.042832\n",
      "loss in epoch 5 , step 340 : 0.514291\n",
      "loss in epoch 5 , step 360 : 1.401062\n",
      "loss in epoch 5 , step 380 : 1.810002\n",
      "loss in epoch 5 , step 400 : 0.905141\n",
      "loss in epoch 5 , step 420 : 1.518819\n",
      "loss in epoch 5 , step 440 : 1.586218\n",
      "loss in epoch 5 , step 460 : 3.397951\n",
      "loss in epoch 5 , step 480 : 2.122734\n",
      "loss in epoch 5 , step 500 : 0.228787\n",
      "loss in epoch 5 , step 520 : 0.493720\n",
      "loss in epoch 5 , step 540 : 1.675964\n",
      "loss in epoch 5 , step 560 : 3.730660\n",
      "loss in epoch 5 , step 580 : 1.348573\n",
      "loss in epoch 5 , step 600 : 1.886045\n",
      "loss in epoch 5 , step 620 : 1.857070\n",
      "loss in epoch 5 , step 640 : 0.371149\n",
      "loss in epoch 5 , step 660 : 1.874493\n",
      "loss in epoch 5 , step 680 : 0.166178\n",
      "loss in epoch 5 , step 700 : 0.278871\n",
      "loss in epoch 5 , step 720 : 2.331245\n",
      "loss in epoch 5 , step 740 : 1.244238\n",
      "loss in epoch 5 , step 760 : 1.944768\n",
      "loss in epoch 5 , step 780 : 0.937694\n",
      "loss in epoch 5 , step 800 : 1.406458\n",
      "loss in epoch 5 , step 820 : 0.787057\n",
      "loss in epoch 5 , step 840 : 1.534026\n",
      "loss in epoch 5 , step 860 : 1.325521\n",
      "loss in epoch 5 , step 880 : 1.878234\n",
      "loss in epoch 5 , step 900 : 1.039170\n",
      "loss in epoch 5 , step 920 : 1.951486\n",
      "loss in epoch 5 , step 940 : 0.967019\n",
      "loss in epoch 5 , step 960 : 1.488246\n",
      "loss in epoch 5 , step 980 : 1.274385\n",
      "loss in epoch 5 , step 1000 : 1.215706\n",
      "loss in epoch 5 , step 1020 : 2.469447\n",
      "loss in epoch 5 , step 1040 : 1.145499\n",
      "loss in epoch 5 , step 1060 : 1.619988\n",
      "loss in epoch 5 , step 1080 : 1.015415\n",
      "loss in epoch 5 , step 1100 : 2.206837\n",
      "loss in epoch 5 , step 1120 : 1.375359\n",
      "loss in epoch 5 , step 1140 : 0.147855\n",
      "loss in epoch 5 , step 1160 : 0.945796\n",
      "loss in epoch 5 , step 1180 : 0.839302\n",
      "loss in epoch 5 , step 1200 : 0.813336\n",
      "loss in epoch 5 , step 1220 : 0.678895\n",
      "loss in epoch 5 , step 1240 : 1.003840\n",
      "loss in epoch 5 , step 1260 : 3.887509\n",
      "loss in epoch 5 , step 1280 : 0.286138\n",
      "loss in epoch 5 , step 1300 : 2.103425\n",
      "loss in epoch 5 , step 1320 : 1.810258\n",
      "loss in epoch 5 , step 1340 : 1.909016\n",
      "loss in epoch 5 , step 1360 : 1.590310\n",
      "loss in epoch 5 , step 1380 : 0.422589\n",
      "loss in epoch 5 , step 1400 : 1.850057\n",
      "loss in epoch 5 , step 1420 : 2.287488\n",
      "loss in epoch 5 , step 1440 : 2.432292\n",
      "loss in epoch 5 , step 1460 : 1.894931\n",
      "loss in epoch 5 , step 1480 : 2.622618\n",
      "loss in epoch 5 , step 1500 : 1.625764\n",
      "loss in epoch 5 , step 1520 : 1.836531\n",
      "loss in epoch 5 , step 1540 : 1.151743\n",
      "loss in epoch 5 , step 1560 : 1.368464\n",
      "loss in epoch 5 , step 1580 : 1.724451\n",
      "loss in epoch 5 , step 1600 : 1.656192\n",
      "loss in epoch 5 , step 1620 : 0.131500\n",
      "loss in epoch 5 , step 1640 : 0.078026\n",
      "loss in epoch 5 , step 1660 : 1.070361\n",
      "loss in epoch 5 , step 1680 : 1.981840\n",
      "loss in epoch 5 , step 1700 : 1.745685\n",
      "loss in epoch 5 , step 1720 : 0.207910\n",
      "loss in epoch 5 , step 1740 : 1.398853\n",
      "loss in epoch 5 , step 1760 : 1.656432\n",
      "loss in epoch 5 , step 1780 : 1.923486\n",
      "loss in epoch 5 , step 1800 : 1.365939\n",
      "loss in epoch 5 , step 1820 : 0.176835\n",
      "loss in epoch 5 , step 1840 : 0.127150\n",
      "loss in epoch 5 , step 1860 : 0.742383\n",
      "loss in epoch 5 , step 1880 : 0.919066\n",
      "loss in epoch 5 , step 1900 : 1.858529\n",
      "loss in epoch 5 , step 1920 : 2.088150\n",
      "loss in epoch 5 , step 1940 : 1.372870\n",
      "loss in epoch 5 , step 1960 : 0.459418\n",
      "loss in epoch 5 , step 1980 : 1.451358\n",
      "loss in epoch 5 , step 2000 : 1.129601\n",
      "loss in epoch 5 , step 2020 : 1.432197\n",
      "loss in epoch 5 , step 2040 : 1.862075\n",
      "loss in epoch 5 , step 2060 : 1.173653\n",
      "loss in epoch 5 , step 2080 : 2.783824\n",
      "loss in epoch 5 , step 2100 : 1.850848\n",
      "loss in epoch 5 , step 2120 : 1.798211\n",
      "loss in epoch 5 , step 2140 : 1.015115\n",
      "loss in epoch 5 , step 2160 : 1.067958\n",
      "loss in epoch 5 , step 2180 : 0.220786\n",
      "loss in epoch 5 , step 2200 : 1.240101\n",
      "loss in epoch 5 , step 2220 : 1.166844\n",
      "loss in epoch 5 , step 2240 : 2.190220\n",
      "loss in epoch 5 , step 2260 : 0.207731\n",
      "loss in epoch 5 , step 2280 : 1.556102\n",
      "loss in epoch 5 , step 2300 : 1.815138\n",
      "loss in epoch 5 , step 2320 : 0.904709\n",
      "loss in epoch 5 , step 2340 : 0.739812\n",
      "loss in epoch 5 , step 2360 : 1.688193\n",
      "loss in epoch 5 , step 2380 : 2.257922\n",
      "loss in epoch 5 , step 2400 : 1.503409\n",
      "loss in epoch 5 , step 2420 : 0.914882\n",
      "loss in epoch 5 , step 2440 : 1.314698\n",
      "loss in epoch 5 , step 2460 : 0.521999\n",
      "loss in epoch 5 , step 2480 : 0.259368\n",
      "loss in epoch 5 , step 2500 : 1.856432\n",
      "loss in epoch 5 , step 2520 : 0.693757\n",
      "loss in epoch 5 , step 2540 : 3.263740\n",
      "loss in epoch 5 , step 2560 : 1.415580\n",
      "loss in epoch 5 , step 2580 : 2.093191\n",
      "loss in epoch 5 , step 2600 : 1.327026\n",
      "loss in epoch 5 , step 2620 : 2.366075\n",
      "loss in epoch 5 , step 2640 : 1.825018\n",
      "loss in epoch 5 , step 2660 : 1.618887\n",
      "loss in epoch 5 , step 2680 : 0.947145\n",
      "loss in epoch 5 , step 2700 : 2.075484\n",
      "loss in epoch 5 , step 2720 : 1.647331\n",
      "loss in epoch 5 , step 2740 : 0.088032\n",
      "loss in epoch 5 , step 2760 : 0.988854\n",
      "loss in epoch 5 , step 2780 : 1.169851\n",
      "loss in epoch 5 , step 2800 : 1.558558\n",
      "loss in epoch 5 , step 2820 : 1.224055\n",
      "loss in epoch 5 , step 2840 : 2.147455\n",
      "loss in epoch 5 , step 2860 : 2.363279\n",
      "loss in epoch 5 , step 2880 : 0.473762\n",
      "loss in epoch 5 , step 2900 : 0.950601\n",
      "loss in epoch 5 , step 2920 : 1.432759\n",
      "loss in epoch 5 , step 2940 : 3.374020\n",
      "loss in epoch 5 , step 2960 : 1.750642\n",
      "loss in epoch 5 , step 2980 : 1.375001\n",
      "loss in epoch 5 , step 3000 : 1.525090\n",
      "loss in epoch 5 , step 3020 : 0.666454\n",
      "loss in epoch 5 , step 3040 : 1.053758\n",
      "loss in epoch 5 , step 3060 : 1.659715\n",
      "loss in epoch 5 , step 3080 : 1.292992\n",
      "loss in epoch 5 , step 3100 : 1.894588\n",
      "loss in epoch 5 , step 3120 : 2.145039\n",
      "loss in epoch 5 , step 3140 : 0.378655\n",
      "loss in epoch 5 , step 3160 : 3.327497\n",
      "loss in epoch 5 , step 3180 : 1.974795\n",
      "loss in epoch 5 , step 3200 : 0.134671\n",
      "loss in epoch 5 , step 3220 : 1.775269\n",
      "loss in epoch 5 , step 3240 : 2.394879\n",
      "loss in epoch 5 , step 3260 : 3.225635\n",
      "loss in epoch 5 , step 3280 : 1.691138\n",
      "loss in epoch 5 , step 3300 : 0.226936\n",
      "loss in epoch 5 , step 3320 : 1.393689\n",
      "loss in epoch 5 , step 3340 : 1.425467\n",
      "loss in epoch 5 , step 3360 : 0.273341\n",
      "loss in epoch 5 , step 3380 : 2.026818\n",
      "loss in epoch 5 , step 3400 : 2.996595\n",
      "loss in epoch 5 , step 3420 : 1.840328\n",
      "loss in epoch 5 , step 3440 : 2.059470\n",
      "loss in epoch 5 , step 3460 : 4.111854\n",
      "loss in epoch 5 , step 3480 : 1.901883\n",
      "loss in epoch 5 , step 3500 : 2.106424\n",
      "loss in epoch 5 , step 3520 : 1.749403\n",
      "loss in epoch 5 , step 3540 : 1.503183\n",
      "loss in epoch 5 , step 3560 : 2.637825\n",
      "loss in epoch 5 , step 3580 : 1.593246\n",
      "loss in epoch 5 , step 3600 : 1.940462\n",
      "loss in epoch 5 , step 3620 : 0.931722\n",
      "loss in epoch 5 , step 3640 : 1.881140\n",
      "loss in epoch 5 , step 3660 : 1.409422\n",
      "loss in epoch 5 , step 3680 : 1.259839\n",
      "loss in epoch 5 , step 3700 : 1.455350\n",
      "loss in epoch 5 , step 3720 : 1.458327\n",
      "loss in epoch 5 , step 3740 : 1.712147\n",
      "loss in epoch 5 , step 3760 : 1.657526\n",
      "loss in epoch 5 , step 3780 : 1.095853\n",
      "loss in epoch 5 , step 3800 : 1.935046\n",
      "loss in epoch 5 , step 3820 : 1.472875\n",
      "loss in epoch 5 , step 3840 : 1.697183\n",
      "loss in epoch 5 , step 3860 : 1.868356\n",
      "loss in epoch 5 , step 3880 : 0.512495\n",
      "loss in epoch 5 , step 3900 : 1.903096\n",
      "loss in epoch 5 , step 3920 : 0.887057\n",
      "loss in epoch 5 , step 3940 : 0.654882\n",
      "loss in epoch 5 , step 3960 : 0.951611\n",
      "loss in epoch 5 , step 3980 : 1.214463\n",
      "loss in epoch 5 , step 4000 : 1.169667\n",
      "loss in epoch 5 , step 4020 : 1.206205\n",
      "loss in epoch 5 , step 4040 : 0.366000\n",
      "loss in epoch 5 , step 4060 : 2.433360\n",
      "loss in epoch 5 , step 4080 : 2.458613\n",
      "loss in epoch 5 , step 4100 : 1.588293\n",
      "loss in epoch 5 , step 4120 : 0.155929\n",
      "loss in epoch 5 , step 4140 : 1.180925\n",
      "loss in epoch 5 , step 4160 : 0.875354\n",
      "loss in epoch 5 , step 4180 : 1.871800\n",
      "loss in epoch 5 , step 4200 : 0.224165\n",
      "loss in epoch 5 , step 4220 : 1.717835\n",
      "loss in epoch 5 , step 4240 : 0.757322\n",
      "loss in epoch 5 , step 4260 : 0.069032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 5 , step 4280 : 1.473035\n",
      "loss in epoch 5 , step 4300 : 1.203787\n",
      "loss in epoch 5 , step 4320 : 1.340151\n",
      "loss in epoch 5 , step 4340 : 2.287119\n",
      "loss in epoch 5 , step 4360 : 1.392791\n",
      "loss in epoch 5 , step 4380 : 0.782258\n",
      "loss in epoch 5 , step 4400 : 1.521562\n",
      "loss in epoch 5 , step 4420 : 1.867737\n",
      "loss in epoch 5 , step 4440 : 0.886437\n",
      "loss in epoch 5 , step 4460 : 1.776495\n",
      "loss in epoch 5 , step 4480 : 2.069930\n",
      "loss in epoch 5 , step 4500 : 0.138275\n",
      "loss in epoch 5 , step 4520 : 1.358160\n",
      "loss in epoch 5 , step 4540 : 1.242092\n",
      "loss in epoch 5 , step 4560 : 1.129000\n",
      "loss in epoch 5 , step 4580 : 1.768749\n",
      "loss in epoch 5 , step 4600 : 1.975772\n",
      "loss in epoch 5 , step 4620 : 1.326187\n",
      "loss in epoch 5 , step 4640 : 1.709711\n",
      "loss in epoch 5 , step 4660 : 0.612296\n",
      "loss in epoch 5 , step 4680 : 0.157930\n",
      "loss in epoch 5 , step 4700 : 1.631226\n",
      "loss in epoch 5 , step 4720 : 1.668628\n",
      "loss in epoch 5 , step 4740 : 0.525301\n",
      "loss in epoch 5 , step 4760 : 0.986430\n",
      "loss in epoch 5 , step 4780 : 2.548862\n",
      "loss in epoch 5 , step 4800 : 1.306360\n",
      "loss in epoch 5 , step 4820 : 2.529537\n",
      "loss in epoch 5 , step 4840 : 2.160559\n",
      "loss in epoch 5 , step 4860 : 2.148695\n",
      "loss in epoch 5 , step 4880 : 2.364574\n",
      "loss in epoch 5 , step 4900 : 2.348135\n",
      "loss in epoch 5 , step 4920 : 1.953036\n",
      "loss in epoch 5 , step 4940 : 2.277474\n",
      "loss in epoch 5 , step 4960 : 0.586946\n",
      "loss in epoch 5 , step 4980 : 1.936375\n",
      "loss in epoch 5 , step 5000 : 1.470822\n",
      "loss in epoch 5 , step 5020 : 1.777570\n",
      "loss in epoch 5 , step 5040 : 2.296637\n",
      "loss in epoch 5 , step 5060 : 2.451636\n",
      "loss in epoch 5 , step 5080 : 1.956238\n",
      "loss in epoch 5 , step 5100 : 1.839216\n",
      "loss in epoch 5 , step 5120 : 0.985530\n",
      "loss in epoch 5 , step 5140 : 2.045631\n",
      "loss in epoch 5 , step 5160 : 1.659587\n",
      "loss in epoch 5 , step 5180 : 2.827124\n",
      "loss in epoch 5 , step 5200 : 1.286436\n",
      "loss in epoch 5 , step 5220 : 2.714587\n",
      "loss in epoch 5 , step 5240 : 0.042845\n",
      "loss in epoch 5 , step 5260 : 1.900065\n",
      "loss in epoch 5 , step 5280 : 2.515748\n",
      "loss in epoch 5 , step 5300 : 0.835682\n",
      "loss in epoch 5 , step 5320 : 1.392358\n",
      "loss in epoch 5 , step 5340 : 1.078204\n",
      "loss in epoch 5 , step 5360 : 1.856634\n",
      "loss in epoch 5 , step 5380 : 1.099725\n",
      "loss in epoch 5 , step 5400 : 1.015682\n",
      "loss in epoch 5 , step 5420 : 0.258631\n",
      "loss in epoch 5 , step 5440 : 1.592417\n",
      "loss in epoch 5 , step 5460 : 0.128144\n",
      "loss in epoch 5 , step 5480 : 2.271442\n",
      "loss in epoch 5 , step 5500 : 0.979624\n",
      "loss in epoch 5 , step 5520 : 1.751961\n",
      "loss in epoch 5 , step 5540 : 0.267234\n",
      "loss in epoch 5 , step 5560 : 1.433206\n",
      "loss in epoch 5 , step 5580 : 0.163401\n",
      "loss in epoch 5 , step 5600 : 0.161416\n",
      "loss in epoch 5 , step 5620 : 0.942576\n",
      "loss in epoch 5 , step 5640 : 0.488649\n",
      "loss in epoch 5 , step 5660 : 2.097492\n",
      "loss in epoch 5 , step 5680 : 1.929249\n",
      "loss in epoch 5 , step 5700 : 0.204793\n",
      "loss in epoch 5 , step 5720 : 0.050031\n",
      "loss in epoch 5 , step 5740 : 1.884752\n",
      "loss in epoch 5 , step 5760 : 2.918246\n",
      "loss in epoch 5 , step 5780 : 0.923797\n",
      "loss in epoch 5 , step 5800 : 1.722438\n",
      "loss in epoch 5 , step 5820 : 1.070792\n",
      "loss in epoch 5 , step 5840 : 1.152001\n",
      "loss in epoch 5 , step 5860 : 1.334096\n",
      "loss in epoch 5 , step 5880 : 4.239409\n",
      "loss in epoch 5 , step 5900 : 0.452196\n",
      "loss in epoch 5 , step 5920 : 1.995555\n",
      "loss in epoch 5 , step 5940 : 2.562643\n",
      "loss in epoch 5 , step 5960 : 1.796126\n",
      "loss in epoch 5 , step 5980 : 1.658947\n",
      "loss in epoch 5 , step 6000 : 1.189098\n",
      "loss in epoch 5 , step 6020 : 0.553332\n",
      "loss in epoch 5 , step 6040 : 1.012264\n",
      "loss in epoch 5 , step 6060 : 1.167083\n",
      "loss in epoch 5 , step 6080 : 0.267679\n",
      "loss in epoch 5 , step 6100 : 1.594936\n",
      "loss in epoch 5 , step 6120 : 1.312976\n",
      "loss in epoch 5 , step 6140 : 1.634011\n",
      "loss in epoch 5 , step 6160 : 1.428715\n",
      "loss in epoch 5 , step 6180 : 1.721918\n",
      "loss in epoch 5 , step 6200 : 0.988805\n",
      "loss in epoch 5 , step 6220 : 0.826608\n",
      "loss in epoch 5 , step 6240 : 0.783348\n",
      "loss in epoch 5 , step 6260 : 1.198677\n",
      "loss in epoch 5 , step 6280 : 2.510200\n",
      "loss in epoch 5 , step 6300 : 0.462444\n",
      "loss in epoch 5 , step 6320 : 1.349695\n",
      "loss in epoch 5 , step 6340 : 2.115650\n",
      "loss in epoch 5 , step 6360 : 1.659519\n",
      "loss in epoch 5 , step 6380 : 1.964819\n",
      "loss in epoch 5 , step 6400 : 0.136987\n",
      "loss in epoch 5 , step 6420 : 4.604760\n",
      "loss in epoch 5 , step 6440 : 2.460384\n",
      "loss in epoch 5 , step 6460 : 1.443739\n",
      "loss in epoch 5 , step 6480 : 0.112562\n",
      "loss in epoch 5 , step 6500 : 0.568182\n",
      "loss in epoch 5 , step 6520 : 0.747439\n",
      "loss in epoch 5 , step 6540 : 1.840747\n",
      "loss in epoch 5 , step 6560 : 0.103622\n",
      "loss in epoch 5 , step 6580 : 1.704644\n",
      "loss in epoch 5 , step 6600 : 0.610474\n",
      "loss in epoch 5 , step 6620 : 1.743318\n",
      "loss in epoch 5 , step 6640 : 1.525167\n",
      "loss in epoch 5 , step 6660 : 0.981648\n",
      "loss in epoch 5 , step 6680 : 1.721969\n",
      "loss in epoch 5 , step 6700 : 2.317481\n",
      "loss in epoch 5 , step 6720 : 2.807698\n",
      "loss in epoch 5 , step 6740 : 2.004710\n",
      "loss in epoch 5 , step 6760 : 1.204962\n",
      "loss in epoch 5 , step 6780 : 0.585210\n",
      "loss in epoch 5 , step 6800 : 0.408139\n",
      "loss in epoch 5 , step 6820 : 0.488917\n",
      "loss in epoch 5 , step 6840 : 1.673305\n",
      "loss in epoch 5 , step 6860 : 1.724815\n",
      "loss in epoch 5 , step 6880 : 0.158215\n",
      "loss in epoch 5 , step 6900 : 1.379746\n",
      "loss in epoch 5 , step 6920 : 1.768540\n",
      "loss in epoch 5 , step 6940 : 0.231956\n",
      "loss in epoch 5 , step 6960 : 1.340442\n",
      "loss in epoch 5 , step 6980 : 0.302971\n",
      "loss in epoch 5 , step 7000 : 1.569195\n",
      "loss in epoch 5 , step 7020 : 2.723332\n",
      "loss in epoch 5 , step 7040 : 2.299792\n",
      "loss in epoch 5 , step 7060 : 0.888032\n",
      "loss in epoch 5 , step 7080 : 2.199482\n",
      "loss in epoch 5 , step 7100 : 2.094613\n",
      "loss in epoch 5 , step 7120 : 0.990525\n",
      "loss in epoch 5 , step 7140 : 2.935045\n",
      "loss in epoch 5 , step 7160 : 0.584535\n",
      "loss in epoch 5 , step 7180 : 0.841113\n",
      "loss in epoch 5 , step 7200 : 1.858158\n",
      "loss in epoch 5 , step 7220 : 1.657590\n",
      "loss in epoch 5 , step 7240 : 1.730689\n",
      "loss in epoch 5 , step 7260 : 1.842026\n",
      "loss in epoch 5 , step 7280 : 1.466905\n",
      "loss in epoch 5 , step 7300 : 2.369945\n",
      "loss in epoch 5 , step 7320 : 2.672118\n",
      "loss in epoch 5 , step 7340 : 1.381370\n",
      "loss in epoch 5 , step 7360 : 2.094190\n",
      "loss in epoch 5 , step 7380 : 2.583883\n",
      "loss in epoch 5 , step 7400 : 2.236061\n",
      "loss in epoch 5 , step 7420 : 0.552124\n",
      "loss in epoch 5 , step 7440 : 1.206968\n",
      "loss in epoch 5 , step 7460 : 2.095801\n",
      "loss in epoch 5 , step 7480 : 1.879189\n",
      "loss in epoch 5 , step 7500 : 1.244315\n",
      "loss in epoch 5 , step 7520 : 1.363126\n",
      "loss in epoch 5 , step 7540 : 1.273939\n",
      "loss in epoch 5 , step 7560 : 2.104445\n",
      "loss in epoch 5 , step 7580 : 0.123651\n",
      "loss in epoch 5 , step 7600 : 1.901472\n",
      "loss in epoch 5 , step 7620 : 0.439508\n",
      "loss in epoch 5 , step 7640 : 1.083422\n",
      "loss in epoch 5 , step 7660 : 1.913177\n",
      "loss in epoch 5 , step 7680 : 0.763407\n",
      "loss in epoch 5 , step 7700 : 1.976070\n",
      "loss in epoch 5 , step 7720 : 1.044814\n",
      "loss in epoch 5 , step 7740 : 1.888518\n",
      "loss in epoch 5 , step 7760 : 2.087328\n",
      "loss in epoch 5 , step 7780 : 0.912521\n",
      "loss in epoch 5 , step 7800 : 2.059398\n",
      "loss in epoch 5 , step 7820 : 1.564776\n",
      "loss in epoch 5 , step 7840 : 1.658186\n",
      "loss in epoch 5 , step 7860 : 0.928808\n",
      "loss in epoch 5 , step 7880 : 1.399460\n",
      "loss in epoch 5 , step 7900 : 0.859030\n",
      "loss in epoch 5 , step 7920 : 1.184841\n",
      "loss in epoch 5 , step 7940 : 0.347599\n",
      "loss in epoch 5 , step 7960 : 0.957243\n",
      "loss in epoch 5 , step 7980 : 2.163136\n",
      "loss in epoch 5 , step 8000 : 1.159494\n",
      "loss in epoch 5 , step 8020 : 0.401850\n",
      "loss in epoch 5 , step 8040 : 1.737200\n",
      "loss in epoch 5 , step 8060 : 1.799962\n",
      "loss in epoch 5 , step 8080 : 2.194937\n",
      "loss in epoch 5 , step 8100 : 1.653275\n",
      "loss in epoch 5 , step 8120 : 2.102841\n",
      "loss in epoch 5 , step 8140 : 1.602314\n",
      "loss in epoch 5 , step 8160 : 2.100297\n",
      "loss in epoch 5 , step 8180 : 2.097286\n",
      "loss in epoch 5 , step 8200 : 0.085807\n",
      "loss in epoch 5 , step 8220 : 1.626658\n",
      "loss in epoch 5 , step 8240 : 1.128746\n",
      "loss in epoch 5 , step 8260 : 0.160682\n",
      "loss in epoch 5 , step 8280 : 0.242372\n",
      "loss in epoch 5 , step 8300 : 0.577588\n",
      "loss in epoch 5 , step 8320 : 1.556792\n",
      "loss in epoch 5 , step 8340 : 1.952453\n",
      "loss in epoch 5 , step 8360 : 2.002058\n",
      "loss in epoch 5 , step 8380 : 1.585522\n",
      "loss in epoch 5 , step 8400 : 3.462238\n",
      "loss in epoch 5 , step 8420 : 2.756732\n",
      "loss in epoch 5 , step 8440 : 1.542361\n",
      "loss in epoch 5 , step 8460 : 1.585827\n",
      "loss in epoch 5 , step 8480 : 1.530014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 5 , step 8500 : 1.744409\n",
      "loss in epoch 5 , step 8520 : 1.395881\n",
      "loss in epoch 5 , step 8540 : 1.112172\n",
      "loss in epoch 5 , step 8560 : 1.728229\n",
      "loss in epoch 5 , step 8580 : 1.676884\n",
      "loss in epoch 5 , step 8600 : 0.640040\n",
      "loss in epoch 5 , step 8620 : 1.197260\n",
      "loss in epoch 5 , step 8640 : 1.879086\n",
      "loss in epoch 5 , step 8660 : 0.912498\n",
      "loss in epoch 5 , step 8680 : 1.308132\n",
      "loss in epoch 5 , step 8700 : 1.365086\n",
      "loss in epoch 5 , step 8720 : 0.118093\n",
      "loss in epoch 5 , step 8740 : 2.264083\n",
      "loss in epoch 5 , step 8760 : 0.596834\n",
      "loss in epoch 5 , step 8780 : 0.851560\n",
      "loss in epoch 5 , step 8800 : 1.436867\n",
      "loss in epoch 5 , step 8820 : 0.771057\n",
      "loss in epoch 5 , step 8840 : 0.842115\n",
      "loss in epoch 5 , step 8860 : 0.130550\n",
      "loss in epoch 5 , step 8880 : 1.357104\n",
      "loss in epoch 5 , step 8900 : 1.622233\n",
      "loss in epoch 5 , step 8920 : 1.997619\n",
      "loss in epoch 5 , step 8940 : 1.140591\n",
      "loss in epoch 5 , step 8960 : 1.637909\n",
      "loss in epoch 5 , step 8980 : 1.744845\n",
      "loss in epoch 5 , step 9000 : 2.125428\n",
      "loss in epoch 5 , step 9020 : 2.534680\n",
      "loss in epoch 5 , step 9040 : 0.892052\n",
      "loss in epoch 5 , step 9060 : 1.627314\n",
      "loss in epoch 5 , step 9080 : 2.493216\n",
      "loss in epoch 5 , step 9100 : 1.480911\n",
      "loss in epoch 5 , step 9120 : 1.628263\n",
      "loss in epoch 5 , step 9140 : 0.661959\n",
      "loss in epoch 5 , step 9160 : 0.175383\n",
      "loss in epoch 5 , step 9180 : 1.317156\n",
      "loss in epoch 5 , step 9200 : 4.085330\n",
      "loss in epoch 5 , step 9220 : 1.517340\n",
      "loss in epoch 5 , step 9240 : 1.561135\n",
      "loss in epoch 5 , step 9260 : 1.931548\n",
      "loss in epoch 5 , step 9280 : 1.654256\n",
      "loss in epoch 5 , step 9300 : 1.247553\n",
      "loss in epoch 5 , step 9320 : 1.163132\n",
      "loss in epoch 5 , step 9340 : 1.287086\n",
      "loss in epoch 5 , step 9360 : 1.548392\n",
      "loss in epoch 5 , step 9380 : 1.404212\n",
      "loss in epoch 5 , step 9400 : 1.422459\n",
      "loss in epoch 5 , step 9420 : 1.461241\n",
      "loss in epoch 5 , step 9440 : 1.287284\n",
      "loss in epoch 5 , step 9460 : 1.202408\n",
      "loss in epoch 5 , step 9480 : 1.412183\n",
      "loss in epoch 5 , step 9500 : 0.768861\n",
      "loss in epoch 5 , step 9520 : 0.978853\n",
      "loss in epoch 5 , step 9540 : 1.910578\n",
      "loss in epoch 5 , step 9560 : 1.634584\n",
      "loss in epoch 5 , step 9580 : 1.390652\n",
      "loss in epoch 5 , step 9600 : 1.314300\n",
      "loss in epoch 5 , step 9620 : 1.246885\n",
      "loss in epoch 5 , step 9640 : 1.877308\n",
      "loss in epoch 5 , step 9660 : 3.673735\n",
      "loss in epoch 5 , step 9680 : 1.174044\n",
      "loss in epoch 5 , step 9700 : 1.293064\n",
      "loss in epoch 5 , step 9720 : 1.654003\n",
      "loss in epoch 5 , step 9740 : 1.300308\n",
      "loss in epoch 5 , step 9760 : 0.414895\n",
      "loss in epoch 5 , step 9780 : 1.449479\n",
      "loss in epoch 5 , step 9800 : 1.008004\n",
      "loss in epoch 5 , step 9820 : 1.758262\n",
      "loss in epoch 5 , step 9840 : 1.413953\n",
      "loss in epoch 5 , step 9860 : 1.888006\n",
      "loss in epoch 5 , step 9880 : 0.343112\n",
      "loss in epoch 5 , step 9900 : 2.173688\n",
      "loss in epoch 5 , step 9920 : 1.953737\n",
      "loss in epoch 5 , step 9940 : 2.204072\n",
      "loss in epoch 5 , step 9960 : 2.635397\n",
      "loss in epoch 5 , step 9980 : 1.746884\n",
      "loss in epoch 5 , step 10000 : 1.914445\n",
      "loss in epoch 5 , step 10020 : 1.164725\n",
      "loss in epoch 5 , step 10040 : 2.007936\n",
      "loss in epoch 5 , step 10060 : 1.447940\n",
      "loss in epoch 5 , step 10080 : 0.606237\n",
      "loss in epoch 5 , step 10100 : 0.145660\n",
      "loss in epoch 5 , step 10120 : 2.266517\n",
      "loss in epoch 5 , step 10140 : 2.712328\n",
      "loss in epoch 5 , step 10160 : 2.204921\n",
      "loss in epoch 5 , step 10180 : 1.335660\n",
      "loss in epoch 5 , step 10200 : 1.031600\n",
      "loss in epoch 5 , step 10220 : 0.101563\n",
      "loss in epoch 5 , step 10240 : 1.218438\n",
      "loss in epoch 5 , step 10260 : 2.737388\n",
      "loss in epoch 5 , step 10280 : 2.803411\n",
      "loss in epoch 5 , step 10300 : 1.486750\n",
      "loss in epoch 5 , step 10320 : 1.585347\n",
      "loss in epoch 5 , step 10340 : 1.096972\n",
      "loss in epoch 5 , step 10360 : 1.348437\n",
      "loss in epoch 5 , step 10380 : 2.152820\n",
      "loss in epoch 5 , step 10400 : 1.210652\n",
      "loss in epoch 5 , step 10420 : 1.185511\n",
      "loss in epoch 5 , step 10440 : 1.509598\n",
      "loss in epoch 5 , step 10460 : 0.951526\n",
      "loss in epoch 5 , step 10480 : 2.002944\n",
      "loss in epoch 5 , step 10500 : 1.334510\n",
      "loss in epoch 5 , step 10520 : 1.757815\n",
      "loss in epoch 5 , step 10540 : 1.398865\n",
      "loss in epoch 5 , step 10560 : 0.483944\n",
      "loss in epoch 5 , step 10580 : 0.755761\n",
      "loss in epoch 5 , step 10600 : 2.315549\n",
      "loss in epoch 5 , step 10620 : 0.213777\n",
      "loss in epoch 5 , step 10640 : 1.651923\n",
      "loss in epoch 5 , step 10660 : 0.081939\n",
      "loss in epoch 5 , step 10680 : 0.045007\n",
      "loss in epoch 5 , step 10700 : 0.987873\n",
      "loss in epoch 5 , step 10720 : 1.687544\n",
      "loss in epoch 5 , step 10740 : 2.025754\n",
      "loss in epoch 5 , step 10760 : 1.320771\n",
      "loss in epoch 5 , step 10780 : 1.897079\n",
      "loss in epoch 5 , step 10800 : 1.219053\n",
      "loss in epoch 5 , step 10820 : 0.721588\n",
      "loss in epoch 5 , step 10840 : 1.883656\n",
      "loss in epoch 5 , step 10860 : 0.332924\n",
      "loss in epoch 5 , step 10880 : 1.024689\n",
      "loss in epoch 5 , step 10900 : 1.713578\n",
      "loss in epoch 5 , step 10920 : 2.056278\n",
      "loss in epoch 5 , step 10940 : 2.216990\n",
      "loss in epoch 5 , step 10960 : 1.026668\n",
      "loss in epoch 5 , step 10980 : 0.628732\n",
      "loss in epoch 5 , step 11000 : 1.246516\n",
      "loss in epoch 5 , step 11020 : 4.085864\n",
      "loss in epoch 5 , step 11040 : 1.544930\n",
      "loss in epoch 5 , step 11060 : 1.616197\n",
      "loss in epoch 5 , step 11080 : 1.950063\n",
      "loss in epoch 5 , step 11100 : 1.375443\n",
      "loss in epoch 5 , step 11120 : 0.203398\n",
      "loss in epoch 5 , step 11140 : 3.541121\n",
      "loss in epoch 5 , step 11160 : 1.051804\n",
      "loss in epoch 5 , step 11180 : 0.878065\n",
      "loss in epoch 5 , step 11200 : 1.969420\n",
      "loss in epoch 5 , step 11220 : 1.770423\n",
      "loss in epoch 5 , step 11240 : 1.425981\n",
      "loss in epoch 5 , step 11260 : 2.745825\n",
      "loss in epoch 5 , step 11280 : 1.818230\n",
      "loss in epoch 5 , step 11300 : 1.220442\n",
      "loss in epoch 5 , step 11320 : 0.189429\n",
      "loss in epoch 5 , step 11340 : 1.370059\n",
      "loss in epoch 5 , step 11360 : 1.888416\n",
      "loss in epoch 5 , step 11380 : 1.264843\n",
      "loss in epoch 5 , step 11400 : 2.908867\n",
      "loss in epoch 5 , step 11420 : 1.637385\n",
      "loss in epoch 5 , step 11440 : 1.353123\n",
      "loss in epoch 5 , step 11460 : 1.836320\n",
      "loss in epoch 5 , step 11480 : 0.578630\n",
      "loss in epoch 5 , step 11500 : 1.608758\n",
      "loss in epoch 5 , step 11520 : 1.068960\n",
      "loss in epoch 5 , step 11540 : 1.825234\n",
      "loss in epoch 5 , step 11560 : 1.884513\n",
      "loss in epoch 5 , step 11580 : 1.192163\n",
      "loss in epoch 5 , step 11600 : 0.766774\n",
      "loss in epoch 5 , step 11620 : 1.701499\n",
      "loss in epoch 5 , step 11640 : 0.742666\n",
      "loss in epoch 5 , step 11660 : 1.895752\n",
      "loss in epoch 5 , step 11680 : 1.231273\n",
      "loss in epoch 5 , step 11700 : 1.666414\n",
      "loss in epoch 5 , step 11720 : 1.515941\n",
      "loss in epoch 5 , step 11740 : 1.373423\n",
      "loss in epoch 5 , step 11760 : 2.356824\n",
      "loss in epoch 5 , step 11780 : 1.036237\n",
      "loss in epoch 5 , step 11800 : 1.394544\n",
      "loss in epoch 5 , step 11820 : 1.820142\n",
      "loss in epoch 5 , step 11840 : 1.792968\n",
      "loss in epoch 5 , step 11860 : 0.250597\n",
      "loss in epoch 5 , step 11880 : 2.012881\n",
      "loss in epoch 5 , step 11900 : 0.677273\n",
      "loss in epoch 5 , step 11920 : 0.221488\n",
      "loss in epoch 5 , step 11940 : 1.504247\n",
      "loss in epoch 5 , step 11960 : 0.321526\n",
      "loss in epoch 5 , step 11980 : 1.741855\n",
      "loss in epoch 5 , step 12000 : 1.425086\n",
      "loss in epoch 5 , step 12020 : 0.415218\n",
      "loss in epoch 5 , step 12040 : 1.607297\n",
      "loss in epoch 5 , step 12060 : 1.963956\n",
      "loss in epoch 5 , step 12080 : 2.277939\n",
      "loss in epoch 5 , step 12100 : 3.004683\n",
      "loss in epoch 5 , step 12120 : 1.405938\n",
      "loss in epoch 5 , step 12140 : 1.333702\n",
      "loss in epoch 5 , step 12160 : 0.591122\n",
      "loss in epoch 5 , step 12180 : 2.446697\n",
      "loss in epoch 5 , step 12200 : 2.165828\n",
      "loss in epoch 5 , step 12220 : 1.533240\n",
      "loss in epoch 5 , step 12240 : 1.554402\n",
      "loss in epoch 5 , step 12260 : 1.744336\n",
      "loss in epoch 5 , step 12280 : 0.876256\n",
      "loss in epoch 5 , step 12300 : 2.248106\n",
      "loss in epoch 5 , step 12320 : 1.029587\n",
      "loss in epoch 5 , step 12340 : 3.081127\n",
      "loss in epoch 5 , step 12360 : 1.324834\n",
      "loss in epoch 5 , step 12380 : 0.864956\n",
      "loss in epoch 5 , step 12400 : 2.854571\n",
      "loss in epoch 5 , step 12420 : 0.989626\n",
      "loss in epoch 5 , step 12440 : 2.265477\n",
      "loss in epoch 5 , step 12460 : 0.111909\n",
      "loss in epoch 5 , step 12480 : 0.870689\n",
      "loss in epoch 5 , step 12500 : 1.795313\n",
      "loss in epoch 5 , step 12520 : 1.946642\n",
      "loss in epoch 5 , step 12540 : 1.211319\n",
      "loss in epoch 5 , step 12560 : 1.471876\n",
      "loss in epoch 5 , step 12580 : 2.178881\n",
      "loss in epoch 5 , step 12600 : 1.436499\n",
      "loss in epoch 5 , step 12620 : 1.563283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 5 , step 12640 : 0.884148\n",
      "loss in epoch 5 , step 12660 : 2.302366\n",
      "loss in epoch 5 , step 12680 : 1.034384\n",
      "loss in epoch 5 , step 12700 : 1.367584\n",
      "loss in epoch 5 , step 12720 : 2.182660\n",
      "loss in epoch 5 , step 12740 : 1.504257\n",
      "loss in epoch 5 , step 12760 : 1.123783\n",
      "loss in epoch 5 , step 12780 : 1.375985\n",
      "loss in epoch 5 , step 12800 : 2.064109\n",
      "loss in epoch 5 , step 12820 : 0.785709\n",
      "loss in epoch 5 , step 12840 : 1.387036\n",
      "loss in epoch 5 , step 12860 : 1.966736\n",
      "loss in epoch 5 , step 12880 : 2.941549\n",
      "loss in epoch 5 , step 12900 : 0.321963\n",
      "loss in epoch 5 , step 12920 : 1.447104\n",
      "loss in epoch 5 , step 12940 : 1.694382\n",
      "loss in epoch 5 , step 12960 : 1.302875\n",
      "loss in epoch 5 , step 12980 : 3.457778\n",
      "loss in epoch 5 , step 13000 : 2.049924\n",
      "loss in epoch 5 , step 13020 : 0.955400\n",
      "loss in epoch 5 , step 13040 : 1.555455\n",
      "loss in epoch 5 , step 13060 : 1.479068\n",
      "loss in epoch 5 , step 13080 : 2.296320\n",
      "loss in epoch 5 , step 13100 : 0.729913\n",
      "loss in epoch 5 , step 13120 : 2.415723\n",
      "loss in epoch 5 , step 13140 : 2.410505\n",
      "loss in epoch 5 , step 13160 : 1.538165\n",
      "loss in epoch 5 , step 13180 : 1.512398\n",
      "loss in epoch 5 , step 13200 : 1.030163\n",
      "loss in epoch 5 , step 13220 : 1.939777\n",
      "loss in epoch 5 , step 13240 : 2.052817\n",
      "loss in epoch 5 , step 13260 : 1.289666\n",
      "loss in epoch 5 , step 13280 : 1.624086\n",
      "loss in epoch 5 , step 13300 : 1.803434\n",
      "loss in epoch 5 , step 13320 : 1.285422\n",
      "loss in epoch 5 , step 13340 : 0.618895\n",
      "loss in epoch 5 , step 13360 : 1.489364\n",
      "loss in epoch 5 , step 13380 : 1.049994\n",
      "loss in epoch 5 , step 13400 : 2.087546\n",
      "loss in epoch 5 , step 13420 : 1.989001\n",
      "loss in epoch 5 , step 13440 : 1.748048\n",
      "loss in epoch 5 , step 13460 : 1.032488\n",
      "loss in epoch 5 , step 13480 : 1.751450\n",
      "loss in epoch 5 , step 13500 : 1.175633\n",
      "loss in epoch 5 , step 13520 : 0.087674\n",
      "loss in epoch 5 , step 13540 : 3.259121\n",
      "loss in epoch 5 , step 13560 : 0.273282\n",
      "loss in epoch 5 , step 13580 : 1.245311\n",
      "loss in epoch 5 , step 13600 : 1.805330\n",
      "loss in epoch 5 , step 13620 : 1.243422\n",
      "loss in epoch 5 , step 13640 : 1.667362\n",
      "loss in epoch 5 , step 13660 : 2.533698\n",
      "loss in epoch 5 , step 13680 : 1.853438\n",
      "loss in epoch 5 , step 13700 : 1.214745\n",
      "loss in epoch 5 , step 13720 : 1.854530\n",
      "loss in epoch 5 , step 13740 : 1.112093\n",
      "loss in epoch 5 , step 13760 : 1.315510\n",
      "loss in epoch 5 , step 13780 : 1.272702\n",
      "loss in epoch 5 , step 13800 : 0.882227\n",
      "loss in epoch 5 , step 13820 : 1.920866\n",
      "loss in epoch 5 , step 13840 : 0.617547\n",
      "loss in epoch 5 , step 13860 : 1.475535\n",
      "loss in epoch 5 , step 13880 : 1.641850\n",
      "loss in epoch 5 , step 13900 : 1.318457\n",
      "loss in epoch 5 , step 13920 : 2.198035\n",
      "loss in epoch 5 , step 13940 : 1.748397\n",
      "loss in epoch 5 , step 13960 : 1.645923\n",
      "loss in epoch 5 , step 13980 : 1.586805\n",
      "loss in epoch 5 , step 14000 : 1.147797\n",
      "loss in epoch 5 , step 14020 : 1.340445\n",
      "loss in epoch 5 , step 14040 : 1.717324\n",
      "loss in epoch 5 , step 14060 : 1.580021\n",
      "loss in epoch 5 , step 14080 : 0.703412\n",
      "loss in epoch 5 , step 14100 : 3.136068\n",
      "loss in epoch 5 , step 14120 : 1.710906\n",
      "loss in epoch 5 , step 14140 : 0.187336\n",
      "loss in epoch 5 , step 14160 : 0.510953\n",
      "loss in epoch 5 , step 14180 : 0.419391\n",
      "loss in epoch 5 , step 14200 : 1.850699\n",
      "loss in epoch 5 , step 14220 : 1.816272\n",
      "loss in epoch 5 , step 14240 : 2.008554\n",
      "loss in epoch 5 , step 14260 : 1.070464\n",
      "loss in epoch 5 , step 14280 : 1.850786\n",
      "loss in epoch 5 , step 14300 : 1.792621\n",
      "loss in epoch 5 , step 14320 : 1.550897\n",
      "loss in epoch 5 , step 14340 : 0.732565\n",
      "loss in epoch 5 , step 14360 : 1.721061\n",
      "loss in epoch 5 , step 14380 : 1.403681\n",
      "loss in epoch 5 , step 14400 : 2.179233\n",
      "loss in epoch 5 , step 14420 : 0.896527\n",
      "loss in epoch 5 , step 14440 : 0.910335\n",
      "loss in epoch 5 , step 14460 : 1.237684\n",
      "loss in epoch 5 , step 14480 : 1.677946\n",
      "loss in epoch 5 , step 14500 : 2.063512\n",
      "loss in epoch 5 , step 14520 : 1.740179\n",
      "loss in epoch 5 , step 14540 : 1.532769\n",
      "loss in epoch 5 , step 14560 : 1.745808\n",
      "loss in epoch 5 , step 14580 : 1.083238\n",
      "loss in epoch 5 , step 14600 : 1.931620\n",
      "loss in epoch 5 , step 14620 : 0.227956\n",
      "loss in epoch 5 , step 14640 : 1.725996\n",
      "loss in epoch 5 , step 14660 : 1.348206\n",
      "loss in epoch 5 , step 14680 : 0.950837\n",
      "loss in epoch 5 , step 14700 : 1.490025\n",
      "loss in epoch 5 , step 14720 : 3.395076\n",
      "loss in epoch 5 , step 14740 : 2.244780\n",
      "loss in epoch 5 , step 14760 : 0.959778\n",
      "loss in epoch 5 , step 14780 : 1.516737\n",
      "loss in epoch 5 , step 14800 : 1.119137\n",
      "loss in epoch 5 , step 14820 : 0.529113\n",
      "loss in epoch 5 , step 14840 : 1.411140\n",
      "loss in epoch 5 , step 14860 : 0.358642\n",
      "loss in epoch 5 , step 14880 : 4.121501\n",
      "loss in epoch 5 , step 14900 : 1.221906\n",
      "loss in epoch 5 , step 14920 : 0.587383\n",
      "loss in epoch 5 , step 14940 : 2.260410\n",
      "loss in epoch 5 , step 14960 : 0.422283\n",
      "loss in epoch 5 , step 14980 : 2.181379\n",
      "loss in epoch 5 , step 15000 : 1.040671\n",
      "loss in epoch 5 , step 15020 : 1.644047\n",
      "loss in epoch 5 , step 15040 : 1.960312\n",
      "loss in epoch 5 , step 15060 : 1.856218\n",
      "loss in epoch 5 , step 15080 : 1.442114\n",
      "loss in epoch 5 , step 15100 : 1.168617\n",
      "loss in epoch 5 , step 15120 : 2.248445\n",
      "loss in epoch 5 , step 15140 : 1.936088\n",
      "loss in epoch 5 , step 15160 : 0.098746\n",
      "loss in epoch 5 , step 15180 : 0.804418\n",
      "loss in epoch 5 , step 15200 : 2.786839\n",
      "loss in epoch 5 , step 15220 : 1.614558\n",
      "loss in epoch 5 , step 15240 : 2.398253\n",
      "loss in epoch 5 , step 15260 : 0.055980\n",
      "loss in epoch 5 , step 15280 : 1.850849\n",
      "loss in epoch 5 , step 15300 : 1.845634\n",
      "loss in epoch 5 , step 15320 : 1.585763\n",
      "loss in epoch 5 , step 15340 : 1.070048\n",
      "loss in epoch 5 , step 15360 : 1.939615\n",
      "loss in epoch 5 , step 15380 : 0.824127\n",
      "loss in epoch 5 , step 15400 : 0.054620\n",
      "loss in epoch 5 , step 15420 : 0.302427\n",
      "loss in epoch 5 , step 15440 : 1.287988\n",
      "loss in epoch 5 , step 15460 : 2.067948\n",
      "loss in epoch 5 , step 15480 : 1.578040\n",
      "loss in epoch 5 , step 15500 : 0.221770\n",
      "loss in epoch 5 , step 15520 : 2.975138\n",
      "loss in epoch 5 , step 15540 : 0.022647\n",
      "loss in epoch 5 , step 15560 : 1.408525\n",
      "loss in epoch 5 , step 15580 : 0.745436\n",
      "loss in epoch 5 , step 15600 : 1.861588\n",
      "loss in epoch 5 , step 15620 : 1.317141\n",
      "loss in epoch 5 , step 15640 : 1.152557\n",
      "loss in epoch 5 , step 15660 : 0.391534\n",
      "loss in epoch 5 , step 15680 : 2.142697\n",
      "loss in epoch 5 , step 15700 : 1.409047\n",
      "loss in epoch 5 , step 15720 : 2.101830\n",
      "loss in epoch 5 , step 15740 : 1.805526\n",
      "loss in epoch 5 , step 15760 : 2.339921\n",
      "loss in epoch 5 , step 15780 : 1.768470\n",
      "loss in epoch 5 , step 15800 : 2.156358\n",
      "loss in epoch 5 , step 15820 : 1.715709\n",
      "loss in epoch 5 , step 15840 : 1.542408\n",
      "loss in epoch 5 , step 15860 : 2.909736\n",
      "loss in epoch 5 , step 15880 : 1.826267\n",
      "loss in epoch 5 , step 15900 : 1.238899\n",
      "loss in epoch 5 , step 15920 : 2.353106\n",
      "loss in epoch 5 , step 15940 : 0.572998\n",
      "loss in epoch 5 , step 15960 : 0.439598\n",
      "loss in epoch 5 , step 15980 : 1.744144\n",
      "loss in epoch 5 , step 16000 : 1.202382\n",
      "loss in epoch 5 , step 16020 : 1.931048\n",
      "loss in epoch 5 , step 16040 : 0.348653\n",
      "loss in epoch 5 , step 16060 : 0.569420\n",
      "loss in epoch 5 , step 16080 : 0.929074\n",
      "loss in epoch 5 , step 16100 : 0.791453\n",
      "loss in epoch 5 , step 16120 : 1.423124\n",
      "loss in epoch 5 , step 16140 : 1.240848\n",
      "loss in epoch 5 , step 16160 : 1.568018\n",
      "loss in epoch 5 , step 16180 : 1.128278\n",
      "loss in epoch 5 , step 16200 : 1.817311\n",
      "loss in epoch 5 , step 16220 : 1.761311\n",
      "loss in epoch 5 , step 16240 : 2.259279\n",
      "loss in epoch 5 , step 16260 : 1.252614\n",
      "loss in epoch 5 , step 16280 : 1.070704\n",
      "loss in epoch 5 , step 16300 : 2.734831\n",
      "loss in epoch 5 , step 16320 : 0.936495\n",
      "loss in epoch 5 , step 16340 : 1.650112\n",
      "loss in epoch 5 , step 16360 : 1.433247\n",
      "loss in epoch 5 , step 16380 : 0.106168\n",
      "loss in epoch 5 , step 16400 : 1.990573\n",
      "loss in epoch 5 , step 16420 : 0.257425\n",
      "loss in epoch 5 , step 16440 : 1.541640\n",
      "loss in epoch 5 , step 16460 : 1.200432\n",
      "loss in epoch 5 , step 16480 : 0.899340\n",
      "loss in epoch 5 , step 16500 : 1.042851\n",
      "loss in epoch 5 , step 16520 : 4.187004\n",
      "loss in epoch 5 , step 16540 : 1.503502\n",
      "loss in epoch 5 , step 16560 : 1.115269\n",
      "loss in epoch 5 , step 16580 : 1.025099\n",
      "loss in epoch 5 , step 16600 : 1.904987\n",
      "loss in epoch 5 , step 16620 : 1.968131\n",
      "loss in epoch 5 , step 16640 : 1.596524\n",
      "loss in epoch 5 , step 16660 : 1.422969\n",
      "loss in epoch 5 , step 16680 : 0.292853\n",
      "loss in epoch 5 , step 16700 : 1.006899\n",
      "loss in epoch 5 , step 16720 : 1.721735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 5 , step 16740 : 1.644370\n",
      "loss in epoch 5 , step 16760 : 1.298713\n",
      "loss in epoch 5 , step 16780 : 2.635091\n",
      "loss in epoch 5 , step 16800 : 0.682766\n",
      "loss in epoch 5 , step 16820 : 0.495112\n",
      "loss in epoch 5 , step 16840 : 0.548515\n",
      "loss in epoch 5 , step 16860 : 2.434328\n",
      "loss in epoch 5 , step 16880 : 2.388271\n",
      "loss in epoch 5 , step 16900 : 2.283803\n",
      "loss in epoch 5 , step 16920 : 0.670463\n",
      "loss in epoch 5 , step 16940 : 2.132821\n",
      "loss in epoch 5 , step 16960 : 1.678532\n",
      "loss in epoch 5 , step 16980 : 1.071644\n",
      "loss in epoch 5 , step 17000 : 0.899076\n",
      "loss in epoch 5 , step 17020 : 0.063165\n",
      "loss in epoch 5 , step 17040 : 1.465862\n",
      "loss in epoch 5 , step 17060 : 1.597912\n",
      "loss in epoch 5 , step 17080 : 1.820420\n",
      "loss in epoch 5 , step 17100 : 2.313700\n",
      "loss in epoch 5 , step 17120 : 0.244000\n",
      "loss in epoch 5 , step 17140 : 2.404321\n",
      "loss in epoch 5 , step 17160 : 1.369123\n",
      "loss in epoch 5 , step 17180 : 2.135250\n",
      "loss in epoch 5 , step 17200 : 1.390809\n",
      "loss in epoch 5 , step 17220 : 2.232428\n",
      "loss in epoch 5 , step 17240 : 2.119105\n",
      "loss in epoch 5 , step 17260 : 0.105793\n",
      "loss in epoch 5 , step 17280 : 0.042800\n",
      "loss in epoch 5 , step 17300 : 1.102148\n",
      "loss in epoch 5 , step 17320 : 0.307490\n",
      "loss in epoch 5 , step 17340 : 1.609462\n",
      "loss in epoch 5 , step 17360 : 0.964574\n",
      "loss in epoch 5 , step 17380 : 0.784175\n",
      "loss in epoch 5 , step 17400 : 1.704321\n",
      "loss in epoch 5 , step 17420 : 1.335788\n",
      "loss in epoch 5 , step 17440 : 0.269088\n",
      "loss in epoch 5 , step 17460 : 1.492045\n",
      "loss in epoch 5 , step 17480 : 0.447725\n",
      "loss in epoch 5 , step 17500 : 0.974073\n",
      "loss in epoch 5 , step 17520 : 0.142863\n",
      "loss in epoch 5 , step 17540 : 1.165244\n",
      "loss in epoch 5 , step 17560 : 1.924842\n",
      "loss in epoch 5 , step 17580 : 0.314956\n",
      "loss in epoch 5 , step 17600 : 1.724593\n",
      "loss in epoch 5 , step 17620 : 0.102122\n",
      "loss in epoch 5 , step 17640 : 2.090757\n",
      "loss in epoch 5 , step 17660 : 1.991341\n",
      "loss in epoch 5 , step 17680 : 0.146160\n",
      "loss in epoch 5 , step 17700 : 1.622304\n",
      "loss in epoch 5 , step 17720 : 0.314372\n",
      "loss in epoch 5 , step 17740 : 0.163198\n",
      "loss in epoch 5 , step 17760 : 0.949903\n",
      "loss in epoch 5 , step 17780 : 0.697953\n",
      "loss in epoch 5 , step 17800 : 2.975337\n",
      "loss in epoch 5 , step 17820 : 1.327991\n",
      "loss in epoch 5 , step 17840 : 1.444409\n",
      "loss in epoch 5 , step 17860 : 1.401381\n",
      "loss in epoch 5 , step 17880 : 1.643203\n",
      "loss in epoch 5 , step 17900 : 1.315031\n",
      "loss in epoch 5 , step 17920 : 1.294654\n",
      "loss in epoch 5 , step 17940 : 1.218852\n",
      "loss in epoch 5 , step 17960 : 1.885074\n",
      "loss in epoch 5 , step 17980 : 2.092311\n",
      "loss in epoch 5 , step 18000 : 1.750381\n",
      "loss in epoch 5 , step 18020 : 1.762579\n",
      "loss in epoch 5 , step 18040 : 1.759510\n",
      "loss in epoch 5 , step 18060 : 1.061209\n",
      "loss in epoch 5 , step 18080 : 1.641901\n",
      "loss in epoch 5 , step 18100 : 2.857088\n",
      "loss in epoch 5 , step 18120 : 1.330850\n",
      "loss in epoch 5 , step 18140 : 1.242208\n",
      "loss in epoch 5 , step 18160 : 3.619174\n",
      "loss in epoch 5 , step 18180 : 0.085847\n",
      "loss in epoch 5 , step 18200 : 2.019196\n",
      "loss in epoch 5 , step 18220 : 1.156085\n",
      "loss in epoch 5 , step 18240 : 0.832946\n",
      "loss in epoch 5 , step 18260 : 0.891099\n",
      "loss in epoch 5 , step 18280 : 0.929619\n",
      "loss in epoch 5 , step 18300 : 1.243209\n",
      "loss in epoch 5 , step 18320 : 1.004080\n",
      "loss in epoch 5 , step 18340 : 0.381696\n",
      "loss in epoch 5 , step 18360 : 0.530414\n",
      "loss in epoch 5 , step 18380 : 0.294991\n",
      "loss in epoch 5 , step 18400 : 0.815519\n",
      "loss in epoch 5 , step 18420 : 1.549792\n",
      "loss in epoch 5 , step 18440 : 2.178150\n",
      "loss in epoch 5 , step 18460 : 2.553376\n",
      "loss in epoch 5 , step 18480 : 2.307129\n",
      "loss in epoch 5 , step 18500 : 1.831634\n",
      "loss in epoch 5 , step 18520 : 1.433415\n",
      "loss in epoch 5 , step 18540 : 1.723894\n",
      "loss in epoch 5 , step 18560 : 1.720558\n",
      "loss in epoch 5 , step 18580 : 1.819920\n",
      "loss in epoch 5 , step 18600 : 0.926024\n",
      "loss in epoch 5 , step 18620 : 0.561117\n",
      "loss in epoch 5 , step 18640 : 0.741591\n",
      "loss in epoch 5 , step 18660 : 2.024667\n",
      "loss in epoch 5 , step 18680 : 1.562864\n",
      "loss in epoch 5 , step 18700 : 2.019152\n",
      "loss in epoch 5 , step 18720 : 1.446687\n",
      "loss in epoch 5 , step 18740 : 1.773147\n",
      "loss in epoch 5 , step 18760 : 1.398249\n",
      "loss in epoch 5 , step 18780 : 0.205752\n",
      "loss in epoch 5 , step 18800 : 1.117655\n",
      "loss in epoch 5 , step 18820 : 1.285786\n",
      "loss in epoch 5 , step 18840 : 0.918345\n",
      "loss in epoch 5 , step 18860 : 1.764366\n",
      "loss in epoch 5 , step 18880 : 1.535326\n",
      "loss in epoch 5 , step 18900 : 1.107270\n",
      "loss in epoch 5 , step 18920 : 1.104918\n",
      "loss in epoch 5 , step 18940 : 0.380868\n",
      "loss in epoch 5 , step 18960 : 2.206249\n",
      "loss in epoch 5 , step 18980 : 1.561982\n",
      "loss in epoch 5 , step 19000 : 1.957050\n",
      "loss in epoch 5 , step 19020 : 1.745638\n",
      "loss in epoch 5 , step 19040 : 1.480455\n",
      "loss in epoch 5 , step 19060 : 2.510760\n",
      "loss in epoch 5 , step 19080 : 0.985067\n",
      "loss in epoch 5 , step 19100 : 1.339382\n",
      "loss in epoch 5 , step 19120 : 2.916398\n",
      "loss in epoch 5 , step 19140 : 0.939595\n",
      "loss in epoch 5 , step 19160 : 1.563383\n",
      "loss in epoch 5 , step 19180 : 0.787341\n",
      "loss in epoch 5 , step 19200 : 0.879979\n",
      "loss in epoch 5 , step 19220 : 1.904189\n",
      "loss in epoch 5 , step 19240 : 1.840804\n",
      "loss in epoch 5 , step 19260 : 1.415086\n",
      "loss in epoch 5 , step 19280 : 1.413254\n",
      "loss in epoch 5 , step 19300 : 1.698014\n",
      "loss in epoch 5 , step 19320 : 1.568960\n",
      "loss in epoch 5 , step 19340 : 1.432040\n",
      "loss in epoch 5 , step 19360 : 2.422698\n",
      "loss in epoch 5 , step 19380 : 1.077893\n",
      "loss in epoch 5 , step 19400 : 2.466535\n",
      "loss in epoch 5 , step 19420 : 2.141261\n",
      "loss in epoch 5 , step 19440 : 1.155277\n",
      "loss in epoch 5 , step 19460 : 1.746383\n",
      "loss in epoch 5 , step 19480 : 1.102638\n",
      "loss in epoch 5 , step 19500 : 1.009015\n",
      "loss in epoch 5 , step 19520 : 0.056446\n",
      "loss in epoch 5 , step 19540 : 1.900776\n",
      "loss in epoch 5 , step 19560 : 0.800051\n",
      "loss in epoch 5 , step 19580 : 0.237826\n",
      "loss in epoch 5 , step 19600 : 2.211915\n",
      "loss in epoch 5 , step 19620 : 1.028365\n",
      "loss in epoch 5 , step 19640 : 1.750951\n",
      "loss in epoch 5 , step 19660 : 1.066164\n",
      "loss in epoch 5 , step 19680 : 0.586200\n",
      "loss in epoch 5 , step 19700 : 2.358689\n",
      "loss in epoch 5 , step 19720 : 0.386776\n",
      "loss in epoch 5 , step 19740 : 0.732273\n",
      "loss in epoch 5 , step 19760 : 1.432309\n",
      "loss in epoch 5 , step 19780 : 0.214421\n",
      "loss in epoch 5 , step 19800 : 0.980855\n",
      "loss in epoch 5 , step 19820 : 0.609140\n",
      "loss in epoch 5 , step 19840 : 1.143233\n",
      "loss in epoch 5 , step 19860 : 1.797730\n",
      "loss in epoch 5 , step 19880 : 1.270439\n",
      "loss in epoch 5 , step 19900 : 1.907461\n",
      "loss in epoch 5 , step 19920 : 1.270886\n",
      "loss in epoch 5 , step 19940 : 0.548394\n",
      "Accuracy in epoch 5 : 24.051594\n",
      "loss in epoch 6 , step 0 : 0.775272\n",
      "loss in epoch 6 , step 20 : 0.889040\n",
      "loss in epoch 6 , step 40 : 1.339623\n",
      "loss in epoch 6 , step 60 : 0.945195\n",
      "loss in epoch 6 , step 80 : 1.527396\n",
      "loss in epoch 6 , step 100 : 1.076445\n",
      "loss in epoch 6 , step 120 : 1.499712\n",
      "loss in epoch 6 , step 140 : 1.706275\n",
      "loss in epoch 6 , step 160 : 1.493470\n",
      "loss in epoch 6 , step 180 : 1.580954\n",
      "loss in epoch 6 , step 200 : 1.069463\n",
      "loss in epoch 6 , step 220 : 1.309903\n",
      "loss in epoch 6 , step 240 : 2.296554\n",
      "loss in epoch 6 , step 260 : 0.038766\n",
      "loss in epoch 6 , step 280 : 0.752744\n",
      "loss in epoch 6 , step 300 : 0.231993\n",
      "loss in epoch 6 , step 320 : 0.502226\n",
      "loss in epoch 6 , step 340 : 0.715446\n",
      "loss in epoch 6 , step 360 : 1.504625\n",
      "loss in epoch 6 , step 380 : 0.611414\n",
      "loss in epoch 6 , step 400 : 2.307024\n",
      "loss in epoch 6 , step 420 : 1.128478\n",
      "loss in epoch 6 , step 440 : 1.249088\n",
      "loss in epoch 6 , step 460 : 0.144062\n",
      "loss in epoch 6 , step 480 : 1.474571\n",
      "loss in epoch 6 , step 500 : 1.999248\n",
      "loss in epoch 6 , step 520 : 1.144014\n",
      "loss in epoch 6 , step 540 : 2.153275\n",
      "loss in epoch 6 , step 560 : 1.137531\n",
      "loss in epoch 6 , step 580 : 1.702229\n",
      "loss in epoch 6 , step 600 : 1.855834\n",
      "loss in epoch 6 , step 620 : 1.992523\n",
      "loss in epoch 6 , step 640 : 1.332877\n",
      "loss in epoch 6 , step 660 : 4.887074\n",
      "loss in epoch 6 , step 680 : 2.209588\n",
      "loss in epoch 6 , step 700 : 2.058896\n",
      "loss in epoch 6 , step 720 : 0.983873\n",
      "loss in epoch 6 , step 740 : 2.501105\n",
      "loss in epoch 6 , step 760 : 1.169029\n",
      "loss in epoch 6 , step 780 : 2.138574\n",
      "loss in epoch 6 , step 800 : 1.267852\n",
      "loss in epoch 6 , step 820 : 1.539342\n",
      "loss in epoch 6 , step 840 : 1.679007\n",
      "loss in epoch 6 , step 860 : 2.019876\n",
      "loss in epoch 6 , step 880 : 1.143522\n",
      "loss in epoch 6 , step 900 : 1.373550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 6 , step 920 : 2.785803\n",
      "loss in epoch 6 , step 940 : 1.260700\n",
      "loss in epoch 6 , step 960 : 1.435886\n",
      "loss in epoch 6 , step 980 : 1.848912\n",
      "loss in epoch 6 , step 1000 : 1.309409\n",
      "loss in epoch 6 , step 1020 : 2.333652\n",
      "loss in epoch 6 , step 1040 : 0.516673\n",
      "loss in epoch 6 , step 1060 : 0.182014\n",
      "loss in epoch 6 , step 1080 : 1.218156\n",
      "loss in epoch 6 , step 1100 : 1.088245\n",
      "loss in epoch 6 , step 1120 : 0.882110\n",
      "loss in epoch 6 , step 1140 : 1.483388\n",
      "loss in epoch 6 , step 1160 : 1.629404\n",
      "loss in epoch 6 , step 1180 : 1.906485\n",
      "loss in epoch 6 , step 1200 : 1.534859\n",
      "loss in epoch 6 , step 1220 : 1.926874\n",
      "loss in epoch 6 , step 1240 : 1.273651\n",
      "loss in epoch 6 , step 1260 : 0.237091\n",
      "loss in epoch 6 , step 1280 : 1.991900\n",
      "loss in epoch 6 , step 1300 : 0.719612\n",
      "loss in epoch 6 , step 1320 : 2.631253\n",
      "loss in epoch 6 , step 1340 : 2.398932\n",
      "loss in epoch 6 , step 1360 : 2.345617\n",
      "loss in epoch 6 , step 1380 : 1.310186\n",
      "loss in epoch 6 , step 1400 : 1.137916\n",
      "loss in epoch 6 , step 1420 : 0.155532\n",
      "loss in epoch 6 , step 1440 : 1.515393\n",
      "loss in epoch 6 , step 1460 : 1.328871\n",
      "loss in epoch 6 , step 1480 : 2.185062\n",
      "loss in epoch 6 , step 1500 : 0.228214\n",
      "loss in epoch 6 , step 1520 : 0.403922\n",
      "loss in epoch 6 , step 1540 : 1.301551\n",
      "loss in epoch 6 , step 1560 : 0.627480\n",
      "loss in epoch 6 , step 1580 : 1.207091\n",
      "loss in epoch 6 , step 1600 : 1.216490\n",
      "loss in epoch 6 , step 1620 : 1.293354\n",
      "loss in epoch 6 , step 1640 : 0.640131\n",
      "loss in epoch 6 , step 1660 : 0.617789\n",
      "loss in epoch 6 , step 1680 : 1.677626\n",
      "loss in epoch 6 , step 1700 : 1.426841\n",
      "loss in epoch 6 , step 1720 : 0.159328\n",
      "loss in epoch 6 , step 1740 : 2.477652\n",
      "loss in epoch 6 , step 1760 : 2.025084\n",
      "loss in epoch 6 , step 1780 : 1.389328\n",
      "loss in epoch 6 , step 1800 : 0.089858\n",
      "loss in epoch 6 , step 1820 : 1.650168\n",
      "loss in epoch 6 , step 1840 : 1.343728\n",
      "loss in epoch 6 , step 1860 : 1.192387\n",
      "loss in epoch 6 , step 1880 : 3.936614\n",
      "loss in epoch 6 , step 1900 : 1.499369\n",
      "loss in epoch 6 , step 1920 : 1.606530\n",
      "loss in epoch 6 , step 1940 : 1.473187\n",
      "loss in epoch 6 , step 1960 : 0.353790\n",
      "loss in epoch 6 , step 1980 : 0.922662\n",
      "loss in epoch 6 , step 2000 : 2.300570\n",
      "loss in epoch 6 , step 2020 : 1.231695\n",
      "loss in epoch 6 , step 2040 : 1.220076\n",
      "loss in epoch 6 , step 2060 : 1.049628\n",
      "loss in epoch 6 , step 2080 : 3.339262\n",
      "loss in epoch 6 , step 2100 : 2.113356\n",
      "loss in epoch 6 , step 2120 : 0.040563\n",
      "loss in epoch 6 , step 2140 : 1.588172\n",
      "loss in epoch 6 , step 2160 : 4.191251\n",
      "loss in epoch 6 , step 2180 : 2.878516\n",
      "loss in epoch 6 , step 2200 : 2.029069\n",
      "loss in epoch 6 , step 2220 : 1.296159\n",
      "loss in epoch 6 , step 2240 : 1.627524\n",
      "loss in epoch 6 , step 2260 : 1.040019\n",
      "loss in epoch 6 , step 2280 : 0.364461\n",
      "loss in epoch 6 , step 2300 : 1.182581\n",
      "loss in epoch 6 , step 2320 : 1.490842\n",
      "loss in epoch 6 , step 2340 : 1.234055\n",
      "loss in epoch 6 , step 2360 : 0.060875\n",
      "loss in epoch 6 , step 2380 : 1.228120\n",
      "loss in epoch 6 , step 2400 : 2.276453\n",
      "loss in epoch 6 , step 2420 : 1.422981\n",
      "loss in epoch 6 , step 2440 : 1.282742\n",
      "loss in epoch 6 , step 2460 : 2.132916\n",
      "loss in epoch 6 , step 2480 : 1.480963\n",
      "loss in epoch 6 , step 2500 : 0.582498\n",
      "loss in epoch 6 , step 2520 : 2.529549\n",
      "loss in epoch 6 , step 2540 : 1.159462\n",
      "loss in epoch 6 , step 2560 : 1.628908\n",
      "loss in epoch 6 , step 2580 : 1.855037\n",
      "loss in epoch 6 , step 2600 : 0.179423\n",
      "loss in epoch 6 , step 2620 : 1.083192\n",
      "loss in epoch 6 , step 2640 : 1.998687\n",
      "loss in epoch 6 , step 2660 : 3.193549\n",
      "loss in epoch 6 , step 2680 : 1.553519\n",
      "loss in epoch 6 , step 2700 : 1.578880\n",
      "loss in epoch 6 , step 2720 : 0.992900\n",
      "loss in epoch 6 , step 2740 : 1.529407\n",
      "loss in epoch 6 , step 2760 : 1.163790\n",
      "loss in epoch 6 , step 2780 : 1.272266\n",
      "loss in epoch 6 , step 2800 : 0.945046\n",
      "loss in epoch 6 , step 2820 : 1.679792\n",
      "loss in epoch 6 , step 2840 : 1.817144\n",
      "loss in epoch 6 , step 2860 : 3.006304\n",
      "loss in epoch 6 , step 2880 : 0.063838\n",
      "loss in epoch 6 , step 2900 : 2.269810\n",
      "loss in epoch 6 , step 2920 : 1.663278\n",
      "loss in epoch 6 , step 2940 : 0.067636\n",
      "loss in epoch 6 , step 2960 : 1.735589\n",
      "loss in epoch 6 , step 2980 : 0.050960\n",
      "loss in epoch 6 , step 3000 : 1.202646\n",
      "loss in epoch 6 , step 3020 : 1.304932\n",
      "loss in epoch 6 , step 3040 : 1.762044\n",
      "loss in epoch 6 , step 3060 : 1.075557\n",
      "loss in epoch 6 , step 3080 : 1.750706\n",
      "loss in epoch 6 , step 3100 : 1.205916\n",
      "loss in epoch 6 , step 3120 : 1.430691\n",
      "loss in epoch 6 , step 3140 : 1.600809\n",
      "loss in epoch 6 , step 3160 : 1.558586\n",
      "loss in epoch 6 , step 3180 : 1.418500\n",
      "loss in epoch 6 , step 3200 : 1.195473\n",
      "loss in epoch 6 , step 3220 : 1.532164\n",
      "loss in epoch 6 , step 3240 : 0.016683\n",
      "loss in epoch 6 , step 3260 : 1.552993\n",
      "loss in epoch 6 , step 3280 : 1.506718\n",
      "loss in epoch 6 , step 3300 : 0.253267\n",
      "loss in epoch 6 , step 3320 : 2.283490\n",
      "loss in epoch 6 , step 3340 : 2.045811\n",
      "loss in epoch 6 , step 3360 : 1.679583\n",
      "loss in epoch 6 , step 3380 : 1.025732\n",
      "loss in epoch 6 , step 3400 : 1.369422\n",
      "loss in epoch 6 , step 3420 : 0.546021\n",
      "loss in epoch 6 , step 3440 : 4.468004\n",
      "loss in epoch 6 , step 3460 : 2.289023\n",
      "loss in epoch 6 , step 3480 : 1.829591\n",
      "loss in epoch 6 , step 3500 : 0.166224\n",
      "loss in epoch 6 , step 3520 : 0.317333\n",
      "loss in epoch 6 , step 3540 : 2.110781\n",
      "loss in epoch 6 , step 3560 : 1.578072\n",
      "loss in epoch 6 , step 3580 : 1.271717\n",
      "loss in epoch 6 , step 3600 : 1.794093\n",
      "loss in epoch 6 , step 3620 : 0.342689\n",
      "loss in epoch 6 , step 3640 : 1.990264\n",
      "loss in epoch 6 , step 3660 : 1.169270\n",
      "loss in epoch 6 , step 3680 : 1.009947\n",
      "loss in epoch 6 , step 3700 : 2.658261\n",
      "loss in epoch 6 , step 3720 : 0.015928\n",
      "loss in epoch 6 , step 3740 : 1.534443\n",
      "loss in epoch 6 , step 3760 : 2.513776\n",
      "loss in epoch 6 , step 3780 : 2.162776\n",
      "loss in epoch 6 , step 3800 : 1.850494\n",
      "loss in epoch 6 , step 3820 : 0.114874\n",
      "loss in epoch 6 , step 3840 : 1.182096\n",
      "loss in epoch 6 , step 3860 : 0.558945\n",
      "loss in epoch 6 , step 3880 : 0.835393\n",
      "loss in epoch 6 , step 3900 : 2.475655\n",
      "loss in epoch 6 , step 3920 : 1.484587\n",
      "loss in epoch 6 , step 3940 : 0.998479\n",
      "loss in epoch 6 , step 3960 : 2.352909\n",
      "loss in epoch 6 , step 3980 : 1.036474\n",
      "loss in epoch 6 , step 4000 : 2.017633\n",
      "loss in epoch 6 , step 4020 : 1.966859\n",
      "loss in epoch 6 , step 4040 : 1.421591\n",
      "loss in epoch 6 , step 4060 : 0.612312\n",
      "loss in epoch 6 , step 4080 : 1.458523\n",
      "loss in epoch 6 , step 4100 : 1.150586\n",
      "loss in epoch 6 , step 4120 : 1.035201\n",
      "loss in epoch 6 , step 4140 : 2.196383\n",
      "loss in epoch 6 , step 4160 : 1.524140\n",
      "loss in epoch 6 , step 4180 : 2.085605\n",
      "loss in epoch 6 , step 4200 : 0.133110\n",
      "loss in epoch 6 , step 4220 : 1.967493\n",
      "loss in epoch 6 , step 4240 : 1.820296\n",
      "loss in epoch 6 , step 4260 : 1.523939\n",
      "loss in epoch 6 , step 4280 : 1.293201\n",
      "loss in epoch 6 , step 4300 : 0.220858\n",
      "loss in epoch 6 , step 4320 : 1.786043\n",
      "loss in epoch 6 , step 4340 : 0.026372\n",
      "loss in epoch 6 , step 4360 : 1.868486\n",
      "loss in epoch 6 , step 4380 : 1.841182\n",
      "loss in epoch 6 , step 4400 : 2.446336\n",
      "loss in epoch 6 , step 4420 : 2.452989\n",
      "loss in epoch 6 , step 4440 : 1.262268\n",
      "loss in epoch 6 , step 4460 : 2.734055\n",
      "loss in epoch 6 , step 4480 : 0.708022\n",
      "loss in epoch 6 , step 4500 : 1.588728\n",
      "loss in epoch 6 , step 4520 : 1.255223\n",
      "loss in epoch 6 , step 4540 : 2.588475\n",
      "loss in epoch 6 , step 4560 : 1.374739\n",
      "loss in epoch 6 , step 4580 : 1.291343\n",
      "loss in epoch 6 , step 4600 : 1.404882\n",
      "loss in epoch 6 , step 4620 : 1.896734\n",
      "loss in epoch 6 , step 4640 : 0.693896\n",
      "loss in epoch 6 , step 4660 : 1.271484\n",
      "loss in epoch 6 , step 4680 : 2.359029\n",
      "loss in epoch 6 , step 4700 : 1.602387\n",
      "loss in epoch 6 , step 4720 : 3.702230\n",
      "loss in epoch 6 , step 4740 : 1.723847\n",
      "loss in epoch 6 , step 4760 : 0.879757\n",
      "loss in epoch 6 , step 4780 : 1.220216\n",
      "loss in epoch 6 , step 4800 : 0.667285\n",
      "loss in epoch 6 , step 4820 : 1.821199\n",
      "loss in epoch 6 , step 4840 : 0.159444\n",
      "loss in epoch 6 , step 4860 : 1.321006\n",
      "loss in epoch 6 , step 4880 : 0.852239\n",
      "loss in epoch 6 , step 4900 : 1.060161\n",
      "loss in epoch 6 , step 4920 : 0.762746\n",
      "loss in epoch 6 , step 4940 : 2.247906\n",
      "loss in epoch 6 , step 4960 : 1.157809\n",
      "loss in epoch 6 , step 4980 : 0.055077\n",
      "loss in epoch 6 , step 5000 : 0.967107\n",
      "loss in epoch 6 , step 5020 : 1.080751\n",
      "loss in epoch 6 , step 5040 : 1.470914\n",
      "loss in epoch 6 , step 5060 : 0.059808\n",
      "loss in epoch 6 , step 5080 : 1.357572\n",
      "loss in epoch 6 , step 5100 : 2.217048\n",
      "loss in epoch 6 , step 5120 : 0.964453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 6 , step 5140 : 1.713911\n",
      "loss in epoch 6 , step 5160 : 1.555729\n",
      "loss in epoch 6 , step 5180 : 0.242055\n",
      "loss in epoch 6 , step 5200 : 1.203086\n",
      "loss in epoch 6 , step 5220 : 0.038536\n",
      "loss in epoch 6 , step 5240 : 0.227024\n",
      "loss in epoch 6 , step 5260 : 0.679617\n",
      "loss in epoch 6 , step 5280 : 1.790186\n",
      "loss in epoch 6 , step 5300 : 0.107034\n",
      "loss in epoch 6 , step 5320 : 1.645029\n",
      "loss in epoch 6 , step 5340 : 3.649175\n",
      "loss in epoch 6 , step 5360 : 1.357101\n",
      "loss in epoch 6 , step 5380 : 1.422274\n",
      "loss in epoch 6 , step 5400 : 1.974746\n",
      "loss in epoch 6 , step 5420 : 1.176126\n",
      "loss in epoch 6 , step 5440 : 1.625360\n",
      "loss in epoch 6 , step 5460 : 0.819061\n",
      "loss in epoch 6 , step 5480 : 1.070808\n",
      "loss in epoch 6 , step 5500 : 1.712194\n",
      "loss in epoch 6 , step 5520 : 0.093264\n",
      "loss in epoch 6 , step 5540 : 1.121185\n",
      "loss in epoch 6 , step 5560 : 0.192881\n",
      "loss in epoch 6 , step 5580 : 0.646595\n",
      "loss in epoch 6 , step 5600 : 1.150308\n",
      "loss in epoch 6 , step 5620 : 2.363920\n",
      "loss in epoch 6 , step 5640 : 2.061616\n",
      "loss in epoch 6 , step 5660 : 0.524002\n",
      "loss in epoch 6 , step 5680 : 2.052391\n",
      "loss in epoch 6 , step 5700 : 0.166996\n",
      "loss in epoch 6 , step 5720 : 0.511602\n",
      "loss in epoch 6 , step 5740 : 2.084571\n",
      "loss in epoch 6 , step 5760 : 1.746972\n",
      "loss in epoch 6 , step 5780 : 1.848583\n",
      "loss in epoch 6 , step 5800 : 2.034825\n",
      "loss in epoch 6 , step 5820 : 3.540564\n",
      "loss in epoch 6 , step 5840 : 2.934292\n",
      "loss in epoch 6 , step 5860 : 1.132681\n",
      "loss in epoch 6 , step 5880 : 1.611989\n",
      "loss in epoch 6 , step 5900 : 1.081217\n",
      "loss in epoch 6 , step 5920 : 1.270555\n",
      "loss in epoch 6 , step 5940 : 0.281622\n",
      "loss in epoch 6 , step 5960 : 0.653027\n",
      "loss in epoch 6 , step 5980 : 0.235738\n",
      "loss in epoch 6 , step 6000 : 1.645120\n",
      "loss in epoch 6 , step 6020 : 1.370574\n",
      "loss in epoch 6 , step 6040 : 1.156375\n",
      "loss in epoch 6 , step 6060 : 1.680122\n",
      "loss in epoch 6 , step 6080 : 0.870004\n",
      "loss in epoch 6 , step 6100 : 1.653514\n",
      "loss in epoch 6 , step 6120 : 1.428895\n",
      "loss in epoch 6 , step 6140 : 1.428141\n",
      "loss in epoch 6 , step 6160 : 0.499431\n",
      "loss in epoch 6 , step 6180 : 1.617123\n",
      "loss in epoch 6 , step 6200 : 1.654661\n",
      "loss in epoch 6 , step 6220 : 1.898541\n",
      "loss in epoch 6 , step 6240 : 1.390450\n",
      "loss in epoch 6 , step 6260 : 1.741773\n",
      "loss in epoch 6 , step 6280 : 0.850093\n",
      "loss in epoch 6 , step 6300 : 0.949688\n",
      "loss in epoch 6 , step 6320 : 1.675774\n",
      "loss in epoch 6 , step 6340 : 1.720311\n",
      "loss in epoch 6 , step 6360 : 2.996976\n",
      "loss in epoch 6 , step 6380 : 1.025452\n",
      "loss in epoch 6 , step 6400 : 1.477277\n",
      "loss in epoch 6 , step 6420 : 2.496981\n",
      "loss in epoch 6 , step 6440 : 2.198409\n",
      "loss in epoch 6 , step 6460 : 2.270439\n",
      "loss in epoch 6 , step 6480 : 0.358397\n",
      "loss in epoch 6 , step 6500 : 1.407748\n",
      "loss in epoch 6 , step 6520 : 1.427026\n",
      "loss in epoch 6 , step 6540 : 2.039713\n",
      "loss in epoch 6 , step 6560 : 1.979618\n",
      "loss in epoch 6 , step 6580 : 2.666337\n",
      "loss in epoch 6 , step 6600 : 2.448853\n",
      "loss in epoch 6 , step 6620 : 1.493675\n",
      "loss in epoch 6 , step 6640 : 1.041719\n",
      "loss in epoch 6 , step 6660 : 0.967742\n",
      "loss in epoch 6 , step 6680 : 0.648480\n",
      "loss in epoch 6 , step 6700 : 1.669616\n",
      "loss in epoch 6 , step 6720 : 1.810220\n",
      "loss in epoch 6 , step 6740 : 2.406954\n",
      "loss in epoch 6 , step 6760 : 0.628372\n",
      "loss in epoch 6 , step 6780 : 1.123197\n",
      "loss in epoch 6 , step 6800 : 1.018170\n",
      "loss in epoch 6 , step 6820 : 0.968881\n",
      "loss in epoch 6 , step 6840 : 0.183976\n",
      "loss in epoch 6 , step 6860 : 0.048285\n",
      "loss in epoch 6 , step 6880 : 0.517026\n",
      "loss in epoch 6 , step 6900 : 0.399986\n",
      "loss in epoch 6 , step 6920 : 1.086419\n",
      "loss in epoch 6 , step 6940 : 1.753746\n",
      "loss in epoch 6 , step 6960 : 0.889591\n",
      "loss in epoch 6 , step 6980 : 2.157487\n",
      "loss in epoch 6 , step 7000 : 1.165851\n",
      "loss in epoch 6 , step 7020 : 1.093534\n",
      "loss in epoch 6 , step 7040 : 1.812173\n",
      "loss in epoch 6 , step 7060 : 1.591102\n",
      "loss in epoch 6 , step 7080 : 1.067903\n",
      "loss in epoch 6 , step 7100 : 2.306153\n",
      "loss in epoch 6 , step 7120 : 1.490678\n",
      "loss in epoch 6 , step 7140 : 0.186920\n",
      "loss in epoch 6 , step 7160 : 0.174731\n",
      "loss in epoch 6 , step 7180 : 1.813991\n",
      "loss in epoch 6 , step 7200 : 2.820951\n",
      "loss in epoch 6 , step 7220 : 1.814991\n",
      "loss in epoch 6 , step 7240 : 1.398685\n",
      "loss in epoch 6 , step 7260 : 1.835634\n",
      "loss in epoch 6 , step 7280 : 2.079306\n",
      "loss in epoch 6 , step 7300 : 1.845511\n",
      "loss in epoch 6 , step 7320 : 1.111589\n",
      "loss in epoch 6 , step 7340 : 0.328252\n",
      "loss in epoch 6 , step 7360 : 2.090883\n",
      "loss in epoch 6 , step 7380 : 1.452574\n",
      "loss in epoch 6 , step 7400 : 1.237665\n",
      "loss in epoch 6 , step 7420 : 0.193932\n",
      "loss in epoch 6 , step 7440 : 1.779030\n",
      "loss in epoch 6 , step 7460 : 1.756046\n",
      "loss in epoch 6 , step 7480 : 1.326282\n",
      "loss in epoch 6 , step 7500 : 1.702175\n",
      "loss in epoch 6 , step 7520 : 0.750916\n",
      "loss in epoch 6 , step 7540 : 1.762546\n",
      "loss in epoch 6 , step 7560 : 0.959920\n",
      "loss in epoch 6 , step 7580 : 0.308281\n",
      "loss in epoch 6 , step 7600 : 0.830222\n",
      "loss in epoch 6 , step 7620 : 0.480911\n",
      "loss in epoch 6 , step 7640 : 1.434842\n",
      "loss in epoch 6 , step 7660 : 0.333165\n",
      "loss in epoch 6 , step 7680 : 1.227439\n",
      "loss in epoch 6 , step 7700 : 0.120057\n",
      "loss in epoch 6 , step 7720 : 0.476323\n",
      "loss in epoch 6 , step 7740 : 1.623772\n",
      "loss in epoch 6 , step 7760 : 1.882472\n",
      "loss in epoch 6 , step 7780 : 2.161067\n",
      "loss in epoch 6 , step 7800 : 1.212726\n",
      "loss in epoch 6 , step 7820 : 1.592031\n",
      "loss in epoch 6 , step 7840 : 1.068831\n",
      "loss in epoch 6 , step 7860 : 0.894674\n",
      "loss in epoch 6 , step 7880 : 1.001652\n",
      "loss in epoch 6 , step 7900 : 0.246078\n",
      "loss in epoch 6 , step 7920 : 1.982466\n",
      "loss in epoch 6 , step 7940 : 0.738250\n",
      "loss in epoch 6 , step 7960 : 1.344960\n",
      "loss in epoch 6 , step 7980 : 1.189011\n",
      "loss in epoch 6 , step 8000 : 1.454337\n",
      "loss in epoch 6 , step 8020 : 2.252398\n",
      "loss in epoch 6 , step 8040 : 2.435385\n",
      "loss in epoch 6 , step 8060 : 1.601969\n",
      "loss in epoch 6 , step 8080 : 1.039420\n",
      "loss in epoch 6 , step 8100 : 2.094865\n",
      "loss in epoch 6 , step 8120 : 0.186322\n",
      "loss in epoch 6 , step 8140 : 1.230995\n",
      "loss in epoch 6 , step 8160 : 1.126177\n",
      "loss in epoch 6 , step 8180 : 0.083744\n",
      "loss in epoch 6 , step 8200 : 2.554092\n",
      "loss in epoch 6 , step 8220 : 3.484499\n",
      "loss in epoch 6 , step 8240 : 1.494997\n",
      "loss in epoch 6 , step 8260 : 1.726511\n",
      "loss in epoch 6 , step 8280 : 1.527834\n",
      "loss in epoch 6 , step 8300 : 2.557291\n",
      "loss in epoch 6 , step 8320 : 0.590668\n",
      "loss in epoch 6 , step 8340 : 1.749865\n",
      "loss in epoch 6 , step 8360 : 1.280320\n",
      "loss in epoch 6 , step 8380 : 2.153094\n",
      "loss in epoch 6 , step 8400 : 1.286050\n",
      "loss in epoch 6 , step 8420 : 1.110070\n",
      "loss in epoch 6 , step 8440 : 2.022565\n",
      "loss in epoch 6 , step 8460 : 1.659694\n",
      "loss in epoch 6 , step 8480 : 1.316739\n",
      "loss in epoch 6 , step 8500 : 0.920343\n",
      "loss in epoch 6 , step 8520 : 1.561871\n",
      "loss in epoch 6 , step 8540 : 1.603287\n",
      "loss in epoch 6 , step 8560 : 1.596635\n",
      "loss in epoch 6 , step 8580 : 2.064243\n",
      "loss in epoch 6 , step 8600 : 2.794429\n",
      "loss in epoch 6 , step 8620 : 0.877323\n",
      "loss in epoch 6 , step 8640 : 1.533911\n",
      "loss in epoch 6 , step 8660 : 1.407416\n",
      "loss in epoch 6 , step 8680 : 3.177361\n",
      "loss in epoch 6 , step 8700 : 1.249471\n",
      "loss in epoch 6 , step 8720 : 1.626390\n",
      "loss in epoch 6 , step 8740 : 1.252098\n",
      "loss in epoch 6 , step 8760 : 0.871012\n",
      "loss in epoch 6 , step 8780 : 1.945391\n",
      "loss in epoch 6 , step 8800 : 2.410142\n",
      "loss in epoch 6 , step 8820 : 2.198854\n",
      "loss in epoch 6 , step 8840 : 0.199649\n",
      "loss in epoch 6 , step 8860 : 0.509314\n",
      "loss in epoch 6 , step 8880 : 1.219327\n",
      "loss in epoch 6 , step 8900 : 1.917647\n",
      "loss in epoch 6 , step 8920 : 1.246253\n",
      "loss in epoch 6 , step 8940 : 1.355938\n",
      "loss in epoch 6 , step 8960 : 1.530634\n",
      "loss in epoch 6 , step 8980 : 1.792138\n",
      "loss in epoch 6 , step 9000 : 1.745856\n",
      "loss in epoch 6 , step 9020 : 0.178800\n",
      "loss in epoch 6 , step 9040 : 1.256372\n",
      "loss in epoch 6 , step 9060 : 1.503079\n",
      "loss in epoch 6 , step 9080 : 0.037162\n",
      "loss in epoch 6 , step 9100 : 0.547760\n",
      "loss in epoch 6 , step 9120 : 0.217591\n",
      "loss in epoch 6 , step 9140 : 0.124643\n",
      "loss in epoch 6 , step 9160 : 1.901686\n",
      "loss in epoch 6 , step 9180 : 0.062559\n",
      "loss in epoch 6 , step 9200 : 1.748490\n",
      "loss in epoch 6 , step 9220 : 3.001257\n",
      "loss in epoch 6 , step 9240 : 1.165425\n",
      "loss in epoch 6 , step 9260 : 0.670485\n",
      "loss in epoch 6 , step 9280 : 1.078189\n",
      "loss in epoch 6 , step 9300 : 1.277867\n",
      "loss in epoch 6 , step 9320 : 1.424096\n",
      "loss in epoch 6 , step 9340 : 2.025597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 6 , step 9360 : 0.047615\n",
      "loss in epoch 6 , step 9380 : 1.169203\n",
      "loss in epoch 6 , step 9400 : 0.793846\n",
      "loss in epoch 6 , step 9420 : 1.573869\n",
      "loss in epoch 6 , step 9440 : 1.504109\n",
      "loss in epoch 6 , step 9460 : 0.548074\n",
      "loss in epoch 6 , step 9480 : 2.804488\n",
      "loss in epoch 6 , step 9500 : 1.367271\n",
      "loss in epoch 6 , step 9520 : 0.805391\n",
      "loss in epoch 6 , step 9540 : 0.027538\n",
      "loss in epoch 6 , step 9560 : 2.116973\n",
      "loss in epoch 6 , step 9580 : 0.226453\n",
      "loss in epoch 6 , step 9600 : 1.147920\n",
      "loss in epoch 6 , step 9620 : 1.919191\n",
      "loss in epoch 6 , step 9640 : 1.387508\n",
      "loss in epoch 6 , step 9660 : 2.621729\n",
      "loss in epoch 6 , step 9680 : 1.047222\n",
      "loss in epoch 6 , step 9700 : 2.528888\n",
      "loss in epoch 6 , step 9720 : 0.454437\n",
      "loss in epoch 6 , step 9740 : 1.017842\n",
      "loss in epoch 6 , step 9760 : 1.309731\n",
      "loss in epoch 6 , step 9780 : 0.164257\n",
      "loss in epoch 6 , step 9800 : 1.440763\n",
      "loss in epoch 6 , step 9820 : 1.537480\n",
      "loss in epoch 6 , step 9840 : 2.033026\n",
      "loss in epoch 6 , step 9860 : 1.451050\n",
      "loss in epoch 6 , step 9880 : 0.114566\n",
      "loss in epoch 6 , step 9900 : 1.711409\n",
      "loss in epoch 6 , step 9920 : 0.326145\n",
      "loss in epoch 6 , step 9940 : 1.231038\n",
      "loss in epoch 6 , step 9960 : 0.530539\n",
      "loss in epoch 6 , step 9980 : 2.366878\n",
      "loss in epoch 6 , step 10000 : 1.237621\n",
      "loss in epoch 6 , step 10020 : 1.164492\n",
      "loss in epoch 6 , step 10040 : 1.446765\n",
      "loss in epoch 6 , step 10060 : 0.464965\n",
      "loss in epoch 6 , step 10080 : 2.365993\n",
      "loss in epoch 6 , step 10100 : 2.032462\n",
      "loss in epoch 6 , step 10120 : 0.094530\n",
      "loss in epoch 6 , step 10140 : 1.933850\n",
      "loss in epoch 6 , step 10160 : 1.762635\n",
      "loss in epoch 6 , step 10180 : 2.434007\n",
      "loss in epoch 6 , step 10200 : 0.351366\n",
      "loss in epoch 6 , step 10220 : 3.930300\n",
      "loss in epoch 6 , step 10240 : 0.141323\n",
      "loss in epoch 6 , step 10260 : 1.643757\n",
      "loss in epoch 6 , step 10280 : 1.461795\n",
      "loss in epoch 6 , step 10300 : 0.892080\n",
      "loss in epoch 6 , step 10320 : 2.331059\n",
      "loss in epoch 6 , step 10340 : 1.934107\n",
      "loss in epoch 6 , step 10360 : 2.277598\n",
      "loss in epoch 6 , step 10380 : 1.678576\n",
      "loss in epoch 6 , step 10400 : 1.663145\n",
      "loss in epoch 6 , step 10420 : 3.206419\n",
      "loss in epoch 6 , step 10440 : 1.107384\n",
      "loss in epoch 6 , step 10460 : 1.381550\n",
      "loss in epoch 6 , step 10480 : 1.470098\n",
      "loss in epoch 6 , step 10500 : 1.613455\n",
      "loss in epoch 6 , step 10520 : 1.213825\n",
      "loss in epoch 6 , step 10540 : 1.602546\n",
      "loss in epoch 6 , step 10560 : 1.309733\n",
      "loss in epoch 6 , step 10580 : 1.763545\n",
      "loss in epoch 6 , step 10600 : 1.352137\n",
      "loss in epoch 6 , step 10620 : 2.447224\n",
      "loss in epoch 6 , step 10640 : 0.138287\n",
      "loss in epoch 6 , step 10660 : 1.066825\n",
      "loss in epoch 6 , step 10680 : 1.997504\n",
      "loss in epoch 6 , step 10700 : 0.225860\n",
      "loss in epoch 6 , step 10720 : 3.269556\n",
      "loss in epoch 6 , step 10740 : 5.889773\n",
      "loss in epoch 6 , step 10760 : 0.882285\n",
      "loss in epoch 6 , step 10780 : 1.338014\n",
      "loss in epoch 6 , step 10800 : 2.856313\n",
      "loss in epoch 6 , step 10820 : 0.681054\n",
      "loss in epoch 6 , step 10840 : 0.988319\n",
      "loss in epoch 6 , step 10860 : 1.662434\n",
      "loss in epoch 6 , step 10880 : 1.889800\n",
      "loss in epoch 6 , step 10900 : 1.330678\n",
      "loss in epoch 6 , step 10920 : 1.152604\n",
      "loss in epoch 6 , step 10940 : 1.600232\n",
      "loss in epoch 6 , step 10960 : 1.326088\n",
      "loss in epoch 6 , step 10980 : 1.403993\n",
      "loss in epoch 6 , step 11000 : 1.089446\n",
      "loss in epoch 6 , step 11020 : 0.539527\n",
      "loss in epoch 6 , step 11040 : 1.366041\n",
      "loss in epoch 6 , step 11060 : 2.002979\n",
      "loss in epoch 6 , step 11080 : 1.274000\n",
      "loss in epoch 6 , step 11100 : 0.303807\n",
      "loss in epoch 6 , step 11120 : 2.418080\n",
      "loss in epoch 6 , step 11140 : 2.356093\n",
      "loss in epoch 6 , step 11160 : 1.507855\n",
      "loss in epoch 6 , step 11180 : 0.405105\n",
      "loss in epoch 6 , step 11200 : 1.312664\n",
      "loss in epoch 6 , step 11220 : 0.929400\n",
      "loss in epoch 6 , step 11240 : 0.710032\n",
      "loss in epoch 6 , step 11260 : 0.052919\n",
      "loss in epoch 6 , step 11280 : 0.759490\n",
      "loss in epoch 6 , step 11300 : 3.048926\n",
      "loss in epoch 6 , step 11320 : 1.201887\n",
      "loss in epoch 6 , step 11340 : 0.593103\n",
      "loss in epoch 6 , step 11360 : 1.211169\n",
      "loss in epoch 6 , step 11380 : 1.314553\n",
      "loss in epoch 6 , step 11400 : 1.093870\n",
      "loss in epoch 6 , step 11420 : 1.298034\n",
      "loss in epoch 6 , step 11440 : 0.207474\n",
      "loss in epoch 6 , step 11460 : 4.105515\n",
      "loss in epoch 6 , step 11480 : 0.660704\n",
      "loss in epoch 6 , step 11500 : 1.432234\n",
      "loss in epoch 6 , step 11520 : 1.429928\n",
      "loss in epoch 6 , step 11540 : 3.318714\n",
      "loss in epoch 6 , step 11560 : 1.397644\n",
      "loss in epoch 6 , step 11580 : 1.940280\n",
      "loss in epoch 6 , step 11600 : 0.160832\n",
      "loss in epoch 6 , step 11620 : 1.106460\n",
      "loss in epoch 6 , step 11640 : 1.875472\n",
      "loss in epoch 6 , step 11660 : 0.396780\n",
      "loss in epoch 6 , step 11680 : 3.371400\n",
      "loss in epoch 6 , step 11700 : 0.053433\n",
      "loss in epoch 6 , step 11720 : 0.059501\n",
      "loss in epoch 6 , step 11740 : 3.892110\n",
      "loss in epoch 6 , step 11760 : 1.849886\n",
      "loss in epoch 6 , step 11780 : 2.029352\n",
      "loss in epoch 6 , step 11800 : 2.103577\n",
      "loss in epoch 6 , step 11820 : 0.065180\n",
      "loss in epoch 6 , step 11840 : 0.329205\n",
      "loss in epoch 6 , step 11860 : 0.190623\n",
      "loss in epoch 6 , step 11880 : 1.103689\n",
      "loss in epoch 6 , step 11900 : 1.960486\n",
      "loss in epoch 6 , step 11920 : 1.237493\n",
      "loss in epoch 6 , step 11940 : 0.345771\n",
      "loss in epoch 6 , step 11960 : 2.014850\n",
      "loss in epoch 6 , step 11980 : 2.241667\n",
      "loss in epoch 6 , step 12000 : 2.934115\n",
      "loss in epoch 6 , step 12020 : 1.401592\n",
      "loss in epoch 6 , step 12040 : 1.694798\n",
      "loss in epoch 6 , step 12060 : 1.355103\n",
      "loss in epoch 6 , step 12080 : 1.853834\n",
      "loss in epoch 6 , step 12100 : 1.743218\n",
      "loss in epoch 6 , step 12120 : 0.565750\n",
      "loss in epoch 6 , step 12140 : 0.932743\n",
      "loss in epoch 6 , step 12160 : 0.402239\n",
      "loss in epoch 6 , step 12180 : 2.401302\n",
      "loss in epoch 6 , step 12200 : 1.689918\n",
      "loss in epoch 6 , step 12220 : 1.237332\n",
      "loss in epoch 6 , step 12240 : 0.516415\n",
      "loss in epoch 6 , step 12260 : 1.266591\n",
      "loss in epoch 6 , step 12280 : 1.473895\n",
      "loss in epoch 6 , step 12300 : 2.348948\n",
      "loss in epoch 6 , step 12320 : 1.136933\n",
      "loss in epoch 6 , step 12340 : 1.223575\n",
      "loss in epoch 6 , step 12360 : 1.962578\n",
      "loss in epoch 6 , step 12380 : 1.432421\n",
      "loss in epoch 6 , step 12400 : 1.542092\n",
      "loss in epoch 6 , step 12420 : 0.467664\n",
      "loss in epoch 6 , step 12440 : 1.710870\n",
      "loss in epoch 6 , step 12460 : 0.931584\n",
      "loss in epoch 6 , step 12480 : 2.123117\n",
      "loss in epoch 6 , step 12500 : 1.340980\n",
      "loss in epoch 6 , step 12520 : 0.764241\n",
      "loss in epoch 6 , step 12540 : 1.135465\n",
      "loss in epoch 6 , step 12560 : 1.221230\n",
      "loss in epoch 6 , step 12580 : 0.563562\n",
      "loss in epoch 6 , step 12600 : 1.684784\n",
      "loss in epoch 6 , step 12620 : 2.474782\n",
      "loss in epoch 6 , step 12640 : 0.878256\n",
      "loss in epoch 6 , step 12660 : 1.183041\n",
      "loss in epoch 6 , step 12680 : 1.103449\n",
      "loss in epoch 6 , step 12700 : 0.657735\n",
      "loss in epoch 6 , step 12720 : 0.679370\n",
      "loss in epoch 6 , step 12740 : 0.318634\n",
      "loss in epoch 6 , step 12760 : 2.163181\n",
      "loss in epoch 6 , step 12780 : 1.596775\n",
      "loss in epoch 6 , step 12800 : 1.129913\n",
      "loss in epoch 6 , step 12820 : 1.271010\n",
      "loss in epoch 6 , step 12840 : 1.040585\n",
      "loss in epoch 6 , step 12860 : 1.205058\n",
      "loss in epoch 6 , step 12880 : 1.738819\n",
      "loss in epoch 6 , step 12900 : 1.227446\n",
      "loss in epoch 6 , step 12920 : 2.388334\n",
      "loss in epoch 6 , step 12940 : 1.083380\n",
      "loss in epoch 6 , step 12960 : 1.970574\n",
      "loss in epoch 6 , step 12980 : 1.741734\n",
      "loss in epoch 6 , step 13000 : 1.906176\n",
      "loss in epoch 6 , step 13020 : 0.865398\n",
      "loss in epoch 6 , step 13040 : 1.560969\n",
      "loss in epoch 6 , step 13060 : 0.151929\n",
      "loss in epoch 6 , step 13080 : 0.848903\n",
      "loss in epoch 6 , step 13100 : 1.919679\n",
      "loss in epoch 6 , step 13120 : 0.581351\n",
      "loss in epoch 6 , step 13140 : 1.178678\n",
      "loss in epoch 6 , step 13160 : 1.139170\n",
      "loss in epoch 6 , step 13180 : 0.247603\n",
      "loss in epoch 6 , step 13200 : 1.358812\n",
      "loss in epoch 6 , step 13220 : 0.218826\n",
      "loss in epoch 6 , step 13240 : 1.494931\n",
      "loss in epoch 6 , step 13260 : 1.511099\n",
      "loss in epoch 6 , step 13280 : 0.690650\n",
      "loss in epoch 6 , step 13300 : 1.279530\n",
      "loss in epoch 6 , step 13320 : 1.889326\n",
      "loss in epoch 6 , step 13340 : 0.942207\n",
      "loss in epoch 6 , step 13360 : 1.414155\n",
      "loss in epoch 6 , step 13380 : 1.715821\n",
      "loss in epoch 6 , step 13400 : 1.926568\n",
      "loss in epoch 6 , step 13420 : 1.271584\n",
      "loss in epoch 6 , step 13440 : 1.511997\n",
      "loss in epoch 6 , step 13460 : 1.313065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 6 , step 13480 : 1.279420\n",
      "loss in epoch 6 , step 13500 : 0.818968\n",
      "loss in epoch 6 , step 13520 : 2.091376\n",
      "loss in epoch 6 , step 13540 : 1.788910\n",
      "loss in epoch 6 , step 13560 : 2.246151\n",
      "loss in epoch 6 , step 13580 : 0.083391\n",
      "loss in epoch 6 , step 13600 : 0.989153\n",
      "loss in epoch 6 , step 13620 : 1.981699\n",
      "loss in epoch 6 , step 13640 : 2.396048\n",
      "loss in epoch 6 , step 13660 : 1.973166\n",
      "loss in epoch 6 , step 13680 : 1.632721\n",
      "loss in epoch 6 , step 13700 : 0.028185\n",
      "loss in epoch 6 , step 13720 : 0.332679\n",
      "loss in epoch 6 , step 13740 : 2.379921\n",
      "loss in epoch 6 , step 13760 : 0.075656\n",
      "loss in epoch 6 , step 13780 : 0.948488\n",
      "loss in epoch 6 , step 13800 : 2.434945\n",
      "loss in epoch 6 , step 13820 : 1.648882\n",
      "loss in epoch 6 , step 13840 : 0.536409\n",
      "loss in epoch 6 , step 13860 : 1.451951\n",
      "loss in epoch 6 , step 13880 : 0.337300\n",
      "loss in epoch 6 , step 13900 : 1.641825\n",
      "loss in epoch 6 , step 13920 : 1.392540\n",
      "loss in epoch 6 , step 13940 : 2.307756\n",
      "loss in epoch 6 , step 13960 : 1.644781\n",
      "loss in epoch 6 , step 13980 : 1.530956\n",
      "loss in epoch 6 , step 14000 : 0.731173\n",
      "loss in epoch 6 , step 14020 : 0.873552\n",
      "loss in epoch 6 , step 14040 : 1.590410\n",
      "loss in epoch 6 , step 14060 : 2.134408\n",
      "loss in epoch 6 , step 14080 : 1.530362\n",
      "loss in epoch 6 , step 14100 : 1.734058\n",
      "loss in epoch 6 , step 14120 : 1.370798\n",
      "loss in epoch 6 , step 14140 : 0.945707\n",
      "loss in epoch 6 , step 14160 : 0.627668\n",
      "loss in epoch 6 , step 14180 : 0.680803\n",
      "loss in epoch 6 , step 14200 : 0.106184\n",
      "loss in epoch 6 , step 14220 : 1.377448\n",
      "loss in epoch 6 , step 14240 : 1.527455\n",
      "loss in epoch 6 , step 14260 : 0.048039\n",
      "loss in epoch 6 , step 14280 : 0.162635\n",
      "loss in epoch 6 , step 14300 : 4.160476\n",
      "loss in epoch 6 , step 14320 : 1.750901\n",
      "loss in epoch 6 , step 14340 : 0.544900\n",
      "loss in epoch 6 , step 14360 : 1.605435\n",
      "loss in epoch 6 , step 14380 : 2.796719\n",
      "loss in epoch 6 , step 14400 : 1.044204\n",
      "loss in epoch 6 , step 14420 : 2.071128\n",
      "loss in epoch 6 , step 14440 : 1.412789\n",
      "loss in epoch 6 , step 14460 : 1.958035\n",
      "loss in epoch 6 , step 14480 : 2.137452\n",
      "loss in epoch 6 , step 14500 : 0.853378\n",
      "loss in epoch 6 , step 14520 : 2.700291\n",
      "loss in epoch 6 , step 14540 : 1.666199\n",
      "loss in epoch 6 , step 14560 : 1.487828\n",
      "loss in epoch 6 , step 14580 : 2.036427\n",
      "loss in epoch 6 , step 14600 : 1.247695\n",
      "loss in epoch 6 , step 14620 : 1.334705\n",
      "loss in epoch 6 , step 14640 : 0.804709\n",
      "loss in epoch 6 , step 14660 : 1.037536\n",
      "loss in epoch 6 , step 14680 : 1.912420\n",
      "loss in epoch 6 , step 14700 : 1.394630\n",
      "loss in epoch 6 , step 14720 : 0.479999\n",
      "loss in epoch 6 , step 14740 : 0.051526\n",
      "loss in epoch 6 , step 14760 : 0.012227\n",
      "loss in epoch 6 , step 14780 : 1.634033\n",
      "loss in epoch 6 , step 14800 : 1.423136\n",
      "loss in epoch 6 , step 14820 : 1.125216\n",
      "loss in epoch 6 , step 14840 : 2.776701\n",
      "loss in epoch 6 , step 14860 : 1.604190\n",
      "loss in epoch 6 , step 14880 : 1.956543\n",
      "loss in epoch 6 , step 14900 : 1.028463\n",
      "loss in epoch 6 , step 14920 : 4.132157\n",
      "loss in epoch 6 , step 14940 : 1.397514\n",
      "loss in epoch 6 , step 14960 : 1.287145\n",
      "loss in epoch 6 , step 14980 : 2.740317\n",
      "loss in epoch 6 , step 15000 : 1.282518\n",
      "loss in epoch 6 , step 15020 : 3.445634\n",
      "loss in epoch 6 , step 15040 : 0.100531\n",
      "loss in epoch 6 , step 15060 : 3.093338\n",
      "loss in epoch 6 , step 15080 : 1.836813\n",
      "loss in epoch 6 , step 15100 : 4.598794\n",
      "loss in epoch 6 , step 15120 : 0.259204\n",
      "loss in epoch 6 , step 15140 : 2.064057\n",
      "loss in epoch 6 , step 15160 : 2.177843\n",
      "loss in epoch 6 , step 15180 : 2.253498\n",
      "loss in epoch 6 , step 15200 : 0.123291\n",
      "loss in epoch 6 , step 15220 : 0.382582\n",
      "loss in epoch 6 , step 15240 : 1.825571\n",
      "loss in epoch 6 , step 15260 : 0.553903\n",
      "loss in epoch 6 , step 15280 : 1.163824\n",
      "loss in epoch 6 , step 15300 : 1.466307\n",
      "loss in epoch 6 , step 15320 : 1.305494\n",
      "loss in epoch 6 , step 15340 : 1.342665\n",
      "loss in epoch 6 , step 15360 : 1.229509\n",
      "loss in epoch 6 , step 15380 : 1.669837\n",
      "loss in epoch 6 , step 15400 : 1.171718\n",
      "loss in epoch 6 , step 15420 : 1.075558\n",
      "loss in epoch 6 , step 15440 : 2.017938\n",
      "loss in epoch 6 , step 15460 : 1.348028\n",
      "loss in epoch 6 , step 15480 : 1.179776\n",
      "loss in epoch 6 , step 15500 : 0.350602\n",
      "loss in epoch 6 , step 15520 : 2.019763\n",
      "loss in epoch 6 , step 15540 : 0.816241\n",
      "loss in epoch 6 , step 15560 : 0.836206\n",
      "loss in epoch 6 , step 15580 : 2.171583\n",
      "loss in epoch 6 , step 15600 : 2.313042\n",
      "loss in epoch 6 , step 15620 : 1.399415\n",
      "loss in epoch 6 , step 15640 : 0.652356\n",
      "loss in epoch 6 , step 15660 : 0.810258\n",
      "loss in epoch 6 , step 15680 : 2.180848\n",
      "loss in epoch 6 , step 15700 : 1.745786\n",
      "loss in epoch 6 , step 15720 : 2.106115\n",
      "loss in epoch 6 , step 15740 : 1.198139\n",
      "loss in epoch 6 , step 15760 : 1.449853\n",
      "loss in epoch 6 , step 15780 : 2.229605\n",
      "loss in epoch 6 , step 15800 : 2.118936\n",
      "loss in epoch 6 , step 15820 : 2.147551\n",
      "loss in epoch 6 , step 15840 : 0.844230\n",
      "loss in epoch 6 , step 15860 : 1.271560\n",
      "loss in epoch 6 , step 15880 : 2.147969\n",
      "loss in epoch 6 , step 15900 : 1.020120\n",
      "loss in epoch 6 , step 15920 : 1.568763\n",
      "loss in epoch 6 , step 15940 : 2.802940\n",
      "loss in epoch 6 , step 15960 : 2.496407\n",
      "loss in epoch 6 , step 15980 : 2.045889\n",
      "loss in epoch 6 , step 16000 : 0.529812\n",
      "loss in epoch 6 , step 16020 : 0.282966\n",
      "loss in epoch 6 , step 16040 : 2.711471\n",
      "loss in epoch 6 , step 16060 : 2.538150\n",
      "loss in epoch 6 , step 16080 : 0.053640\n",
      "loss in epoch 6 , step 16100 : 1.369207\n",
      "loss in epoch 6 , step 16120 : 0.178119\n",
      "loss in epoch 6 , step 16140 : 2.365895\n",
      "loss in epoch 6 , step 16160 : 1.578522\n",
      "loss in epoch 6 , step 16180 : 1.207197\n",
      "loss in epoch 6 , step 16200 : 0.526892\n",
      "loss in epoch 6 , step 16220 : 3.269133\n",
      "loss in epoch 6 , step 16240 : 0.976415\n",
      "loss in epoch 6 , step 16260 : 0.757229\n",
      "loss in epoch 6 , step 16280 : 1.641364\n",
      "loss in epoch 6 , step 16300 : 0.380619\n",
      "loss in epoch 6 , step 16320 : 1.325851\n",
      "loss in epoch 6 , step 16340 : 1.320630\n",
      "loss in epoch 6 , step 16360 : 1.602230\n",
      "loss in epoch 6 , step 16380 : 2.382526\n",
      "loss in epoch 6 , step 16400 : 1.762678\n",
      "loss in epoch 6 , step 16420 : 0.551536\n",
      "loss in epoch 6 , step 16440 : 0.765556\n",
      "loss in epoch 6 , step 16460 : 0.443956\n",
      "loss in epoch 6 , step 16480 : 0.184564\n",
      "loss in epoch 6 , step 16500 : 1.163008\n",
      "loss in epoch 6 , step 16520 : 1.915661\n",
      "loss in epoch 6 , step 16540 : 1.767421\n",
      "loss in epoch 6 , step 16560 : 2.074629\n",
      "loss in epoch 6 , step 16580 : 0.497442\n",
      "loss in epoch 6 , step 16600 : 1.301179\n",
      "loss in epoch 6 , step 16620 : 2.273747\n",
      "loss in epoch 6 , step 16640 : 1.563326\n",
      "loss in epoch 6 , step 16660 : 0.507540\n",
      "loss in epoch 6 , step 16680 : 4.432936\n",
      "loss in epoch 6 , step 16700 : 1.729721\n",
      "loss in epoch 6 , step 16720 : 0.996516\n",
      "loss in epoch 6 , step 16740 : 2.072630\n",
      "loss in epoch 6 , step 16760 : 2.113276\n",
      "loss in epoch 6 , step 16780 : 1.674230\n",
      "loss in epoch 6 , step 16800 : 2.806064\n",
      "loss in epoch 6 , step 16820 : 1.673769\n",
      "loss in epoch 6 , step 16840 : 0.048396\n",
      "loss in epoch 6 , step 16860 : 1.538760\n",
      "loss in epoch 6 , step 16880 : 1.617283\n",
      "loss in epoch 6 , step 16900 : 1.562292\n",
      "loss in epoch 6 , step 16920 : 1.394648\n",
      "loss in epoch 6 , step 16940 : 1.744074\n",
      "loss in epoch 6 , step 16960 : 1.402782\n",
      "loss in epoch 6 , step 16980 : 2.142644\n",
      "loss in epoch 6 , step 17000 : 1.622785\n",
      "loss in epoch 6 , step 17020 : 2.216677\n",
      "loss in epoch 6 , step 17040 : 1.593598\n",
      "loss in epoch 6 , step 17060 : 1.774017\n",
      "loss in epoch 6 , step 17080 : 1.094812\n",
      "loss in epoch 6 , step 17100 : 1.864544\n",
      "loss in epoch 6 , step 17120 : 1.423324\n",
      "loss in epoch 6 , step 17140 : 2.452487\n",
      "loss in epoch 6 , step 17160 : 1.868882\n",
      "loss in epoch 6 , step 17180 : 0.311060\n",
      "loss in epoch 6 , step 17200 : 3.235250\n",
      "loss in epoch 6 , step 17220 : 0.947623\n",
      "loss in epoch 6 , step 17240 : 2.113828\n",
      "loss in epoch 6 , step 17260 : 1.417174\n",
      "loss in epoch 6 , step 17280 : 0.742414\n",
      "loss in epoch 6 , step 17300 : 0.996078\n",
      "loss in epoch 6 , step 17320 : 1.036674\n",
      "loss in epoch 6 , step 17340 : 1.877823\n",
      "loss in epoch 6 , step 17360 : 0.060072\n",
      "loss in epoch 6 , step 17380 : 2.277149\n",
      "loss in epoch 6 , step 17400 : 0.492410\n",
      "loss in epoch 6 , step 17420 : 1.783950\n",
      "loss in epoch 6 , step 17440 : 1.440083\n",
      "loss in epoch 6 , step 17460 : 0.264986\n",
      "loss in epoch 6 , step 17480 : 0.788704\n",
      "loss in epoch 6 , step 17500 : 1.806506\n",
      "loss in epoch 6 , step 17520 : 1.429106\n",
      "loss in epoch 6 , step 17540 : 0.410116\n",
      "loss in epoch 6 , step 17560 : 0.768571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 6 , step 17580 : 2.111494\n",
      "loss in epoch 6 , step 17600 : 1.079739\n",
      "loss in epoch 6 , step 17620 : 0.309929\n",
      "loss in epoch 6 , step 17640 : 1.483273\n",
      "loss in epoch 6 , step 17660 : 2.205575\n",
      "loss in epoch 6 , step 17680 : 1.186144\n",
      "loss in epoch 6 , step 17700 : 1.164065\n",
      "loss in epoch 6 , step 17720 : 0.161902\n",
      "loss in epoch 6 , step 17740 : 1.076605\n",
      "loss in epoch 6 , step 17760 : 2.192098\n",
      "loss in epoch 6 , step 17780 : 1.341590\n",
      "loss in epoch 6 , step 17800 : 2.025352\n",
      "loss in epoch 6 , step 17820 : 0.351231\n",
      "loss in epoch 6 , step 17840 : 0.916655\n",
      "loss in epoch 6 , step 17860 : 0.149042\n",
      "loss in epoch 6 , step 17880 : 2.105983\n",
      "loss in epoch 6 , step 17900 : 0.854511\n",
      "loss in epoch 6 , step 17920 : 0.962261\n",
      "loss in epoch 6 , step 17940 : 1.134282\n",
      "loss in epoch 6 , step 17960 : 1.534684\n",
      "loss in epoch 6 , step 17980 : 0.155494\n",
      "loss in epoch 6 , step 18000 : 1.582311\n",
      "loss in epoch 6 , step 18020 : 2.929630\n",
      "loss in epoch 6 , step 18040 : 0.042752\n",
      "loss in epoch 6 , step 18060 : 0.523215\n",
      "loss in epoch 6 , step 18080 : 1.393648\n",
      "loss in epoch 6 , step 18100 : 1.873941\n",
      "loss in epoch 6 , step 18120 : 3.590372\n",
      "loss in epoch 6 , step 18140 : 2.338776\n",
      "loss in epoch 6 , step 18160 : 1.380287\n",
      "loss in epoch 6 , step 18180 : 2.283244\n",
      "loss in epoch 6 , step 18200 : 0.714459\n",
      "loss in epoch 6 , step 18220 : 1.854689\n",
      "loss in epoch 6 , step 18240 : 2.528503\n",
      "loss in epoch 6 , step 18260 : 0.039900\n",
      "loss in epoch 6 , step 18280 : 0.974628\n",
      "loss in epoch 6 , step 18300 : 1.248311\n",
      "loss in epoch 6 , step 18320 : 2.688121\n",
      "loss in epoch 6 , step 18340 : 1.447422\n",
      "loss in epoch 6 , step 18360 : 1.241315\n",
      "loss in epoch 6 , step 18380 : 0.017813\n",
      "loss in epoch 6 , step 18400 : 1.549948\n",
      "loss in epoch 6 , step 18420 : 0.325924\n",
      "loss in epoch 6 , step 18440 : 0.972073\n",
      "loss in epoch 6 , step 18460 : 1.863587\n",
      "loss in epoch 6 , step 18480 : 1.494404\n",
      "loss in epoch 6 , step 18500 : 0.385851\n",
      "loss in epoch 6 , step 18520 : 0.977738\n",
      "loss in epoch 6 , step 18540 : 1.911130\n",
      "loss in epoch 6 , step 18560 : 0.407691\n",
      "loss in epoch 6 , step 18580 : 1.877550\n",
      "loss in epoch 6 , step 18600 : 1.913813\n",
      "loss in epoch 6 , step 18620 : 1.475918\n",
      "loss in epoch 6 , step 18640 : 1.568441\n",
      "loss in epoch 6 , step 18660 : 1.110265\n",
      "loss in epoch 6 , step 18680 : 1.880611\n",
      "loss in epoch 6 , step 18700 : 2.508139\n",
      "loss in epoch 6 , step 18720 : 1.267201\n",
      "loss in epoch 6 , step 18740 : 0.248480\n",
      "loss in epoch 6 , step 18760 : 1.789973\n",
      "loss in epoch 6 , step 18780 : 1.342258\n",
      "loss in epoch 6 , step 18800 : 0.617776\n",
      "loss in epoch 6 , step 18820 : 0.945853\n",
      "loss in epoch 6 , step 18840 : 3.353398\n",
      "loss in epoch 6 , step 18860 : 1.564096\n",
      "loss in epoch 6 , step 18880 : 1.146303\n",
      "loss in epoch 6 , step 18900 : 0.997778\n",
      "loss in epoch 6 , step 18920 : 0.744167\n",
      "loss in epoch 6 , step 18940 : 1.733241\n",
      "loss in epoch 6 , step 18960 : 1.271408\n",
      "loss in epoch 6 , step 18980 : 0.042710\n",
      "loss in epoch 6 , step 19000 : 1.450745\n",
      "loss in epoch 6 , step 19020 : 1.609146\n",
      "loss in epoch 6 , step 19040 : 2.674025\n",
      "loss in epoch 6 , step 19060 : 1.708668\n",
      "loss in epoch 6 , step 19080 : 1.589055\n",
      "loss in epoch 6 , step 19100 : 1.825512\n",
      "loss in epoch 6 , step 19120 : 1.131195\n",
      "loss in epoch 6 , step 19140 : 0.064304\n",
      "loss in epoch 6 , step 19160 : 0.857896\n",
      "loss in epoch 6 , step 19180 : 0.289791\n",
      "loss in epoch 6 , step 19200 : 0.194904\n",
      "loss in epoch 6 , step 19220 : 0.787264\n",
      "loss in epoch 6 , step 19240 : 0.389564\n",
      "loss in epoch 6 , step 19260 : 1.631014\n",
      "loss in epoch 6 , step 19280 : 0.702242\n",
      "loss in epoch 6 , step 19300 : 1.212347\n",
      "loss in epoch 6 , step 19320 : 0.812312\n",
      "loss in epoch 6 , step 19340 : 0.584750\n",
      "loss in epoch 6 , step 19360 : 0.052413\n",
      "loss in epoch 6 , step 19380 : 0.281087\n",
      "loss in epoch 6 , step 19400 : 1.985643\n",
      "loss in epoch 6 , step 19420 : 0.277713\n",
      "loss in epoch 6 , step 19440 : 0.684687\n",
      "loss in epoch 6 , step 19460 : 0.631585\n",
      "loss in epoch 6 , step 19480 : 1.687279\n",
      "loss in epoch 6 , step 19500 : 2.293332\n",
      "loss in epoch 6 , step 19520 : 1.624629\n",
      "loss in epoch 6 , step 19540 : 0.664622\n",
      "loss in epoch 6 , step 19560 : 1.462436\n",
      "loss in epoch 6 , step 19580 : 0.252501\n",
      "loss in epoch 6 , step 19600 : 1.637713\n",
      "loss in epoch 6 , step 19620 : 0.273089\n",
      "loss in epoch 6 , step 19640 : 1.350277\n",
      "loss in epoch 6 , step 19660 : 1.385248\n",
      "loss in epoch 6 , step 19680 : 2.210592\n",
      "loss in epoch 6 , step 19700 : 2.158525\n",
      "loss in epoch 6 , step 19720 : 1.048825\n",
      "loss in epoch 6 , step 19740 : 0.764490\n",
      "loss in epoch 6 , step 19760 : 2.058460\n",
      "loss in epoch 6 , step 19780 : 1.932070\n",
      "loss in epoch 6 , step 19800 : 1.552247\n",
      "loss in epoch 6 , step 19820 : 0.361976\n",
      "loss in epoch 6 , step 19840 : 0.142688\n",
      "loss in epoch 6 , step 19860 : 0.633073\n",
      "loss in epoch 6 , step 19880 : 0.877068\n",
      "loss in epoch 6 , step 19900 : 0.162646\n",
      "loss in epoch 6 , step 19920 : 0.436318\n",
      "loss in epoch 6 , step 19940 : 1.695455\n",
      "Accuracy in epoch 6 : 27.478502\n",
      "loss in epoch 7 , step 0 : 1.919552\n",
      "loss in epoch 7 , step 20 : 1.387142\n",
      "loss in epoch 7 , step 40 : 0.221728\n",
      "loss in epoch 7 , step 60 : 1.105976\n",
      "loss in epoch 7 , step 80 : 1.108448\n",
      "loss in epoch 7 , step 100 : 0.139263\n",
      "loss in epoch 7 , step 120 : 1.594154\n",
      "loss in epoch 7 , step 140 : 1.818954\n",
      "loss in epoch 7 , step 160 : 1.999799\n",
      "loss in epoch 7 , step 180 : 0.434079\n",
      "loss in epoch 7 , step 200 : 1.859113\n",
      "loss in epoch 7 , step 220 : 0.802266\n",
      "loss in epoch 7 , step 240 : 0.135568\n",
      "loss in epoch 7 , step 260 : 0.553844\n",
      "loss in epoch 7 , step 280 : 0.147342\n",
      "loss in epoch 7 , step 300 : 1.311953\n",
      "loss in epoch 7 , step 320 : 0.166027\n",
      "loss in epoch 7 , step 340 : 0.690545\n",
      "loss in epoch 7 , step 360 : 2.115969\n",
      "loss in epoch 7 , step 380 : 0.904349\n",
      "loss in epoch 7 , step 400 : 1.018935\n",
      "loss in epoch 7 , step 420 : 2.013564\n",
      "loss in epoch 7 , step 440 : 1.891919\n",
      "loss in epoch 7 , step 460 : 1.401737\n",
      "loss in epoch 7 , step 480 : 0.015067\n",
      "loss in epoch 7 , step 500 : 2.034878\n",
      "loss in epoch 7 , step 520 : 0.842334\n",
      "loss in epoch 7 , step 540 : 0.600687\n",
      "loss in epoch 7 , step 560 : 1.294486\n",
      "loss in epoch 7 , step 580 : 0.873525\n",
      "loss in epoch 7 , step 600 : 0.514962\n",
      "loss in epoch 7 , step 620 : 0.698424\n",
      "loss in epoch 7 , step 640 : 0.015979\n",
      "loss in epoch 7 , step 660 : 1.547975\n",
      "loss in epoch 7 , step 680 : 1.939135\n",
      "loss in epoch 7 , step 700 : 1.328530\n",
      "loss in epoch 7 , step 720 : 0.738581\n",
      "loss in epoch 7 , step 740 : 1.734914\n",
      "loss in epoch 7 , step 760 : 0.964077\n",
      "loss in epoch 7 , step 780 : 0.399832\n",
      "loss in epoch 7 , step 800 : 2.247535\n",
      "loss in epoch 7 , step 820 : 1.557191\n",
      "loss in epoch 7 , step 840 : 1.248045\n",
      "loss in epoch 7 , step 860 : 0.186328\n",
      "loss in epoch 7 , step 880 : 0.977768\n",
      "loss in epoch 7 , step 900 : 1.262130\n",
      "loss in epoch 7 , step 920 : 0.654064\n",
      "loss in epoch 7 , step 940 : 2.043063\n",
      "loss in epoch 7 , step 960 : 1.482215\n",
      "loss in epoch 7 , step 980 : 0.069910\n",
      "loss in epoch 7 , step 1000 : 1.012143\n",
      "loss in epoch 7 , step 1020 : 2.968356\n",
      "loss in epoch 7 , step 1040 : 1.262727\n",
      "loss in epoch 7 , step 1060 : 0.994961\n",
      "loss in epoch 7 , step 1080 : 0.605216\n",
      "loss in epoch 7 , step 1100 : 2.231561\n",
      "loss in epoch 7 , step 1120 : 1.951168\n",
      "loss in epoch 7 , step 1140 : 0.996102\n",
      "loss in epoch 7 , step 1160 : 0.403221\n",
      "loss in epoch 7 , step 1180 : 1.366351\n",
      "loss in epoch 7 , step 1200 : 1.645696\n",
      "loss in epoch 7 , step 1220 : 2.525313\n",
      "loss in epoch 7 , step 1240 : 2.000300\n",
      "loss in epoch 7 , step 1260 : 2.400257\n",
      "loss in epoch 7 , step 1280 : 1.029388\n",
      "loss in epoch 7 , step 1300 : 0.394966\n",
      "loss in epoch 7 , step 1320 : 0.508359\n",
      "loss in epoch 7 , step 1340 : 0.048111\n",
      "loss in epoch 7 , step 1360 : 0.030329\n",
      "loss in epoch 7 , step 1380 : 1.488287\n",
      "loss in epoch 7 , step 1400 : 1.552580\n",
      "loss in epoch 7 , step 1420 : 1.082475\n",
      "loss in epoch 7 , step 1440 : 0.834679\n",
      "loss in epoch 7 , step 1460 : 0.796035\n",
      "loss in epoch 7 , step 1480 : 0.601645\n",
      "loss in epoch 7 , step 1500 : 1.910512\n",
      "loss in epoch 7 , step 1520 : 0.914782\n",
      "loss in epoch 7 , step 1540 : 0.732962\n",
      "loss in epoch 7 , step 1560 : 0.061655\n",
      "loss in epoch 7 , step 1580 : 0.952419\n",
      "loss in epoch 7 , step 1600 : 1.069185\n",
      "loss in epoch 7 , step 1620 : 0.183477\n",
      "loss in epoch 7 , step 1640 : 0.369033\n",
      "loss in epoch 7 , step 1660 : 1.806499\n",
      "loss in epoch 7 , step 1680 : 1.444188\n",
      "loss in epoch 7 , step 1700 : 1.525098\n",
      "loss in epoch 7 , step 1720 : 1.895657\n",
      "loss in epoch 7 , step 1740 : 0.343591\n",
      "loss in epoch 7 , step 1760 : 0.618407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 7 , step 1780 : 0.224334\n",
      "loss in epoch 7 , step 1800 : 1.525658\n",
      "loss in epoch 7 , step 1820 : 0.400938\n",
      "loss in epoch 7 , step 1840 : 2.065824\n",
      "loss in epoch 7 , step 1860 : 1.561400\n",
      "loss in epoch 7 , step 1880 : 1.246029\n",
      "loss in epoch 7 , step 1900 : 0.209278\n",
      "loss in epoch 7 , step 1920 : 0.875256\n",
      "loss in epoch 7 , step 1940 : 1.188839\n",
      "loss in epoch 7 , step 1960 : 1.464050\n",
      "loss in epoch 7 , step 1980 : 1.621192\n",
      "loss in epoch 7 , step 2000 : 0.728893\n",
      "loss in epoch 7 , step 2020 : 2.146754\n",
      "loss in epoch 7 , step 2040 : 1.265754\n",
      "loss in epoch 7 , step 2060 : 1.261016\n",
      "loss in epoch 7 , step 2080 : 0.689562\n",
      "loss in epoch 7 , step 2100 : 1.641477\n",
      "loss in epoch 7 , step 2120 : 1.662664\n",
      "loss in epoch 7 , step 2140 : 1.504502\n",
      "loss in epoch 7 , step 2160 : 1.790987\n",
      "loss in epoch 7 , step 2180 : 3.003444\n",
      "loss in epoch 7 , step 2200 : 2.264637\n",
      "loss in epoch 7 , step 2220 : 1.490509\n",
      "loss in epoch 7 , step 2240 : 2.847748\n",
      "loss in epoch 7 , step 2260 : 0.606897\n",
      "loss in epoch 7 , step 2280 : 2.021372\n",
      "loss in epoch 7 , step 2300 : 2.261105\n",
      "loss in epoch 7 , step 2320 : 0.245917\n",
      "loss in epoch 7 , step 2340 : 1.412621\n",
      "loss in epoch 7 , step 2360 : 0.247481\n",
      "loss in epoch 7 , step 2380 : 0.373299\n",
      "loss in epoch 7 , step 2400 : 0.224807\n",
      "loss in epoch 7 , step 2420 : 1.449739\n",
      "loss in epoch 7 , step 2440 : 2.267305\n",
      "loss in epoch 7 , step 2460 : 0.708494\n",
      "loss in epoch 7 , step 2480 : 2.506480\n",
      "loss in epoch 7 , step 2500 : 1.339355\n",
      "loss in epoch 7 , step 2520 : 0.803593\n",
      "loss in epoch 7 , step 2540 : 2.295829\n",
      "loss in epoch 7 , step 2560 : 1.947134\n",
      "loss in epoch 7 , step 2580 : 1.532713\n",
      "loss in epoch 7 , step 2600 : 1.436540\n",
      "loss in epoch 7 , step 2620 : 1.404845\n",
      "loss in epoch 7 , step 2640 : 1.505856\n",
      "loss in epoch 7 , step 2660 : 2.031354\n",
      "loss in epoch 7 , step 2680 : 2.115502\n",
      "loss in epoch 7 , step 2700 : 1.798579\n",
      "loss in epoch 7 , step 2720 : 1.491089\n",
      "loss in epoch 7 , step 2740 : 0.920131\n",
      "loss in epoch 7 , step 2760 : 2.491651\n",
      "loss in epoch 7 , step 2780 : 1.588006\n",
      "loss in epoch 7 , step 2800 : 2.285036\n",
      "loss in epoch 7 , step 2820 : 0.898863\n",
      "loss in epoch 7 , step 2840 : 1.876993\n",
      "loss in epoch 7 , step 2860 : 0.848614\n",
      "loss in epoch 7 , step 2880 : 1.878885\n",
      "loss in epoch 7 , step 2900 : 0.671085\n",
      "loss in epoch 7 , step 2920 : 1.514543\n",
      "loss in epoch 7 , step 2940 : 0.393264\n",
      "loss in epoch 7 , step 2960 : 1.533419\n",
      "loss in epoch 7 , step 2980 : 1.526908\n",
      "loss in epoch 7 , step 3000 : 1.459694\n",
      "loss in epoch 7 , step 3020 : 1.103108\n",
      "loss in epoch 7 , step 3040 : 0.842679\n",
      "loss in epoch 7 , step 3060 : 0.201317\n",
      "loss in epoch 7 , step 3080 : 1.834806\n",
      "loss in epoch 7 , step 3100 : 0.374801\n",
      "loss in epoch 7 , step 3120 : 0.070517\n",
      "loss in epoch 7 , step 3140 : 1.445832\n",
      "loss in epoch 7 , step 3160 : 1.358680\n",
      "loss in epoch 7 , step 3180 : 0.160535\n",
      "loss in epoch 7 , step 3200 : 1.735526\n",
      "loss in epoch 7 , step 3220 : 1.346318\n",
      "loss in epoch 7 , step 3240 : 0.161407\n",
      "loss in epoch 7 , step 3260 : 1.499191\n",
      "loss in epoch 7 , step 3280 : 1.373090\n",
      "loss in epoch 7 , step 3300 : 2.412076\n",
      "loss in epoch 7 , step 3320 : 0.988937\n",
      "loss in epoch 7 , step 3340 : 1.812490\n",
      "loss in epoch 7 , step 3360 : 0.896845\n",
      "loss in epoch 7 , step 3380 : 2.012601\n",
      "loss in epoch 7 , step 3400 : 1.042962\n",
      "loss in epoch 7 , step 3420 : 1.557634\n",
      "loss in epoch 7 , step 3440 : 1.786435\n",
      "loss in epoch 7 , step 3460 : 1.245139\n",
      "loss in epoch 7 , step 3480 : 3.188259\n",
      "loss in epoch 7 , step 3500 : 2.270877\n",
      "loss in epoch 7 , step 3520 : 0.538703\n",
      "loss in epoch 7 , step 3540 : 0.569344\n",
      "loss in epoch 7 , step 3560 : 0.132466\n",
      "loss in epoch 7 , step 3580 : 1.383617\n",
      "loss in epoch 7 , step 3600 : 1.731954\n",
      "loss in epoch 7 , step 3620 : 1.162829\n",
      "loss in epoch 7 , step 3640 : 1.413878\n",
      "loss in epoch 7 , step 3660 : 1.919933\n",
      "loss in epoch 7 , step 3680 : 0.750992\n",
      "loss in epoch 7 , step 3700 : 1.046529\n",
      "loss in epoch 7 , step 3720 : 1.022994\n",
      "loss in epoch 7 , step 3740 : 1.694560\n",
      "loss in epoch 7 , step 3760 : 2.543084\n",
      "loss in epoch 7 , step 3780 : 1.545414\n",
      "loss in epoch 7 , step 3800 : 0.325229\n",
      "loss in epoch 7 , step 3820 : 2.457572\n",
      "loss in epoch 7 , step 3840 : 0.059215\n",
      "loss in epoch 7 , step 3860 : 2.560000\n",
      "loss in epoch 7 , step 3880 : 0.206171\n",
      "loss in epoch 7 , step 3900 : 1.648472\n",
      "loss in epoch 7 , step 3920 : 1.852936\n",
      "loss in epoch 7 , step 3940 : 1.006582\n",
      "loss in epoch 7 , step 3960 : 0.084930\n",
      "loss in epoch 7 , step 3980 : 3.280630\n",
      "loss in epoch 7 , step 4000 : 2.563867\n",
      "loss in epoch 7 , step 4020 : 0.438923\n",
      "loss in epoch 7 , step 4040 : 0.803747\n",
      "loss in epoch 7 , step 4060 : 1.609674\n",
      "loss in epoch 7 , step 4080 : 0.083721\n",
      "loss in epoch 7 , step 4100 : 0.587562\n",
      "loss in epoch 7 , step 4120 : 0.314153\n",
      "loss in epoch 7 , step 4140 : 0.214129\n",
      "loss in epoch 7 , step 4160 : 0.956475\n",
      "loss in epoch 7 , step 4180 : 2.949209\n",
      "loss in epoch 7 , step 4200 : 1.281034\n",
      "loss in epoch 7 , step 4220 : 1.198104\n",
      "loss in epoch 7 , step 4240 : 1.421967\n",
      "loss in epoch 7 , step 4260 : 1.241760\n",
      "loss in epoch 7 , step 4280 : 1.684245\n",
      "loss in epoch 7 , step 4300 : 0.497468\n",
      "loss in epoch 7 , step 4320 : 0.511977\n",
      "loss in epoch 7 , step 4340 : 1.762445\n",
      "loss in epoch 7 , step 4360 : 0.774847\n",
      "loss in epoch 7 , step 4380 : 1.588630\n",
      "loss in epoch 7 , step 4400 : 0.138661\n",
      "loss in epoch 7 , step 4420 : 1.028965\n",
      "loss in epoch 7 , step 4440 : 2.153866\n",
      "loss in epoch 7 , step 4460 : 1.524627\n",
      "loss in epoch 7 , step 4480 : 1.629287\n",
      "loss in epoch 7 , step 4500 : 1.581872\n",
      "loss in epoch 7 , step 4520 : 0.469579\n",
      "loss in epoch 7 , step 4540 : 0.997962\n",
      "loss in epoch 7 , step 4560 : 1.924457\n",
      "loss in epoch 7 , step 4580 : 1.927943\n",
      "loss in epoch 7 , step 4600 : 1.391500\n",
      "loss in epoch 7 , step 4620 : 2.081573\n",
      "loss in epoch 7 , step 4640 : 0.786461\n",
      "loss in epoch 7 , step 4660 : 1.113870\n",
      "loss in epoch 7 , step 4680 : 0.063376\n",
      "loss in epoch 7 , step 4700 : 1.884060\n",
      "loss in epoch 7 , step 4720 : 1.663688\n",
      "loss in epoch 7 , step 4740 : 1.348318\n",
      "loss in epoch 7 , step 4760 : 1.948103\n",
      "loss in epoch 7 , step 4780 : 1.341366\n",
      "loss in epoch 7 , step 4800 : 2.100882\n",
      "loss in epoch 7 , step 4820 : 0.304804\n",
      "loss in epoch 7 , step 4840 : 0.198388\n",
      "loss in epoch 7 , step 4860 : 0.085867\n",
      "loss in epoch 7 , step 4880 : 1.024894\n",
      "loss in epoch 7 , step 4900 : 0.250898\n",
      "loss in epoch 7 , step 4920 : 0.859492\n",
      "loss in epoch 7 , step 4940 : 0.620011\n",
      "loss in epoch 7 , step 4960 : 1.723741\n",
      "loss in epoch 7 , step 4980 : 0.087616\n",
      "loss in epoch 7 , step 5000 : 0.482924\n",
      "loss in epoch 7 , step 5020 : 0.949016\n",
      "loss in epoch 7 , step 5040 : 1.994242\n",
      "loss in epoch 7 , step 5060 : 1.111318\n",
      "loss in epoch 7 , step 5080 : 0.075649\n",
      "loss in epoch 7 , step 5100 : 0.360051\n",
      "loss in epoch 7 , step 5120 : 2.188953\n",
      "loss in epoch 7 , step 5140 : 0.826187\n",
      "loss in epoch 7 , step 5160 : 0.965506\n",
      "loss in epoch 7 , step 5180 : 1.901186\n",
      "loss in epoch 7 , step 5200 : 2.544959\n",
      "loss in epoch 7 , step 5220 : 0.266335\n",
      "loss in epoch 7 , step 5240 : 0.114666\n",
      "loss in epoch 7 , step 5260 : 0.961597\n",
      "loss in epoch 7 , step 5280 : 0.600003\n",
      "loss in epoch 7 , step 5300 : 2.599282\n",
      "loss in epoch 7 , step 5320 : 0.349854\n",
      "loss in epoch 7 , step 5340 : 0.580115\n",
      "loss in epoch 7 , step 5360 : 1.327819\n",
      "loss in epoch 7 , step 5380 : 1.837698\n",
      "loss in epoch 7 , step 5400 : 1.057114\n",
      "loss in epoch 7 , step 5420 : 1.548303\n",
      "loss in epoch 7 , step 5440 : 2.150359\n",
      "loss in epoch 7 , step 5460 : 1.173431\n",
      "loss in epoch 7 , step 5480 : 0.455510\n",
      "loss in epoch 7 , step 5500 : 2.988315\n",
      "loss in epoch 7 , step 5520 : 0.542311\n",
      "loss in epoch 7 , step 5540 : 1.255667\n",
      "loss in epoch 7 , step 5560 : 1.909320\n",
      "loss in epoch 7 , step 5580 : 1.632639\n",
      "loss in epoch 7 , step 5600 : 0.352229\n",
      "loss in epoch 7 , step 5620 : 1.147637\n",
      "loss in epoch 7 , step 5640 : 0.693448\n",
      "loss in epoch 7 , step 5660 : 2.260464\n",
      "loss in epoch 7 , step 5680 : 1.950474\n",
      "loss in epoch 7 , step 5700 : 1.367791\n",
      "loss in epoch 7 , step 5720 : 0.546223\n",
      "loss in epoch 7 , step 5740 : 1.960713\n",
      "loss in epoch 7 , step 5760 : 1.641754\n",
      "loss in epoch 7 , step 5780 : 0.175395\n",
      "loss in epoch 7 , step 5800 : 0.123822\n",
      "loss in epoch 7 , step 5820 : 0.942730\n",
      "loss in epoch 7 , step 5840 : 1.834351\n",
      "loss in epoch 7 , step 5860 : 1.560487\n",
      "loss in epoch 7 , step 5880 : 1.544287\n",
      "loss in epoch 7 , step 5900 : 0.018285\n",
      "loss in epoch 7 , step 5920 : 0.987773\n",
      "loss in epoch 7 , step 5940 : 1.770969\n",
      "loss in epoch 7 , step 5960 : 0.349180\n",
      "loss in epoch 7 , step 5980 : 2.177894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 7 , step 6000 : 0.432230\n",
      "loss in epoch 7 , step 6020 : 1.955053\n",
      "loss in epoch 7 , step 6040 : 1.538342\n",
      "loss in epoch 7 , step 6060 : 1.347458\n",
      "loss in epoch 7 , step 6080 : 0.929251\n",
      "loss in epoch 7 , step 6100 : 0.194943\n",
      "loss in epoch 7 , step 6120 : 0.052643\n",
      "loss in epoch 7 , step 6140 : 2.116654\n",
      "loss in epoch 7 , step 6160 : 1.302840\n",
      "loss in epoch 7 , step 6180 : 1.555292\n",
      "loss in epoch 7 , step 6200 : 0.114482\n",
      "loss in epoch 7 , step 6220 : 1.419041\n",
      "loss in epoch 7 , step 6240 : 1.716464\n",
      "loss in epoch 7 , step 6260 : 0.195613\n",
      "loss in epoch 7 , step 6280 : 1.207121\n",
      "loss in epoch 7 , step 6300 : 1.527542\n",
      "loss in epoch 7 , step 6320 : 0.100125\n",
      "loss in epoch 7 , step 6340 : 1.574393\n",
      "loss in epoch 7 , step 6360 : 2.170567\n",
      "loss in epoch 7 , step 6380 : 0.520398\n",
      "loss in epoch 7 , step 6400 : 0.584952\n",
      "loss in epoch 7 , step 6420 : 2.445273\n",
      "loss in epoch 7 , step 6440 : 1.676131\n",
      "loss in epoch 7 , step 6460 : 2.160735\n",
      "loss in epoch 7 , step 6480 : 2.167742\n",
      "loss in epoch 7 , step 6500 : 1.189042\n",
      "loss in epoch 7 , step 6520 : 2.250184\n",
      "loss in epoch 7 , step 6540 : 1.376146\n",
      "loss in epoch 7 , step 6560 : 5.052067\n",
      "loss in epoch 7 , step 6580 : 0.138671\n",
      "loss in epoch 7 , step 6600 : 1.839350\n",
      "loss in epoch 7 , step 6620 : 0.993428\n",
      "loss in epoch 7 , step 6640 : 1.611054\n",
      "loss in epoch 7 , step 6660 : 1.579451\n",
      "loss in epoch 7 , step 6680 : 1.413366\n",
      "loss in epoch 7 , step 6700 : 0.146355\n",
      "loss in epoch 7 , step 6720 : 1.974696\n",
      "loss in epoch 7 , step 6740 : 0.110342\n",
      "loss in epoch 7 , step 6760 : 1.581156\n",
      "loss in epoch 7 , step 6780 : 1.865280\n",
      "loss in epoch 7 , step 6800 : 1.674465\n",
      "loss in epoch 7 , step 6820 : 2.177291\n",
      "loss in epoch 7 , step 6840 : 2.086466\n",
      "loss in epoch 7 , step 6860 : 1.669487\n",
      "loss in epoch 7 , step 6880 : 1.867976\n",
      "loss in epoch 7 , step 6900 : 1.024025\n",
      "loss in epoch 7 , step 6920 : 0.722654\n",
      "loss in epoch 7 , step 6940 : 1.311702\n",
      "loss in epoch 7 , step 6960 : 2.384393\n",
      "loss in epoch 7 , step 6980 : 1.273362\n",
      "loss in epoch 7 , step 7000 : 0.072811\n",
      "loss in epoch 7 , step 7020 : 0.749307\n",
      "loss in epoch 7 , step 7040 : 0.361447\n",
      "loss in epoch 7 , step 7060 : 2.294635\n",
      "loss in epoch 7 , step 7080 : 2.089116\n",
      "loss in epoch 7 , step 7100 : 0.081698\n",
      "loss in epoch 7 , step 7120 : 0.005811\n",
      "loss in epoch 7 , step 7140 : 1.176770\n",
      "loss in epoch 7 , step 7160 : 1.308072\n",
      "loss in epoch 7 , step 7180 : 1.475956\n",
      "loss in epoch 7 , step 7200 : 1.361846\n",
      "loss in epoch 7 , step 7220 : 2.436492\n",
      "loss in epoch 7 , step 7240 : 0.076477\n",
      "loss in epoch 7 , step 7260 : 1.036881\n",
      "loss in epoch 7 , step 7280 : 2.168675\n",
      "loss in epoch 7 , step 7300 : 1.607364\n",
      "loss in epoch 7 , step 7320 : 1.644325\n",
      "loss in epoch 7 , step 7340 : 0.054411\n",
      "loss in epoch 7 , step 7360 : 0.063612\n",
      "loss in epoch 7 , step 7380 : 1.222973\n",
      "loss in epoch 7 , step 7400 : 1.708316\n",
      "loss in epoch 7 , step 7420 : 1.524772\n",
      "loss in epoch 7 , step 7440 : 1.100494\n",
      "loss in epoch 7 , step 7460 : 1.444899\n",
      "loss in epoch 7 , step 7480 : 1.898475\n",
      "loss in epoch 7 , step 7500 : 1.177089\n",
      "loss in epoch 7 , step 7520 : 0.189151\n",
      "loss in epoch 7 , step 7540 : 2.287529\n",
      "loss in epoch 7 , step 7560 : 2.245453\n",
      "loss in epoch 7 , step 7580 : 1.130475\n",
      "loss in epoch 7 , step 7600 : 1.606751\n",
      "loss in epoch 7 , step 7620 : 1.118558\n",
      "loss in epoch 7 , step 7640 : 2.585057\n",
      "loss in epoch 7 , step 7660 : 1.612599\n",
      "loss in epoch 7 , step 7680 : 0.791490\n",
      "loss in epoch 7 , step 7700 : 0.117380\n",
      "loss in epoch 7 , step 7720 : 1.417044\n",
      "loss in epoch 7 , step 7740 : 1.629110\n",
      "loss in epoch 7 , step 7760 : 1.309087\n",
      "loss in epoch 7 , step 7780 : 0.027045\n",
      "loss in epoch 7 , step 7800 : 2.274196\n",
      "loss in epoch 7 , step 7820 : 1.666261\n",
      "loss in epoch 7 , step 7840 : 1.803294\n",
      "loss in epoch 7 , step 7860 : 0.329536\n",
      "loss in epoch 7 , step 7880 : 2.169598\n",
      "loss in epoch 7 , step 7900 : 1.787040\n",
      "loss in epoch 7 , step 7920 : 4.171380\n",
      "loss in epoch 7 , step 7940 : 2.486441\n",
      "loss in epoch 7 , step 7960 : 0.072082\n",
      "loss in epoch 7 , step 7980 : 1.252036\n",
      "loss in epoch 7 , step 8000 : 0.014886\n",
      "loss in epoch 7 , step 8020 : 0.462837\n",
      "loss in epoch 7 , step 8040 : 1.647074\n",
      "loss in epoch 7 , step 8060 : 1.674631\n",
      "loss in epoch 7 , step 8080 : 1.303857\n",
      "loss in epoch 7 , step 8100 : 0.014983\n",
      "loss in epoch 7 , step 8120 : 1.788255\n",
      "loss in epoch 7 , step 8140 : 1.127379\n",
      "loss in epoch 7 , step 8160 : 0.305402\n",
      "loss in epoch 7 , step 8180 : 0.184496\n",
      "loss in epoch 7 , step 8200 : 1.686989\n",
      "loss in epoch 7 , step 8220 : 1.468955\n",
      "loss in epoch 7 , step 8240 : 0.121231\n",
      "loss in epoch 7 , step 8260 : 0.950808\n",
      "loss in epoch 7 , step 8280 : 2.350392\n",
      "loss in epoch 7 , step 8300 : 3.598284\n",
      "loss in epoch 7 , step 8320 : 0.016683\n",
      "loss in epoch 7 , step 8340 : 0.186106\n",
      "loss in epoch 7 , step 8360 : 0.064758\n",
      "loss in epoch 7 , step 8380 : 1.467600\n",
      "loss in epoch 7 , step 8400 : 1.736173\n",
      "loss in epoch 7 , step 8420 : 0.583721\n",
      "loss in epoch 7 , step 8440 : 1.757533\n",
      "loss in epoch 7 , step 8460 : 1.515723\n",
      "loss in epoch 7 , step 8480 : 0.082827\n",
      "loss in epoch 7 , step 8500 : 1.600464\n",
      "loss in epoch 7 , step 8520 : 2.218517\n",
      "loss in epoch 7 , step 8540 : 1.884630\n",
      "loss in epoch 7 , step 8560 : 1.558999\n",
      "loss in epoch 7 , step 8580 : 0.091729\n",
      "loss in epoch 7 , step 8600 : 1.339828\n",
      "loss in epoch 7 , step 8620 : 0.488599\n",
      "loss in epoch 7 , step 8640 : 0.540248\n",
      "loss in epoch 7 , step 8660 : 1.122768\n",
      "loss in epoch 7 , step 8680 : 1.303179\n",
      "loss in epoch 7 , step 8700 : 1.383673\n",
      "loss in epoch 7 , step 8720 : 1.537144\n",
      "loss in epoch 7 , step 8740 : 0.023830\n",
      "loss in epoch 7 , step 8760 : 1.486798\n",
      "loss in epoch 7 , step 8780 : 0.679853\n",
      "loss in epoch 7 , step 8800 : 1.230908\n",
      "loss in epoch 7 , step 8820 : 2.035003\n",
      "loss in epoch 7 , step 8840 : 1.767746\n",
      "loss in epoch 7 , step 8860 : 1.570769\n",
      "loss in epoch 7 , step 8880 : 2.282496\n",
      "loss in epoch 7 , step 8900 : 1.388692\n",
      "loss in epoch 7 , step 8920 : 1.044899\n",
      "loss in epoch 7 , step 8940 : 1.153088\n",
      "loss in epoch 7 , step 8960 : 1.845133\n",
      "loss in epoch 7 , step 8980 : 2.218622\n",
      "loss in epoch 7 , step 9000 : 1.220883\n",
      "loss in epoch 7 , step 9020 : 1.223216\n",
      "loss in epoch 7 , step 9040 : 1.148981\n",
      "loss in epoch 7 , step 9060 : 1.585035\n",
      "loss in epoch 7 , step 9080 : 2.607620\n",
      "loss in epoch 7 , step 9100 : 0.626782\n",
      "loss in epoch 7 , step 9120 : 0.823033\n",
      "loss in epoch 7 , step 9140 : 1.297261\n",
      "loss in epoch 7 , step 9160 : 0.136988\n",
      "loss in epoch 7 , step 9180 : 0.516066\n",
      "loss in epoch 7 , step 9200 : 2.389914\n",
      "loss in epoch 7 , step 9220 : 1.178208\n",
      "loss in epoch 7 , step 9240 : 4.854646\n",
      "loss in epoch 7 , step 9260 : 1.489591\n",
      "loss in epoch 7 , step 9280 : 1.762232\n",
      "loss in epoch 7 , step 9300 : 2.292951\n",
      "loss in epoch 7 , step 9320 : 1.492323\n",
      "loss in epoch 7 , step 9340 : 0.493130\n",
      "loss in epoch 7 , step 9360 : 1.470600\n",
      "loss in epoch 7 , step 9380 : 1.981863\n",
      "loss in epoch 7 , step 9400 : 1.765415\n",
      "loss in epoch 7 , step 9420 : 1.070985\n",
      "loss in epoch 7 , step 9440 : 1.226027\n",
      "loss in epoch 7 , step 9460 : 1.271450\n",
      "loss in epoch 7 , step 9480 : 2.220150\n",
      "loss in epoch 7 , step 9500 : 2.200581\n",
      "loss in epoch 7 , step 9520 : 2.978420\n",
      "loss in epoch 7 , step 9540 : 1.357134\n",
      "loss in epoch 7 , step 9560 : 1.870678\n",
      "loss in epoch 7 , step 9580 : 0.020204\n",
      "loss in epoch 7 , step 9600 : 0.271637\n",
      "loss in epoch 7 , step 9620 : 1.409387\n",
      "loss in epoch 7 , step 9640 : 1.203133\n",
      "loss in epoch 7 , step 9660 : 1.132334\n",
      "loss in epoch 7 , step 9680 : 1.735268\n",
      "loss in epoch 7 , step 9700 : 1.158802\n",
      "loss in epoch 7 , step 9720 : 1.692855\n",
      "loss in epoch 7 , step 9740 : 1.356178\n",
      "loss in epoch 7 , step 9760 : 0.421687\n",
      "loss in epoch 7 , step 9780 : 1.102099\n",
      "loss in epoch 7 , step 9800 : 1.736825\n",
      "loss in epoch 7 , step 9820 : 0.401814\n",
      "loss in epoch 7 , step 9840 : 1.261618\n",
      "loss in epoch 7 , step 9860 : 0.627973\n",
      "loss in epoch 7 , step 9880 : 0.895865\n",
      "loss in epoch 7 , step 9900 : 1.707774\n",
      "loss in epoch 7 , step 9920 : 2.055970\n",
      "loss in epoch 7 , step 9940 : 2.054388\n",
      "loss in epoch 7 , step 9960 : 0.923407\n",
      "loss in epoch 7 , step 9980 : 1.006566\n",
      "loss in epoch 7 , step 10000 : 1.345821\n",
      "loss in epoch 7 , step 10020 : 1.174926\n",
      "loss in epoch 7 , step 10040 : 1.365013\n",
      "loss in epoch 7 , step 10060 : 1.746868\n",
      "loss in epoch 7 , step 10080 : 1.582565\n",
      "loss in epoch 7 , step 10100 : 2.798996\n",
      "loss in epoch 7 , step 10120 : 1.138644\n",
      "loss in epoch 7 , step 10140 : 0.206236\n",
      "loss in epoch 7 , step 10160 : 0.277309\n",
      "loss in epoch 7 , step 10180 : 1.873815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 7 , step 10200 : 0.077707\n",
      "loss in epoch 7 , step 10220 : 1.334447\n",
      "loss in epoch 7 , step 10240 : 2.145412\n",
      "loss in epoch 7 , step 10260 : 2.219893\n",
      "loss in epoch 7 , step 10280 : 1.216960\n",
      "loss in epoch 7 , step 10300 : 1.747093\n",
      "loss in epoch 7 , step 10320 : 0.182963\n",
      "loss in epoch 7 , step 10340 : 0.039999\n",
      "loss in epoch 7 , step 10360 : 2.311887\n",
      "loss in epoch 7 , step 10380 : 0.217973\n",
      "loss in epoch 7 , step 10400 : 0.030976\n",
      "loss in epoch 7 , step 10420 : 0.064435\n",
      "loss in epoch 7 , step 10440 : 1.743571\n",
      "loss in epoch 7 , step 10460 : 1.489795\n",
      "loss in epoch 7 , step 10480 : 0.860017\n",
      "loss in epoch 7 , step 10500 : 1.667630\n",
      "loss in epoch 7 , step 10520 : 1.393558\n",
      "loss in epoch 7 , step 10540 : 2.782871\n",
      "loss in epoch 7 , step 10560 : 0.438503\n",
      "loss in epoch 7 , step 10580 : 1.706810\n",
      "loss in epoch 7 , step 10600 : 0.036085\n",
      "loss in epoch 7 , step 10620 : 0.182501\n",
      "loss in epoch 7 , step 10640 : 1.755809\n",
      "loss in epoch 7 , step 10660 : 0.007609\n",
      "loss in epoch 7 , step 10680 : 2.465663\n",
      "loss in epoch 7 , step 10700 : 1.115498\n",
      "loss in epoch 7 , step 10720 : 1.247177\n",
      "loss in epoch 7 , step 10740 : 1.081092\n",
      "loss in epoch 7 , step 10760 : 1.599242\n",
      "loss in epoch 7 , step 10780 : 1.143334\n",
      "loss in epoch 7 , step 10800 : 1.964525\n",
      "loss in epoch 7 , step 10820 : 1.636983\n",
      "loss in epoch 7 , step 10840 : 1.387797\n",
      "loss in epoch 7 , step 10860 : 2.112916\n",
      "loss in epoch 7 , step 10880 : 0.406088\n",
      "loss in epoch 7 , step 10900 : 0.172413\n",
      "loss in epoch 7 , step 10920 : 0.082011\n",
      "loss in epoch 7 , step 10940 : 0.722569\n",
      "loss in epoch 7 , step 10960 : 2.127292\n",
      "loss in epoch 7 , step 10980 : 0.562214\n",
      "loss in epoch 7 , step 11000 : 2.136233\n",
      "loss in epoch 7 , step 11020 : 0.255626\n",
      "loss in epoch 7 , step 11040 : 1.702566\n",
      "loss in epoch 7 , step 11060 : 0.416274\n",
      "loss in epoch 7 , step 11080 : 0.598477\n",
      "loss in epoch 7 , step 11100 : 0.675986\n",
      "loss in epoch 7 , step 11120 : 2.345117\n",
      "loss in epoch 7 , step 11140 : 2.002931\n",
      "loss in epoch 7 , step 11160 : 4.005456\n",
      "loss in epoch 7 , step 11180 : 1.727579\n",
      "loss in epoch 7 , step 11200 : 1.237749\n",
      "loss in epoch 7 , step 11220 : 0.301710\n",
      "loss in epoch 7 , step 11240 : 0.731028\n",
      "loss in epoch 7 , step 11260 : 1.331183\n",
      "loss in epoch 7 , step 11280 : 2.696761\n",
      "loss in epoch 7 , step 11300 : 2.017350\n",
      "loss in epoch 7 , step 11320 : 1.356523\n",
      "loss in epoch 7 , step 11340 : 0.821866\n",
      "loss in epoch 7 , step 11360 : 0.675621\n",
      "loss in epoch 7 , step 11380 : 1.448027\n",
      "loss in epoch 7 , step 11400 : 0.793575\n",
      "loss in epoch 7 , step 11420 : 0.267346\n",
      "loss in epoch 7 , step 11440 : 1.911564\n",
      "loss in epoch 7 , step 11460 : 0.124136\n",
      "loss in epoch 7 , step 11480 : 2.314243\n",
      "loss in epoch 7 , step 11500 : 1.863384\n",
      "loss in epoch 7 , step 11520 : 0.346698\n",
      "loss in epoch 7 , step 11540 : 1.598049\n",
      "loss in epoch 7 , step 11560 : 1.863575\n",
      "loss in epoch 7 , step 11580 : 0.795368\n",
      "loss in epoch 7 , step 11600 : 0.921405\n",
      "loss in epoch 7 , step 11620 : 1.982823\n",
      "loss in epoch 7 , step 11640 : 0.928361\n",
      "loss in epoch 7 , step 11660 : 1.464223\n",
      "loss in epoch 7 , step 11680 : 1.621650\n",
      "loss in epoch 7 , step 11700 : 0.296554\n",
      "loss in epoch 7 , step 11720 : 1.836311\n",
      "loss in epoch 7 , step 11740 : 2.450073\n",
      "loss in epoch 7 , step 11760 : 0.675021\n",
      "loss in epoch 7 , step 11780 : 1.097548\n",
      "loss in epoch 7 , step 11800 : 1.709998\n",
      "loss in epoch 7 , step 11820 : 2.435471\n",
      "loss in epoch 7 , step 11840 : 0.172969\n",
      "loss in epoch 7 , step 11860 : 1.346933\n",
      "loss in epoch 7 , step 11880 : 0.067021\n",
      "loss in epoch 7 , step 11900 : 1.476150\n",
      "loss in epoch 7 , step 11920 : 1.305694\n",
      "loss in epoch 7 , step 11940 : 1.347992\n",
      "loss in epoch 7 , step 11960 : 1.379410\n",
      "loss in epoch 7 , step 11980 : 0.065148\n",
      "loss in epoch 7 , step 12000 : 1.041801\n",
      "loss in epoch 7 , step 12020 : 1.825338\n",
      "loss in epoch 7 , step 12040 : 1.193202\n",
      "loss in epoch 7 , step 12060 : 1.634002\n",
      "loss in epoch 7 , step 12080 : 0.370429\n",
      "loss in epoch 7 , step 12100 : 0.313368\n",
      "loss in epoch 7 , step 12120 : 0.064882\n",
      "loss in epoch 7 , step 12140 : 0.252119\n",
      "loss in epoch 7 , step 12160 : 0.021077\n",
      "loss in epoch 7 , step 12180 : 1.924031\n",
      "loss in epoch 7 , step 12200 : 2.048097\n",
      "loss in epoch 7 , step 12220 : 0.150447\n",
      "loss in epoch 7 , step 12240 : 1.007408\n",
      "loss in epoch 7 , step 12260 : 0.603281\n",
      "loss in epoch 7 , step 12280 : 1.572831\n",
      "loss in epoch 7 , step 12300 : 0.090843\n",
      "loss in epoch 7 , step 12320 : 2.079613\n",
      "loss in epoch 7 , step 12340 : 0.735939\n",
      "loss in epoch 7 , step 12360 : 2.246683\n",
      "loss in epoch 7 , step 12380 : 0.701859\n",
      "loss in epoch 7 , step 12400 : 1.562382\n",
      "loss in epoch 7 , step 12420 : 2.910525\n",
      "loss in epoch 7 , step 12440 : 0.233497\n",
      "loss in epoch 7 , step 12460 : 1.282528\n",
      "loss in epoch 7 , step 12480 : 0.651797\n",
      "loss in epoch 7 , step 12500 : 2.099008\n",
      "loss in epoch 7 , step 12520 : 0.275931\n",
      "loss in epoch 7 , step 12540 : 0.015860\n",
      "loss in epoch 7 , step 12560 : 1.426324\n",
      "loss in epoch 7 , step 12580 : 2.149249\n",
      "loss in epoch 7 , step 12600 : 1.119425\n",
      "loss in epoch 7 , step 12620 : 0.634291\n",
      "loss in epoch 7 , step 12640 : 2.715803\n",
      "loss in epoch 7 , step 12660 : 2.095081\n",
      "loss in epoch 7 , step 12680 : 1.610628\n",
      "loss in epoch 7 , step 12700 : 0.097936\n",
      "loss in epoch 7 , step 12720 : 1.547458\n",
      "loss in epoch 7 , step 12740 : 2.303643\n",
      "loss in epoch 7 , step 12760 : 1.423468\n",
      "loss in epoch 7 , step 12780 : 0.945227\n",
      "loss in epoch 7 , step 12800 : 1.159752\n",
      "loss in epoch 7 , step 12820 : 1.772716\n",
      "loss in epoch 7 , step 12840 : 0.023110\n",
      "loss in epoch 7 , step 12860 : 1.625126\n",
      "loss in epoch 7 , step 12880 : 1.463870\n",
      "loss in epoch 7 , step 12900 : 1.844189\n",
      "loss in epoch 7 , step 12920 : 1.563344\n",
      "loss in epoch 7 , step 12940 : 1.223903\n",
      "loss in epoch 7 , step 12960 : 1.929393\n",
      "loss in epoch 7 , step 12980 : 1.114490\n",
      "loss in epoch 7 , step 13000 : 1.050934\n",
      "loss in epoch 7 , step 13020 : 0.152933\n",
      "loss in epoch 7 , step 13040 : 1.093545\n",
      "loss in epoch 7 , step 13060 : 3.405350\n",
      "loss in epoch 7 , step 13080 : 1.052747\n",
      "loss in epoch 7 , step 13100 : 1.545747\n",
      "loss in epoch 7 , step 13120 : 1.168661\n",
      "loss in epoch 7 , step 13140 : 0.269531\n",
      "loss in epoch 7 , step 13160 : 1.868462\n",
      "loss in epoch 7 , step 13180 : 0.899927\n",
      "loss in epoch 7 , step 13200 : 1.333840\n",
      "loss in epoch 7 , step 13220 : 1.533469\n",
      "loss in epoch 7 , step 13240 : 1.368666\n",
      "loss in epoch 7 , step 13260 : 0.289691\n",
      "loss in epoch 7 , step 13280 : 1.770511\n",
      "loss in epoch 7 , step 13300 : 0.879681\n",
      "loss in epoch 7 , step 13320 : 1.742561\n",
      "loss in epoch 7 , step 13340 : 1.001548\n",
      "loss in epoch 7 , step 13360 : 1.102678\n",
      "loss in epoch 7 , step 13380 : 0.387474\n",
      "loss in epoch 7 , step 13400 : 1.840987\n",
      "loss in epoch 7 , step 13420 : 0.908716\n",
      "loss in epoch 7 , step 13440 : 0.029590\n",
      "loss in epoch 7 , step 13460 : 0.604149\n",
      "loss in epoch 7 , step 13480 : 1.590763\n",
      "loss in epoch 7 , step 13500 : 1.749392\n",
      "loss in epoch 7 , step 13520 : 2.509059\n",
      "loss in epoch 7 , step 13540 : 1.968889\n",
      "loss in epoch 7 , step 13560 : 1.152275\n",
      "loss in epoch 7 , step 13580 : 0.746773\n",
      "loss in epoch 7 , step 13600 : 1.712499\n",
      "loss in epoch 7 , step 13620 : 0.863735\n",
      "loss in epoch 7 , step 13640 : 1.456722\n",
      "loss in epoch 7 , step 13660 : 1.973208\n",
      "loss in epoch 7 , step 13680 : 1.020616\n",
      "loss in epoch 7 , step 13700 : 0.622368\n",
      "loss in epoch 7 , step 13720 : 1.624096\n",
      "loss in epoch 7 , step 13740 : 1.668122\n",
      "loss in epoch 7 , step 13760 : 1.723724\n",
      "loss in epoch 7 , step 13780 : 0.092043\n",
      "loss in epoch 7 , step 13800 : 0.839143\n",
      "loss in epoch 7 , step 13820 : 1.741954\n",
      "loss in epoch 7 , step 13840 : 0.912361\n",
      "loss in epoch 7 , step 13860 : 0.714269\n",
      "loss in epoch 7 , step 13880 : 0.497329\n",
      "loss in epoch 7 , step 13900 : 0.537641\n",
      "loss in epoch 7 , step 13920 : 1.881510\n",
      "loss in epoch 7 , step 13940 : 0.819594\n",
      "loss in epoch 7 , step 13960 : 1.177635\n",
      "loss in epoch 7 , step 13980 : 1.971174\n",
      "loss in epoch 7 , step 14000 : 0.613477\n",
      "loss in epoch 7 , step 14020 : 1.558750\n",
      "loss in epoch 7 , step 14040 : 0.157920\n",
      "loss in epoch 7 , step 14060 : 0.111079\n",
      "loss in epoch 7 , step 14080 : 1.344609\n",
      "loss in epoch 7 , step 14100 : 1.260799\n",
      "loss in epoch 7 , step 14120 : 0.483940\n",
      "loss in epoch 7 , step 14140 : 2.806632\n",
      "loss in epoch 7 , step 14160 : 0.381153\n",
      "loss in epoch 7 , step 14180 : 0.921759\n",
      "loss in epoch 7 , step 14200 : 0.652566\n",
      "loss in epoch 7 , step 14220 : 1.530959\n",
      "loss in epoch 7 , step 14240 : 1.324414\n",
      "loss in epoch 7 , step 14260 : 2.106441\n",
      "loss in epoch 7 , step 14280 : 1.256238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 7 , step 14300 : 1.521087\n",
      "loss in epoch 7 , step 14320 : 1.260141\n",
      "loss in epoch 7 , step 14340 : 2.080835\n",
      "loss in epoch 7 , step 14360 : 1.110398\n",
      "loss in epoch 7 , step 14380 : 0.248195\n",
      "loss in epoch 7 , step 14400 : 0.355874\n",
      "loss in epoch 7 , step 14420 : 1.774482\n",
      "loss in epoch 7 , step 14440 : 1.861282\n",
      "loss in epoch 7 , step 14460 : 0.278108\n",
      "loss in epoch 7 , step 14480 : 1.629813\n",
      "loss in epoch 7 , step 14500 : 0.545466\n",
      "loss in epoch 7 , step 14520 : 1.406964\n",
      "loss in epoch 7 , step 14540 : 0.014486\n",
      "loss in epoch 7 , step 14560 : 4.340895\n",
      "loss in epoch 7 , step 14580 : 1.437315\n",
      "loss in epoch 7 , step 14600 : 1.181941\n",
      "loss in epoch 7 , step 14620 : 0.900331\n",
      "loss in epoch 7 , step 14640 : 1.429597\n",
      "loss in epoch 7 , step 14660 : 1.176535\n",
      "loss in epoch 7 , step 14680 : 1.386366\n",
      "loss in epoch 7 , step 14700 : 1.810862\n",
      "loss in epoch 7 , step 14720 : 1.986653\n",
      "loss in epoch 7 , step 14740 : 1.201764\n",
      "loss in epoch 7 , step 14760 : 2.770040\n",
      "loss in epoch 7 , step 14780 : 1.411741\n",
      "loss in epoch 7 , step 14800 : 1.670288\n",
      "loss in epoch 7 , step 14820 : 0.019786\n",
      "loss in epoch 7 , step 14840 : 1.898848\n",
      "loss in epoch 7 , step 14860 : 0.193907\n",
      "loss in epoch 7 , step 14880 : 1.848289\n",
      "loss in epoch 7 , step 14900 : 1.353876\n",
      "loss in epoch 7 , step 14920 : 1.602922\n",
      "loss in epoch 7 , step 14940 : 1.488937\n",
      "loss in epoch 7 , step 14960 : 1.121424\n",
      "loss in epoch 7 , step 14980 : 1.148386\n",
      "loss in epoch 7 , step 15000 : 0.747474\n",
      "loss in epoch 7 , step 15020 : 0.144764\n",
      "loss in epoch 7 , step 15040 : 1.093873\n",
      "loss in epoch 7 , step 15060 : 0.086650\n",
      "loss in epoch 7 , step 15080 : 0.860308\n",
      "loss in epoch 7 , step 15100 : 4.371124\n",
      "loss in epoch 7 , step 15120 : 0.108378\n",
      "loss in epoch 7 , step 15140 : 0.075015\n",
      "loss in epoch 7 , step 15160 : 1.170616\n",
      "loss in epoch 7 , step 15180 : 3.036138\n",
      "loss in epoch 7 , step 15200 : 1.003389\n",
      "loss in epoch 7 , step 15220 : 0.996638\n",
      "loss in epoch 7 , step 15240 : 0.937757\n",
      "loss in epoch 7 , step 15260 : 0.932719\n",
      "loss in epoch 7 , step 15280 : 0.398860\n",
      "loss in epoch 7 , step 15300 : 0.094201\n",
      "loss in epoch 7 , step 15320 : 2.492348\n",
      "loss in epoch 7 , step 15340 : 1.273038\n",
      "loss in epoch 7 , step 15360 : 2.266422\n",
      "loss in epoch 7 , step 15380 : 1.352841\n",
      "loss in epoch 7 , step 15400 : 0.070932\n",
      "loss in epoch 7 , step 15420 : 1.449520\n",
      "loss in epoch 7 , step 15440 : 1.689338\n",
      "loss in epoch 7 , step 15460 : 1.847178\n",
      "loss in epoch 7 , step 15480 : 3.819300\n",
      "loss in epoch 7 , step 15500 : 2.626084\n",
      "loss in epoch 7 , step 15520 : 1.173563\n",
      "loss in epoch 7 , step 15540 : 1.921024\n",
      "loss in epoch 7 , step 15560 : 2.007513\n",
      "loss in epoch 7 , step 15580 : 0.857596\n",
      "loss in epoch 7 , step 15600 : 1.661890\n",
      "loss in epoch 7 , step 15620 : 1.298764\n",
      "loss in epoch 7 , step 15640 : 1.532984\n",
      "loss in epoch 7 , step 15660 : 1.292652\n",
      "loss in epoch 7 , step 15680 : 0.556127\n",
      "loss in epoch 7 , step 15700 : 1.290432\n",
      "loss in epoch 7 , step 15720 : 1.165769\n",
      "loss in epoch 7 , step 15740 : 0.168466\n",
      "loss in epoch 7 , step 15760 : 1.374286\n",
      "loss in epoch 7 , step 15780 : 1.159675\n",
      "loss in epoch 7 , step 15800 : 0.219832\n",
      "loss in epoch 7 , step 15820 : 1.594192\n",
      "loss in epoch 7 , step 15840 : 2.005747\n",
      "loss in epoch 7 , step 15860 : 1.826577\n",
      "loss in epoch 7 , step 15880 : 1.803235\n",
      "loss in epoch 7 , step 15900 : 1.670791\n",
      "loss in epoch 7 , step 15920 : 1.745861\n",
      "loss in epoch 7 , step 15940 : 0.417426\n",
      "loss in epoch 7 , step 15960 : 0.555971\n",
      "loss in epoch 7 , step 15980 : 1.505724\n",
      "loss in epoch 7 , step 16000 : 1.218340\n",
      "loss in epoch 7 , step 16020 : 0.628005\n",
      "loss in epoch 7 , step 16040 : 0.176532\n",
      "loss in epoch 7 , step 16060 : 0.387470\n",
      "loss in epoch 7 , step 16080 : 0.259305\n",
      "loss in epoch 7 , step 16100 : 1.489124\n",
      "loss in epoch 7 , step 16120 : 1.273971\n",
      "loss in epoch 7 , step 16140 : 0.267099\n",
      "loss in epoch 7 , step 16160 : 1.380839\n",
      "loss in epoch 7 , step 16180 : 0.140482\n",
      "loss in epoch 7 , step 16200 : 1.916186\n",
      "loss in epoch 7 , step 16220 : 1.511472\n",
      "loss in epoch 7 , step 16240 : 1.595455\n",
      "loss in epoch 7 , step 16260 : 0.795395\n",
      "loss in epoch 7 , step 16280 : 1.156256\n",
      "loss in epoch 7 , step 16300 : 2.127879\n",
      "loss in epoch 7 , step 16320 : 1.258854\n",
      "loss in epoch 7 , step 16340 : 0.121317\n",
      "loss in epoch 7 , step 16360 : 1.549678\n",
      "loss in epoch 7 , step 16380 : 0.545552\n",
      "loss in epoch 7 , step 16400 : 2.370461\n",
      "loss in epoch 7 , step 16420 : 1.567527\n",
      "loss in epoch 7 , step 16440 : 1.055339\n",
      "loss in epoch 7 , step 16460 : 0.952826\n",
      "loss in epoch 7 , step 16480 : 1.332071\n",
      "loss in epoch 7 , step 16500 : 0.902383\n",
      "loss in epoch 7 , step 16520 : 0.063996\n",
      "loss in epoch 7 , step 16540 : 1.520937\n",
      "loss in epoch 7 , step 16560 : 1.166079\n",
      "loss in epoch 7 , step 16580 : 1.322126\n",
      "loss in epoch 7 , step 16600 : 1.918888\n",
      "loss in epoch 7 , step 16620 : 1.625739\n",
      "loss in epoch 7 , step 16640 : 1.204635\n",
      "loss in epoch 7 , step 16660 : 1.115376\n",
      "loss in epoch 7 , step 16680 : 3.566464\n",
      "loss in epoch 7 , step 16700 : 1.367680\n",
      "loss in epoch 7 , step 16720 : 0.357340\n",
      "loss in epoch 7 , step 16740 : 2.033384\n",
      "loss in epoch 7 , step 16760 : 0.678343\n",
      "loss in epoch 7 , step 16780 : 1.318146\n",
      "loss in epoch 7 , step 16800 : 1.816953\n",
      "loss in epoch 7 , step 16820 : 0.270097\n",
      "loss in epoch 7 , step 16840 : 1.985843\n",
      "loss in epoch 7 , step 16860 : 0.857967\n",
      "loss in epoch 7 , step 16880 : 0.363490\n",
      "loss in epoch 7 , step 16900 : 0.753527\n",
      "loss in epoch 7 , step 16920 : 0.256120\n",
      "loss in epoch 7 , step 16940 : 1.573347\n",
      "loss in epoch 7 , step 16960 : 0.267175\n",
      "loss in epoch 7 , step 16980 : 0.441654\n",
      "loss in epoch 7 , step 17000 : 1.666492\n",
      "loss in epoch 7 , step 17020 : 1.482101\n",
      "loss in epoch 7 , step 17040 : 0.014712\n",
      "loss in epoch 7 , step 17060 : 1.920576\n",
      "loss in epoch 7 , step 17080 : 0.821281\n",
      "loss in epoch 7 , step 17100 : 1.548780\n",
      "loss in epoch 7 , step 17120 : 1.969451\n",
      "loss in epoch 7 , step 17140 : 1.331015\n",
      "loss in epoch 7 , step 17160 : 0.591663\n",
      "loss in epoch 7 , step 17180 : 0.533623\n",
      "loss in epoch 7 , step 17200 : 1.125641\n",
      "loss in epoch 7 , step 17220 : 1.215789\n",
      "loss in epoch 7 , step 17240 : 1.263490\n",
      "loss in epoch 7 , step 17260 : 0.503492\n",
      "loss in epoch 7 , step 17280 : 0.973084\n",
      "loss in epoch 7 , step 17300 : 1.565889\n",
      "loss in epoch 7 , step 17320 : 0.660202\n",
      "loss in epoch 7 , step 17340 : 1.636611\n",
      "loss in epoch 7 , step 17360 : 1.146289\n",
      "loss in epoch 7 , step 17380 : 0.072815\n",
      "loss in epoch 7 , step 17400 : 0.719319\n",
      "loss in epoch 7 , step 17420 : 1.215632\n",
      "loss in epoch 7 , step 17440 : 2.067406\n",
      "loss in epoch 7 , step 17460 : 1.471573\n",
      "loss in epoch 7 , step 17480 : 2.024742\n",
      "loss in epoch 7 , step 17500 : 1.664138\n",
      "loss in epoch 7 , step 17520 : 2.243143\n",
      "loss in epoch 7 , step 17540 : 1.130064\n",
      "loss in epoch 7 , step 17560 : 1.853985\n",
      "loss in epoch 7 , step 17580 : 0.240376\n",
      "loss in epoch 7 , step 17600 : 0.016010\n",
      "loss in epoch 7 , step 17620 : 0.747424\n",
      "loss in epoch 7 , step 17640 : 0.677111\n",
      "loss in epoch 7 , step 17660 : 0.053821\n",
      "loss in epoch 7 , step 17680 : 2.050048\n",
      "loss in epoch 7 , step 17700 : 0.972657\n",
      "loss in epoch 7 , step 17720 : 0.041357\n",
      "loss in epoch 7 , step 17740 : 1.380009\n",
      "loss in epoch 7 , step 17760 : 2.347619\n",
      "loss in epoch 7 , step 17780 : 1.904725\n",
      "loss in epoch 7 , step 17800 : 0.497767\n",
      "loss in epoch 7 , step 17820 : 0.830333\n",
      "loss in epoch 7 , step 17840 : 0.675472\n",
      "loss in epoch 7 , step 17860 : 1.243222\n",
      "loss in epoch 7 , step 17880 : 1.911734\n",
      "loss in epoch 7 , step 17900 : 0.135756\n",
      "loss in epoch 7 , step 17920 : 1.752747\n",
      "loss in epoch 7 , step 17940 : 0.196400\n",
      "loss in epoch 7 , step 17960 : 1.467436\n",
      "loss in epoch 7 , step 17980 : 1.123497\n",
      "loss in epoch 7 , step 18000 : 3.216576\n",
      "loss in epoch 7 , step 18020 : 2.017511\n",
      "loss in epoch 7 , step 18040 : 0.464612\n",
      "loss in epoch 7 , step 18060 : 1.075090\n",
      "loss in epoch 7 , step 18080 : 1.448604\n",
      "loss in epoch 7 , step 18100 : 1.890428\n",
      "loss in epoch 7 , step 18120 : 0.054099\n",
      "loss in epoch 7 , step 18140 : 0.731261\n",
      "loss in epoch 7 , step 18160 : 1.734468\n",
      "loss in epoch 7 , step 18180 : 1.099925\n",
      "loss in epoch 7 , step 18200 : 1.370674\n",
      "loss in epoch 7 , step 18220 : 4.525871\n",
      "loss in epoch 7 , step 18240 : 0.185112\n",
      "loss in epoch 7 , step 18260 : 1.564853\n",
      "loss in epoch 7 , step 18280 : 0.322907\n",
      "loss in epoch 7 , step 18300 : 0.259835\n",
      "loss in epoch 7 , step 18320 : 0.050361\n",
      "loss in epoch 7 , step 18340 : 0.275622\n",
      "loss in epoch 7 , step 18360 : 0.236111\n",
      "loss in epoch 7 , step 18380 : 0.735437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 7 , step 18400 : 1.808222\n",
      "loss in epoch 7 , step 18420 : 1.430137\n",
      "loss in epoch 7 , step 18440 : 0.048630\n",
      "loss in epoch 7 , step 18460 : 2.116495\n",
      "loss in epoch 7 , step 18480 : 1.595835\n",
      "loss in epoch 7 , step 18500 : 2.599906\n",
      "loss in epoch 7 , step 18520 : 0.802456\n",
      "loss in epoch 7 , step 18540 : 1.704095\n",
      "loss in epoch 7 , step 18560 : 0.025491\n",
      "loss in epoch 7 , step 18580 : 1.449371\n",
      "loss in epoch 7 , step 18600 : 0.161183\n",
      "loss in epoch 7 , step 18620 : 2.248355\n",
      "loss in epoch 7 , step 18640 : 1.636648\n",
      "loss in epoch 7 , step 18660 : 1.582306\n",
      "loss in epoch 7 , step 18680 : 1.184160\n",
      "loss in epoch 7 , step 18700 : 1.211457\n",
      "loss in epoch 7 , step 18720 : 0.036163\n",
      "loss in epoch 7 , step 18740 : 1.736369\n",
      "loss in epoch 7 , step 18760 : 3.330063\n",
      "loss in epoch 7 , step 18780 : 1.086464\n",
      "loss in epoch 7 , step 18800 : 1.651640\n",
      "loss in epoch 7 , step 18820 : 0.818089\n",
      "loss in epoch 7 , step 18840 : 0.021152\n",
      "loss in epoch 7 , step 18860 : 0.863555\n",
      "loss in epoch 7 , step 18880 : 3.092890\n",
      "loss in epoch 7 , step 18900 : 1.354632\n",
      "loss in epoch 7 , step 18920 : 1.399038\n",
      "loss in epoch 7 , step 18940 : 1.107629\n",
      "loss in epoch 7 , step 18960 : 0.663619\n",
      "loss in epoch 7 , step 18980 : 0.130479\n",
      "loss in epoch 7 , step 19000 : 0.100580\n",
      "loss in epoch 7 , step 19020 : 1.435032\n",
      "loss in epoch 7 , step 19040 : 1.858186\n",
      "loss in epoch 7 , step 19060 : 0.032176\n",
      "loss in epoch 7 , step 19080 : 1.708275\n",
      "loss in epoch 7 , step 19100 : 1.945900\n",
      "loss in epoch 7 , step 19120 : 2.100914\n",
      "loss in epoch 7 , step 19140 : 1.288758\n",
      "loss in epoch 7 , step 19160 : 0.235229\n",
      "loss in epoch 7 , step 19180 : 0.479934\n",
      "loss in epoch 7 , step 19200 : 1.031764\n",
      "loss in epoch 7 , step 19220 : 1.279746\n",
      "loss in epoch 7 , step 19240 : 1.034223\n",
      "loss in epoch 7 , step 19260 : 1.484918\n",
      "loss in epoch 7 , step 19280 : 1.375244\n",
      "loss in epoch 7 , step 19300 : 2.440659\n",
      "loss in epoch 7 , step 19320 : 1.317051\n",
      "loss in epoch 7 , step 19340 : 0.390183\n",
      "loss in epoch 7 , step 19360 : 1.767938\n",
      "loss in epoch 7 , step 19380 : 0.824568\n",
      "loss in epoch 7 , step 19400 : 0.562084\n",
      "loss in epoch 7 , step 19420 : 0.757589\n",
      "loss in epoch 7 , step 19440 : 2.427964\n",
      "loss in epoch 7 , step 19460 : 1.930024\n",
      "loss in epoch 7 , step 19480 : 1.800386\n",
      "loss in epoch 7 , step 19500 : 0.661990\n",
      "loss in epoch 7 , step 19520 : 1.770593\n",
      "loss in epoch 7 , step 19540 : 0.786097\n",
      "loss in epoch 7 , step 19560 : 2.033711\n",
      "loss in epoch 7 , step 19580 : 3.937569\n",
      "loss in epoch 7 , step 19600 : 1.594775\n",
      "loss in epoch 7 , step 19620 : 1.266001\n",
      "loss in epoch 7 , step 19640 : 1.399382\n",
      "loss in epoch 7 , step 19660 : 1.064328\n",
      "loss in epoch 7 , step 19680 : 2.346922\n",
      "loss in epoch 7 , step 19700 : 1.400728\n",
      "loss in epoch 7 , step 19720 : 1.653551\n",
      "loss in epoch 7 , step 19740 : 1.127630\n",
      "loss in epoch 7 , step 19760 : 0.233152\n",
      "loss in epoch 7 , step 19780 : 0.294036\n",
      "loss in epoch 7 , step 19800 : 1.289180\n",
      "loss in epoch 7 , step 19820 : 1.282224\n",
      "loss in epoch 7 , step 19840 : 0.844589\n",
      "loss in epoch 7 , step 19860 : 0.345230\n",
      "loss in epoch 7 , step 19880 : 1.386682\n",
      "loss in epoch 7 , step 19900 : 2.303432\n",
      "loss in epoch 7 , step 19920 : 1.868578\n",
      "loss in epoch 7 , step 19940 : 0.829855\n",
      "Accuracy in epoch 7 : 27.567020\n",
      "loss in epoch 8 , step 0 : 2.368348\n",
      "loss in epoch 8 , step 20 : 1.391844\n",
      "loss in epoch 8 , step 40 : 1.575854\n",
      "loss in epoch 8 , step 60 : 1.407055\n",
      "loss in epoch 8 , step 80 : 1.418307\n",
      "loss in epoch 8 , step 100 : 0.401846\n",
      "loss in epoch 8 , step 120 : 0.030581\n",
      "loss in epoch 8 , step 140 : 1.660196\n",
      "loss in epoch 8 , step 160 : 0.499780\n",
      "loss in epoch 8 , step 180 : 1.070718\n",
      "loss in epoch 8 , step 200 : 1.086001\n",
      "loss in epoch 8 , step 220 : 4.653429\n",
      "loss in epoch 8 , step 240 : 0.814744\n",
      "loss in epoch 8 , step 260 : 1.660309\n",
      "loss in epoch 8 , step 280 : 1.002115\n",
      "loss in epoch 8 , step 300 : 1.548626\n",
      "loss in epoch 8 , step 320 : 2.992213\n",
      "loss in epoch 8 , step 340 : 0.915158\n",
      "loss in epoch 8 , step 360 : 3.265436\n",
      "loss in epoch 8 , step 380 : 0.766232\n",
      "loss in epoch 8 , step 400 : 2.269356\n",
      "loss in epoch 8 , step 420 : 1.275105\n",
      "loss in epoch 8 , step 440 : 1.419445\n",
      "loss in epoch 8 , step 460 : 1.274961\n",
      "loss in epoch 8 , step 480 : 0.135063\n",
      "loss in epoch 8 , step 500 : 0.987266\n",
      "loss in epoch 8 , step 520 : 0.674164\n",
      "loss in epoch 8 , step 540 : 1.457949\n",
      "loss in epoch 8 , step 560 : 1.595503\n",
      "loss in epoch 8 , step 580 : 0.760931\n",
      "loss in epoch 8 , step 600 : 0.441752\n",
      "loss in epoch 8 , step 620 : 1.618490\n",
      "loss in epoch 8 , step 640 : 0.649948\n",
      "loss in epoch 8 , step 660 : 0.493143\n",
      "loss in epoch 8 , step 680 : 1.633878\n",
      "loss in epoch 8 , step 700 : 0.957383\n",
      "loss in epoch 8 , step 720 : 1.333339\n",
      "loss in epoch 8 , step 740 : 0.833187\n",
      "loss in epoch 8 , step 760 : 1.581517\n",
      "loss in epoch 8 , step 780 : 1.000932\n",
      "loss in epoch 8 , step 800 : 1.779246\n",
      "loss in epoch 8 , step 820 : 0.077475\n",
      "loss in epoch 8 , step 840 : 0.020562\n",
      "loss in epoch 8 , step 860 : 1.767755\n",
      "loss in epoch 8 , step 880 : 0.017860\n",
      "loss in epoch 8 , step 900 : 0.015624\n",
      "loss in epoch 8 , step 920 : 0.668654\n",
      "loss in epoch 8 , step 940 : 1.507035\n",
      "loss in epoch 8 , step 960 : 1.537465\n",
      "loss in epoch 8 , step 980 : 0.475444\n",
      "loss in epoch 8 , step 1000 : 0.336288\n",
      "loss in epoch 8 , step 1020 : 1.423591\n",
      "loss in epoch 8 , step 1040 : 0.081108\n",
      "loss in epoch 8 , step 1060 : 1.249158\n",
      "loss in epoch 8 , step 1080 : 0.017611\n",
      "loss in epoch 8 , step 1100 : 1.213116\n",
      "loss in epoch 8 , step 1120 : 1.445457\n",
      "loss in epoch 8 , step 1140 : 1.967233\n",
      "loss in epoch 8 , step 1160 : 0.425917\n",
      "loss in epoch 8 , step 1180 : 1.403033\n",
      "loss in epoch 8 , step 1200 : 0.215287\n",
      "loss in epoch 8 , step 1220 : 0.009235\n",
      "loss in epoch 8 , step 1240 : 1.192932\n",
      "loss in epoch 8 , step 1260 : 0.307165\n",
      "loss in epoch 8 , step 1280 : 0.853999\n",
      "loss in epoch 8 , step 1300 : 2.178614\n",
      "loss in epoch 8 , step 1320 : 1.506422\n",
      "loss in epoch 8 , step 1340 : 1.633771\n",
      "loss in epoch 8 , step 1360 : 1.835186\n",
      "loss in epoch 8 , step 1380 : 0.823204\n",
      "loss in epoch 8 , step 1400 : 1.278013\n",
      "loss in epoch 8 , step 1420 : 0.354151\n",
      "loss in epoch 8 , step 1440 : 0.029311\n",
      "loss in epoch 8 , step 1460 : 1.074102\n",
      "loss in epoch 8 , step 1480 : 0.643228\n",
      "loss in epoch 8 , step 1500 : 0.011986\n",
      "loss in epoch 8 , step 1520 : 0.743337\n",
      "loss in epoch 8 , step 1540 : 0.157346\n",
      "loss in epoch 8 , step 1560 : 2.649295\n",
      "loss in epoch 8 , step 1580 : 3.669718\n",
      "loss in epoch 8 , step 1600 : 0.943696\n",
      "loss in epoch 8 , step 1620 : 1.284131\n",
      "loss in epoch 8 , step 1640 : 1.107674\n",
      "loss in epoch 8 , step 1660 : 1.099905\n",
      "loss in epoch 8 , step 1680 : 1.417720\n",
      "loss in epoch 8 , step 1700 : 1.304867\n",
      "loss in epoch 8 , step 1720 : 0.038699\n",
      "loss in epoch 8 , step 1740 : 0.012658\n",
      "loss in epoch 8 , step 1760 : 1.639155\n",
      "loss in epoch 8 , step 1780 : 1.012583\n",
      "loss in epoch 8 , step 1800 : 2.846820\n",
      "loss in epoch 8 , step 1820 : 0.296412\n",
      "loss in epoch 8 , step 1840 : 1.242022\n",
      "loss in epoch 8 , step 1860 : 1.266168\n",
      "loss in epoch 8 , step 1880 : 1.008046\n",
      "loss in epoch 8 , step 1900 : 1.668099\n",
      "loss in epoch 8 , step 1920 : 0.826937\n",
      "loss in epoch 8 , step 1940 : 0.021454\n",
      "loss in epoch 8 , step 1960 : 1.620345\n",
      "loss in epoch 8 , step 1980 : 1.554985\n",
      "loss in epoch 8 , step 2000 : 1.310313\n",
      "loss in epoch 8 , step 2020 : 1.817504\n",
      "loss in epoch 8 , step 2040 : 0.155113\n",
      "loss in epoch 8 , step 2060 : 0.213374\n",
      "loss in epoch 8 , step 2080 : 1.327406\n",
      "loss in epoch 8 , step 2100 : 0.110727\n",
      "loss in epoch 8 , step 2120 : 1.277257\n",
      "loss in epoch 8 , step 2140 : 1.601231\n",
      "loss in epoch 8 , step 2160 : 1.399061\n",
      "loss in epoch 8 , step 2180 : 0.047374\n",
      "loss in epoch 8 , step 2200 : 1.911174\n",
      "loss in epoch 8 , step 2220 : 0.854533\n",
      "loss in epoch 8 , step 2240 : 1.309273\n",
      "loss in epoch 8 , step 2260 : 0.894665\n",
      "loss in epoch 8 , step 2280 : 0.853982\n",
      "loss in epoch 8 , step 2300 : 1.529200\n",
      "loss in epoch 8 , step 2320 : 2.231860\n",
      "loss in epoch 8 , step 2340 : 2.532168\n",
      "loss in epoch 8 , step 2360 : 0.014291\n",
      "loss in epoch 8 , step 2380 : 0.924282\n",
      "loss in epoch 8 , step 2400 : 0.127480\n",
      "loss in epoch 8 , step 2420 : 4.062611\n",
      "loss in epoch 8 , step 2440 : 1.469819\n",
      "loss in epoch 8 , step 2460 : 2.030439\n",
      "loss in epoch 8 , step 2480 : 1.341969\n",
      "loss in epoch 8 , step 2500 : 0.977281\n",
      "loss in epoch 8 , step 2520 : 0.589559\n",
      "loss in epoch 8 , step 2540 : 1.770200\n",
      "loss in epoch 8 , step 2560 : 0.769089\n",
      "loss in epoch 8 , step 2580 : 2.519854\n",
      "loss in epoch 8 , step 2600 : 1.749131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 8 , step 2620 : 1.482473\n",
      "loss in epoch 8 , step 2640 : 0.835747\n",
      "loss in epoch 8 , step 2660 : 0.467575\n",
      "loss in epoch 8 , step 2680 : 0.217220\n",
      "loss in epoch 8 , step 2700 : 1.492906\n",
      "loss in epoch 8 , step 2720 : 0.214228\n",
      "loss in epoch 8 , step 2740 : 1.275169\n",
      "loss in epoch 8 , step 2760 : 1.200577\n",
      "loss in epoch 8 , step 2780 : 0.717883\n",
      "loss in epoch 8 , step 2800 : 0.225245\n",
      "loss in epoch 8 , step 2820 : 1.880778\n",
      "loss in epoch 8 , step 2840 : 0.013073\n",
      "loss in epoch 8 , step 2860 : 2.135178\n",
      "loss in epoch 8 , step 2880 : 1.110886\n",
      "loss in epoch 8 , step 2900 : 2.035857\n",
      "loss in epoch 8 , step 2920 : 0.414277\n",
      "loss in epoch 8 , step 2940 : 1.499009\n",
      "loss in epoch 8 , step 2960 : 0.853891\n",
      "loss in epoch 8 , step 2980 : 1.184067\n",
      "loss in epoch 8 , step 3000 : 1.576340\n",
      "loss in epoch 8 , step 3020 : 0.408741\n",
      "loss in epoch 8 , step 3040 : 1.342157\n",
      "loss in epoch 8 , step 3060 : 1.131055\n",
      "loss in epoch 8 , step 3080 : 1.779317\n",
      "loss in epoch 8 , step 3100 : 0.034194\n",
      "loss in epoch 8 , step 3120 : 1.376417\n",
      "loss in epoch 8 , step 3140 : 1.307858\n",
      "loss in epoch 8 , step 3160 : 0.891599\n",
      "loss in epoch 8 , step 3180 : 1.407796\n",
      "loss in epoch 8 , step 3200 : 3.344836\n",
      "loss in epoch 8 , step 3220 : 1.908094\n",
      "loss in epoch 8 , step 3240 : 2.297751\n",
      "loss in epoch 8 , step 3260 : 2.096768\n",
      "loss in epoch 8 , step 3280 : 0.025699\n",
      "loss in epoch 8 , step 3300 : 0.200372\n",
      "loss in epoch 8 , step 3320 : 1.834105\n",
      "loss in epoch 8 , step 3340 : 0.014170\n",
      "loss in epoch 8 , step 3360 : 0.221793\n",
      "loss in epoch 8 , step 3380 : 1.875165\n",
      "loss in epoch 8 , step 3400 : 0.931589\n",
      "loss in epoch 8 , step 3420 : 0.013546\n",
      "loss in epoch 8 , step 3440 : 0.789533\n",
      "loss in epoch 8 , step 3460 : 1.136142\n",
      "loss in epoch 8 , step 3480 : 0.234886\n",
      "loss in epoch 8 , step 3500 : 1.156778\n",
      "loss in epoch 8 , step 3520 : 0.774784\n",
      "loss in epoch 8 , step 3540 : 0.018708\n",
      "loss in epoch 8 , step 3560 : 1.501382\n",
      "loss in epoch 8 , step 3580 : 0.575035\n",
      "loss in epoch 8 , step 3600 : 0.573545\n",
      "loss in epoch 8 , step 3620 : 0.028507\n",
      "loss in epoch 8 , step 3640 : 0.243139\n",
      "loss in epoch 8 , step 3660 : 1.611364\n",
      "loss in epoch 8 , step 3680 : 0.935985\n",
      "loss in epoch 8 , step 3700 : 1.624724\n",
      "loss in epoch 8 , step 3720 : 3.168049\n",
      "loss in epoch 8 , step 3740 : 1.150153\n",
      "loss in epoch 8 , step 3760 : 1.560228\n",
      "loss in epoch 8 , step 3780 : 0.248566\n",
      "loss in epoch 8 , step 3800 : 1.476152\n",
      "loss in epoch 8 , step 3820 : 0.925391\n",
      "loss in epoch 8 , step 3840 : 0.640969\n",
      "loss in epoch 8 , step 3860 : 2.384698\n",
      "loss in epoch 8 , step 3880 : 2.343238\n",
      "loss in epoch 8 , step 3900 : 0.797766\n",
      "loss in epoch 8 , step 3920 : 0.173507\n",
      "loss in epoch 8 , step 3940 : 1.859795\n",
      "loss in epoch 8 , step 3960 : 1.399935\n",
      "loss in epoch 8 , step 3980 : 1.155015\n",
      "loss in epoch 8 , step 4000 : 0.708101\n",
      "loss in epoch 8 , step 4020 : 2.109975\n",
      "loss in epoch 8 , step 4040 : 2.110346\n",
      "loss in epoch 8 , step 4060 : 1.327911\n",
      "loss in epoch 8 , step 4080 : 0.107193\n",
      "loss in epoch 8 , step 4100 : 1.843292\n",
      "loss in epoch 8 , step 4120 : 1.275512\n",
      "loss in epoch 8 , step 4140 : 1.642426\n",
      "loss in epoch 8 , step 4160 : 0.764548\n",
      "loss in epoch 8 , step 4180 : 0.923338\n",
      "loss in epoch 8 , step 4200 : 0.261864\n",
      "loss in epoch 8 , step 4220 : 1.400055\n",
      "loss in epoch 8 , step 4240 : 1.086035\n",
      "loss in epoch 8 , step 4260 : 1.141093\n",
      "loss in epoch 8 , step 4280 : 1.239729\n",
      "loss in epoch 8 , step 4300 : 1.833069\n",
      "loss in epoch 8 , step 4320 : 0.347406\n",
      "loss in epoch 8 , step 4340 : 0.083567\n",
      "loss in epoch 8 , step 4360 : 1.191407\n",
      "loss in epoch 8 , step 4380 : 2.118032\n",
      "loss in epoch 8 , step 4400 : 2.001464\n",
      "loss in epoch 8 , step 4420 : 0.783125\n",
      "loss in epoch 8 , step 4440 : 1.244229\n",
      "loss in epoch 8 , step 4460 : 0.789369\n",
      "loss in epoch 8 , step 4480 : 1.451017\n",
      "loss in epoch 8 , step 4500 : 1.463829\n",
      "loss in epoch 8 , step 4520 : 1.991196\n",
      "loss in epoch 8 , step 4540 : 2.268642\n",
      "loss in epoch 8 , step 4560 : 1.023164\n",
      "loss in epoch 8 , step 4580 : 1.173013\n",
      "loss in epoch 8 , step 4600 : 0.428341\n",
      "loss in epoch 8 , step 4620 : 0.791751\n",
      "loss in epoch 8 , step 4640 : 1.703328\n",
      "loss in epoch 8 , step 4660 : 1.501019\n",
      "loss in epoch 8 , step 4680 : 0.967609\n",
      "loss in epoch 8 , step 4700 : 1.555367\n",
      "loss in epoch 8 , step 4720 : 1.170194\n",
      "loss in epoch 8 , step 4740 : 1.313299\n",
      "loss in epoch 8 , step 4760 : 0.056528\n",
      "loss in epoch 8 , step 4780 : 0.257907\n",
      "loss in epoch 8 , step 4800 : 2.162952\n",
      "loss in epoch 8 , step 4820 : 3.200089\n",
      "loss in epoch 8 , step 4840 : 0.297963\n",
      "loss in epoch 8 , step 4860 : 0.524488\n",
      "loss in epoch 8 , step 4880 : 0.074562\n",
      "loss in epoch 8 , step 4900 : 1.440751\n",
      "loss in epoch 8 , step 4920 : 0.047830\n",
      "loss in epoch 8 , step 4940 : 1.137668\n",
      "loss in epoch 8 , step 4960 : 0.614969\n",
      "loss in epoch 8 , step 4980 : 1.160044\n",
      "loss in epoch 8 , step 5000 : 0.565319\n",
      "loss in epoch 8 , step 5020 : 1.196838\n",
      "loss in epoch 8 , step 5040 : 0.162508\n",
      "loss in epoch 8 , step 5060 : 0.228266\n",
      "loss in epoch 8 , step 5080 : 1.477599\n",
      "loss in epoch 8 , step 5100 : 1.430504\n",
      "loss in epoch 8 , step 5120 : 1.987554\n",
      "loss in epoch 8 , step 5140 : 2.229482\n",
      "loss in epoch 8 , step 5160 : 1.272253\n",
      "loss in epoch 8 , step 5180 : 1.088110\n",
      "loss in epoch 8 , step 5200 : 1.439383\n",
      "loss in epoch 8 , step 5220 : 0.741677\n",
      "loss in epoch 8 , step 5240 : 0.006250\n",
      "loss in epoch 8 , step 5260 : 1.760722\n",
      "loss in epoch 8 , step 5280 : 1.626384\n",
      "loss in epoch 8 , step 5300 : 1.348400\n",
      "loss in epoch 8 , step 5320 : 1.330721\n",
      "loss in epoch 8 , step 5340 : 0.053142\n",
      "loss in epoch 8 , step 5360 : 2.691281\n",
      "loss in epoch 8 , step 5380 : 1.433197\n",
      "loss in epoch 8 , step 5400 : 0.970427\n",
      "loss in epoch 8 , step 5420 : 1.649746\n",
      "loss in epoch 8 , step 5440 : 0.970643\n",
      "loss in epoch 8 , step 5460 : 0.456801\n",
      "loss in epoch 8 , step 5480 : 2.233650\n",
      "loss in epoch 8 , step 5500 : 2.266542\n",
      "loss in epoch 8 , step 5520 : 1.856974\n",
      "loss in epoch 8 , step 5540 : 0.673797\n",
      "loss in epoch 8 , step 5560 : 0.419766\n",
      "loss in epoch 8 , step 5580 : 3.159719\n",
      "loss in epoch 8 , step 5600 : 0.464433\n",
      "loss in epoch 8 , step 5620 : 1.407455\n",
      "loss in epoch 8 , step 5640 : 1.796834\n",
      "loss in epoch 8 , step 5660 : 0.660754\n",
      "loss in epoch 8 , step 5680 : 0.670953\n",
      "loss in epoch 8 , step 5700 : 0.640019\n",
      "loss in epoch 8 , step 5720 : 1.134444\n",
      "loss in epoch 8 , step 5740 : 1.524916\n",
      "loss in epoch 8 , step 5760 : 1.655289\n",
      "loss in epoch 8 , step 5780 : 0.538031\n",
      "loss in epoch 8 , step 5800 : 1.318606\n",
      "loss in epoch 8 , step 5820 : 0.111673\n",
      "loss in epoch 8 , step 5840 : 1.652599\n",
      "loss in epoch 8 , step 5860 : 2.061210\n",
      "loss in epoch 8 , step 5880 : 0.954456\n",
      "loss in epoch 8 , step 5900 : 0.690146\n",
      "loss in epoch 8 , step 5920 : 2.787239\n",
      "loss in epoch 8 , step 5940 : 1.358760\n",
      "loss in epoch 8 , step 5960 : 1.005564\n",
      "loss in epoch 8 , step 5980 : 0.555792\n",
      "loss in epoch 8 , step 6000 : 1.934511\n",
      "loss in epoch 8 , step 6020 : 1.153690\n",
      "loss in epoch 8 , step 6040 : 2.095605\n",
      "loss in epoch 8 , step 6060 : 2.579732\n",
      "loss in epoch 8 , step 6080 : 0.803507\n",
      "loss in epoch 8 , step 6100 : 0.650017\n",
      "loss in epoch 8 , step 6120 : 1.652271\n",
      "loss in epoch 8 , step 6140 : 0.030893\n",
      "loss in epoch 8 , step 6160 : 2.187347\n",
      "loss in epoch 8 , step 6180 : 1.102798\n",
      "loss in epoch 8 , step 6200 : 1.240292\n",
      "loss in epoch 8 , step 6220 : 1.166858\n",
      "loss in epoch 8 , step 6240 : 1.488855\n",
      "loss in epoch 8 , step 6260 : 1.496993\n",
      "loss in epoch 8 , step 6280 : 1.507232\n",
      "loss in epoch 8 , step 6300 : 0.366674\n",
      "loss in epoch 8 , step 6320 : 0.460320\n",
      "loss in epoch 8 , step 6340 : 0.361562\n",
      "loss in epoch 8 , step 6360 : 1.724887\n",
      "loss in epoch 8 , step 6380 : 0.611317\n",
      "loss in epoch 8 , step 6400 : 1.654204\n",
      "loss in epoch 8 , step 6420 : 1.932421\n",
      "loss in epoch 8 , step 6440 : 0.850410\n",
      "loss in epoch 8 , step 6460 : 1.082383\n",
      "loss in epoch 8 , step 6480 : 0.842504\n",
      "loss in epoch 8 , step 6500 : 0.100170\n",
      "loss in epoch 8 , step 6520 : 1.335393\n",
      "loss in epoch 8 , step 6540 : 0.484257\n",
      "loss in epoch 8 , step 6560 : 1.443308\n",
      "loss in epoch 8 , step 6580 : 1.765555\n",
      "loss in epoch 8 , step 6600 : 0.158473\n",
      "loss in epoch 8 , step 6620 : 1.971545\n",
      "loss in epoch 8 , step 6640 : 0.123991\n",
      "loss in epoch 8 , step 6660 : 0.862566\n",
      "loss in epoch 8 , step 6680 : 0.648812\n",
      "loss in epoch 8 , step 6700 : 1.216649\n",
      "loss in epoch 8 , step 6720 : 2.786355\n",
      "loss in epoch 8 , step 6740 : 1.328277\n",
      "loss in epoch 8 , step 6760 : 0.011640\n",
      "loss in epoch 8 , step 6780 : 2.183442\n",
      "loss in epoch 8 , step 6800 : 1.108640\n",
      "loss in epoch 8 , step 6820 : 1.039867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 8 , step 6840 : 3.017692\n",
      "loss in epoch 8 , step 6860 : 1.066058\n",
      "loss in epoch 8 , step 6880 : 4.250851\n",
      "loss in epoch 8 , step 6900 : 4.518720\n",
      "loss in epoch 8 , step 6920 : 1.712243\n",
      "loss in epoch 8 , step 6940 : 1.394615\n",
      "loss in epoch 8 , step 6960 : 1.088336\n",
      "loss in epoch 8 , step 6980 : 1.159832\n",
      "loss in epoch 8 , step 7000 : 1.920795\n",
      "loss in epoch 8 , step 7020 : 1.249600\n",
      "loss in epoch 8 , step 7040 : 0.156830\n",
      "loss in epoch 8 , step 7060 : 1.376026\n",
      "loss in epoch 8 , step 7080 : 1.105043\n",
      "loss in epoch 8 , step 7100 : 1.477224\n",
      "loss in epoch 8 , step 7120 : 3.233742\n",
      "loss in epoch 8 , step 7140 : 1.211247\n",
      "loss in epoch 8 , step 7160 : 0.523296\n",
      "loss in epoch 8 , step 7180 : 2.503335\n",
      "loss in epoch 8 , step 7200 : 1.608442\n",
      "loss in epoch 8 , step 7220 : 1.239749\n",
      "loss in epoch 8 , step 7240 : 1.825122\n",
      "loss in epoch 8 , step 7260 : 2.461712\n",
      "loss in epoch 8 , step 7280 : 0.748866\n",
      "loss in epoch 8 , step 7300 : 1.272842\n",
      "loss in epoch 8 , step 7320 : 1.070700\n",
      "loss in epoch 8 , step 7340 : 1.756718\n",
      "loss in epoch 8 , step 7360 : 1.660714\n",
      "loss in epoch 8 , step 7380 : 0.817007\n",
      "loss in epoch 8 , step 7400 : 0.017735\n",
      "loss in epoch 8 , step 7420 : 2.419001\n",
      "loss in epoch 8 , step 7440 : 0.051730\n",
      "loss in epoch 8 , step 7460 : 2.020102\n",
      "loss in epoch 8 , step 7480 : 1.926069\n",
      "loss in epoch 8 , step 7500 : 1.275903\n",
      "loss in epoch 8 , step 7520 : 0.983381\n",
      "loss in epoch 8 , step 7540 : 1.721210\n",
      "loss in epoch 8 , step 7560 : 0.103275\n",
      "loss in epoch 8 , step 7580 : 0.199350\n",
      "loss in epoch 8 , step 7600 : 1.661602\n",
      "loss in epoch 8 , step 7620 : 1.928011\n",
      "loss in epoch 8 , step 7640 : 1.005788\n",
      "loss in epoch 8 , step 7660 : 1.263345\n",
      "loss in epoch 8 , step 7680 : 1.532474\n",
      "loss in epoch 8 , step 7700 : 1.207160\n",
      "loss in epoch 8 , step 7720 : 0.677385\n",
      "loss in epoch 8 , step 7740 : 2.409091\n",
      "loss in epoch 8 , step 7760 : 0.164350\n",
      "loss in epoch 8 , step 7780 : 0.287260\n",
      "loss in epoch 8 , step 7800 : 2.750575\n",
      "loss in epoch 8 , step 7820 : 1.827727\n",
      "loss in epoch 8 , step 7840 : 2.286888\n",
      "loss in epoch 8 , step 7860 : 0.032648\n",
      "loss in epoch 8 , step 7880 : 0.021540\n",
      "loss in epoch 8 , step 7900 : 1.907731\n",
      "loss in epoch 8 , step 7920 : 2.397760\n",
      "loss in epoch 8 , step 7940 : 0.893042\n",
      "loss in epoch 8 , step 7960 : 0.589937\n",
      "loss in epoch 8 , step 7980 : 2.222965\n",
      "loss in epoch 8 , step 8000 : 0.774543\n",
      "loss in epoch 8 , step 8020 : 1.279833\n",
      "loss in epoch 8 , step 8040 : 2.293725\n",
      "loss in epoch 8 , step 8060 : 1.055003\n",
      "loss in epoch 8 , step 8080 : 0.833418\n",
      "loss in epoch 8 , step 8100 : 1.050164\n",
      "loss in epoch 8 , step 8120 : 0.782316\n",
      "loss in epoch 8 , step 8140 : 1.065149\n",
      "loss in epoch 8 , step 8160 : 1.598863\n",
      "loss in epoch 8 , step 8180 : 1.672879\n",
      "loss in epoch 8 , step 8200 : 1.738349\n",
      "loss in epoch 8 , step 8220 : 1.763418\n",
      "loss in epoch 8 , step 8240 : 1.243883\n",
      "loss in epoch 8 , step 8260 : 0.404816\n",
      "loss in epoch 8 , step 8280 : 1.382141\n",
      "loss in epoch 8 , step 8300 : 1.672334\n",
      "loss in epoch 8 , step 8320 : 0.604633\n",
      "loss in epoch 8 , step 8340 : 0.569598\n",
      "loss in epoch 8 , step 8360 : 1.232792\n",
      "loss in epoch 8 , step 8380 : 1.351588\n",
      "loss in epoch 8 , step 8400 : 0.055306\n",
      "loss in epoch 8 , step 8420 : 2.766963\n",
      "loss in epoch 8 , step 8440 : 1.131433\n",
      "loss in epoch 8 , step 8460 : 0.298633\n",
      "loss in epoch 8 , step 8480 : 1.889571\n",
      "loss in epoch 8 , step 8500 : 0.251614\n",
      "loss in epoch 8 , step 8520 : 1.917988\n",
      "loss in epoch 8 , step 8540 : 0.326616\n",
      "loss in epoch 8 , step 8560 : 1.986425\n",
      "loss in epoch 8 , step 8580 : 1.706290\n",
      "loss in epoch 8 , step 8600 : 1.133391\n",
      "loss in epoch 8 , step 8620 : 1.099359\n",
      "loss in epoch 8 , step 8640 : 1.228161\n",
      "loss in epoch 8 , step 8660 : 2.055225\n",
      "loss in epoch 8 , step 8680 : 1.732008\n",
      "loss in epoch 8 , step 8700 : 1.156781\n",
      "loss in epoch 8 , step 8720 : 0.021742\n",
      "loss in epoch 8 , step 8740 : 1.396216\n",
      "loss in epoch 8 , step 8760 : 1.212772\n",
      "loss in epoch 8 , step 8780 : 0.198705\n",
      "loss in epoch 8 , step 8800 : 1.816092\n",
      "loss in epoch 8 , step 8820 : 0.480245\n",
      "loss in epoch 8 , step 8840 : 2.215633\n",
      "loss in epoch 8 , step 8860 : 0.011068\n",
      "loss in epoch 8 , step 8880 : 0.010601\n",
      "loss in epoch 8 , step 8900 : 1.330215\n",
      "loss in epoch 8 , step 8920 : 0.208482\n",
      "loss in epoch 8 , step 8940 : 1.263178\n",
      "loss in epoch 8 , step 8960 : 4.255749\n",
      "loss in epoch 8 , step 8980 : 2.251529\n",
      "loss in epoch 8 , step 9000 : 1.826425\n",
      "loss in epoch 8 , step 9020 : 1.896916\n",
      "loss in epoch 8 , step 9040 : 0.063104\n",
      "loss in epoch 8 , step 9060 : 1.624660\n",
      "loss in epoch 8 , step 9080 : 1.029706\n",
      "loss in epoch 8 , step 9100 : 1.943491\n",
      "loss in epoch 8 , step 9120 : 1.061116\n",
      "loss in epoch 8 , step 9140 : 1.618842\n",
      "loss in epoch 8 , step 9160 : 1.595818\n",
      "loss in epoch 8 , step 9180 : 1.144145\n",
      "loss in epoch 8 , step 9200 : 1.787703\n",
      "loss in epoch 8 , step 9220 : 0.036778\n",
      "loss in epoch 8 , step 9240 : 2.257694\n",
      "loss in epoch 8 , step 9260 : 1.922922\n",
      "loss in epoch 8 , step 9280 : 0.541922\n",
      "loss in epoch 8 , step 9300 : 0.503704\n",
      "loss in epoch 8 , step 9320 : 1.044151\n",
      "loss in epoch 8 , step 9340 : 2.128056\n",
      "loss in epoch 8 , step 9360 : 0.181985\n",
      "loss in epoch 8 , step 9380 : 1.941941\n",
      "loss in epoch 8 , step 9400 : 0.712393\n",
      "loss in epoch 8 , step 9420 : 1.644660\n",
      "loss in epoch 8 , step 9440 : 0.635628\n",
      "loss in epoch 8 , step 9460 : 1.312525\n",
      "loss in epoch 8 , step 9480 : 1.596208\n",
      "loss in epoch 8 , step 9500 : 1.593587\n",
      "loss in epoch 8 , step 9520 : 0.051573\n",
      "loss in epoch 8 , step 9540 : 1.286843\n",
      "loss in epoch 8 , step 9560 : 0.007391\n",
      "loss in epoch 8 , step 9580 : 0.914477\n",
      "loss in epoch 8 , step 9600 : 0.035674\n",
      "loss in epoch 8 , step 9620 : 0.893453\n",
      "loss in epoch 8 , step 9640 : 0.901511\n",
      "loss in epoch 8 , step 9660 : 1.345264\n",
      "loss in epoch 8 , step 9680 : 1.497843\n",
      "loss in epoch 8 , step 9700 : 0.596560\n",
      "loss in epoch 8 , step 9720 : 0.529937\n",
      "loss in epoch 8 , step 9740 : 1.334396\n",
      "loss in epoch 8 , step 9760 : 1.635830\n",
      "loss in epoch 8 , step 9780 : 2.694119\n",
      "loss in epoch 8 , step 9800 : 0.175403\n",
      "loss in epoch 8 , step 9820 : 0.484742\n",
      "loss in epoch 8 , step 9840 : 2.156103\n",
      "loss in epoch 8 , step 9860 : 1.397386\n",
      "loss in epoch 8 , step 9880 : 1.719365\n",
      "loss in epoch 8 , step 9900 : 1.412405\n",
      "loss in epoch 8 , step 9920 : 1.325703\n",
      "loss in epoch 8 , step 9940 : 1.079254\n",
      "loss in epoch 8 , step 9960 : 0.017495\n",
      "loss in epoch 8 , step 9980 : 1.064786\n",
      "loss in epoch 8 , step 10000 : 1.236845\n",
      "loss in epoch 8 , step 10020 : 0.107125\n",
      "loss in epoch 8 , step 10040 : 2.860673\n",
      "loss in epoch 8 , step 10060 : 2.665716\n",
      "loss in epoch 8 , step 10080 : 1.697610\n",
      "loss in epoch 8 , step 10100 : 0.740022\n",
      "loss in epoch 8 , step 10120 : 2.706879\n",
      "loss in epoch 8 , step 10140 : 0.443218\n",
      "loss in epoch 8 , step 10160 : 0.821911\n",
      "loss in epoch 8 , step 10180 : 2.712497\n",
      "loss in epoch 8 , step 10200 : 1.294537\n",
      "loss in epoch 8 , step 10220 : 2.249603\n",
      "loss in epoch 8 , step 10240 : 2.169914\n",
      "loss in epoch 8 , step 10260 : 1.454679\n",
      "loss in epoch 8 , step 10280 : 1.427769\n",
      "loss in epoch 8 , step 10300 : 0.243486\n",
      "loss in epoch 8 , step 10320 : 0.303032\n",
      "loss in epoch 8 , step 10340 : 2.361578\n",
      "loss in epoch 8 , step 10360 : 1.208078\n",
      "loss in epoch 8 , step 10380 : 1.461280\n",
      "loss in epoch 8 , step 10400 : 0.474791\n",
      "loss in epoch 8 , step 10420 : 0.622908\n",
      "loss in epoch 8 , step 10440 : 0.901238\n",
      "loss in epoch 8 , step 10460 : 1.054049\n",
      "loss in epoch 8 , step 10480 : 1.468679\n",
      "loss in epoch 8 , step 10500 : 1.964661\n",
      "loss in epoch 8 , step 10520 : 1.836156\n",
      "loss in epoch 8 , step 10540 : 1.426631\n",
      "loss in epoch 8 , step 10560 : 0.042186\n",
      "loss in epoch 8 , step 10580 : 0.278283\n",
      "loss in epoch 8 , step 10600 : 0.119592\n",
      "loss in epoch 8 , step 10620 : 1.965504\n",
      "loss in epoch 8 , step 10640 : 0.625574\n",
      "loss in epoch 8 , step 10660 : 0.635624\n",
      "loss in epoch 8 , step 10680 : 0.024086\n",
      "loss in epoch 8 , step 10700 : 2.170914\n",
      "loss in epoch 8 , step 10720 : 2.283492\n",
      "loss in epoch 8 , step 10740 : 0.194159\n",
      "loss in epoch 8 , step 10760 : 1.178419\n",
      "loss in epoch 8 , step 10780 : 0.015709\n",
      "loss in epoch 8 , step 10800 : 2.232115\n",
      "loss in epoch 8 , step 10820 : 1.512125\n",
      "loss in epoch 8 , step 10840 : 1.131031\n",
      "loss in epoch 8 , step 10860 : 1.136560\n",
      "loss in epoch 8 , step 10880 : 1.356043\n",
      "loss in epoch 8 , step 10900 : 1.406284\n",
      "loss in epoch 8 , step 10920 : 0.007280\n",
      "loss in epoch 8 , step 10940 : 0.047316\n",
      "loss in epoch 8 , step 10960 : 1.261817\n",
      "loss in epoch 8 , step 10980 : 1.783108\n",
      "loss in epoch 8 , step 11000 : 1.490257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 8 , step 11020 : 1.268505\n",
      "loss in epoch 8 , step 11040 : 0.105520\n",
      "loss in epoch 8 , step 11060 : 1.524602\n",
      "loss in epoch 8 , step 11080 : 1.265850\n",
      "loss in epoch 8 , step 11100 : 0.325189\n",
      "loss in epoch 8 , step 11120 : 1.360597\n",
      "loss in epoch 8 , step 11140 : 1.670593\n",
      "loss in epoch 8 , step 11160 : 0.017089\n",
      "loss in epoch 8 , step 11180 : 1.274407\n",
      "loss in epoch 8 , step 11200 : 2.343211\n",
      "loss in epoch 8 , step 11220 : 2.225072\n",
      "loss in epoch 8 , step 11240 : 0.819805\n",
      "loss in epoch 8 , step 11260 : 0.084836\n",
      "loss in epoch 8 , step 11280 : 1.625317\n",
      "loss in epoch 8 , step 11300 : 1.440600\n",
      "loss in epoch 8 , step 11320 : 3.640397\n",
      "loss in epoch 8 , step 11340 : 3.368412\n",
      "loss in epoch 8 , step 11360 : 3.131870\n",
      "loss in epoch 8 , step 11380 : 0.323595\n",
      "loss in epoch 8 , step 11400 : 1.051292\n",
      "loss in epoch 8 , step 11420 : 0.832774\n",
      "loss in epoch 8 , step 11440 : 1.046060\n",
      "loss in epoch 8 , step 11460 : 0.878720\n",
      "loss in epoch 8 , step 11480 : 1.654990\n",
      "loss in epoch 8 , step 11500 : 0.926452\n",
      "loss in epoch 8 , step 11520 : 0.776060\n",
      "loss in epoch 8 , step 11540 : 1.835564\n",
      "loss in epoch 8 , step 11560 : 0.230315\n",
      "loss in epoch 8 , step 11580 : 1.597750\n",
      "loss in epoch 8 , step 11600 : 0.266359\n",
      "loss in epoch 8 , step 11620 : 0.144777\n",
      "loss in epoch 8 , step 11640 : 1.054427\n",
      "loss in epoch 8 , step 11660 : 0.618660\n",
      "loss in epoch 8 , step 11680 : 0.084425\n",
      "loss in epoch 8 , step 11700 : 0.288231\n",
      "loss in epoch 8 , step 11720 : 1.298255\n",
      "loss in epoch 8 , step 11740 : 0.442741\n",
      "loss in epoch 8 , step 11760 : 1.102338\n",
      "loss in epoch 8 , step 11780 : 0.285179\n",
      "loss in epoch 8 , step 11800 : 1.234994\n",
      "loss in epoch 8 , step 11820 : 1.504311\n",
      "loss in epoch 8 , step 11840 : 0.900732\n",
      "loss in epoch 8 , step 11860 : 0.397887\n",
      "loss in epoch 8 , step 11880 : 0.547471\n",
      "loss in epoch 8 , step 11900 : 0.077413\n",
      "loss in epoch 8 , step 11920 : 3.599526\n",
      "loss in epoch 8 , step 11940 : 1.845817\n",
      "loss in epoch 8 , step 11960 : 0.495974\n",
      "loss in epoch 8 , step 11980 : 1.635649\n",
      "loss in epoch 8 , step 12000 : 2.960376\n",
      "loss in epoch 8 , step 12020 : 1.164767\n",
      "loss in epoch 8 , step 12040 : 0.475703\n",
      "loss in epoch 8 , step 12060 : 1.792427\n",
      "loss in epoch 8 , step 12080 : 1.613875\n",
      "loss in epoch 8 , step 12100 : 1.982327\n",
      "loss in epoch 8 , step 12120 : 1.148343\n",
      "loss in epoch 8 , step 12140 : 1.282268\n",
      "loss in epoch 8 , step 12160 : 0.232357\n",
      "loss in epoch 8 , step 12180 : 0.111786\n",
      "loss in epoch 8 , step 12200 : 1.609010\n",
      "loss in epoch 8 , step 12220 : 1.269686\n",
      "loss in epoch 8 , step 12240 : 0.940906\n",
      "loss in epoch 8 , step 12260 : 0.323810\n",
      "loss in epoch 8 , step 12280 : 2.050141\n",
      "loss in epoch 8 , step 12300 : 1.370391\n",
      "loss in epoch 8 , step 12320 : 1.308962\n",
      "loss in epoch 8 , step 12340 : 2.156341\n",
      "loss in epoch 8 , step 12360 : 2.458505\n",
      "loss in epoch 8 , step 12380 : 1.728200\n",
      "loss in epoch 8 , step 12400 : 1.130738\n",
      "loss in epoch 8 , step 12420 : 1.684861\n",
      "loss in epoch 8 , step 12440 : 1.748942\n",
      "loss in epoch 8 , step 12460 : 0.118179\n",
      "loss in epoch 8 , step 12480 : 1.501379\n",
      "loss in epoch 8 , step 12500 : 1.690643\n",
      "loss in epoch 8 , step 12520 : 1.326476\n",
      "loss in epoch 8 , step 12540 : 1.202710\n",
      "loss in epoch 8 , step 12560 : 1.850072\n",
      "loss in epoch 8 , step 12580 : 0.060138\n",
      "loss in epoch 8 , step 12600 : 1.263979\n",
      "loss in epoch 8 , step 12620 : 0.596428\n",
      "loss in epoch 8 , step 12640 : 1.555143\n",
      "loss in epoch 8 , step 12660 : 0.179555\n",
      "loss in epoch 8 , step 12680 : 0.257225\n",
      "loss in epoch 8 , step 12700 : 2.137053\n",
      "loss in epoch 8 , step 12720 : 0.751656\n",
      "loss in epoch 8 , step 12740 : 1.643669\n",
      "loss in epoch 8 , step 12760 : 1.041647\n",
      "loss in epoch 8 , step 12780 : 1.579245\n",
      "loss in epoch 8 , step 12800 : 1.874941\n",
      "loss in epoch 8 , step 12820 : 1.772744\n",
      "loss in epoch 8 , step 12840 : 1.822996\n",
      "loss in epoch 8 , step 12860 : 1.326893\n",
      "loss in epoch 8 , step 12880 : 5.544018\n",
      "loss in epoch 8 , step 12900 : 2.852811\n",
      "loss in epoch 8 , step 12920 : 0.998240\n",
      "loss in epoch 8 , step 12940 : 1.814282\n",
      "loss in epoch 8 , step 12960 : 0.565648\n",
      "loss in epoch 8 , step 12980 : 1.884647\n",
      "loss in epoch 8 , step 13000 : 0.520470\n",
      "loss in epoch 8 , step 13020 : 2.023308\n",
      "loss in epoch 8 , step 13040 : 1.097678\n",
      "loss in epoch 8 , step 13060 : 0.399831\n",
      "loss in epoch 8 , step 13080 : 0.198954\n",
      "loss in epoch 8 , step 13100 : 2.110334\n",
      "loss in epoch 8 , step 13120 : 1.322451\n",
      "loss in epoch 8 , step 13140 : 2.939476\n",
      "loss in epoch 8 , step 13160 : 0.042974\n",
      "loss in epoch 8 , step 13180 : 1.289268\n",
      "loss in epoch 8 , step 13200 : 0.258743\n",
      "loss in epoch 8 , step 13220 : 1.914796\n",
      "loss in epoch 8 , step 13240 : 3.156610\n",
      "loss in epoch 8 , step 13260 : 2.491424\n",
      "loss in epoch 8 , step 13280 : 0.620021\n",
      "loss in epoch 8 , step 13300 : 2.296818\n",
      "loss in epoch 8 , step 13320 : 1.999670\n",
      "loss in epoch 8 , step 13340 : 0.172193\n",
      "loss in epoch 8 , step 13360 : 0.327999\n",
      "loss in epoch 8 , step 13380 : 1.030006\n",
      "loss in epoch 8 , step 13400 : 3.045150\n",
      "loss in epoch 8 , step 13420 : 1.163253\n",
      "loss in epoch 8 , step 13440 : 0.158589\n",
      "loss in epoch 8 , step 13460 : 0.194943\n",
      "loss in epoch 8 , step 13480 : 0.208359\n",
      "loss in epoch 8 , step 13500 : 0.194312\n",
      "loss in epoch 8 , step 13520 : 2.191733\n",
      "loss in epoch 8 , step 13540 : 2.130960\n",
      "loss in epoch 8 , step 13560 : 0.875294\n",
      "loss in epoch 8 , step 13580 : 1.114861\n",
      "loss in epoch 8 , step 13600 : 1.318686\n",
      "loss in epoch 8 , step 13620 : 0.985390\n",
      "loss in epoch 8 , step 13640 : 0.023846\n",
      "loss in epoch 8 , step 13660 : 0.458167\n",
      "loss in epoch 8 , step 13680 : 0.870218\n",
      "loss in epoch 8 , step 13700 : 3.020423\n",
      "loss in epoch 8 , step 13720 : 0.130551\n",
      "loss in epoch 8 , step 13740 : 1.294965\n",
      "loss in epoch 8 , step 13760 : 2.104976\n",
      "loss in epoch 8 , step 13780 : 0.499866\n",
      "loss in epoch 8 , step 13800 : 1.637054\n",
      "loss in epoch 8 , step 13820 : 1.357538\n",
      "loss in epoch 8 , step 13840 : 1.241440\n",
      "loss in epoch 8 , step 13860 : 0.050205\n",
      "loss in epoch 8 , step 13880 : 1.451084\n",
      "loss in epoch 8 , step 13900 : 1.606464\n",
      "loss in epoch 8 , step 13920 : 0.014333\n",
      "loss in epoch 8 , step 13940 : 2.142496\n",
      "loss in epoch 8 , step 13960 : 0.272189\n",
      "loss in epoch 8 , step 13980 : 0.813863\n",
      "loss in epoch 8 , step 14000 : 0.809587\n",
      "loss in epoch 8 , step 14020 : 1.709918\n",
      "loss in epoch 8 , step 14040 : 0.934606\n",
      "loss in epoch 8 , step 14060 : 0.101588\n",
      "loss in epoch 8 , step 14080 : 1.586807\n",
      "loss in epoch 8 , step 14100 : 1.936757\n",
      "loss in epoch 8 , step 14120 : 0.198814\n",
      "loss in epoch 8 , step 14140 : 2.240292\n",
      "loss in epoch 8 , step 14160 : 3.284275\n",
      "loss in epoch 8 , step 14180 : 1.477749\n",
      "loss in epoch 8 , step 14200 : 0.013929\n",
      "loss in epoch 8 , step 14220 : 1.578675\n",
      "loss in epoch 8 , step 14240 : 0.416046\n",
      "loss in epoch 8 , step 14260 : 0.034077\n",
      "loss in epoch 8 , step 14280 : 2.317325\n",
      "loss in epoch 8 , step 14300 : 1.304252\n",
      "loss in epoch 8 , step 14320 : 1.083250\n",
      "loss in epoch 8 , step 14340 : 0.050371\n",
      "loss in epoch 8 , step 14360 : 1.274762\n",
      "loss in epoch 8 , step 14380 : 2.223863\n",
      "loss in epoch 8 , step 14400 : 0.780755\n",
      "loss in epoch 8 , step 14420 : 1.225708\n",
      "loss in epoch 8 , step 14440 : 0.172047\n",
      "loss in epoch 8 , step 14460 : 1.947857\n",
      "loss in epoch 8 , step 14480 : 1.902054\n",
      "loss in epoch 8 , step 14500 : 0.922135\n",
      "loss in epoch 8 , step 14520 : 0.670429\n",
      "loss in epoch 8 , step 14540 : 0.032551\n",
      "loss in epoch 8 , step 14560 : 1.178472\n",
      "loss in epoch 8 , step 14580 : 2.552138\n",
      "loss in epoch 8 , step 14600 : 1.378125\n",
      "loss in epoch 8 , step 14620 : 0.015671\n",
      "loss in epoch 8 , step 14640 : 0.975791\n",
      "loss in epoch 8 , step 14660 : 1.067160\n",
      "loss in epoch 8 , step 14680 : 1.548599\n",
      "loss in epoch 8 , step 14700 : 0.082265\n",
      "loss in epoch 8 , step 14720 : 0.737461\n",
      "loss in epoch 8 , step 14740 : 0.024263\n",
      "loss in epoch 8 , step 14760 : 1.283580\n",
      "loss in epoch 8 , step 14780 : 1.355479\n",
      "loss in epoch 8 , step 14800 : 0.521368\n",
      "loss in epoch 8 , step 14820 : 0.833532\n",
      "loss in epoch 8 , step 14840 : 0.815215\n",
      "loss in epoch 8 , step 14860 : 0.010767\n",
      "loss in epoch 8 , step 14880 : 0.556677\n",
      "loss in epoch 8 , step 14900 : 0.197802\n",
      "loss in epoch 8 , step 14920 : 0.883406\n",
      "loss in epoch 8 , step 14940 : 2.416371\n",
      "loss in epoch 8 , step 14960 : 1.414979\n",
      "loss in epoch 8 , step 14980 : 0.795727\n",
      "loss in epoch 8 , step 15000 : 1.889167\n",
      "loss in epoch 8 , step 15020 : 3.220437\n",
      "loss in epoch 8 , step 15040 : 0.617347\n",
      "loss in epoch 8 , step 15060 : 0.542871\n",
      "loss in epoch 8 , step 15080 : 0.074253\n",
      "loss in epoch 8 , step 15100 : 1.537041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 8 , step 15120 : 0.533162\n",
      "loss in epoch 8 , step 15140 : 0.502034\n",
      "loss in epoch 8 , step 15160 : 0.543552\n",
      "loss in epoch 8 , step 15180 : 0.809389\n",
      "loss in epoch 8 , step 15200 : 0.541054\n",
      "loss in epoch 8 , step 15220 : 2.354916\n",
      "loss in epoch 8 , step 15240 : 0.189493\n",
      "loss in epoch 8 , step 15260 : 0.373072\n",
      "loss in epoch 8 , step 15280 : 1.316746\n",
      "loss in epoch 8 , step 15300 : 2.772537\n",
      "loss in epoch 8 , step 15320 : 1.104843\n",
      "loss in epoch 8 , step 15340 : 2.741482\n",
      "loss in epoch 8 , step 15360 : 1.828862\n",
      "loss in epoch 8 , step 15380 : 0.024223\n",
      "loss in epoch 8 , step 15400 : 1.069497\n",
      "loss in epoch 8 , step 15420 : 0.444098\n",
      "loss in epoch 8 , step 15440 : 0.037552\n",
      "loss in epoch 8 , step 15460 : 1.549278\n",
      "loss in epoch 8 , step 15480 : 0.970614\n",
      "loss in epoch 8 , step 15500 : 2.049171\n",
      "loss in epoch 8 , step 15520 : 1.440368\n",
      "loss in epoch 8 , step 15540 : 1.397199\n",
      "loss in epoch 8 , step 15560 : 1.648145\n",
      "loss in epoch 8 , step 15580 : 2.547797\n",
      "loss in epoch 8 , step 15600 : 0.151522\n",
      "loss in epoch 8 , step 15620 : 2.717597\n",
      "loss in epoch 8 , step 15640 : 1.267230\n",
      "loss in epoch 8 , step 15660 : 0.364384\n",
      "loss in epoch 8 , step 15680 : 0.768797\n",
      "loss in epoch 8 , step 15700 : 1.464777\n",
      "loss in epoch 8 , step 15720 : 1.436352\n",
      "loss in epoch 8 , step 15740 : 0.688527\n",
      "loss in epoch 8 , step 15760 : 1.321398\n",
      "loss in epoch 8 , step 15780 : 0.184631\n",
      "loss in epoch 8 , step 15800 : 2.234954\n",
      "loss in epoch 8 , step 15820 : 0.911813\n",
      "loss in epoch 8 , step 15840 : 0.323431\n",
      "loss in epoch 8 , step 15860 : 0.364055\n",
      "loss in epoch 8 , step 15880 : 0.011054\n",
      "loss in epoch 8 , step 15900 : 2.351587\n",
      "loss in epoch 8 , step 15920 : 2.775612\n",
      "loss in epoch 8 , step 15940 : 1.278769\n",
      "loss in epoch 8 , step 15960 : 0.099112\n",
      "loss in epoch 8 , step 15980 : 1.226934\n",
      "loss in epoch 8 , step 16000 : 3.171252\n",
      "loss in epoch 8 , step 16020 : 0.302172\n",
      "loss in epoch 8 , step 16040 : 1.600083\n",
      "loss in epoch 8 , step 16060 : 2.133761\n",
      "loss in epoch 8 , step 16080 : 1.634600\n",
      "loss in epoch 8 , step 16100 : 0.005428\n",
      "loss in epoch 8 , step 16120 : 1.887516\n",
      "loss in epoch 8 , step 16140 : 1.187626\n",
      "loss in epoch 8 , step 16160 : 0.979134\n",
      "loss in epoch 8 , step 16180 : 0.165509\n",
      "loss in epoch 8 , step 16200 : 0.171902\n",
      "loss in epoch 8 , step 16220 : 2.937273\n",
      "loss in epoch 8 , step 16240 : 0.332257\n",
      "loss in epoch 8 , step 16260 : 1.877152\n",
      "loss in epoch 8 , step 16280 : 0.507315\n",
      "loss in epoch 8 , step 16300 : 1.088524\n",
      "loss in epoch 8 , step 16320 : 0.122148\n",
      "loss in epoch 8 , step 16340 : 1.832409\n",
      "loss in epoch 8 , step 16360 : 0.035399\n",
      "loss in epoch 8 , step 16380 : 1.746007\n",
      "loss in epoch 8 , step 16400 : 0.390615\n",
      "loss in epoch 8 , step 16420 : 0.013424\n",
      "loss in epoch 8 , step 16440 : 0.161765\n",
      "loss in epoch 8 , step 16460 : 1.680221\n",
      "loss in epoch 8 , step 16480 : 1.880207\n",
      "loss in epoch 8 , step 16500 : 0.785060\n",
      "loss in epoch 8 , step 16520 : 4.023428\n",
      "loss in epoch 8 , step 16540 : 0.959513\n",
      "loss in epoch 8 , step 16560 : 1.657480\n",
      "loss in epoch 8 , step 16580 : 1.044217\n",
      "loss in epoch 8 , step 16600 : 0.771706\n",
      "loss in epoch 8 , step 16620 : 1.228424\n",
      "loss in epoch 8 , step 16640 : 2.550009\n",
      "loss in epoch 8 , step 16660 : 1.855946\n",
      "loss in epoch 8 , step 16680 : 0.686927\n",
      "loss in epoch 8 , step 16700 : 1.336581\n",
      "loss in epoch 8 , step 16720 : 1.564420\n",
      "loss in epoch 8 , step 16740 : 0.161758\n",
      "loss in epoch 8 , step 16760 : 1.354939\n",
      "loss in epoch 8 , step 16780 : 2.098207\n",
      "loss in epoch 8 , step 16800 : 3.244500\n",
      "loss in epoch 8 , step 16820 : 1.411590\n",
      "loss in epoch 8 , step 16840 : 0.016534\n",
      "loss in epoch 8 , step 16860 : 1.727457\n",
      "loss in epoch 8 , step 16880 : 1.699264\n",
      "loss in epoch 8 , step 16900 : 1.935886\n",
      "loss in epoch 8 , step 16920 : 2.643816\n",
      "loss in epoch 8 , step 16940 : 1.014300\n",
      "loss in epoch 8 , step 16960 : 1.361233\n",
      "loss in epoch 8 , step 16980 : 1.735926\n",
      "loss in epoch 8 , step 17000 : 2.005811\n",
      "loss in epoch 8 , step 17020 : 1.033615\n",
      "loss in epoch 8 , step 17040 : 0.048929\n",
      "loss in epoch 8 , step 17060 : 0.068165\n",
      "loss in epoch 8 , step 17080 : 0.040127\n",
      "loss in epoch 8 , step 17100 : 0.089858\n",
      "loss in epoch 8 , step 17120 : 1.646920\n",
      "loss in epoch 8 , step 17140 : 1.032914\n",
      "loss in epoch 8 , step 17160 : 0.303172\n",
      "loss in epoch 8 , step 17180 : 1.080686\n",
      "loss in epoch 8 , step 17200 : 1.311876\n",
      "loss in epoch 8 , step 17220 : 1.915157\n",
      "loss in epoch 8 , step 17240 : 1.834181\n",
      "loss in epoch 8 , step 17260 : 0.919287\n",
      "loss in epoch 8 , step 17280 : 0.794536\n",
      "loss in epoch 8 , step 17300 : 2.323272\n",
      "loss in epoch 8 , step 17320 : 0.362476\n",
      "loss in epoch 8 , step 17340 : 0.081349\n",
      "loss in epoch 8 , step 17360 : 0.560592\n",
      "loss in epoch 8 , step 17380 : 1.449209\n",
      "loss in epoch 8 , step 17400 : 1.729160\n",
      "loss in epoch 8 , step 17420 : 0.777742\n",
      "loss in epoch 8 , step 17440 : 1.977032\n",
      "loss in epoch 8 , step 17460 : 1.476924\n",
      "loss in epoch 8 , step 17480 : 1.210054\n",
      "loss in epoch 8 , step 17500 : 2.031425\n",
      "loss in epoch 8 , step 17520 : 2.042306\n",
      "loss in epoch 8 , step 17540 : 1.243224\n",
      "loss in epoch 8 , step 17560 : 0.007985\n",
      "loss in epoch 8 , step 17580 : 0.976152\n",
      "loss in epoch 8 , step 17600 : 0.889504\n",
      "loss in epoch 8 , step 17620 : 1.466326\n",
      "loss in epoch 8 , step 17640 : 2.720742\n",
      "loss in epoch 8 , step 17660 : 0.029823\n",
      "loss in epoch 8 , step 17680 : 1.863025\n",
      "loss in epoch 8 , step 17700 : 1.242257\n",
      "loss in epoch 8 , step 17720 : 1.243268\n",
      "loss in epoch 8 , step 17740 : 0.066650\n",
      "loss in epoch 8 , step 17760 : 1.412742\n",
      "loss in epoch 8 , step 17780 : 0.011514\n",
      "loss in epoch 8 , step 17800 : 0.391815\n",
      "loss in epoch 8 , step 17820 : 0.097163\n",
      "loss in epoch 8 , step 17840 : 0.120166\n",
      "loss in epoch 8 , step 17860 : 1.983008\n",
      "loss in epoch 8 , step 17880 : 0.855436\n",
      "loss in epoch 8 , step 17900 : 3.170909\n",
      "loss in epoch 8 , step 17920 : 0.653825\n",
      "loss in epoch 8 , step 17940 : 1.620402\n",
      "loss in epoch 8 , step 17960 : 1.463529\n",
      "loss in epoch 8 , step 17980 : 1.544627\n",
      "loss in epoch 8 , step 18000 : 1.508095\n",
      "loss in epoch 8 , step 18020 : 4.592071\n",
      "loss in epoch 8 , step 18040 : 0.701850\n",
      "loss in epoch 8 , step 18060 : 1.781622\n",
      "loss in epoch 8 , step 18080 : 1.633239\n",
      "loss in epoch 8 , step 18100 : 2.198011\n",
      "loss in epoch 8 , step 18120 : 0.196479\n",
      "loss in epoch 8 , step 18140 : 0.376793\n",
      "loss in epoch 8 , step 18160 : 0.139274\n",
      "loss in epoch 8 , step 18180 : 0.421850\n",
      "loss in epoch 8 , step 18200 : 1.446158\n",
      "loss in epoch 8 , step 18220 : 1.417416\n",
      "loss in epoch 8 , step 18240 : 1.109657\n",
      "loss in epoch 8 , step 18260 : 0.196736\n",
      "loss in epoch 8 , step 18280 : 1.962042\n",
      "loss in epoch 8 , step 18300 : 1.079827\n",
      "loss in epoch 8 , step 18320 : 0.086298\n",
      "loss in epoch 8 , step 18340 : 0.470094\n",
      "loss in epoch 8 , step 18360 : 1.094372\n",
      "loss in epoch 8 , step 18380 : 1.429240\n",
      "loss in epoch 8 , step 18400 : 0.473659\n",
      "loss in epoch 8 , step 18420 : 1.216479\n",
      "loss in epoch 8 , step 18440 : 1.978699\n",
      "loss in epoch 8 , step 18460 : 1.211488\n",
      "loss in epoch 8 , step 18480 : 0.969845\n",
      "loss in epoch 8 , step 18500 : 1.403083\n",
      "loss in epoch 8 , step 18520 : 0.255129\n",
      "loss in epoch 8 , step 18540 : 1.952962\n",
      "loss in epoch 8 , step 18560 : 1.075129\n",
      "loss in epoch 8 , step 18580 : 0.997028\n",
      "loss in epoch 8 , step 18600 : 0.136879\n",
      "loss in epoch 8 , step 18620 : 0.364185\n",
      "loss in epoch 8 , step 18640 : 1.206690\n",
      "loss in epoch 8 , step 18660 : 0.184782\n",
      "loss in epoch 8 , step 18680 : 0.433066\n",
      "loss in epoch 8 , step 18700 : 0.098062\n",
      "loss in epoch 8 , step 18720 : 2.098518\n",
      "loss in epoch 8 , step 18740 : 0.867462\n",
      "loss in epoch 8 , step 18760 : 0.316794\n",
      "loss in epoch 8 , step 18780 : 0.004001\n",
      "loss in epoch 8 , step 18800 : 1.618232\n",
      "loss in epoch 8 , step 18820 : 1.418057\n",
      "loss in epoch 8 , step 18840 : 0.830763\n",
      "loss in epoch 8 , step 18860 : 1.312067\n",
      "loss in epoch 8 , step 18880 : 0.039561\n",
      "loss in epoch 8 , step 18900 : 3.260777\n",
      "loss in epoch 8 , step 18920 : 0.012340\n",
      "loss in epoch 8 , step 18940 : 0.009844\n",
      "loss in epoch 8 , step 18960 : 0.708129\n",
      "loss in epoch 8 , step 18980 : 1.152930\n",
      "loss in epoch 8 , step 19000 : 1.410877\n",
      "loss in epoch 8 , step 19020 : 0.750609\n",
      "loss in epoch 8 , step 19040 : 2.240871\n",
      "loss in epoch 8 , step 19060 : 1.503000\n",
      "loss in epoch 8 , step 19080 : 0.023128\n",
      "loss in epoch 8 , step 19100 : 1.589831\n",
      "loss in epoch 8 , step 19120 : 2.518586\n",
      "loss in epoch 8 , step 19140 : 1.170712\n",
      "loss in epoch 8 , step 19160 : 2.440027\n",
      "loss in epoch 8 , step 19180 : 1.710192\n",
      "loss in epoch 8 , step 19200 : 0.071356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 8 , step 19220 : 1.467769\n",
      "loss in epoch 8 , step 19240 : 1.838906\n",
      "loss in epoch 8 , step 19260 : 0.931735\n",
      "loss in epoch 8 , step 19280 : 1.802085\n",
      "loss in epoch 8 , step 19300 : 1.483433\n",
      "loss in epoch 8 , step 19320 : 0.095103\n",
      "loss in epoch 8 , step 19340 : 1.181018\n",
      "loss in epoch 8 , step 19360 : 1.525443\n",
      "loss in epoch 8 , step 19380 : 0.940131\n",
      "loss in epoch 8 , step 19400 : 0.998281\n",
      "loss in epoch 8 , step 19420 : 2.485288\n",
      "loss in epoch 8 , step 19440 : 1.149635\n",
      "loss in epoch 8 , step 19460 : 2.341866\n",
      "loss in epoch 8 , step 19480 : 1.054639\n",
      "loss in epoch 8 , step 19500 : 0.336738\n",
      "loss in epoch 8 , step 19520 : 0.743606\n",
      "loss in epoch 8 , step 19540 : 3.464982\n",
      "loss in epoch 8 , step 19560 : 1.812173\n",
      "loss in epoch 8 , step 19580 : 1.264838\n",
      "loss in epoch 8 , step 19600 : 1.320792\n",
      "loss in epoch 8 , step 19620 : 1.039930\n",
      "loss in epoch 8 , step 19640 : 0.205715\n",
      "loss in epoch 8 , step 19660 : 2.023851\n",
      "loss in epoch 8 , step 19680 : 0.741681\n",
      "loss in epoch 8 , step 19700 : 0.809097\n",
      "loss in epoch 8 , step 19720 : 2.318453\n",
      "loss in epoch 8 , step 19740 : 1.812704\n",
      "loss in epoch 8 , step 19760 : 1.212814\n",
      "loss in epoch 8 , step 19780 : 1.431543\n",
      "loss in epoch 8 , step 19800 : 0.085087\n",
      "loss in epoch 8 , step 19820 : 0.498376\n",
      "loss in epoch 8 , step 19840 : 0.268659\n",
      "loss in epoch 8 , step 19860 : 0.400006\n",
      "loss in epoch 8 , step 19880 : 1.169072\n",
      "loss in epoch 8 , step 19900 : 1.753691\n",
      "loss in epoch 8 , step 19920 : 0.826603\n",
      "loss in epoch 8 , step 19940 : 0.019921\n",
      "Accuracy in epoch 8 : 26.719778\n",
      "loss in epoch 9 , step 0 : 0.903954\n",
      "loss in epoch 9 , step 20 : 0.243122\n",
      "loss in epoch 9 , step 40 : 2.151600\n",
      "loss in epoch 9 , step 60 : 1.632460\n",
      "loss in epoch 9 , step 80 : 1.599150\n",
      "loss in epoch 9 , step 100 : 4.076579\n",
      "loss in epoch 9 , step 120 : 1.110267\n",
      "loss in epoch 9 , step 140 : 0.148716\n",
      "loss in epoch 9 , step 160 : 1.541867\n",
      "loss in epoch 9 , step 180 : 0.759181\n",
      "loss in epoch 9 , step 200 : 0.249432\n",
      "loss in epoch 9 , step 220 : 1.788041\n",
      "loss in epoch 9 , step 240 : 1.096922\n",
      "loss in epoch 9 , step 260 : 0.238231\n",
      "loss in epoch 9 , step 280 : 1.165078\n",
      "loss in epoch 9 , step 300 : 1.337339\n",
      "loss in epoch 9 , step 320 : 0.721928\n",
      "loss in epoch 9 , step 340 : 2.973423\n",
      "loss in epoch 9 , step 360 : 0.610747\n",
      "loss in epoch 9 , step 380 : 1.304015\n",
      "loss in epoch 9 , step 400 : 0.580343\n",
      "loss in epoch 9 , step 420 : 0.106941\n",
      "loss in epoch 9 , step 440 : 0.133168\n",
      "loss in epoch 9 , step 460 : 1.110084\n",
      "loss in epoch 9 , step 480 : 0.035468\n",
      "loss in epoch 9 , step 500 : 1.041374\n",
      "loss in epoch 9 , step 520 : 1.343851\n",
      "loss in epoch 9 , step 540 : 0.035003\n",
      "loss in epoch 9 , step 560 : 0.868526\n",
      "loss in epoch 9 , step 580 : 0.572049\n",
      "loss in epoch 9 , step 600 : 1.774530\n",
      "loss in epoch 9 , step 620 : 1.579996\n",
      "loss in epoch 9 , step 640 : 2.684370\n",
      "loss in epoch 9 , step 660 : 1.497258\n",
      "loss in epoch 9 , step 680 : 0.238856\n",
      "loss in epoch 9 , step 700 : 0.952003\n",
      "loss in epoch 9 , step 720 : 1.828302\n",
      "loss in epoch 9 , step 740 : 1.178257\n",
      "loss in epoch 9 , step 760 : 0.142777\n",
      "loss in epoch 9 , step 780 : 3.163972\n",
      "loss in epoch 9 , step 800 : 1.206268\n",
      "loss in epoch 9 , step 820 : 0.525768\n",
      "loss in epoch 9 , step 840 : 0.545884\n",
      "loss in epoch 9 , step 860 : 2.275255\n",
      "loss in epoch 9 , step 880 : 1.245901\n",
      "loss in epoch 9 , step 900 : 1.655685\n",
      "loss in epoch 9 , step 920 : 1.035328\n",
      "loss in epoch 9 , step 940 : 0.708531\n",
      "loss in epoch 9 , step 960 : 1.043833\n",
      "loss in epoch 9 , step 980 : 0.320111\n",
      "loss in epoch 9 , step 1000 : 1.710577\n",
      "loss in epoch 9 , step 1020 : 0.047474\n",
      "loss in epoch 9 , step 1040 : 2.260737\n",
      "loss in epoch 9 , step 1060 : 1.178242\n",
      "loss in epoch 9 , step 1080 : 0.994899\n",
      "loss in epoch 9 , step 1100 : 2.124313\n",
      "loss in epoch 9 , step 1120 : 0.434263\n",
      "loss in epoch 9 , step 1140 : 0.423830\n",
      "loss in epoch 9 , step 1160 : 1.457742\n",
      "loss in epoch 9 , step 1180 : 1.748587\n",
      "loss in epoch 9 , step 1200 : 0.916986\n",
      "loss in epoch 9 , step 1220 : 1.874042\n",
      "loss in epoch 9 , step 1240 : 0.591960\n",
      "loss in epoch 9 , step 1260 : 0.005497\n",
      "loss in epoch 9 , step 1280 : 1.386564\n",
      "loss in epoch 9 , step 1300 : 1.117071\n",
      "loss in epoch 9 , step 1320 : 0.808196\n",
      "loss in epoch 9 , step 1340 : 1.523761\n",
      "loss in epoch 9 , step 1360 : 1.689459\n",
      "loss in epoch 9 , step 1380 : 2.174919\n",
      "loss in epoch 9 , step 1400 : 0.019941\n",
      "loss in epoch 9 , step 1420 : 1.127450\n",
      "loss in epoch 9 , step 1440 : 1.114496\n",
      "loss in epoch 9 , step 1460 : 1.123783\n",
      "loss in epoch 9 , step 1480 : 0.146151\n",
      "loss in epoch 9 , step 1500 : 1.169761\n",
      "loss in epoch 9 , step 1520 : 1.035952\n",
      "loss in epoch 9 , step 1540 : 0.623309\n",
      "loss in epoch 9 , step 1560 : 0.276594\n",
      "loss in epoch 9 , step 1580 : 2.181846\n",
      "loss in epoch 9 , step 1600 : 2.917702\n",
      "loss in epoch 9 , step 1620 : 2.698859\n",
      "loss in epoch 9 , step 1640 : 0.674514\n",
      "loss in epoch 9 , step 1660 : 3.251854\n",
      "loss in epoch 9 , step 1680 : 2.021674\n",
      "loss in epoch 9 , step 1700 : 0.003126\n",
      "loss in epoch 9 , step 1720 : 0.675437\n",
      "loss in epoch 9 , step 1740 : 1.834709\n",
      "loss in epoch 9 , step 1760 : 1.275736\n",
      "loss in epoch 9 , step 1780 : 0.044173\n",
      "loss in epoch 9 , step 1800 : 0.823193\n",
      "loss in epoch 9 , step 1820 : 2.667398\n",
      "loss in epoch 9 , step 1840 : 0.637953\n",
      "loss in epoch 9 , step 1860 : 0.086935\n",
      "loss in epoch 9 , step 1880 : 1.916381\n",
      "loss in epoch 9 , step 1900 : 0.695989\n",
      "loss in epoch 9 , step 1920 : 0.850824\n",
      "loss in epoch 9 , step 1940 : 0.685022\n",
      "loss in epoch 9 , step 1960 : 1.309794\n",
      "loss in epoch 9 , step 1980 : 0.666852\n",
      "loss in epoch 9 , step 2000 : 1.316395\n",
      "loss in epoch 9 , step 2020 : 1.645070\n",
      "loss in epoch 9 , step 2040 : 1.184001\n",
      "loss in epoch 9 , step 2060 : 1.274675\n",
      "loss in epoch 9 , step 2080 : 0.463730\n",
      "loss in epoch 9 , step 2100 : 0.610442\n",
      "loss in epoch 9 , step 2120 : 0.787102\n",
      "loss in epoch 9 , step 2140 : 1.815321\n",
      "loss in epoch 9 , step 2160 : 0.116837\n",
      "loss in epoch 9 , step 2180 : 2.152853\n",
      "loss in epoch 9 , step 2200 : 0.258911\n",
      "loss in epoch 9 , step 2220 : 0.006073\n",
      "loss in epoch 9 , step 2240 : 1.075471\n",
      "loss in epoch 9 , step 2260 : 1.947455\n",
      "loss in epoch 9 , step 2280 : 1.949711\n",
      "loss in epoch 9 , step 2300 : 3.137206\n",
      "loss in epoch 9 , step 2320 : 3.371240\n",
      "loss in epoch 9 , step 2340 : 2.950581\n",
      "loss in epoch 9 , step 2360 : 1.403906\n",
      "loss in epoch 9 , step 2380 : 1.250011\n",
      "loss in epoch 9 , step 2400 : 0.695977\n",
      "loss in epoch 9 , step 2420 : 0.704514\n",
      "loss in epoch 9 , step 2440 : 0.129771\n",
      "loss in epoch 9 , step 2460 : 0.824509\n",
      "loss in epoch 9 , step 2480 : 0.471104\n",
      "loss in epoch 9 , step 2500 : 0.429913\n",
      "loss in epoch 9 , step 2520 : 1.375359\n",
      "loss in epoch 9 , step 2540 : 0.316055\n",
      "loss in epoch 9 , step 2560 : 1.537849\n",
      "loss in epoch 9 , step 2580 : 1.163794\n",
      "loss in epoch 9 , step 2600 : 0.412922\n",
      "loss in epoch 9 , step 2620 : 1.965117\n",
      "loss in epoch 9 , step 2640 : 0.282678\n",
      "loss in epoch 9 , step 2660 : 1.558204\n",
      "loss in epoch 9 , step 2680 : 1.169520\n",
      "loss in epoch 9 , step 2700 : 1.154552\n",
      "loss in epoch 9 , step 2720 : 0.312422\n",
      "loss in epoch 9 , step 2740 : 1.305907\n",
      "loss in epoch 9 , step 2760 : 1.524695\n",
      "loss in epoch 9 , step 2780 : 0.152469\n",
      "loss in epoch 9 , step 2800 : 0.291675\n",
      "loss in epoch 9 , step 2820 : 0.021507\n",
      "loss in epoch 9 , step 2840 : 1.675341\n",
      "loss in epoch 9 , step 2860 : 0.261392\n",
      "loss in epoch 9 , step 2880 : 2.648651\n",
      "loss in epoch 9 , step 2900 : 0.362844\n",
      "loss in epoch 9 , step 2920 : 1.345409\n",
      "loss in epoch 9 , step 2940 : 0.307959\n",
      "loss in epoch 9 , step 2960 : 1.571326\n",
      "loss in epoch 9 , step 2980 : 0.657066\n",
      "loss in epoch 9 , step 3000 : 0.005431\n",
      "loss in epoch 9 , step 3020 : 1.109200\n",
      "loss in epoch 9 , step 3040 : 1.903629\n",
      "loss in epoch 9 , step 3060 : 0.479876\n",
      "loss in epoch 9 , step 3080 : 1.200993\n",
      "loss in epoch 9 , step 3100 : 0.017402\n",
      "loss in epoch 9 , step 3120 : 1.980901\n",
      "loss in epoch 9 , step 3140 : 0.129808\n",
      "loss in epoch 9 , step 3160 : 1.468199\n",
      "loss in epoch 9 , step 3180 : 0.300215\n",
      "loss in epoch 9 , step 3200 : 2.004165\n",
      "loss in epoch 9 , step 3220 : 0.980958\n",
      "loss in epoch 9 , step 3240 : 0.982788\n",
      "loss in epoch 9 , step 3260 : 0.025506\n",
      "loss in epoch 9 , step 3280 : 0.314995\n",
      "loss in epoch 9 , step 3300 : 1.510960\n",
      "loss in epoch 9 , step 3320 : 0.112477\n",
      "loss in epoch 9 , step 3340 : 2.305999\n",
      "loss in epoch 9 , step 3360 : 0.045929\n",
      "loss in epoch 9 , step 3380 : 0.217659\n",
      "loss in epoch 9 , step 3400 : 1.459490\n",
      "loss in epoch 9 , step 3420 : 0.614043\n",
      "loss in epoch 9 , step 3440 : 1.397056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 9 , step 3460 : 0.310746\n",
      "loss in epoch 9 , step 3480 : 0.760346\n",
      "loss in epoch 9 , step 3500 : 0.140623\n",
      "loss in epoch 9 , step 3520 : 1.371818\n",
      "loss in epoch 9 , step 3540 : 0.181037\n",
      "loss in epoch 9 , step 3560 : 1.452297\n",
      "loss in epoch 9 , step 3580 : 2.695823\n",
      "loss in epoch 9 , step 3600 : 1.336110\n",
      "loss in epoch 9 , step 3620 : 2.372653\n",
      "loss in epoch 9 , step 3640 : 0.914375\n",
      "loss in epoch 9 , step 3660 : 2.090090\n",
      "loss in epoch 9 , step 3680 : 0.992649\n",
      "loss in epoch 9 , step 3700 : 0.028729\n",
      "loss in epoch 9 , step 3720 : 1.377210\n",
      "loss in epoch 9 , step 3740 : 0.984169\n",
      "loss in epoch 9 , step 3760 : 0.473760\n",
      "loss in epoch 9 , step 3780 : 2.035304\n",
      "loss in epoch 9 , step 3800 : 0.766631\n",
      "loss in epoch 9 , step 3820 : 0.114239\n",
      "loss in epoch 9 , step 3840 : 0.837452\n",
      "loss in epoch 9 , step 3860 : 2.493206\n",
      "loss in epoch 9 , step 3880 : 0.759216\n",
      "loss in epoch 9 , step 3900 : 0.552015\n",
      "loss in epoch 9 , step 3920 : 2.176383\n",
      "loss in epoch 9 , step 3940 : 2.028067\n",
      "loss in epoch 9 , step 3960 : 1.625191\n",
      "loss in epoch 9 , step 3980 : 0.074893\n",
      "loss in epoch 9 , step 4000 : 0.245925\n",
      "loss in epoch 9 , step 4020 : 1.422551\n",
      "loss in epoch 9 , step 4040 : 1.151245\n",
      "loss in epoch 9 , step 4060 : 1.270016\n",
      "loss in epoch 9 , step 4080 : 1.616906\n",
      "loss in epoch 9 , step 4100 : 2.425979\n",
      "loss in epoch 9 , step 4120 : 1.171399\n",
      "loss in epoch 9 , step 4140 : 0.988769\n",
      "loss in epoch 9 , step 4160 : 0.126509\n",
      "loss in epoch 9 , step 4180 : 0.539659\n",
      "loss in epoch 9 , step 4200 : 1.347261\n",
      "loss in epoch 9 , step 4220 : 1.818182\n",
      "loss in epoch 9 , step 4240 : 2.806161\n",
      "loss in epoch 9 , step 4260 : 0.085335\n",
      "loss in epoch 9 , step 4280 : 0.042585\n",
      "loss in epoch 9 , step 4300 : 0.680080\n",
      "loss in epoch 9 , step 4320 : 1.103549\n",
      "loss in epoch 9 , step 4340 : 1.890642\n",
      "loss in epoch 9 , step 4360 : 1.221730\n",
      "loss in epoch 9 , step 4380 : 0.102233\n",
      "loss in epoch 9 , step 4400 : 0.068251\n",
      "loss in epoch 9 , step 4420 : 2.266543\n",
      "loss in epoch 9 , step 4440 : 0.013748\n",
      "loss in epoch 9 , step 4460 : 0.012055\n",
      "loss in epoch 9 , step 4480 : 0.655155\n",
      "loss in epoch 9 , step 4500 : 0.207702\n",
      "loss in epoch 9 , step 4520 : 1.139249\n",
      "loss in epoch 9 , step 4540 : 1.120179\n",
      "loss in epoch 9 , step 4560 : 1.442902\n",
      "loss in epoch 9 , step 4580 : 0.700441\n",
      "loss in epoch 9 , step 4600 : 0.569000\n",
      "loss in epoch 9 , step 4620 : 0.154501\n",
      "loss in epoch 9 , step 4640 : 0.851452\n",
      "loss in epoch 9 , step 4660 : 1.810283\n",
      "loss in epoch 9 , step 4680 : 1.506877\n",
      "loss in epoch 9 , step 4700 : 1.023184\n",
      "loss in epoch 9 , step 4720 : 0.586614\n",
      "loss in epoch 9 , step 4740 : 1.129814\n",
      "loss in epoch 9 , step 4760 : 1.859100\n",
      "loss in epoch 9 , step 4780 : 0.228222\n",
      "loss in epoch 9 , step 4800 : 2.329576\n",
      "loss in epoch 9 , step 4820 : 1.035294\n",
      "loss in epoch 9 , step 4840 : 0.036075\n",
      "loss in epoch 9 , step 4860 : 0.400270\n",
      "loss in epoch 9 , step 4880 : 1.799368\n",
      "loss in epoch 9 , step 4900 : 0.021985\n",
      "loss in epoch 9 , step 4920 : 1.630157\n",
      "loss in epoch 9 , step 4940 : 0.071465\n",
      "loss in epoch 9 , step 4960 : 0.813022\n",
      "loss in epoch 9 , step 4980 : 0.510807\n",
      "loss in epoch 9 , step 5000 : 0.863506\n",
      "loss in epoch 9 , step 5020 : 2.517578\n",
      "loss in epoch 9 , step 5040 : 1.469490\n",
      "loss in epoch 9 , step 5060 : 2.352244\n",
      "loss in epoch 9 , step 5080 : 1.221770\n",
      "loss in epoch 9 , step 5100 : 1.942925\n",
      "loss in epoch 9 , step 5120 : 1.925541\n",
      "loss in epoch 9 , step 5140 : 0.538896\n",
      "loss in epoch 9 , step 5160 : 0.056759\n",
      "loss in epoch 9 , step 5180 : 1.340872\n",
      "loss in epoch 9 , step 5200 : 0.127945\n",
      "loss in epoch 9 , step 5220 : 1.430505\n",
      "loss in epoch 9 , step 5240 : 0.908773\n",
      "loss in epoch 9 , step 5260 : 0.019563\n",
      "loss in epoch 9 , step 5280 : 0.451619\n",
      "loss in epoch 9 , step 5300 : 0.755726\n",
      "loss in epoch 9 , step 5320 : 1.458088\n",
      "loss in epoch 9 , step 5340 : 1.163575\n",
      "loss in epoch 9 , step 5360 : 0.399053\n",
      "loss in epoch 9 , step 5380 : 1.625783\n",
      "loss in epoch 9 , step 5400 : 0.461415\n",
      "loss in epoch 9 , step 5420 : 0.565973\n",
      "loss in epoch 9 , step 5440 : 0.027988\n",
      "loss in epoch 9 , step 5460 : 1.289642\n",
      "loss in epoch 9 , step 5480 : 0.975391\n",
      "loss in epoch 9 , step 5500 : 1.104274\n",
      "loss in epoch 9 , step 5520 : 1.447554\n",
      "loss in epoch 9 , step 5540 : 2.173639\n",
      "loss in epoch 9 , step 5560 : 0.196114\n",
      "loss in epoch 9 , step 5580 : 1.778010\n",
      "loss in epoch 9 , step 5600 : 2.223393\n",
      "loss in epoch 9 , step 5620 : 0.904393\n",
      "loss in epoch 9 , step 5640 : 0.723627\n",
      "loss in epoch 9 , step 5660 : 0.700311\n",
      "loss in epoch 9 , step 5680 : 0.630302\n",
      "loss in epoch 9 , step 5700 : 1.645983\n",
      "loss in epoch 9 , step 5720 : 2.996163\n",
      "loss in epoch 9 , step 5740 : 0.470493\n",
      "loss in epoch 9 , step 5760 : 0.059446\n",
      "loss in epoch 9 , step 5780 : 1.202480\n",
      "loss in epoch 9 , step 5800 : 1.645008\n",
      "loss in epoch 9 , step 5820 : 1.554658\n",
      "loss in epoch 9 , step 5840 : 0.055520\n",
      "loss in epoch 9 , step 5860 : 0.178298\n",
      "loss in epoch 9 , step 5880 : 2.100986\n",
      "loss in epoch 9 , step 5900 : 1.202909\n",
      "loss in epoch 9 , step 5920 : 0.098048\n",
      "loss in epoch 9 , step 5940 : 0.546305\n",
      "loss in epoch 9 , step 5960 : 1.450193\n",
      "loss in epoch 9 , step 5980 : 0.113991\n",
      "loss in epoch 9 , step 6000 : 1.630821\n",
      "loss in epoch 9 , step 6020 : 1.773287\n",
      "loss in epoch 9 , step 6040 : 0.268264\n",
      "loss in epoch 9 , step 6060 : 0.941718\n",
      "loss in epoch 9 , step 6080 : 2.044929\n",
      "loss in epoch 9 , step 6100 : 0.710435\n",
      "loss in epoch 9 , step 6120 : 0.467097\n",
      "loss in epoch 9 , step 6140 : 1.011694\n",
      "loss in epoch 9 , step 6160 : 0.717484\n",
      "loss in epoch 9 , step 6180 : 1.076052\n",
      "loss in epoch 9 , step 6200 : 0.300785\n",
      "loss in epoch 9 , step 6220 : 1.562430\n",
      "loss in epoch 9 , step 6240 : 1.540871\n",
      "loss in epoch 9 , step 6260 : 2.284098\n",
      "loss in epoch 9 , step 6280 : 1.852618\n",
      "loss in epoch 9 , step 6300 : 3.078264\n",
      "loss in epoch 9 , step 6320 : 1.115486\n",
      "loss in epoch 9 , step 6340 : 0.081857\n",
      "loss in epoch 9 , step 6360 : 1.059149\n",
      "loss in epoch 9 , step 6380 : 0.870890\n",
      "loss in epoch 9 , step 6400 : 1.758746\n",
      "loss in epoch 9 , step 6420 : 2.436330\n",
      "loss in epoch 9 , step 6440 : 2.170431\n",
      "loss in epoch 9 , step 6460 : 0.727737\n",
      "loss in epoch 9 , step 6480 : 0.963959\n",
      "loss in epoch 9 , step 6500 : 1.698977\n",
      "loss in epoch 9 , step 6520 : 0.557175\n",
      "loss in epoch 9 , step 6540 : 1.566273\n",
      "loss in epoch 9 , step 6560 : 0.306668\n",
      "loss in epoch 9 , step 6580 : 0.228062\n",
      "loss in epoch 9 , step 6600 : 0.748607\n",
      "loss in epoch 9 , step 6620 : 2.872336\n",
      "loss in epoch 9 , step 6640 : 0.023409\n",
      "loss in epoch 9 , step 6660 : 1.525225\n",
      "loss in epoch 9 , step 6680 : 0.517641\n",
      "loss in epoch 9 , step 6700 : 1.669385\n",
      "loss in epoch 9 , step 6720 : 1.447356\n",
      "loss in epoch 9 , step 6740 : 2.618888\n",
      "loss in epoch 9 , step 6760 : 1.346391\n",
      "loss in epoch 9 , step 6780 : 0.351735\n",
      "loss in epoch 9 , step 6800 : 1.365954\n",
      "loss in epoch 9 , step 6820 : 2.007618\n",
      "loss in epoch 9 , step 6840 : 1.659551\n",
      "loss in epoch 9 , step 6860 : 1.673349\n",
      "loss in epoch 9 , step 6880 : 1.830730\n",
      "loss in epoch 9 , step 6900 : 1.914597\n",
      "loss in epoch 9 , step 6920 : 2.198745\n",
      "loss in epoch 9 , step 6940 : 0.414795\n",
      "loss in epoch 9 , step 6960 : 0.988369\n",
      "loss in epoch 9 , step 6980 : 2.395118\n",
      "loss in epoch 9 , step 7000 : 1.551151\n",
      "loss in epoch 9 , step 7020 : 0.308963\n",
      "loss in epoch 9 , step 7040 : 1.998701\n",
      "loss in epoch 9 , step 7060 : 0.327759\n",
      "loss in epoch 9 , step 7080 : 1.306398\n",
      "loss in epoch 9 , step 7100 : 3.302104\n",
      "loss in epoch 9 , step 7120 : 1.646040\n",
      "loss in epoch 9 , step 7140 : 0.987182\n",
      "loss in epoch 9 , step 7160 : 1.949507\n",
      "loss in epoch 9 , step 7180 : 0.799363\n",
      "loss in epoch 9 , step 7200 : 0.260233\n",
      "loss in epoch 9 , step 7220 : 0.289971\n",
      "loss in epoch 9 , step 7240 : 1.171897\n",
      "loss in epoch 9 , step 7260 : 1.186908\n",
      "loss in epoch 9 , step 7280 : 0.321031\n",
      "loss in epoch 9 , step 7300 : 1.394624\n",
      "loss in epoch 9 , step 7320 : 0.336077\n",
      "loss in epoch 9 , step 7340 : 1.330611\n",
      "loss in epoch 9 , step 7360 : 2.036940\n",
      "loss in epoch 9 , step 7380 : 1.776083\n",
      "loss in epoch 9 , step 7400 : 1.699130\n",
      "loss in epoch 9 , step 7420 : 0.607191\n",
      "loss in epoch 9 , step 7440 : 1.368539\n",
      "loss in epoch 9 , step 7460 : 2.528897\n",
      "loss in epoch 9 , step 7480 : 0.377007\n",
      "loss in epoch 9 , step 7500 : 0.895885\n",
      "loss in epoch 9 , step 7520 : 1.625136\n",
      "loss in epoch 9 , step 7540 : 0.076556\n",
      "loss in epoch 9 , step 7560 : 0.546341\n",
      "loss in epoch 9 , step 7580 : 1.702225\n",
      "loss in epoch 9 , step 7600 : 0.285172\n",
      "loss in epoch 9 , step 7620 : 1.444661\n",
      "loss in epoch 9 , step 7640 : 0.694671\n",
      "loss in epoch 9 , step 7660 : 0.257142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 9 , step 7680 : 1.768369\n",
      "loss in epoch 9 , step 7700 : 0.753214\n",
      "loss in epoch 9 , step 7720 : 1.124743\n",
      "loss in epoch 9 , step 7740 : 0.521140\n",
      "loss in epoch 9 , step 7760 : 0.064309\n",
      "loss in epoch 9 , step 7780 : 0.703032\n",
      "loss in epoch 9 , step 7800 : 0.861361\n",
      "loss in epoch 9 , step 7820 : 0.840457\n",
      "loss in epoch 9 , step 7840 : 2.500631\n",
      "loss in epoch 9 , step 7860 : 0.812178\n",
      "loss in epoch 9 , step 7880 : 1.547388\n",
      "loss in epoch 9 , step 7900 : 0.729138\n",
      "loss in epoch 9 , step 7920 : 1.514246\n",
      "loss in epoch 9 , step 7940 : 0.323498\n",
      "loss in epoch 9 , step 7960 : 0.404859\n",
      "loss in epoch 9 , step 7980 : 0.890678\n",
      "loss in epoch 9 , step 8000 : 1.419087\n",
      "loss in epoch 9 , step 8020 : 1.814759\n",
      "loss in epoch 9 , step 8040 : 1.340411\n",
      "loss in epoch 9 , step 8060 : 1.618894\n",
      "loss in epoch 9 , step 8080 : 1.281565\n",
      "loss in epoch 9 , step 8100 : 0.446957\n",
      "loss in epoch 9 , step 8120 : 0.911138\n",
      "loss in epoch 9 , step 8140 : 1.337078\n",
      "loss in epoch 9 , step 8160 : 0.771066\n",
      "loss in epoch 9 , step 8180 : 0.921728\n",
      "loss in epoch 9 , step 8200 : 0.035647\n",
      "loss in epoch 9 , step 8220 : 1.480351\n",
      "loss in epoch 9 , step 8240 : 1.446242\n",
      "loss in epoch 9 , step 8260 : 0.482398\n",
      "loss in epoch 9 , step 8280 : 0.650334\n",
      "loss in epoch 9 , step 8300 : 1.365460\n",
      "loss in epoch 9 , step 8320 : 0.988451\n",
      "loss in epoch 9 , step 8340 : 0.677199\n",
      "loss in epoch 9 , step 8360 : 1.067537\n",
      "loss in epoch 9 , step 8380 : 2.452990\n",
      "loss in epoch 9 , step 8400 : 0.099940\n",
      "loss in epoch 9 , step 8420 : 1.762449\n",
      "loss in epoch 9 , step 8440 : 1.006829\n",
      "loss in epoch 9 , step 8460 : 0.253840\n",
      "loss in epoch 9 , step 8480 : 0.136560\n",
      "loss in epoch 9 , step 8500 : 1.108171\n",
      "loss in epoch 9 , step 8520 : 2.178262\n",
      "loss in epoch 9 , step 8540 : 1.796835\n",
      "loss in epoch 9 , step 8560 : 1.746492\n",
      "loss in epoch 9 , step 8580 : 2.232033\n",
      "loss in epoch 9 , step 8600 : 0.315179\n",
      "loss in epoch 9 , step 8620 : 3.751318\n",
      "loss in epoch 9 , step 8640 : 2.183382\n",
      "loss in epoch 9 , step 8660 : 1.325373\n",
      "loss in epoch 9 , step 8680 : 0.663309\n",
      "loss in epoch 9 , step 8700 : 3.384537\n",
      "loss in epoch 9 , step 8720 : 1.662116\n",
      "loss in epoch 9 , step 8740 : 1.606349\n",
      "loss in epoch 9 , step 8760 : 0.115966\n",
      "loss in epoch 9 , step 8780 : 1.551085\n",
      "loss in epoch 9 , step 8800 : 1.895425\n",
      "loss in epoch 9 , step 8820 : 0.693524\n",
      "loss in epoch 9 , step 8840 : 0.782974\n",
      "loss in epoch 9 , step 8860 : 0.602880\n",
      "loss in epoch 9 , step 8880 : 1.538305\n",
      "loss in epoch 9 , step 8900 : 1.033826\n",
      "loss in epoch 9 , step 8920 : 1.249920\n",
      "loss in epoch 9 , step 8940 : 0.832942\n",
      "loss in epoch 9 , step 8960 : 0.233233\n",
      "loss in epoch 9 , step 8980 : 0.038179\n",
      "loss in epoch 9 , step 9000 : 1.825588\n",
      "loss in epoch 9 , step 9020 : 0.305269\n",
      "loss in epoch 9 , step 9040 : 0.696873\n",
      "loss in epoch 9 , step 9060 : 0.099065\n",
      "loss in epoch 9 , step 9080 : 1.539593\n",
      "loss in epoch 9 , step 9100 : 0.167796\n",
      "loss in epoch 9 , step 9120 : 2.253011\n",
      "loss in epoch 9 , step 9140 : 0.692258\n",
      "loss in epoch 9 , step 9160 : 1.977107\n",
      "loss in epoch 9 , step 9180 : 2.771977\n",
      "loss in epoch 9 , step 9200 : 0.218035\n",
      "loss in epoch 9 , step 9220 : 0.565256\n",
      "loss in epoch 9 , step 9240 : 1.416590\n",
      "loss in epoch 9 , step 9260 : 0.620893\n",
      "loss in epoch 9 , step 9280 : 1.792647\n",
      "loss in epoch 9 , step 9300 : 1.574979\n",
      "loss in epoch 9 , step 9320 : 0.087966\n",
      "loss in epoch 9 , step 9340 : 2.055236\n",
      "loss in epoch 9 , step 9360 : 0.868538\n",
      "loss in epoch 9 , step 9380 : 0.063889\n",
      "loss in epoch 9 , step 9400 : 0.181427\n",
      "loss in epoch 9 , step 9420 : 0.274385\n",
      "loss in epoch 9 , step 9440 : 1.291309\n",
      "loss in epoch 9 , step 9460 : 0.978980\n",
      "loss in epoch 9 , step 9480 : 1.107157\n",
      "loss in epoch 9 , step 9500 : 0.021257\n",
      "loss in epoch 9 , step 9520 : 0.194634\n",
      "loss in epoch 9 , step 9540 : 0.840267\n",
      "loss in epoch 9 , step 9560 : 0.280376\n",
      "loss in epoch 9 , step 9580 : 2.191499\n",
      "loss in epoch 9 , step 9600 : 1.563943\n",
      "loss in epoch 9 , step 9620 : 1.286059\n",
      "loss in epoch 9 , step 9640 : 1.853140\n",
      "loss in epoch 9 , step 9660 : 1.424154\n",
      "loss in epoch 9 , step 9680 : 1.699597\n",
      "loss in epoch 9 , step 9700 : 0.343579\n",
      "loss in epoch 9 , step 9720 : 0.051175\n",
      "loss in epoch 9 , step 9740 : 0.289645\n",
      "loss in epoch 9 , step 9760 : 0.035929\n",
      "loss in epoch 9 , step 9780 : 0.038728\n",
      "loss in epoch 9 , step 9800 : 2.800000\n",
      "loss in epoch 9 , step 9820 : 1.941697\n",
      "loss in epoch 9 , step 9840 : 0.628163\n",
      "loss in epoch 9 , step 9860 : 0.085437\n",
      "loss in epoch 9 , step 9880 : 0.095041\n",
      "loss in epoch 9 , step 9900 : 0.117666\n",
      "loss in epoch 9 , step 9920 : 1.012195\n",
      "loss in epoch 9 , step 9940 : 1.459185\n",
      "loss in epoch 9 , step 9960 : 1.412815\n",
      "loss in epoch 9 , step 9980 : 1.438595\n",
      "loss in epoch 9 , step 10000 : 1.670659\n",
      "loss in epoch 9 , step 10020 : 1.707936\n",
      "loss in epoch 9 , step 10040 : 0.293836\n",
      "loss in epoch 9 , step 10060 : 1.088378\n",
      "loss in epoch 9 , step 10080 : 2.466748\n",
      "loss in epoch 9 , step 10100 : 0.428723\n",
      "loss in epoch 9 , step 10120 : 0.689765\n",
      "loss in epoch 9 , step 10140 : 1.198143\n",
      "loss in epoch 9 , step 10160 : 1.507897\n",
      "loss in epoch 9 , step 10180 : 0.060817\n",
      "loss in epoch 9 , step 10200 : 1.737301\n",
      "loss in epoch 9 , step 10220 : 0.700264\n",
      "loss in epoch 9 , step 10240 : 1.932227\n",
      "loss in epoch 9 , step 10260 : 1.008152\n",
      "loss in epoch 9 , step 10280 : 1.138041\n",
      "loss in epoch 9 , step 10300 : 2.029210\n",
      "loss in epoch 9 , step 10320 : 0.745882\n",
      "loss in epoch 9 , step 10340 : 0.686915\n",
      "loss in epoch 9 , step 10360 : 1.371229\n",
      "loss in epoch 9 , step 10380 : 1.640205\n",
      "loss in epoch 9 , step 10400 : 0.065980\n",
      "loss in epoch 9 , step 10420 : 2.048095\n",
      "loss in epoch 9 , step 10440 : 0.014930\n",
      "loss in epoch 9 , step 10460 : 1.249346\n",
      "loss in epoch 9 , step 10480 : 0.184469\n",
      "loss in epoch 9 , step 10500 : 0.741193\n",
      "loss in epoch 9 , step 10520 : 1.123524\n",
      "loss in epoch 9 , step 10540 : 1.712424\n",
      "loss in epoch 9 , step 10560 : 1.745762\n",
      "loss in epoch 9 , step 10580 : 2.600191\n",
      "loss in epoch 9 , step 10600 : 1.040866\n",
      "loss in epoch 9 , step 10620 : 1.505729\n",
      "loss in epoch 9 , step 10640 : 0.903945\n",
      "loss in epoch 9 , step 10660 : 2.275971\n",
      "loss in epoch 9 , step 10680 : 0.700101\n",
      "loss in epoch 9 , step 10700 : 0.003495\n",
      "loss in epoch 9 , step 10720 : 0.164803\n",
      "loss in epoch 9 , step 10740 : 0.024343\n",
      "loss in epoch 9 , step 10760 : 1.544475\n",
      "loss in epoch 9 , step 10780 : 2.200624\n",
      "loss in epoch 9 , step 10800 : 0.020700\n",
      "loss in epoch 9 , step 10820 : 1.124531\n",
      "loss in epoch 9 , step 10840 : 1.347269\n",
      "loss in epoch 9 , step 10860 : 2.237168\n",
      "loss in epoch 9 , step 10880 : 2.481468\n",
      "loss in epoch 9 , step 10900 : 3.105629\n",
      "loss in epoch 9 , step 10920 : 0.979890\n",
      "loss in epoch 9 , step 10940 : 0.031853\n",
      "loss in epoch 9 , step 10960 : 1.146629\n",
      "loss in epoch 9 , step 10980 : 1.747498\n",
      "loss in epoch 9 , step 11000 : 0.404806\n",
      "loss in epoch 9 , step 11020 : 0.840394\n",
      "loss in epoch 9 , step 11040 : 0.538424\n",
      "loss in epoch 9 , step 11060 : 1.263462\n",
      "loss in epoch 9 , step 11080 : 0.085939\n",
      "loss in epoch 9 , step 11100 : 0.681447\n",
      "loss in epoch 9 , step 11120 : 0.392633\n",
      "loss in epoch 9 , step 11140 : 4.427855\n",
      "loss in epoch 9 , step 11160 : 1.678734\n",
      "loss in epoch 9 , step 11180 : 1.552768\n",
      "loss in epoch 9 , step 11200 : 1.067418\n",
      "loss in epoch 9 , step 11220 : 0.925091\n",
      "loss in epoch 9 , step 11240 : 1.318585\n",
      "loss in epoch 9 , step 11260 : 0.996516\n",
      "loss in epoch 9 , step 11280 : 1.417420\n",
      "loss in epoch 9 , step 11300 : 0.373137\n",
      "loss in epoch 9 , step 11320 : 0.910539\n",
      "loss in epoch 9 , step 11340 : 0.020534\n",
      "loss in epoch 9 , step 11360 : 1.620776\n",
      "loss in epoch 9 , step 11380 : 1.995150\n",
      "loss in epoch 9 , step 11400 : 1.273128\n",
      "loss in epoch 9 , step 11420 : 0.796385\n",
      "loss in epoch 9 , step 11440 : 1.348347\n",
      "loss in epoch 9 , step 11460 : 0.109271\n",
      "loss in epoch 9 , step 11480 : 0.420257\n",
      "loss in epoch 9 , step 11500 : 2.217089\n",
      "loss in epoch 9 , step 11520 : 0.005615\n",
      "loss in epoch 9 , step 11540 : 0.271043\n",
      "loss in epoch 9 , step 11560 : 1.133383\n",
      "loss in epoch 9 , step 11580 : 1.709311\n",
      "loss in epoch 9 , step 11600 : 0.004323\n",
      "loss in epoch 9 , step 11620 : 1.109465\n",
      "loss in epoch 9 , step 11640 : 4.682882\n",
      "loss in epoch 9 , step 11660 : 0.725497\n",
      "loss in epoch 9 , step 11680 : 2.053963\n",
      "loss in epoch 9 , step 11700 : 1.494264\n",
      "loss in epoch 9 , step 11720 : 0.084361\n",
      "loss in epoch 9 , step 11740 : 1.149463\n",
      "loss in epoch 9 , step 11760 : 2.011688\n",
      "loss in epoch 9 , step 11780 : 1.521614\n",
      "loss in epoch 9 , step 11800 : 0.022840\n",
      "loss in epoch 9 , step 11820 : 1.074989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 9 , step 11840 : 1.102088\n",
      "loss in epoch 9 , step 11860 : 3.102853\n",
      "loss in epoch 9 , step 11880 : 1.139112\n",
      "loss in epoch 9 , step 11900 : 1.251664\n",
      "loss in epoch 9 , step 11920 : 1.714013\n",
      "loss in epoch 9 , step 11940 : 2.263270\n",
      "loss in epoch 9 , step 11960 : 2.414649\n",
      "loss in epoch 9 , step 11980 : 0.284544\n",
      "loss in epoch 9 , step 12000 : 2.956866\n",
      "loss in epoch 9 , step 12020 : 1.373283\n",
      "loss in epoch 9 , step 12040 : 1.693893\n",
      "loss in epoch 9 , step 12060 : 1.364029\n",
      "loss in epoch 9 , step 12080 : 0.049110\n",
      "loss in epoch 9 , step 12100 : 1.174849\n",
      "loss in epoch 9 , step 12120 : 1.773863\n",
      "loss in epoch 9 , step 12140 : 0.651921\n",
      "loss in epoch 9 , step 12160 : 0.331425\n",
      "loss in epoch 9 , step 12180 : 1.042977\n",
      "loss in epoch 9 , step 12200 : 0.378475\n",
      "loss in epoch 9 , step 12220 : 1.102758\n",
      "loss in epoch 9 , step 12240 : 0.198665\n",
      "loss in epoch 9 , step 12260 : 1.438824\n",
      "loss in epoch 9 , step 12280 : 3.100618\n",
      "loss in epoch 9 , step 12300 : 1.641458\n",
      "loss in epoch 9 , step 12320 : 2.670831\n",
      "loss in epoch 9 , step 12340 : 0.376094\n",
      "loss in epoch 9 , step 12360 : 1.289640\n",
      "loss in epoch 9 , step 12380 : 1.317403\n",
      "loss in epoch 9 , step 12400 : 0.523925\n",
      "loss in epoch 9 , step 12420 : 0.021395\n",
      "loss in epoch 9 , step 12440 : 0.191170\n",
      "loss in epoch 9 , step 12460 : 1.009298\n",
      "loss in epoch 9 , step 12480 : 0.383324\n",
      "loss in epoch 9 , step 12500 : 0.745014\n",
      "loss in epoch 9 , step 12520 : 0.074841\n",
      "loss in epoch 9 , step 12540 : 0.964456\n",
      "loss in epoch 9 , step 12560 : 2.259637\n",
      "loss in epoch 9 , step 12580 : 0.041032\n",
      "loss in epoch 9 , step 12600 : 0.593595\n",
      "loss in epoch 9 , step 12620 : 0.032035\n",
      "loss in epoch 9 , step 12640 : 2.135848\n",
      "loss in epoch 9 , step 12660 : 0.712403\n",
      "loss in epoch 9 , step 12680 : 1.337681\n",
      "loss in epoch 9 , step 12700 : 1.626261\n",
      "loss in epoch 9 , step 12720 : 0.053718\n",
      "loss in epoch 9 , step 12740 : 1.644770\n",
      "loss in epoch 9 , step 12760 : 0.104593\n",
      "loss in epoch 9 , step 12780 : 1.629561\n",
      "loss in epoch 9 , step 12800 : 0.415759\n",
      "loss in epoch 9 , step 12820 : 1.311691\n",
      "loss in epoch 9 , step 12840 : 0.271556\n",
      "loss in epoch 9 , step 12860 : 1.345010\n",
      "loss in epoch 9 , step 12880 : 0.575036\n",
      "loss in epoch 9 , step 12900 : 0.042386\n",
      "loss in epoch 9 , step 12920 : 1.557430\n",
      "loss in epoch 9 , step 12940 : 0.230637\n",
      "loss in epoch 9 , step 12960 : 1.928246\n",
      "loss in epoch 9 , step 12980 : 1.656516\n",
      "loss in epoch 9 , step 13000 : 0.351327\n",
      "loss in epoch 9 , step 13020 : 1.150314\n",
      "loss in epoch 9 , step 13040 : 0.613010\n",
      "loss in epoch 9 , step 13060 : 0.945747\n",
      "loss in epoch 9 , step 13080 : 0.803279\n",
      "loss in epoch 9 , step 13100 : 0.299633\n",
      "loss in epoch 9 , step 13120 : 4.319911\n",
      "loss in epoch 9 , step 13140 : 0.180592\n",
      "loss in epoch 9 , step 13160 : 1.454675\n",
      "loss in epoch 9 , step 13180 : 0.238605\n",
      "loss in epoch 9 , step 13200 : 0.759185\n",
      "loss in epoch 9 , step 13220 : 0.837966\n",
      "loss in epoch 9 , step 13240 : 1.234060\n",
      "loss in epoch 9 , step 13260 : 2.246427\n",
      "loss in epoch 9 , step 13280 : 0.952301\n",
      "loss in epoch 9 , step 13300 : 3.101826\n",
      "loss in epoch 9 , step 13320 : 0.017577\n",
      "loss in epoch 9 , step 13340 : 1.325315\n",
      "loss in epoch 9 , step 13360 : 2.024349\n",
      "loss in epoch 9 , step 13380 : 0.986065\n",
      "loss in epoch 9 , step 13400 : 0.445874\n",
      "loss in epoch 9 , step 13420 : 2.436676\n",
      "loss in epoch 9 , step 13440 : 0.748873\n",
      "loss in epoch 9 , step 13460 : 0.014336\n",
      "loss in epoch 9 , step 13480 : 2.115077\n",
      "loss in epoch 9 , step 13500 : 0.083530\n",
      "loss in epoch 9 , step 13520 : 2.267677\n",
      "loss in epoch 9 , step 13540 : 0.718233\n",
      "loss in epoch 9 , step 13560 : 0.496117\n",
      "loss in epoch 9 , step 13580 : 1.508893\n",
      "loss in epoch 9 , step 13600 : 0.617709\n",
      "loss in epoch 9 , step 13620 : 0.372268\n",
      "loss in epoch 9 , step 13640 : 0.775435\n",
      "loss in epoch 9 , step 13660 : 1.022958\n",
      "loss in epoch 9 , step 13680 : 0.545492\n",
      "loss in epoch 9 , step 13700 : 0.190870\n",
      "loss in epoch 9 , step 13720 : 1.725229\n",
      "loss in epoch 9 , step 13740 : 0.711142\n",
      "loss in epoch 9 , step 13760 : 0.015973\n",
      "loss in epoch 9 , step 13780 : 1.460503\n",
      "loss in epoch 9 , step 13800 : 0.191480\n",
      "loss in epoch 9 , step 13820 : 0.282489\n",
      "loss in epoch 9 , step 13840 : 3.214068\n",
      "loss in epoch 9 , step 13860 : 0.913870\n",
      "loss in epoch 9 , step 13880 : 0.237577\n",
      "loss in epoch 9 , step 13900 : 1.323892\n",
      "loss in epoch 9 , step 13920 : 1.100707\n",
      "loss in epoch 9 , step 13940 : 0.248113\n",
      "loss in epoch 9 , step 13960 : 0.032605\n",
      "loss in epoch 9 , step 13980 : 0.065144\n",
      "loss in epoch 9 , step 14000 : 1.180403\n",
      "loss in epoch 9 , step 14020 : 1.350424\n",
      "loss in epoch 9 , step 14040 : 1.928906\n",
      "loss in epoch 9 , step 14060 : 0.168588\n",
      "loss in epoch 9 , step 14080 : 1.362005\n",
      "loss in epoch 9 , step 14100 : 0.110836\n",
      "loss in epoch 9 , step 14120 : 1.732155\n",
      "loss in epoch 9 , step 14140 : 0.740119\n",
      "loss in epoch 9 , step 14160 : 1.367546\n",
      "loss in epoch 9 , step 14180 : 0.380562\n",
      "loss in epoch 9 , step 14200 : 1.324463\n",
      "loss in epoch 9 , step 14220 : 0.420281\n",
      "loss in epoch 9 , step 14240 : 1.578690\n",
      "loss in epoch 9 , step 14260 : 1.463719\n",
      "loss in epoch 9 , step 14280 : 1.708226\n",
      "loss in epoch 9 , step 14300 : 0.543443\n",
      "loss in epoch 9 , step 14320 : 0.894478\n",
      "loss in epoch 9 , step 14340 : 0.906414\n",
      "loss in epoch 9 , step 14360 : 1.546715\n",
      "loss in epoch 9 , step 14380 : 1.951530\n",
      "loss in epoch 9 , step 14400 : 1.363937\n",
      "loss in epoch 9 , step 14420 : 0.113244\n",
      "loss in epoch 9 , step 14440 : 1.316899\n",
      "loss in epoch 9 , step 14460 : 1.382156\n",
      "loss in epoch 9 , step 14480 : 1.359914\n",
      "loss in epoch 9 , step 14500 : 0.475248\n",
      "loss in epoch 9 , step 14520 : 0.039742\n",
      "loss in epoch 9 , step 14540 : 0.866696\n",
      "loss in epoch 9 , step 14560 : 1.343035\n",
      "loss in epoch 9 , step 14580 : 1.424205\n",
      "loss in epoch 9 , step 14600 : 1.729979\n",
      "loss in epoch 9 , step 14620 : 1.705407\n",
      "loss in epoch 9 , step 14640 : 0.123965\n",
      "loss in epoch 9 , step 14660 : 2.223807\n",
      "loss in epoch 9 , step 14680 : 2.259854\n",
      "loss in epoch 9 , step 14700 : 1.387678\n",
      "loss in epoch 9 , step 14720 : 1.307928\n",
      "loss in epoch 9 , step 14740 : 0.301865\n",
      "loss in epoch 9 , step 14760 : 1.360937\n",
      "loss in epoch 9 , step 14780 : 1.403630\n",
      "loss in epoch 9 , step 14800 : 2.513017\n",
      "loss in epoch 9 , step 14820 : 0.862318\n",
      "loss in epoch 9 , step 14840 : 0.029061\n",
      "loss in epoch 9 , step 14860 : 0.227858\n",
      "loss in epoch 9 , step 14880 : 0.815162\n",
      "loss in epoch 9 , step 14900 : 0.088155\n",
      "loss in epoch 9 , step 14920 : 1.501641\n",
      "loss in epoch 9 , step 14940 : 0.034884\n",
      "loss in epoch 9 , step 14960 : 1.816712\n",
      "loss in epoch 9 , step 14980 : 0.120040\n",
      "loss in epoch 9 , step 15000 : 0.931014\n",
      "loss in epoch 9 , step 15020 : 1.528487\n",
      "loss in epoch 9 , step 15040 : 1.377497\n",
      "loss in epoch 9 , step 15060 : 0.947440\n",
      "loss in epoch 9 , step 15080 : 2.184433\n",
      "loss in epoch 9 , step 15100 : 3.704616\n",
      "loss in epoch 9 , step 15120 : 1.893320\n",
      "loss in epoch 9 , step 15140 : 0.054372\n",
      "loss in epoch 9 , step 15160 : 2.467127\n",
      "loss in epoch 9 , step 15180 : 2.356697\n",
      "loss in epoch 9 , step 15200 : 1.034893\n",
      "loss in epoch 9 , step 15220 : 2.300560\n",
      "loss in epoch 9 , step 15240 : 1.866268\n",
      "loss in epoch 9 , step 15260 : 0.507058\n",
      "loss in epoch 9 , step 15280 : 0.262492\n",
      "loss in epoch 9 , step 15300 : 0.754009\n",
      "loss in epoch 9 , step 15320 : 1.540578\n",
      "loss in epoch 9 , step 15340 : 1.550644\n",
      "loss in epoch 9 , step 15360 : 1.345710\n",
      "loss in epoch 9 , step 15380 : 1.228089\n",
      "loss in epoch 9 , step 15400 : 3.315096\n",
      "loss in epoch 9 , step 15420 : 1.600607\n",
      "loss in epoch 9 , step 15440 : 1.844706\n",
      "loss in epoch 9 , step 15460 : 0.162719\n",
      "loss in epoch 9 , step 15480 : 0.305631\n",
      "loss in epoch 9 , step 15500 : 1.120797\n",
      "loss in epoch 9 , step 15520 : 0.010562\n",
      "loss in epoch 9 , step 15540 : 0.048388\n",
      "loss in epoch 9 , step 15560 : 0.011533\n",
      "loss in epoch 9 , step 15580 : 1.378582\n",
      "loss in epoch 9 , step 15600 : 0.160007\n",
      "loss in epoch 9 , step 15620 : 2.425409\n",
      "loss in epoch 9 , step 15640 : 0.593477\n",
      "loss in epoch 9 , step 15660 : 2.028710\n",
      "loss in epoch 9 , step 15680 : 0.963459\n",
      "loss in epoch 9 , step 15700 : 6.176594\n",
      "loss in epoch 9 , step 15720 : 1.479511\n",
      "loss in epoch 9 , step 15740 : 1.935856\n",
      "loss in epoch 9 , step 15760 : 0.070120\n",
      "loss in epoch 9 , step 15780 : 1.414594\n",
      "loss in epoch 9 , step 15800 : 2.150161\n",
      "loss in epoch 9 , step 15820 : 0.884736\n",
      "loss in epoch 9 , step 15840 : 1.838551\n",
      "loss in epoch 9 , step 15860 : 0.995956\n",
      "loss in epoch 9 , step 15880 : 2.640571\n",
      "loss in epoch 9 , step 15900 : 1.205999\n",
      "loss in epoch 9 , step 15920 : 0.053196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 9 , step 15940 : 1.946050\n",
      "loss in epoch 9 , step 15960 : 2.945768\n",
      "loss in epoch 9 , step 15980 : 2.150785\n",
      "loss in epoch 9 , step 16000 : 1.720581\n",
      "loss in epoch 9 , step 16020 : 1.521163\n",
      "loss in epoch 9 , step 16040 : 2.179331\n",
      "loss in epoch 9 , step 16060 : 0.911572\n",
      "loss in epoch 9 , step 16080 : 1.192373\n",
      "loss in epoch 9 , step 16100 : 1.534810\n",
      "loss in epoch 9 , step 16120 : 1.889036\n",
      "loss in epoch 9 , step 16140 : 1.163723\n",
      "loss in epoch 9 , step 16160 : 1.912553\n",
      "loss in epoch 9 , step 16180 : 1.657014\n",
      "loss in epoch 9 , step 16200 : 3.347507\n",
      "loss in epoch 9 , step 16220 : 0.194945\n",
      "loss in epoch 9 , step 16240 : 2.809238\n",
      "loss in epoch 9 , step 16260 : 0.870888\n",
      "loss in epoch 9 , step 16280 : 0.085464\n",
      "loss in epoch 9 , step 16300 : 0.768192\n",
      "loss in epoch 9 , step 16320 : 0.459207\n",
      "loss in epoch 9 , step 16340 : 1.501271\n",
      "loss in epoch 9 , step 16360 : 0.611174\n",
      "loss in epoch 9 , step 16380 : 0.006865\n",
      "loss in epoch 9 , step 16400 : 0.171226\n",
      "loss in epoch 9 , step 16420 : 2.230600\n",
      "loss in epoch 9 , step 16440 : 0.657925\n",
      "loss in epoch 9 , step 16460 : 1.155177\n",
      "loss in epoch 9 , step 16480 : 1.330189\n",
      "loss in epoch 9 , step 16500 : 1.222861\n",
      "loss in epoch 9 , step 16520 : 0.073346\n",
      "loss in epoch 9 , step 16540 : 0.804300\n",
      "loss in epoch 9 , step 16560 : 1.514124\n",
      "loss in epoch 9 , step 16580 : 0.191844\n",
      "loss in epoch 9 , step 16600 : 1.953241\n",
      "loss in epoch 9 , step 16620 : 1.236503\n",
      "loss in epoch 9 , step 16640 : 0.711345\n",
      "loss in epoch 9 , step 16660 : 1.374965\n",
      "loss in epoch 9 , step 16680 : 3.304399\n",
      "loss in epoch 9 , step 16700 : 1.004267\n",
      "loss in epoch 9 , step 16720 : 0.487998\n",
      "loss in epoch 9 , step 16740 : 0.137281\n",
      "loss in epoch 9 , step 16760 : 1.789666\n",
      "loss in epoch 9 , step 16780 : 1.501675\n",
      "loss in epoch 9 , step 16800 : 0.012557\n",
      "loss in epoch 9 , step 16820 : 0.795237\n",
      "loss in epoch 9 , step 16840 : 0.013242\n",
      "loss in epoch 9 , step 16860 : 1.080213\n",
      "loss in epoch 9 , step 16880 : 0.011119\n",
      "loss in epoch 9 , step 16900 : 1.254319\n",
      "loss in epoch 9 , step 16920 : 1.219103\n",
      "loss in epoch 9 , step 16940 : 2.334615\n",
      "loss in epoch 9 , step 16960 : 0.999106\n",
      "loss in epoch 9 , step 16980 : 1.547314\n",
      "loss in epoch 9 , step 17000 : 1.207047\n",
      "loss in epoch 9 , step 17020 : 0.112739\n",
      "loss in epoch 9 , step 17040 : 0.098506\n",
      "loss in epoch 9 , step 17060 : 0.915389\n",
      "loss in epoch 9 , step 17080 : 1.623741\n",
      "loss in epoch 9 , step 17100 : 2.369643\n",
      "loss in epoch 9 , step 17120 : 1.277830\n",
      "loss in epoch 9 , step 17140 : 0.700605\n",
      "loss in epoch 9 , step 17160 : 1.970834\n",
      "loss in epoch 9 , step 17180 : 1.068260\n",
      "loss in epoch 9 , step 17200 : 0.433111\n",
      "loss in epoch 9 , step 17220 : 1.336226\n",
      "loss in epoch 9 , step 17240 : 0.515627\n",
      "loss in epoch 9 , step 17260 : 0.703187\n",
      "loss in epoch 9 , step 17280 : 2.046829\n",
      "loss in epoch 9 , step 17300 : 1.610514\n",
      "loss in epoch 9 , step 17320 : 0.125158\n",
      "loss in epoch 9 , step 17340 : 0.579889\n",
      "loss in epoch 9 , step 17360 : 0.073050\n",
      "loss in epoch 9 , step 17380 : 0.141638\n",
      "loss in epoch 9 , step 17400 : 0.294538\n",
      "loss in epoch 9 , step 17420 : 3.285306\n",
      "loss in epoch 9 , step 17440 : 0.374275\n",
      "loss in epoch 9 , step 17460 : 1.788844\n",
      "loss in epoch 9 , step 17480 : 0.748218\n",
      "loss in epoch 9 , step 17500 : 0.020888\n",
      "loss in epoch 9 , step 17520 : 1.238547\n",
      "loss in epoch 9 , step 17540 : 0.693305\n",
      "loss in epoch 9 , step 17560 : 0.217650\n",
      "loss in epoch 9 , step 17580 : 0.964488\n",
      "loss in epoch 9 , step 17600 : 0.835135\n",
      "loss in epoch 9 , step 17620 : 0.122632\n",
      "loss in epoch 9 , step 17640 : 1.650319\n",
      "loss in epoch 9 , step 17660 : 1.577134\n",
      "loss in epoch 9 , step 17680 : 0.971719\n",
      "loss in epoch 9 , step 17700 : 0.631844\n",
      "loss in epoch 9 , step 17720 : 0.079845\n",
      "loss in epoch 9 , step 17740 : 0.186477\n",
      "loss in epoch 9 , step 17760 : 0.484943\n",
      "loss in epoch 9 , step 17780 : 1.130142\n",
      "loss in epoch 9 , step 17800 : 1.327800\n",
      "loss in epoch 9 , step 17820 : 2.957407\n",
      "loss in epoch 9 , step 17840 : 2.106463\n",
      "loss in epoch 9 , step 17860 : 0.004214\n",
      "loss in epoch 9 , step 17880 : 2.426963\n",
      "loss in epoch 9 , step 17900 : 0.080154\n",
      "loss in epoch 9 , step 17920 : 2.146046\n",
      "loss in epoch 9 , step 17940 : 1.048694\n",
      "loss in epoch 9 , step 17960 : 0.210211\n",
      "loss in epoch 9 , step 17980 : 1.332619\n",
      "loss in epoch 9 , step 18000 : 0.872861\n",
      "loss in epoch 9 , step 18020 : 1.349472\n",
      "loss in epoch 9 , step 18040 : 0.396867\n",
      "loss in epoch 9 , step 18060 : 0.566401\n",
      "loss in epoch 9 , step 18080 : 0.660083\n",
      "loss in epoch 9 , step 18100 : 1.567543\n",
      "loss in epoch 9 , step 18120 : 1.696162\n",
      "loss in epoch 9 , step 18140 : 0.012662\n",
      "loss in epoch 9 , step 18160 : 0.698041\n",
      "loss in epoch 9 , step 18180 : 1.792744\n",
      "loss in epoch 9 , step 18200 : 1.392982\n",
      "loss in epoch 9 , step 18220 : 0.238467\n",
      "loss in epoch 9 , step 18240 : 0.975211\n",
      "loss in epoch 9 , step 18260 : 2.436643\n",
      "loss in epoch 9 , step 18280 : 0.108339\n",
      "loss in epoch 9 , step 18300 : 2.130704\n",
      "loss in epoch 9 , step 18320 : 0.171790\n",
      "loss in epoch 9 , step 18340 : 3.115959\n",
      "loss in epoch 9 , step 18360 : 0.957479\n",
      "loss in epoch 9 , step 18380 : 1.835950\n",
      "loss in epoch 9 , step 18400 : 0.012567\n",
      "loss in epoch 9 , step 18420 : 0.099193\n",
      "loss in epoch 9 , step 18440 : 1.198820\n",
      "loss in epoch 9 , step 18460 : 0.053667\n",
      "loss in epoch 9 , step 18480 : 1.600439\n",
      "loss in epoch 9 , step 18500 : 0.735245\n",
      "loss in epoch 9 , step 18520 : 0.481062\n",
      "loss in epoch 9 , step 18540 : 1.024685\n",
      "loss in epoch 9 , step 18560 : 0.469875\n",
      "loss in epoch 9 , step 18580 : 3.467585\n",
      "loss in epoch 9 , step 18600 : 1.554646\n",
      "loss in epoch 9 , step 18620 : 0.880900\n",
      "loss in epoch 9 , step 18640 : 0.063551\n",
      "loss in epoch 9 , step 18660 : 2.231622\n",
      "loss in epoch 9 , step 18680 : 0.146027\n",
      "loss in epoch 9 , step 18700 : 2.607862\n",
      "loss in epoch 9 , step 18720 : 0.047756\n",
      "loss in epoch 9 , step 18740 : 2.251146\n",
      "loss in epoch 9 , step 18760 : 1.679306\n",
      "loss in epoch 9 , step 18780 : 0.235428\n",
      "loss in epoch 9 , step 18800 : 0.914680\n",
      "loss in epoch 9 , step 18820 : 2.360679\n",
      "loss in epoch 9 , step 18840 : 1.568729\n",
      "loss in epoch 9 , step 18860 : 0.511395\n",
      "loss in epoch 9 , step 18880 : 0.010865\n",
      "loss in epoch 9 , step 18900 : 1.637396\n",
      "loss in epoch 9 , step 18920 : 0.181474\n",
      "loss in epoch 9 , step 18940 : 0.812597\n",
      "loss in epoch 9 , step 18960 : 1.800125\n",
      "loss in epoch 9 , step 18980 : 0.921388\n",
      "loss in epoch 9 , step 19000 : 1.323443\n",
      "loss in epoch 9 , step 19020 : 1.570527\n",
      "loss in epoch 9 , step 19040 : 0.009500\n",
      "loss in epoch 9 , step 19060 : 0.013364\n",
      "loss in epoch 9 , step 19080 : 0.009429\n",
      "loss in epoch 9 , step 19100 : 0.920498\n",
      "loss in epoch 9 , step 19120 : 2.597949\n",
      "loss in epoch 9 , step 19140 : 2.205009\n",
      "loss in epoch 9 , step 19160 : 0.013214\n",
      "loss in epoch 9 , step 19180 : 1.178812\n",
      "loss in epoch 9 , step 19200 : 1.588903\n",
      "loss in epoch 9 , step 19220 : 2.422184\n",
      "loss in epoch 9 , step 19240 : 2.453172\n",
      "loss in epoch 9 , step 19260 : 1.755270\n",
      "loss in epoch 9 , step 19280 : 0.354038\n",
      "loss in epoch 9 , step 19300 : 1.930121\n",
      "loss in epoch 9 , step 19320 : 2.047587\n",
      "loss in epoch 9 , step 19340 : 2.477461\n",
      "loss in epoch 9 , step 19360 : 1.644340\n",
      "loss in epoch 9 , step 19380 : 1.350100\n",
      "loss in epoch 9 , step 19400 : 2.080563\n",
      "loss in epoch 9 , step 19420 : 1.722204\n",
      "loss in epoch 9 , step 19440 : 2.818917\n",
      "loss in epoch 9 , step 19460 : 0.111609\n",
      "loss in epoch 9 , step 19480 : 1.853534\n",
      "loss in epoch 9 , step 19500 : 1.255030\n",
      "loss in epoch 9 , step 19520 : 2.348145\n",
      "loss in epoch 9 , step 19540 : 1.274234\n",
      "loss in epoch 9 , step 19560 : 0.896469\n",
      "loss in epoch 9 , step 19580 : 0.074489\n",
      "loss in epoch 9 , step 19600 : 0.812699\n",
      "loss in epoch 9 , step 19620 : 0.903788\n",
      "loss in epoch 9 , step 19640 : 0.818879\n",
      "loss in epoch 9 , step 19660 : 0.995974\n",
      "loss in epoch 9 , step 19680 : 1.259755\n",
      "loss in epoch 9 , step 19700 : 0.007306\n",
      "loss in epoch 9 , step 19720 : 1.352272\n",
      "loss in epoch 9 , step 19740 : 2.660744\n",
      "loss in epoch 9 , step 19760 : 0.131196\n",
      "loss in epoch 9 , step 19780 : 2.587983\n",
      "loss in epoch 9 , step 19800 : 1.724786\n",
      "loss in epoch 9 , step 19820 : 1.242521\n",
      "loss in epoch 9 , step 19840 : 0.555012\n",
      "loss in epoch 9 , step 19860 : 0.556148\n",
      "loss in epoch 9 , step 19880 : 1.196592\n",
      "loss in epoch 9 , step 19900 : 1.731961\n",
      "loss in epoch 9 , step 19920 : 1.116314\n",
      "loss in epoch 9 , step 19940 : 4.409561\n",
      "Accuracy in epoch 9 : 26.745068\n",
      "loss in epoch 10 , step 0 : 1.773797\n",
      "loss in epoch 10 , step 20 : 0.710021\n",
      "loss in epoch 10 , step 40 : 1.289356\n",
      "loss in epoch 10 , step 60 : 0.013601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 10 , step 80 : 0.026451\n",
      "loss in epoch 10 , step 100 : 1.744593\n",
      "loss in epoch 10 , step 120 : 1.236470\n",
      "loss in epoch 10 , step 140 : 0.957515\n",
      "loss in epoch 10 , step 160 : 1.944132\n",
      "loss in epoch 10 , step 180 : 2.903225\n",
      "loss in epoch 10 , step 200 : 0.488488\n",
      "loss in epoch 10 , step 220 : 1.644475\n",
      "loss in epoch 10 , step 240 : 0.089727\n",
      "loss in epoch 10 , step 260 : 1.703354\n",
      "loss in epoch 10 , step 280 : 2.932684\n",
      "loss in epoch 10 , step 300 : 1.269574\n",
      "loss in epoch 10 , step 320 : 1.337258\n",
      "loss in epoch 10 , step 340 : 0.276062\n",
      "loss in epoch 10 , step 360 : 1.225644\n",
      "loss in epoch 10 , step 380 : 1.413162\n",
      "loss in epoch 10 , step 400 : 2.016193\n",
      "loss in epoch 10 , step 420 : 0.969675\n",
      "loss in epoch 10 , step 440 : 3.872939\n",
      "loss in epoch 10 , step 460 : 1.433723\n",
      "loss in epoch 10 , step 480 : 1.031430\n",
      "loss in epoch 10 , step 500 : 1.300015\n",
      "loss in epoch 10 , step 520 : 1.326490\n",
      "loss in epoch 10 , step 540 : 0.400811\n",
      "loss in epoch 10 , step 560 : 0.923732\n",
      "loss in epoch 10 , step 580 : 0.201855\n",
      "loss in epoch 10 , step 600 : 1.253800\n",
      "loss in epoch 10 , step 620 : 1.188223\n",
      "loss in epoch 10 , step 640 : 1.357602\n",
      "loss in epoch 10 , step 660 : 0.920037\n",
      "loss in epoch 10 , step 680 : 1.369403\n",
      "loss in epoch 10 , step 700 : 0.546007\n",
      "loss in epoch 10 , step 720 : 0.056343\n",
      "loss in epoch 10 , step 740 : 1.101719\n",
      "loss in epoch 10 , step 760 : 0.205230\n",
      "loss in epoch 10 , step 780 : 0.020999\n",
      "loss in epoch 10 , step 800 : 0.003320\n",
      "loss in epoch 10 , step 820 : 0.136387\n",
      "loss in epoch 10 , step 840 : 1.532624\n",
      "loss in epoch 10 , step 860 : 1.121346\n",
      "loss in epoch 10 , step 880 : 1.297022\n",
      "loss in epoch 10 , step 900 : 0.114768\n",
      "loss in epoch 10 , step 920 : 1.867554\n",
      "loss in epoch 10 , step 940 : 5.003581\n",
      "loss in epoch 10 , step 960 : 2.322049\n",
      "loss in epoch 10 , step 980 : 1.199577\n",
      "loss in epoch 10 , step 1000 : 0.632501\n",
      "loss in epoch 10 , step 1020 : 0.650170\n",
      "loss in epoch 10 , step 1040 : 1.082982\n",
      "loss in epoch 10 , step 1060 : 1.100919\n",
      "loss in epoch 10 , step 1080 : 1.281702\n",
      "loss in epoch 10 , step 1100 : 0.439781\n",
      "loss in epoch 10 , step 1120 : 1.351964\n",
      "loss in epoch 10 , step 1140 : 0.836755\n",
      "loss in epoch 10 , step 1160 : 0.688139\n",
      "loss in epoch 10 , step 1180 : 2.041402\n",
      "loss in epoch 10 , step 1200 : 1.464048\n",
      "loss in epoch 10 , step 1220 : 0.192025\n",
      "loss in epoch 10 , step 1240 : 0.422606\n",
      "loss in epoch 10 , step 1260 : 0.267426\n",
      "loss in epoch 10 , step 1280 : 0.053861\n",
      "loss in epoch 10 , step 1300 : 2.958042\n",
      "loss in epoch 10 , step 1320 : 2.117077\n",
      "loss in epoch 10 , step 1340 : 1.161458\n",
      "loss in epoch 10 , step 1360 : 3.239682\n",
      "loss in epoch 10 , step 1380 : 1.586850\n",
      "loss in epoch 10 , step 1400 : 0.395799\n",
      "loss in epoch 10 , step 1420 : 0.745430\n",
      "loss in epoch 10 , step 1440 : 3.587815\n",
      "loss in epoch 10 , step 1460 : 0.020219\n",
      "loss in epoch 10 , step 1480 : 0.941596\n",
      "loss in epoch 10 , step 1500 : 0.017790\n",
      "loss in epoch 10 , step 1520 : 0.351475\n",
      "loss in epoch 10 , step 1540 : 2.359693\n",
      "loss in epoch 10 , step 1560 : 0.343473\n",
      "loss in epoch 10 , step 1580 : 1.644529\n",
      "loss in epoch 10 , step 1600 : 1.023051\n",
      "loss in epoch 10 , step 1620 : 0.775681\n",
      "loss in epoch 10 , step 1640 : 1.929155\n",
      "loss in epoch 10 , step 1660 : 1.233056\n",
      "loss in epoch 10 , step 1680 : 1.812446\n",
      "loss in epoch 10 , step 1700 : 1.341731\n",
      "loss in epoch 10 , step 1720 : 3.806750\n",
      "loss in epoch 10 , step 1740 : 2.111286\n",
      "loss in epoch 10 , step 1760 : 2.411731\n",
      "loss in epoch 10 , step 1780 : 2.659616\n",
      "loss in epoch 10 , step 1800 : 0.932606\n",
      "loss in epoch 10 , step 1820 : 0.011121\n",
      "loss in epoch 10 , step 1840 : 0.062400\n",
      "loss in epoch 10 , step 1860 : 2.137313\n",
      "loss in epoch 10 , step 1880 : 2.024251\n",
      "loss in epoch 10 , step 1900 : 1.764818\n",
      "loss in epoch 10 , step 1920 : 1.190531\n",
      "loss in epoch 10 , step 1940 : 0.196598\n",
      "loss in epoch 10 , step 1960 : 0.468138\n",
      "loss in epoch 10 , step 1980 : 1.141063\n",
      "loss in epoch 10 , step 2000 : 2.472359\n",
      "loss in epoch 10 , step 2020 : 1.056657\n",
      "loss in epoch 10 , step 2040 : 0.432546\n",
      "loss in epoch 10 , step 2060 : 0.471268\n",
      "loss in epoch 10 , step 2080 : 1.890471\n",
      "loss in epoch 10 , step 2100 : 0.954509\n",
      "loss in epoch 10 , step 2120 : 0.815190\n",
      "loss in epoch 10 , step 2140 : 0.282226\n",
      "loss in epoch 10 , step 2160 : 0.874781\n",
      "loss in epoch 10 , step 2180 : 1.072557\n",
      "loss in epoch 10 , step 2200 : 1.063461\n",
      "loss in epoch 10 , step 2220 : 1.355828\n",
      "loss in epoch 10 , step 2240 : 0.758521\n",
      "loss in epoch 10 , step 2260 : 0.108943\n",
      "loss in epoch 10 , step 2280 : 4.181718\n",
      "loss in epoch 10 , step 2300 : 1.581827\n",
      "loss in epoch 10 , step 2320 : 0.518827\n",
      "loss in epoch 10 , step 2340 : 0.365391\n",
      "loss in epoch 10 , step 2360 : 1.133058\n",
      "loss in epoch 10 , step 2380 : 1.491583\n",
      "loss in epoch 10 , step 2400 : 1.454888\n",
      "loss in epoch 10 , step 2420 : 3.457696\n",
      "loss in epoch 10 , step 2440 : 1.624688\n",
      "loss in epoch 10 , step 2460 : 1.291852\n",
      "loss in epoch 10 , step 2480 : 1.489705\n",
      "loss in epoch 10 , step 2500 : 0.672732\n",
      "loss in epoch 10 , step 2520 : 1.089425\n",
      "loss in epoch 10 , step 2540 : 0.516976\n",
      "loss in epoch 10 , step 2560 : 1.524818\n",
      "loss in epoch 10 , step 2580 : 0.940459\n",
      "loss in epoch 10 , step 2600 : 0.549423\n",
      "loss in epoch 10 , step 2620 : 0.030999\n",
      "loss in epoch 10 , step 2640 : 1.671016\n",
      "loss in epoch 10 , step 2660 : 1.099861\n",
      "loss in epoch 10 , step 2680 : 2.131077\n",
      "loss in epoch 10 , step 2700 : 1.748504\n",
      "loss in epoch 10 , step 2720 : 0.964454\n",
      "loss in epoch 10 , step 2740 : 2.855001\n",
      "loss in epoch 10 , step 2760 : 0.071261\n",
      "loss in epoch 10 , step 2780 : 1.103021\n",
      "loss in epoch 10 , step 2800 : 2.311264\n",
      "loss in epoch 10 , step 2820 : 1.952217\n",
      "loss in epoch 10 , step 2840 : 0.835466\n",
      "loss in epoch 10 , step 2860 : 0.806831\n",
      "loss in epoch 10 , step 2880 : 4.303691\n",
      "loss in epoch 10 , step 2900 : 1.121947\n",
      "loss in epoch 10 , step 2920 : 0.031304\n",
      "loss in epoch 10 , step 2940 : 1.427216\n",
      "loss in epoch 10 , step 2960 : 0.805498\n",
      "loss in epoch 10 , step 2980 : 0.932726\n",
      "loss in epoch 10 , step 3000 : 0.061274\n",
      "loss in epoch 10 , step 3020 : 1.077960\n",
      "loss in epoch 10 , step 3040 : 0.284158\n",
      "loss in epoch 10 , step 3060 : 1.061732\n",
      "loss in epoch 10 , step 3080 : 1.806704\n",
      "loss in epoch 10 , step 3100 : 1.160047\n",
      "loss in epoch 10 , step 3120 : 2.083190\n",
      "loss in epoch 10 , step 3140 : 1.087824\n",
      "loss in epoch 10 , step 3160 : 0.696743\n",
      "loss in epoch 10 , step 3180 : 1.763133\n",
      "loss in epoch 10 , step 3200 : 1.353398\n",
      "loss in epoch 10 , step 3220 : 0.254168\n",
      "loss in epoch 10 , step 3240 : 0.908154\n",
      "loss in epoch 10 , step 3260 : 1.763257\n",
      "loss in epoch 10 , step 3280 : 0.261761\n",
      "loss in epoch 10 , step 3300 : 1.030283\n",
      "loss in epoch 10 , step 3320 : 0.467435\n",
      "loss in epoch 10 , step 3340 : 0.673919\n",
      "loss in epoch 10 , step 3360 : 0.596508\n",
      "loss in epoch 10 , step 3380 : 0.214893\n",
      "loss in epoch 10 , step 3400 : 0.782974\n",
      "loss in epoch 10 , step 3420 : 0.382471\n",
      "loss in epoch 10 , step 3440 : 0.710233\n",
      "loss in epoch 10 , step 3460 : 0.803506\n",
      "loss in epoch 10 , step 3480 : 1.350020\n",
      "loss in epoch 10 , step 3500 : 1.045687\n",
      "loss in epoch 10 , step 3520 : 0.730997\n",
      "loss in epoch 10 , step 3540 : 1.077017\n",
      "loss in epoch 10 , step 3560 : 2.906162\n",
      "loss in epoch 10 , step 3580 : 0.542261\n",
      "loss in epoch 10 , step 3600 : 0.835991\n",
      "loss in epoch 10 , step 3620 : 0.615045\n",
      "loss in epoch 10 , step 3640 : 1.385606\n",
      "loss in epoch 10 , step 3660 : 1.508222\n",
      "loss in epoch 10 , step 3680 : 1.426483\n",
      "loss in epoch 10 , step 3700 : 0.357263\n",
      "loss in epoch 10 , step 3720 : 0.809904\n",
      "loss in epoch 10 , step 3740 : 1.241615\n",
      "loss in epoch 10 , step 3760 : 0.110603\n",
      "loss in epoch 10 , step 3780 : 0.062623\n",
      "loss in epoch 10 , step 3800 : 1.078821\n",
      "loss in epoch 10 , step 3820 : 0.018862\n",
      "loss in epoch 10 , step 3840 : 2.809426\n",
      "loss in epoch 10 , step 3860 : 3.300762\n",
      "loss in epoch 10 , step 3880 : 1.928900\n",
      "loss in epoch 10 , step 3900 : 1.291254\n",
      "loss in epoch 10 , step 3920 : 0.218918\n",
      "loss in epoch 10 , step 3940 : 1.151053\n",
      "loss in epoch 10 , step 3960 : 0.115580\n",
      "loss in epoch 10 , step 3980 : 1.065684\n",
      "loss in epoch 10 , step 4000 : 2.650486\n",
      "loss in epoch 10 , step 4020 : 1.156213\n",
      "loss in epoch 10 , step 4040 : 0.561904\n",
      "loss in epoch 10 , step 4060 : 0.084264\n",
      "loss in epoch 10 , step 4080 : 2.006389\n",
      "loss in epoch 10 , step 4100 : 1.189160\n",
      "loss in epoch 10 , step 4120 : 0.341076\n",
      "loss in epoch 10 , step 4140 : 0.073482\n",
      "loss in epoch 10 , step 4160 : 0.858300\n",
      "loss in epoch 10 , step 4180 : 0.044540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 10 , step 4200 : 0.416264\n",
      "loss in epoch 10 , step 4220 : 0.943050\n",
      "loss in epoch 10 , step 4240 : 0.860547\n",
      "loss in epoch 10 , step 4260 : 0.760805\n",
      "loss in epoch 10 , step 4280 : 0.424618\n",
      "loss in epoch 10 , step 4300 : 1.755947\n",
      "loss in epoch 10 , step 4320 : 0.732578\n",
      "loss in epoch 10 , step 4340 : 0.870503\n",
      "loss in epoch 10 , step 4360 : 1.367921\n",
      "loss in epoch 10 , step 4380 : 0.167694\n",
      "loss in epoch 10 , step 4400 : 1.333011\n",
      "loss in epoch 10 , step 4420 : 2.178431\n",
      "loss in epoch 10 , step 4440 : 0.077158\n",
      "loss in epoch 10 , step 4460 : 5.111395\n",
      "loss in epoch 10 , step 4480 : 2.186818\n",
      "loss in epoch 10 , step 4500 : 1.052668\n",
      "loss in epoch 10 , step 4520 : 0.274903\n",
      "loss in epoch 10 , step 4540 : 0.015189\n",
      "loss in epoch 10 , step 4560 : 0.012817\n",
      "loss in epoch 10 , step 4580 : 1.759589\n",
      "loss in epoch 10 , step 4600 : 0.717590\n",
      "loss in epoch 10 , step 4620 : 0.054960\n",
      "loss in epoch 10 , step 4640 : 1.445863\n",
      "loss in epoch 10 , step 4660 : 0.931247\n",
      "loss in epoch 10 , step 4680 : 0.063203\n",
      "loss in epoch 10 , step 4700 : 1.311308\n",
      "loss in epoch 10 , step 4720 : 1.375747\n",
      "loss in epoch 10 , step 4740 : 1.072288\n",
      "loss in epoch 10 , step 4760 : 1.891528\n",
      "loss in epoch 10 , step 4780 : 0.324671\n",
      "loss in epoch 10 , step 4800 : 1.015584\n",
      "loss in epoch 10 , step 4820 : 1.389103\n",
      "loss in epoch 10 , step 4840 : 1.747332\n",
      "loss in epoch 10 , step 4860 : 1.298553\n",
      "loss in epoch 10 , step 4880 : 0.743883\n",
      "loss in epoch 10 , step 4900 : 0.813545\n",
      "loss in epoch 10 , step 4920 : 1.842317\n",
      "loss in epoch 10 , step 4940 : 0.339005\n",
      "loss in epoch 10 , step 4960 : 2.984776\n",
      "loss in epoch 10 , step 4980 : 0.256498\n",
      "loss in epoch 10 , step 5000 : 0.200968\n",
      "loss in epoch 10 , step 5020 : 0.033061\n",
      "loss in epoch 10 , step 5040 : 0.018593\n",
      "loss in epoch 10 , step 5060 : 0.038379\n",
      "loss in epoch 10 , step 5080 : 2.786702\n",
      "loss in epoch 10 , step 5100 : 0.913171\n",
      "loss in epoch 10 , step 5120 : 0.605240\n",
      "loss in epoch 10 , step 5140 : 1.197411\n",
      "loss in epoch 10 , step 5160 : 1.172672\n",
      "loss in epoch 10 , step 5180 : 1.905762\n",
      "loss in epoch 10 , step 5200 : 4.449636\n",
      "loss in epoch 10 , step 5220 : 0.225385\n",
      "loss in epoch 10 , step 5240 : 1.266053\n",
      "loss in epoch 10 , step 5260 : 0.856320\n",
      "loss in epoch 10 , step 5280 : 0.069432\n",
      "loss in epoch 10 , step 5300 : 2.446155\n",
      "loss in epoch 10 , step 5320 : 0.142346\n",
      "loss in epoch 10 , step 5340 : 0.221788\n",
      "loss in epoch 10 , step 5360 : 0.568546\n",
      "loss in epoch 10 , step 5380 : 0.014317\n",
      "loss in epoch 10 , step 5400 : 2.145666\n",
      "loss in epoch 10 , step 5420 : 0.556208\n",
      "loss in epoch 10 , step 5440 : 1.382343\n",
      "loss in epoch 10 , step 5460 : 0.345714\n",
      "loss in epoch 10 , step 5480 : 0.785877\n",
      "loss in epoch 10 , step 5500 : 0.533963\n",
      "loss in epoch 10 , step 5520 : 0.412771\n",
      "loss in epoch 10 , step 5540 : 1.080505\n",
      "loss in epoch 10 , step 5560 : 1.261745\n",
      "loss in epoch 10 , step 5580 : 1.959110\n",
      "loss in epoch 10 , step 5600 : 1.178181\n",
      "loss in epoch 10 , step 5620 : 1.036022\n",
      "loss in epoch 10 , step 5640 : 0.260119\n",
      "loss in epoch 10 , step 5660 : 0.531730\n",
      "loss in epoch 10 , step 5680 : 1.566576\n",
      "loss in epoch 10 , step 5700 : 1.117479\n",
      "loss in epoch 10 , step 5720 : 0.016502\n",
      "loss in epoch 10 , step 5740 : 0.766768\n",
      "loss in epoch 10 , step 5760 : 0.684112\n",
      "loss in epoch 10 , step 5780 : 1.319598\n",
      "loss in epoch 10 , step 5800 : 0.120963\n",
      "loss in epoch 10 , step 5820 : 1.295671\n",
      "loss in epoch 10 , step 5840 : 0.140474\n",
      "loss in epoch 10 , step 5860 : 1.416312\n",
      "loss in epoch 10 , step 5880 : 1.615289\n",
      "loss in epoch 10 , step 5900 : 1.154913\n",
      "loss in epoch 10 , step 5920 : 1.961444\n",
      "loss in epoch 10 , step 5940 : 4.089466\n",
      "loss in epoch 10 , step 5960 : 1.098025\n",
      "loss in epoch 10 , step 5980 : 0.769988\n",
      "loss in epoch 10 , step 6000 : 0.606758\n",
      "loss in epoch 10 , step 6020 : 1.298583\n",
      "loss in epoch 10 , step 6040 : 0.352699\n",
      "loss in epoch 10 , step 6060 : 0.976165\n",
      "loss in epoch 10 , step 6080 : 0.011229\n",
      "loss in epoch 10 , step 6100 : 0.846247\n",
      "loss in epoch 10 , step 6120 : 1.699253\n",
      "loss in epoch 10 , step 6140 : 1.210721\n",
      "loss in epoch 10 , step 6160 : 3.475564\n",
      "loss in epoch 10 , step 6180 : 0.196623\n",
      "loss in epoch 10 , step 6200 : 2.110793\n",
      "loss in epoch 10 , step 6220 : 0.555121\n",
      "loss in epoch 10 , step 6240 : 2.378065\n",
      "loss in epoch 10 , step 6260 : 0.681155\n",
      "loss in epoch 10 , step 6280 : 0.266707\n",
      "loss in epoch 10 , step 6300 : 0.013981\n",
      "loss in epoch 10 , step 6320 : 0.053801\n",
      "loss in epoch 10 , step 6340 : 1.462362\n",
      "loss in epoch 10 , step 6360 : 1.648467\n",
      "loss in epoch 10 , step 6380 : 0.145590\n",
      "loss in epoch 10 , step 6400 : 0.882018\n",
      "loss in epoch 10 , step 6420 : 1.600569\n",
      "loss in epoch 10 , step 6440 : 1.681660\n",
      "loss in epoch 10 , step 6460 : 2.396480\n",
      "loss in epoch 10 , step 6480 : 0.104967\n",
      "loss in epoch 10 , step 6500 : 1.119784\n",
      "loss in epoch 10 , step 6520 : 0.088871\n",
      "loss in epoch 10 , step 6540 : 0.028070\n",
      "loss in epoch 10 , step 6560 : 1.769147\n",
      "loss in epoch 10 , step 6580 : 0.072038\n",
      "loss in epoch 10 , step 6600 : 1.234982\n",
      "loss in epoch 10 , step 6620 : 1.512908\n",
      "loss in epoch 10 , step 6640 : 0.600629\n",
      "loss in epoch 10 , step 6660 : 1.035389\n",
      "loss in epoch 10 , step 6680 : 3.970083\n",
      "loss in epoch 10 , step 6700 : 2.380181\n",
      "loss in epoch 10 , step 6720 : 1.887219\n",
      "loss in epoch 10 , step 6740 : 1.915472\n",
      "loss in epoch 10 , step 6760 : 0.758578\n",
      "loss in epoch 10 , step 6780 : 1.735493\n",
      "loss in epoch 10 , step 6800 : 1.164172\n",
      "loss in epoch 10 , step 6820 : 1.907216\n",
      "loss in epoch 10 , step 6840 : 1.030812\n",
      "loss in epoch 10 , step 6860 : 0.492818\n",
      "loss in epoch 10 , step 6880 : 0.772428\n",
      "loss in epoch 10 , step 6900 : 0.828822\n",
      "loss in epoch 10 , step 6920 : 1.848235\n",
      "loss in epoch 10 , step 6940 : 1.514683\n",
      "loss in epoch 10 , step 6960 : 2.117918\n",
      "loss in epoch 10 , step 6980 : 1.136740\n",
      "loss in epoch 10 , step 7000 : 0.536087\n",
      "loss in epoch 10 , step 7020 : 0.201067\n",
      "loss in epoch 10 , step 7040 : 0.080938\n",
      "loss in epoch 10 , step 7060 : 1.272130\n",
      "loss in epoch 10 , step 7080 : 0.891621\n",
      "loss in epoch 10 , step 7100 : 0.754584\n",
      "loss in epoch 10 , step 7120 : 1.267145\n",
      "loss in epoch 10 , step 7140 : 0.990863\n",
      "loss in epoch 10 , step 7160 : 1.014514\n",
      "loss in epoch 10 , step 7180 : 2.958102\n",
      "loss in epoch 10 , step 7200 : 0.336857\n",
      "loss in epoch 10 , step 7220 : 1.631259\n",
      "loss in epoch 10 , step 7240 : 1.491052\n",
      "loss in epoch 10 , step 7260 : 1.481660\n",
      "loss in epoch 10 , step 7280 : 3.073338\n",
      "loss in epoch 10 , step 7300 : 1.595958\n",
      "loss in epoch 10 , step 7320 : 0.794200\n",
      "loss in epoch 10 , step 7340 : 0.793384\n",
      "loss in epoch 10 , step 7360 : 0.089136\n",
      "loss in epoch 10 , step 7380 : 2.118436\n",
      "loss in epoch 10 , step 7400 : 0.023272\n",
      "loss in epoch 10 , step 7420 : 0.224310\n",
      "loss in epoch 10 , step 7440 : 0.047105\n",
      "loss in epoch 10 , step 7460 : 1.671748\n",
      "loss in epoch 10 , step 7480 : 1.082014\n",
      "loss in epoch 10 , step 7500 : 2.905518\n",
      "loss in epoch 10 , step 7520 : 1.094753\n",
      "loss in epoch 10 , step 7540 : 1.981164\n",
      "loss in epoch 10 , step 7560 : 1.047958\n",
      "loss in epoch 10 , step 7580 : 0.086024\n",
      "loss in epoch 10 , step 7600 : 1.414237\n",
      "loss in epoch 10 , step 7620 : 1.211569\n",
      "loss in epoch 10 , step 7640 : 0.762526\n",
      "loss in epoch 10 , step 7660 : 0.583059\n",
      "loss in epoch 10 , step 7680 : 0.208312\n",
      "loss in epoch 10 , step 7700 : 0.167144\n",
      "loss in epoch 10 , step 7720 : 0.016851\n",
      "loss in epoch 10 , step 7740 : 0.968724\n",
      "loss in epoch 10 , step 7760 : 1.631601\n",
      "loss in epoch 10 , step 7780 : 0.485669\n",
      "loss in epoch 10 , step 7800 : 0.991368\n",
      "loss in epoch 10 , step 7820 : 1.638070\n",
      "loss in epoch 10 , step 7840 : 0.417903\n",
      "loss in epoch 10 , step 7860 : 1.022994\n",
      "loss in epoch 10 , step 7880 : 0.081664\n",
      "loss in epoch 10 , step 7900 : 1.992873\n",
      "loss in epoch 10 , step 7920 : 0.317869\n",
      "loss in epoch 10 , step 7940 : 0.327005\n",
      "loss in epoch 10 , step 7960 : 1.472091\n",
      "loss in epoch 10 , step 7980 : 0.119548\n",
      "loss in epoch 10 , step 8000 : 1.153136\n",
      "loss in epoch 10 , step 8020 : 0.964947\n",
      "loss in epoch 10 , step 8040 : 1.617372\n",
      "loss in epoch 10 , step 8060 : 0.756604\n",
      "loss in epoch 10 , step 8080 : 2.809445\n",
      "loss in epoch 10 , step 8100 : 0.987573\n",
      "loss in epoch 10 , step 8120 : 1.689155\n",
      "loss in epoch 10 , step 8140 : 0.040760\n",
      "loss in epoch 10 , step 8160 : 1.767547\n",
      "loss in epoch 10 , step 8180 : 0.986534\n",
      "loss in epoch 10 , step 8200 : 2.174529\n",
      "loss in epoch 10 , step 8220 : 0.789943\n",
      "loss in epoch 10 , step 8240 : 1.526395\n",
      "loss in epoch 10 , step 8260 : 0.003984\n",
      "loss in epoch 10 , step 8280 : 0.971286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 10 , step 8300 : 1.751259\n",
      "loss in epoch 10 , step 8320 : 0.763749\n",
      "loss in epoch 10 , step 8340 : 1.159587\n",
      "loss in epoch 10 , step 8360 : 1.888795\n",
      "loss in epoch 10 , step 8380 : 0.360155\n",
      "loss in epoch 10 , step 8400 : 2.964444\n",
      "loss in epoch 10 , step 8420 : 1.443018\n",
      "loss in epoch 10 , step 8440 : 1.025533\n",
      "loss in epoch 10 , step 8460 : 0.883312\n",
      "loss in epoch 10 , step 8480 : 0.611433\n",
      "loss in epoch 10 , step 8500 : 1.468461\n",
      "loss in epoch 10 , step 8520 : 0.047432\n",
      "loss in epoch 10 , step 8540 : 1.330114\n",
      "loss in epoch 10 , step 8560 : 1.820148\n",
      "loss in epoch 10 , step 8580 : 1.086378\n",
      "loss in epoch 10 , step 8600 : 0.743996\n",
      "loss in epoch 10 , step 8620 : 1.626174\n",
      "loss in epoch 10 , step 8640 : 1.450237\n",
      "loss in epoch 10 , step 8660 : 0.015291\n",
      "loss in epoch 10 , step 8680 : 1.246957\n",
      "loss in epoch 10 , step 8700 : 1.137138\n",
      "loss in epoch 10 , step 8720 : 2.766296\n",
      "loss in epoch 10 , step 8740 : 1.453322\n",
      "loss in epoch 10 , step 8760 : 0.549936\n",
      "loss in epoch 10 , step 8780 : 0.052224\n",
      "loss in epoch 10 , step 8800 : 0.014708\n",
      "loss in epoch 10 , step 8820 : 0.329771\n",
      "loss in epoch 10 , step 8840 : 2.082165\n",
      "loss in epoch 10 , step 8860 : 0.041290\n",
      "loss in epoch 10 , step 8880 : 0.307102\n",
      "loss in epoch 10 , step 8900 : 0.006545\n",
      "loss in epoch 10 , step 8920 : 1.299472\n",
      "loss in epoch 10 , step 8940 : 2.328706\n",
      "loss in epoch 10 , step 8960 : 1.395746\n",
      "loss in epoch 10 , step 8980 : 0.017625\n",
      "loss in epoch 10 , step 9000 : 1.640813\n",
      "loss in epoch 10 , step 9020 : 0.119607\n",
      "loss in epoch 10 , step 9040 : 2.613768\n",
      "loss in epoch 10 , step 9060 : 0.781181\n",
      "loss in epoch 10 , step 9080 : 1.380821\n",
      "loss in epoch 10 , step 9100 : 1.644465\n",
      "loss in epoch 10 , step 9120 : 1.815090\n",
      "loss in epoch 10 , step 9140 : 1.779207\n",
      "loss in epoch 10 , step 9160 : 2.121322\n",
      "loss in epoch 10 , step 9180 : 0.948249\n",
      "loss in epoch 10 , step 9200 : 0.674641\n",
      "loss in epoch 10 , step 9220 : 0.102894\n",
      "loss in epoch 10 , step 9240 : 1.476292\n",
      "loss in epoch 10 , step 9260 : 1.200747\n",
      "loss in epoch 10 , step 9280 : 1.630261\n",
      "loss in epoch 10 , step 9300 : 1.096805\n",
      "loss in epoch 10 , step 9320 : 1.796348\n",
      "loss in epoch 10 , step 9340 : 1.996519\n",
      "loss in epoch 10 , step 9360 : 1.346213\n",
      "loss in epoch 10 , step 9380 : 1.594065\n",
      "loss in epoch 10 , step 9400 : 0.323326\n",
      "loss in epoch 10 , step 9420 : 1.678509\n",
      "loss in epoch 10 , step 9440 : 1.606599\n",
      "loss in epoch 10 , step 9460 : 0.825006\n",
      "loss in epoch 10 , step 9480 : 0.767801\n",
      "loss in epoch 10 , step 9500 : 0.353170\n",
      "loss in epoch 10 , step 9520 : 0.326114\n",
      "loss in epoch 10 , step 9540 : 0.049152\n",
      "loss in epoch 10 , step 9560 : 2.984831\n",
      "loss in epoch 10 , step 9580 : 0.698218\n",
      "loss in epoch 10 , step 9600 : 0.011378\n",
      "loss in epoch 10 , step 9620 : 0.453880\n",
      "loss in epoch 10 , step 9640 : 0.214368\n",
      "loss in epoch 10 , step 9660 : 1.228489\n",
      "loss in epoch 10 , step 9680 : 0.125382\n",
      "loss in epoch 10 , step 9700 : 0.154073\n",
      "loss in epoch 10 , step 9720 : 1.367139\n",
      "loss in epoch 10 , step 9740 : 0.709027\n",
      "loss in epoch 10 , step 9760 : 0.075995\n",
      "loss in epoch 10 , step 9780 : 0.098660\n",
      "loss in epoch 10 , step 9800 : 0.521855\n",
      "loss in epoch 10 , step 9820 : 0.251459\n",
      "loss in epoch 10 , step 9840 : 0.950374\n",
      "loss in epoch 10 , step 9860 : 0.521409\n",
      "loss in epoch 10 , step 9880 : 1.615578\n",
      "loss in epoch 10 , step 9900 : 0.064174\n",
      "loss in epoch 10 , step 9920 : 1.196616\n",
      "loss in epoch 10 , step 9940 : 1.407083\n",
      "loss in epoch 10 , step 9960 : 1.500919\n",
      "loss in epoch 10 , step 9980 : 1.933211\n",
      "loss in epoch 10 , step 10000 : 0.363540\n",
      "loss in epoch 10 , step 10020 : 0.275122\n",
      "loss in epoch 10 , step 10040 : 1.572381\n",
      "loss in epoch 10 , step 10060 : 0.459224\n",
      "loss in epoch 10 , step 10080 : 2.558512\n",
      "loss in epoch 10 , step 10100 : 0.560925\n",
      "loss in epoch 10 , step 10120 : 1.193341\n",
      "loss in epoch 10 , step 10140 : 3.335932\n",
      "loss in epoch 10 , step 10160 : 2.149227\n",
      "loss in epoch 10 , step 10180 : 2.311788\n",
      "loss in epoch 10 , step 10200 : 0.486112\n",
      "loss in epoch 10 , step 10220 : 0.026821\n",
      "loss in epoch 10 , step 10240 : 0.038184\n",
      "loss in epoch 10 , step 10260 : 0.813367\n",
      "loss in epoch 10 , step 10280 : 1.869292\n",
      "loss in epoch 10 , step 10300 : 0.877683\n",
      "loss in epoch 10 , step 10320 : 1.141350\n",
      "loss in epoch 10 , step 10340 : 0.199058\n",
      "loss in epoch 10 , step 10360 : 1.733994\n",
      "loss in epoch 10 , step 10380 : 0.646897\n",
      "loss in epoch 10 , step 10400 : 1.334569\n",
      "loss in epoch 10 , step 10420 : 0.881536\n",
      "loss in epoch 10 , step 10440 : 0.043759\n",
      "loss in epoch 10 , step 10460 : 2.844728\n",
      "loss in epoch 10 , step 10480 : 1.061670\n",
      "loss in epoch 10 , step 10500 : 0.807461\n",
      "loss in epoch 10 , step 10520 : 0.821686\n",
      "loss in epoch 10 , step 10540 : 1.256125\n",
      "loss in epoch 10 , step 10560 : 0.008489\n",
      "loss in epoch 10 , step 10580 : 1.858162\n",
      "loss in epoch 10 , step 10600 : 2.055662\n",
      "loss in epoch 10 , step 10620 : 1.443959\n",
      "loss in epoch 10 , step 10640 : 1.365223\n",
      "loss in epoch 10 , step 10660 : 2.365733\n",
      "loss in epoch 10 , step 10680 : 0.195882\n",
      "loss in epoch 10 , step 10700 : 0.453357\n",
      "loss in epoch 10 , step 10720 : 0.792186\n",
      "loss in epoch 10 , step 10740 : 0.911517\n",
      "loss in epoch 10 , step 10760 : 0.987665\n",
      "loss in epoch 10 , step 10780 : 2.330468\n",
      "loss in epoch 10 , step 10800 : 1.330639\n",
      "loss in epoch 10 , step 10820 : 1.059244\n",
      "loss in epoch 10 , step 10840 : 1.447526\n",
      "loss in epoch 10 , step 10860 : 1.026162\n",
      "loss in epoch 10 , step 10880 : 0.718615\n",
      "loss in epoch 10 , step 10900 : 0.377478\n",
      "loss in epoch 10 , step 10920 : 2.258147\n",
      "loss in epoch 10 , step 10940 : 1.093477\n",
      "loss in epoch 10 , step 10960 : 1.024203\n",
      "loss in epoch 10 , step 10980 : 0.968780\n",
      "loss in epoch 10 , step 11000 : 2.689729\n",
      "loss in epoch 10 , step 11020 : 0.063357\n",
      "loss in epoch 10 , step 11040 : 0.448730\n",
      "loss in epoch 10 , step 11060 : 3.383819\n",
      "loss in epoch 10 , step 11080 : 1.362889\n",
      "loss in epoch 10 , step 11100 : 2.491002\n",
      "loss in epoch 10 , step 11120 : 1.460425\n",
      "loss in epoch 10 , step 11140 : 1.372127\n",
      "loss in epoch 10 , step 11160 : 1.953470\n",
      "loss in epoch 10 , step 11180 : 0.100783\n",
      "loss in epoch 10 , step 11200 : 2.001299\n",
      "loss in epoch 10 , step 11220 : 2.365709\n",
      "loss in epoch 10 , step 11240 : 1.212454\n",
      "loss in epoch 10 , step 11260 : 0.295187\n",
      "loss in epoch 10 , step 11280 : 1.638543\n",
      "loss in epoch 10 , step 11300 : 1.081886\n",
      "loss in epoch 10 , step 11320 : 3.093057\n",
      "loss in epoch 10 , step 11340 : 0.005273\n",
      "loss in epoch 10 , step 11360 : 2.929554\n",
      "loss in epoch 10 , step 11380 : 0.258622\n",
      "loss in epoch 10 , step 11400 : 1.339066\n",
      "loss in epoch 10 , step 11420 : 0.008144\n",
      "loss in epoch 10 , step 11440 : 0.590339\n",
      "loss in epoch 10 , step 11460 : 1.125374\n",
      "loss in epoch 10 , step 11480 : 0.419068\n",
      "loss in epoch 10 , step 11500 : 2.040002\n",
      "loss in epoch 10 , step 11520 : 0.074557\n",
      "loss in epoch 10 , step 11540 : 0.064659\n",
      "loss in epoch 10 , step 11560 : 0.783528\n",
      "loss in epoch 10 , step 11580 : 1.382461\n",
      "loss in epoch 10 , step 11600 : 0.245710\n",
      "loss in epoch 10 , step 11620 : 1.093167\n",
      "loss in epoch 10 , step 11640 : 1.476082\n",
      "loss in epoch 10 , step 11660 : 0.570990\n",
      "loss in epoch 10 , step 11680 : 0.009122\n",
      "loss in epoch 10 , step 11700 : 0.034205\n",
      "loss in epoch 10 , step 11720 : 3.702077\n",
      "loss in epoch 10 , step 11740 : 0.171883\n",
      "loss in epoch 10 , step 11760 : 1.619374\n",
      "loss in epoch 10 , step 11780 : 1.014716\n",
      "loss in epoch 10 , step 11800 : 0.474636\n",
      "loss in epoch 10 , step 11820 : 0.477131\n",
      "loss in epoch 10 , step 11840 : 0.287392\n",
      "loss in epoch 10 , step 11860 : 1.541560\n",
      "loss in epoch 10 , step 11880 : 0.737550\n",
      "loss in epoch 10 , step 11900 : 1.727110\n",
      "loss in epoch 10 , step 11920 : 0.822460\n",
      "loss in epoch 10 , step 11940 : 2.142626\n",
      "loss in epoch 10 , step 11960 : 0.934932\n",
      "loss in epoch 10 , step 11980 : 2.616630\n",
      "loss in epoch 10 , step 12000 : 1.869466\n",
      "loss in epoch 10 , step 12020 : 1.169815\n",
      "loss in epoch 10 , step 12040 : 1.108282\n",
      "loss in epoch 10 , step 12060 : 2.206829\n",
      "loss in epoch 10 , step 12080 : 1.620093\n",
      "loss in epoch 10 , step 12100 : 0.930385\n",
      "loss in epoch 10 , step 12120 : 1.228086\n",
      "loss in epoch 10 , step 12140 : 1.034954\n",
      "loss in epoch 10 , step 12160 : 0.556975\n",
      "loss in epoch 10 , step 12180 : 1.366913\n",
      "loss in epoch 10 , step 12200 : 1.345369\n",
      "loss in epoch 10 , step 12220 : 0.848852\n",
      "loss in epoch 10 , step 12240 : 1.951854\n",
      "loss in epoch 10 , step 12260 : 0.202262\n",
      "loss in epoch 10 , step 12280 : 0.924087\n",
      "loss in epoch 10 , step 12300 : 1.005744\n",
      "loss in epoch 10 , step 12320 : 1.144470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 10 , step 12340 : 0.165533\n",
      "loss in epoch 10 , step 12360 : 0.783422\n",
      "loss in epoch 10 , step 12380 : 1.715444\n",
      "loss in epoch 10 , step 12400 : 2.092341\n",
      "loss in epoch 10 , step 12420 : 1.685287\n",
      "loss in epoch 10 , step 12440 : 0.055310\n",
      "loss in epoch 10 , step 12460 : 1.605670\n",
      "loss in epoch 10 , step 12480 : 0.978979\n",
      "loss in epoch 10 , step 12500 : 2.057405\n",
      "loss in epoch 10 , step 12520 : 2.439796\n",
      "loss in epoch 10 , step 12540 : 3.313528\n",
      "loss in epoch 10 , step 12560 : 0.706820\n",
      "loss in epoch 10 , step 12580 : 1.483285\n",
      "loss in epoch 10 , step 12600 : 1.518626\n",
      "loss in epoch 10 , step 12620 : 1.816182\n",
      "loss in epoch 10 , step 12640 : 0.042115\n",
      "loss in epoch 10 , step 12660 : 0.016461\n",
      "loss in epoch 10 , step 12680 : 3.110547\n",
      "loss in epoch 10 , step 12700 : 0.110847\n",
      "loss in epoch 10 , step 12720 : 1.016641\n",
      "loss in epoch 10 , step 12740 : 0.964615\n",
      "loss in epoch 10 , step 12760 : 1.785683\n",
      "loss in epoch 10 , step 12780 : 1.766822\n",
      "loss in epoch 10 , step 12800 : 1.031864\n",
      "loss in epoch 10 , step 12820 : 0.680942\n",
      "loss in epoch 10 , step 12840 : 0.003824\n",
      "loss in epoch 10 , step 12860 : 0.153843\n",
      "loss in epoch 10 , step 12880 : 1.942127\n",
      "loss in epoch 10 , step 12900 : 0.078753\n",
      "loss in epoch 10 , step 12920 : 0.158564\n",
      "loss in epoch 10 , step 12940 : 1.279404\n",
      "loss in epoch 10 , step 12960 : 1.344934\n",
      "loss in epoch 10 , step 12980 : 0.970619\n",
      "loss in epoch 10 , step 13000 : 1.835749\n",
      "loss in epoch 10 , step 13020 : 0.788119\n",
      "loss in epoch 10 , step 13040 : 1.386670\n",
      "loss in epoch 10 , step 13060 : 1.448752\n",
      "loss in epoch 10 , step 13080 : 1.548548\n",
      "loss in epoch 10 , step 13100 : 1.982797\n",
      "loss in epoch 10 , step 13120 : 0.040973\n",
      "loss in epoch 10 , step 13140 : 0.043043\n",
      "loss in epoch 10 , step 13160 : 5.941971\n",
      "loss in epoch 10 , step 13180 : 0.088146\n",
      "loss in epoch 10 , step 13200 : 2.705185\n",
      "loss in epoch 10 , step 13220 : 0.707653\n",
      "loss in epoch 10 , step 13240 : 1.791387\n",
      "loss in epoch 10 , step 13260 : 0.525036\n",
      "loss in epoch 10 , step 13280 : 0.516812\n",
      "loss in epoch 10 , step 13300 : 0.049736\n",
      "loss in epoch 10 , step 13320 : 0.070960\n",
      "loss in epoch 10 , step 13340 : 1.683400\n",
      "loss in epoch 10 , step 13360 : 2.494884\n",
      "loss in epoch 10 , step 13380 : 3.235279\n",
      "loss in epoch 10 , step 13400 : 2.054115\n",
      "loss in epoch 10 , step 13420 : 1.844001\n",
      "loss in epoch 10 , step 13440 : 0.017757\n",
      "loss in epoch 10 , step 13460 : 0.049366\n",
      "loss in epoch 10 , step 13480 : 0.089242\n",
      "loss in epoch 10 , step 13500 : 2.275059\n",
      "loss in epoch 10 , step 13520 : 1.290369\n",
      "loss in epoch 10 , step 13540 : 2.487296\n",
      "loss in epoch 10 , step 13560 : 0.726686\n",
      "loss in epoch 10 , step 13580 : 1.340160\n",
      "loss in epoch 10 , step 13600 : 2.271989\n",
      "loss in epoch 10 , step 13620 : 2.644134\n",
      "loss in epoch 10 , step 13640 : 1.932288\n",
      "loss in epoch 10 , step 13660 : 1.435150\n",
      "loss in epoch 10 , step 13680 : 2.401193\n",
      "loss in epoch 10 , step 13700 : 1.506868\n",
      "loss in epoch 10 , step 13720 : 0.007240\n",
      "loss in epoch 10 , step 13740 : 0.234223\n",
      "loss in epoch 10 , step 13760 : 1.667260\n",
      "loss in epoch 10 , step 13780 : 0.097057\n",
      "loss in epoch 10 , step 13800 : 0.862924\n",
      "loss in epoch 10 , step 13820 : 0.540151\n",
      "loss in epoch 10 , step 13840 : 2.523522\n",
      "loss in epoch 10 , step 13860 : 0.441806\n",
      "loss in epoch 10 , step 13880 : 0.142179\n",
      "loss in epoch 10 , step 13900 : 0.953168\n",
      "loss in epoch 10 , step 13920 : 2.334718\n",
      "loss in epoch 10 , step 13940 : 1.194085\n",
      "loss in epoch 10 , step 13960 : 0.126142\n",
      "loss in epoch 10 , step 13980 : 1.890998\n",
      "loss in epoch 10 , step 14000 : 0.053632\n",
      "loss in epoch 10 , step 14020 : 0.183212\n",
      "loss in epoch 10 , step 14040 : 0.589218\n",
      "loss in epoch 10 , step 14060 : 1.490516\n",
      "loss in epoch 10 , step 14080 : 0.024630\n",
      "loss in epoch 10 , step 14100 : 1.109240\n",
      "loss in epoch 10 , step 14120 : 1.891110\n",
      "loss in epoch 10 , step 14140 : 0.401380\n",
      "loss in epoch 10 , step 14160 : 0.214295\n",
      "loss in epoch 10 , step 14180 : 0.334692\n",
      "loss in epoch 10 , step 14200 : 1.493280\n",
      "loss in epoch 10 , step 14220 : 2.170224\n",
      "loss in epoch 10 , step 14240 : 0.454755\n",
      "loss in epoch 10 , step 14260 : 1.072130\n",
      "loss in epoch 10 , step 14280 : 1.464497\n",
      "loss in epoch 10 , step 14300 : 0.789437\n",
      "loss in epoch 10 , step 14320 : 0.480162\n",
      "loss in epoch 10 , step 14340 : 2.822496\n",
      "loss in epoch 10 , step 14360 : 1.464975\n",
      "loss in epoch 10 , step 14380 : 0.779119\n",
      "loss in epoch 10 , step 14400 : 0.006341\n",
      "loss in epoch 10 , step 14420 : 0.417476\n",
      "loss in epoch 10 , step 14440 : 1.326652\n",
      "loss in epoch 10 , step 14460 : 2.043620\n",
      "loss in epoch 10 , step 14480 : 1.180250\n",
      "loss in epoch 10 , step 14500 : 0.010163\n",
      "loss in epoch 10 , step 14520 : 1.047955\n",
      "loss in epoch 10 , step 14540 : 0.605769\n",
      "loss in epoch 10 , step 14560 : 1.952259\n",
      "loss in epoch 10 , step 14580 : 1.649697\n",
      "loss in epoch 10 , step 14600 : 1.117100\n",
      "loss in epoch 10 , step 14620 : 0.113264\n",
      "loss in epoch 10 , step 14640 : 0.723553\n",
      "loss in epoch 10 , step 14660 : 1.203365\n",
      "loss in epoch 10 , step 14680 : 0.992908\n",
      "loss in epoch 10 , step 14700 : 1.456625\n",
      "loss in epoch 10 , step 14720 : 1.496678\n",
      "loss in epoch 10 , step 14740 : 0.076477\n",
      "loss in epoch 10 , step 14760 : 0.401890\n",
      "loss in epoch 10 , step 14780 : 0.545598\n",
      "loss in epoch 10 , step 14800 : 0.391968\n",
      "loss in epoch 10 , step 14820 : 1.508210\n",
      "loss in epoch 10 , step 14840 : 1.043845\n",
      "loss in epoch 10 , step 14860 : 2.755981\n",
      "loss in epoch 10 , step 14880 : 0.422735\n",
      "loss in epoch 10 , step 14900 : 1.785763\n",
      "loss in epoch 10 , step 14920 : 2.357226\n",
      "loss in epoch 10 , step 14940 : 0.156237\n",
      "loss in epoch 10 , step 14960 : 3.714445\n",
      "loss in epoch 10 , step 14980 : 2.142174\n",
      "loss in epoch 10 , step 15000 : 0.637900\n",
      "loss in epoch 10 , step 15020 : 1.177547\n",
      "loss in epoch 10 , step 15040 : 0.801886\n",
      "loss in epoch 10 , step 15060 : 1.030619\n",
      "loss in epoch 10 , step 15080 : 0.030022\n",
      "loss in epoch 10 , step 15100 : 1.212645\n",
      "loss in epoch 10 , step 15120 : 1.920378\n",
      "loss in epoch 10 , step 15140 : 0.077596\n",
      "loss in epoch 10 , step 15160 : 0.008660\n",
      "loss in epoch 10 , step 15180 : 2.180211\n",
      "loss in epoch 10 , step 15200 : 1.062657\n",
      "loss in epoch 10 , step 15220 : 1.070850\n",
      "loss in epoch 10 , step 15240 : 1.488590\n",
      "loss in epoch 10 , step 15260 : 1.257758\n",
      "loss in epoch 10 , step 15280 : 0.128274\n",
      "loss in epoch 10 , step 15300 : 1.396226\n",
      "loss in epoch 10 , step 15320 : 1.779382\n",
      "loss in epoch 10 , step 15340 : 1.732228\n",
      "loss in epoch 10 , step 15360 : 2.763889\n",
      "loss in epoch 10 , step 15380 : 0.887339\n",
      "loss in epoch 10 , step 15400 : 2.329455\n",
      "loss in epoch 10 , step 15420 : 2.009028\n",
      "loss in epoch 10 , step 15440 : 0.708797\n",
      "loss in epoch 10 , step 15460 : 0.683641\n",
      "loss in epoch 10 , step 15480 : 0.783015\n",
      "loss in epoch 10 , step 15500 : 1.494653\n",
      "loss in epoch 10 , step 15520 : 2.931159\n",
      "loss in epoch 10 , step 15540 : 0.974560\n",
      "loss in epoch 10 , step 15560 : 1.703026\n",
      "loss in epoch 10 , step 15580 : 0.127419\n",
      "loss in epoch 10 , step 15600 : 1.470387\n",
      "loss in epoch 10 , step 15620 : 1.468892\n",
      "loss in epoch 10 , step 15640 : 2.295764\n",
      "loss in epoch 10 , step 15660 : 0.569667\n",
      "loss in epoch 10 , step 15680 : 1.314820\n",
      "loss in epoch 10 , step 15700 : 0.965252\n",
      "loss in epoch 10 , step 15720 : 0.073793\n",
      "loss in epoch 10 , step 15740 : 0.068956\n",
      "loss in epoch 10 , step 15760 : 2.317003\n",
      "loss in epoch 10 , step 15780 : 0.794421\n",
      "loss in epoch 10 , step 15800 : 0.392259\n",
      "loss in epoch 10 , step 15820 : 0.005153\n",
      "loss in epoch 10 , step 15840 : 1.525862\n",
      "loss in epoch 10 , step 15860 : 1.785228\n",
      "loss in epoch 10 , step 15880 : 2.133072\n",
      "loss in epoch 10 , step 15900 : 0.513882\n",
      "loss in epoch 10 , step 15920 : 2.042649\n",
      "loss in epoch 10 , step 15940 : 3.977659\n",
      "loss in epoch 10 , step 15960 : 1.566475\n",
      "loss in epoch 10 , step 15980 : 1.038106\n",
      "loss in epoch 10 , step 16000 : 1.052961\n",
      "loss in epoch 10 , step 16020 : 0.466039\n",
      "loss in epoch 10 , step 16040 : 0.876302\n",
      "loss in epoch 10 , step 16060 : 0.050919\n",
      "loss in epoch 10 , step 16080 : 0.048376\n",
      "loss in epoch 10 , step 16100 : 0.105675\n",
      "loss in epoch 10 , step 16120 : 1.885790\n",
      "loss in epoch 10 , step 16140 : 0.285316\n",
      "loss in epoch 10 , step 16160 : 1.546147\n",
      "loss in epoch 10 , step 16180 : 1.880300\n",
      "loss in epoch 10 , step 16200 : 1.325224\n",
      "loss in epoch 10 , step 16220 : 1.361545\n",
      "loss in epoch 10 , step 16240 : 0.100467\n",
      "loss in epoch 10 , step 16260 : 0.737054\n",
      "loss in epoch 10 , step 16280 : 2.829433\n",
      "loss in epoch 10 , step 16300 : 1.683710\n",
      "loss in epoch 10 , step 16320 : 0.696409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 10 , step 16340 : 1.655634\n",
      "loss in epoch 10 , step 16360 : 0.216199\n",
      "loss in epoch 10 , step 16380 : 1.298248\n",
      "loss in epoch 10 , step 16400 : 0.961149\n",
      "loss in epoch 10 , step 16420 : 1.547139\n",
      "loss in epoch 10 , step 16440 : 0.002788\n",
      "loss in epoch 10 , step 16460 : 0.134481\n",
      "loss in epoch 10 , step 16480 : 1.604516\n",
      "loss in epoch 10 , step 16500 : 0.103171\n",
      "loss in epoch 10 , step 16520 : 0.917750\n",
      "loss in epoch 10 , step 16540 : 1.688341\n",
      "loss in epoch 10 , step 16560 : 0.417500\n",
      "loss in epoch 10 , step 16580 : 0.230104\n",
      "loss in epoch 10 , step 16600 : 0.220608\n",
      "loss in epoch 10 , step 16620 : 1.596354\n",
      "loss in epoch 10 , step 16640 : 1.582271\n",
      "loss in epoch 10 , step 16660 : 0.884732\n",
      "loss in epoch 10 , step 16680 : 0.537863\n",
      "loss in epoch 10 , step 16700 : 2.438341\n",
      "loss in epoch 10 , step 16720 : 2.223980\n",
      "loss in epoch 10 , step 16740 : 2.428279\n",
      "loss in epoch 10 , step 16760 : 0.018204\n",
      "loss in epoch 10 , step 16780 : 0.080908\n",
      "loss in epoch 10 , step 16800 : 0.681595\n",
      "loss in epoch 10 , step 16820 : 2.451928\n",
      "loss in epoch 10 , step 16840 : 0.421918\n",
      "loss in epoch 10 , step 16860 : 0.949975\n",
      "loss in epoch 10 , step 16880 : 1.539977\n",
      "loss in epoch 10 , step 16900 : 2.022633\n",
      "loss in epoch 10 , step 16920 : 1.267442\n",
      "loss in epoch 10 , step 16940 : 1.340895\n",
      "loss in epoch 10 , step 16960 : 0.434004\n",
      "loss in epoch 10 , step 16980 : 0.009433\n",
      "loss in epoch 10 , step 17000 : 0.412830\n",
      "loss in epoch 10 , step 17020 : 0.505679\n",
      "loss in epoch 10 , step 17040 : 0.218691\n",
      "loss in epoch 10 , step 17060 : 0.037121\n",
      "loss in epoch 10 , step 17080 : 0.029215\n",
      "loss in epoch 10 , step 17100 : 1.322698\n",
      "loss in epoch 10 , step 17120 : 1.647885\n",
      "loss in epoch 10 , step 17140 : 0.013918\n",
      "loss in epoch 10 , step 17160 : 2.700195\n",
      "loss in epoch 10 , step 17180 : 1.308415\n",
      "loss in epoch 10 , step 17200 : 0.931121\n",
      "loss in epoch 10 , step 17220 : 1.613287\n",
      "loss in epoch 10 , step 17240 : 0.088529\n",
      "loss in epoch 10 , step 17260 : 1.016219\n",
      "loss in epoch 10 , step 17280 : 1.255332\n",
      "loss in epoch 10 , step 17300 : 2.329598\n",
      "loss in epoch 10 , step 17320 : 0.844628\n",
      "loss in epoch 10 , step 17340 : 2.410200\n",
      "loss in epoch 10 , step 17360 : 1.160841\n",
      "loss in epoch 10 , step 17380 : 0.334982\n",
      "loss in epoch 10 , step 17400 : 0.012025\n",
      "loss in epoch 10 , step 17420 : 2.254345\n",
      "loss in epoch 10 , step 17440 : 0.886678\n",
      "loss in epoch 10 , step 17460 : 0.040326\n",
      "loss in epoch 10 , step 17480 : 0.380647\n",
      "loss in epoch 10 , step 17500 : 1.746873\n",
      "loss in epoch 10 , step 17520 : 1.520942\n",
      "loss in epoch 10 , step 17540 : 1.358083\n",
      "loss in epoch 10 , step 17560 : 0.913482\n",
      "loss in epoch 10 , step 17580 : 0.969719\n",
      "loss in epoch 10 , step 17600 : 1.379923\n",
      "loss in epoch 10 , step 17620 : 0.051579\n",
      "loss in epoch 10 , step 17640 : 0.675498\n",
      "loss in epoch 10 , step 17660 : 0.740080\n",
      "loss in epoch 10 , step 17680 : 0.005035\n",
      "loss in epoch 10 , step 17700 : 0.039231\n",
      "loss in epoch 10 , step 17720 : 1.465223\n",
      "loss in epoch 10 , step 17740 : 1.744590\n",
      "loss in epoch 10 , step 17760 : 0.728747\n",
      "loss in epoch 10 , step 17780 : 1.303762\n",
      "loss in epoch 10 , step 17800 : 1.006902\n",
      "loss in epoch 10 , step 17820 : 0.066695\n",
      "loss in epoch 10 , step 17840 : 0.748099\n",
      "loss in epoch 10 , step 17860 : 1.381334\n",
      "loss in epoch 10 , step 17880 : 0.045756\n",
      "loss in epoch 10 , step 17900 : 0.619798\n",
      "loss in epoch 10 , step 17920 : 0.791186\n",
      "loss in epoch 10 , step 17940 : 0.246752\n",
      "loss in epoch 10 , step 17960 : 3.531377\n",
      "loss in epoch 10 , step 17980 : 0.745822\n",
      "loss in epoch 10 , step 18000 : 0.108711\n",
      "loss in epoch 10 , step 18020 : 1.294112\n",
      "loss in epoch 10 , step 18040 : 1.308446\n",
      "loss in epoch 10 , step 18060 : 0.307888\n",
      "loss in epoch 10 , step 18080 : 0.016164\n",
      "loss in epoch 10 , step 18100 : 0.133049\n",
      "loss in epoch 10 , step 18120 : 0.643658\n",
      "loss in epoch 10 , step 18140 : 0.861671\n",
      "loss in epoch 10 , step 18160 : 0.754550\n",
      "loss in epoch 10 , step 18180 : 1.742242\n",
      "loss in epoch 10 , step 18200 : 2.721997\n",
      "loss in epoch 10 , step 18220 : 0.678240\n",
      "loss in epoch 10 , step 18240 : 2.113402\n",
      "loss in epoch 10 , step 18260 : 1.076314\n",
      "loss in epoch 10 , step 18280 : 0.016203\n",
      "loss in epoch 10 , step 18300 : 2.233795\n",
      "loss in epoch 10 , step 18320 : 0.675036\n",
      "loss in epoch 10 , step 18340 : 0.566492\n",
      "loss in epoch 10 , step 18360 : 0.164831\n",
      "loss in epoch 10 , step 18380 : 1.008292\n",
      "loss in epoch 10 , step 18400 : 0.492417\n",
      "loss in epoch 10 , step 18420 : 2.070137\n",
      "loss in epoch 10 , step 18440 : 0.015422\n",
      "loss in epoch 10 , step 18460 : 0.131625\n",
      "loss in epoch 10 , step 18480 : 0.649598\n",
      "loss in epoch 10 , step 18500 : 2.438652\n",
      "loss in epoch 10 , step 18520 : 1.474278\n",
      "loss in epoch 10 , step 18540 : 0.635474\n",
      "loss in epoch 10 , step 18560 : 0.060926\n",
      "loss in epoch 10 , step 18580 : 0.211536\n",
      "loss in epoch 10 , step 18600 : 1.565554\n",
      "loss in epoch 10 , step 18620 : 0.089877\n",
      "loss in epoch 10 , step 18640 : 0.671883\n",
      "loss in epoch 10 , step 18660 : 0.483766\n",
      "loss in epoch 10 , step 18680 : 0.116160\n",
      "loss in epoch 10 , step 18700 : 1.438280\n",
      "loss in epoch 10 , step 18720 : 0.048888\n",
      "loss in epoch 10 , step 18740 : 1.727823\n",
      "loss in epoch 10 , step 18760 : 1.667835\n",
      "loss in epoch 10 , step 18780 : 0.005464\n",
      "loss in epoch 10 , step 18800 : 0.131930\n",
      "loss in epoch 10 , step 18820 : 1.267197\n",
      "loss in epoch 10 , step 18840 : 1.609807\n",
      "loss in epoch 10 , step 18860 : 0.049748\n",
      "loss in epoch 10 , step 18880 : 1.303756\n",
      "loss in epoch 10 , step 18900 : 0.056942\n",
      "loss in epoch 10 , step 18920 : 1.868646\n",
      "loss in epoch 10 , step 18940 : 3.630412\n",
      "loss in epoch 10 , step 18960 : 0.315061\n",
      "loss in epoch 10 , step 18980 : 1.157635\n",
      "loss in epoch 10 , step 19000 : 1.849139\n",
      "loss in epoch 10 , step 19020 : 1.150344\n",
      "loss in epoch 10 , step 19040 : 1.767224\n",
      "loss in epoch 10 , step 19060 : 1.068499\n",
      "loss in epoch 10 , step 19080 : 0.449435\n",
      "loss in epoch 10 , step 19100 : 1.664598\n",
      "loss in epoch 10 , step 19120 : 0.029036\n",
      "loss in epoch 10 , step 19140 : 1.638894\n",
      "loss in epoch 10 , step 19160 : 0.722464\n",
      "loss in epoch 10 , step 19180 : 0.709608\n",
      "loss in epoch 10 , step 19200 : 1.505090\n",
      "loss in epoch 10 , step 19220 : 1.283531\n",
      "loss in epoch 10 , step 19240 : 0.267385\n",
      "loss in epoch 10 , step 19260 : 1.863200\n",
      "loss in epoch 10 , step 19280 : 2.285743\n",
      "loss in epoch 10 , step 19300 : 0.009190\n",
      "loss in epoch 10 , step 19320 : 2.289032\n",
      "loss in epoch 10 , step 19340 : 0.783577\n",
      "loss in epoch 10 , step 19360 : 0.283228\n",
      "loss in epoch 10 , step 19380 : 1.070307\n",
      "loss in epoch 10 , step 19400 : 1.676926\n",
      "loss in epoch 10 , step 19420 : 0.252925\n",
      "loss in epoch 10 , step 19440 : 0.244893\n",
      "loss in epoch 10 , step 19460 : 0.047427\n",
      "loss in epoch 10 , step 19480 : 1.867956\n",
      "loss in epoch 10 , step 19500 : 0.052827\n",
      "loss in epoch 10 , step 19520 : 0.597949\n",
      "loss in epoch 10 , step 19540 : 0.017584\n",
      "loss in epoch 10 , step 19560 : 1.295774\n",
      "loss in epoch 10 , step 19580 : 2.412869\n",
      "loss in epoch 10 , step 19600 : 2.735633\n",
      "loss in epoch 10 , step 19620 : 0.191687\n",
      "loss in epoch 10 , step 19640 : 0.499273\n",
      "loss in epoch 10 , step 19660 : 0.359877\n",
      "loss in epoch 10 , step 19680 : 2.382116\n",
      "loss in epoch 10 , step 19700 : 0.593950\n",
      "loss in epoch 10 , step 19720 : 1.209130\n",
      "loss in epoch 10 , step 19740 : 0.115005\n",
      "loss in epoch 10 , step 19760 : 0.147631\n",
      "loss in epoch 10 , step 19780 : 1.940543\n",
      "loss in epoch 10 , step 19800 : 2.056528\n",
      "loss in epoch 10 , step 19820 : 1.030873\n",
      "loss in epoch 10 , step 19840 : 0.364553\n",
      "loss in epoch 10 , step 19860 : 1.091302\n",
      "loss in epoch 10 , step 19880 : 1.911731\n",
      "loss in epoch 10 , step 19900 : 0.241212\n",
      "loss in epoch 10 , step 19920 : 0.654253\n",
      "loss in epoch 10 , step 19940 : 0.145913\n",
      "Accuracy in epoch 10 : 31.980272\n",
      "loss in epoch 11 , step 0 : 1.718583\n",
      "loss in epoch 11 , step 20 : 1.975041\n",
      "loss in epoch 11 , step 40 : 1.622492\n",
      "loss in epoch 11 , step 60 : 0.302475\n",
      "loss in epoch 11 , step 80 : 0.987019\n",
      "loss in epoch 11 , step 100 : 1.109101\n",
      "loss in epoch 11 , step 120 : 0.334063\n",
      "loss in epoch 11 , step 140 : 0.663835\n",
      "loss in epoch 11 , step 160 : 1.092795\n",
      "loss in epoch 11 , step 180 : 0.667340\n",
      "loss in epoch 11 , step 200 : 0.345241\n",
      "loss in epoch 11 , step 220 : 2.106208\n",
      "loss in epoch 11 , step 240 : 1.120316\n",
      "loss in epoch 11 , step 260 : 0.530493\n",
      "loss in epoch 11 , step 280 : 0.579898\n",
      "loss in epoch 11 , step 300 : 0.990508\n",
      "loss in epoch 11 , step 320 : 0.771982\n",
      "loss in epoch 11 , step 340 : 0.942135\n",
      "loss in epoch 11 , step 360 : 0.026681\n",
      "loss in epoch 11 , step 380 : 0.089224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 11 , step 400 : 0.276222\n",
      "loss in epoch 11 , step 420 : 1.961256\n",
      "loss in epoch 11 , step 440 : 0.769634\n",
      "loss in epoch 11 , step 460 : 2.076707\n",
      "loss in epoch 11 , step 480 : 0.284929\n",
      "loss in epoch 11 , step 500 : 1.329978\n",
      "loss in epoch 11 , step 520 : 1.107466\n",
      "loss in epoch 11 , step 540 : 0.007791\n",
      "loss in epoch 11 , step 560 : 1.204413\n",
      "loss in epoch 11 , step 580 : 2.336168\n",
      "loss in epoch 11 , step 600 : 0.009539\n",
      "loss in epoch 11 , step 620 : 3.724695\n",
      "loss in epoch 11 , step 640 : 1.755316\n",
      "loss in epoch 11 , step 660 : 0.013524\n",
      "loss in epoch 11 , step 680 : 0.946096\n",
      "loss in epoch 11 , step 700 : 1.285355\n",
      "loss in epoch 11 , step 720 : 1.126810\n",
      "loss in epoch 11 , step 740 : 1.732021\n",
      "loss in epoch 11 , step 760 : 1.689981\n",
      "loss in epoch 11 , step 780 : 0.140807\n",
      "loss in epoch 11 , step 800 : 1.825088\n",
      "loss in epoch 11 , step 820 : 0.034524\n",
      "loss in epoch 11 , step 840 : 1.681754\n",
      "loss in epoch 11 , step 860 : 3.439577\n",
      "loss in epoch 11 , step 880 : 1.913638\n",
      "loss in epoch 11 , step 900 : 1.855944\n",
      "loss in epoch 11 , step 920 : 2.252679\n",
      "loss in epoch 11 , step 940 : 1.531057\n",
      "loss in epoch 11 , step 960 : 0.121436\n",
      "loss in epoch 11 , step 980 : 2.986482\n",
      "loss in epoch 11 , step 1000 : 0.869120\n",
      "loss in epoch 11 , step 1020 : 3.883625\n",
      "loss in epoch 11 , step 1040 : 0.701687\n",
      "loss in epoch 11 , step 1060 : 0.090184\n",
      "loss in epoch 11 , step 1080 : 1.526311\n",
      "loss in epoch 11 , step 1100 : 0.002591\n",
      "loss in epoch 11 , step 1120 : 0.054596\n",
      "loss in epoch 11 , step 1140 : 1.153834\n",
      "loss in epoch 11 , step 1160 : 1.298991\n",
      "loss in epoch 11 , step 1180 : 0.058767\n",
      "loss in epoch 11 , step 1200 : 0.230230\n",
      "loss in epoch 11 , step 1220 : 1.070377\n",
      "loss in epoch 11 , step 1240 : 0.430123\n",
      "loss in epoch 11 , step 1260 : 1.159433\n",
      "loss in epoch 11 , step 1280 : 0.475887\n",
      "loss in epoch 11 , step 1300 : 0.038218\n",
      "loss in epoch 11 , step 1320 : 0.149523\n",
      "loss in epoch 11 , step 1340 : 3.385870\n",
      "loss in epoch 11 , step 1360 : 1.019712\n",
      "loss in epoch 11 , step 1380 : 0.283727\n",
      "loss in epoch 11 , step 1400 : 1.217436\n",
      "loss in epoch 11 , step 1420 : 0.738325\n",
      "loss in epoch 11 , step 1440 : 1.322017\n",
      "loss in epoch 11 , step 1460 : 0.322097\n",
      "loss in epoch 11 , step 1480 : 1.031425\n",
      "loss in epoch 11 , step 1500 : 0.874378\n",
      "loss in epoch 11 , step 1520 : 1.409549\n",
      "loss in epoch 11 , step 1540 : 1.556132\n",
      "loss in epoch 11 , step 1560 : 0.733320\n",
      "loss in epoch 11 , step 1580 : 1.962812\n",
      "loss in epoch 11 , step 1600 : 1.026266\n",
      "loss in epoch 11 , step 1620 : 1.195686\n",
      "loss in epoch 11 , step 1640 : 1.035934\n",
      "loss in epoch 11 , step 1660 : 2.965948\n",
      "loss in epoch 11 , step 1680 : 1.200521\n",
      "loss in epoch 11 , step 1700 : 1.148542\n",
      "loss in epoch 11 , step 1720 : 0.925518\n",
      "loss in epoch 11 , step 1740 : 0.280854\n",
      "loss in epoch 11 , step 1760 : 0.976292\n",
      "loss in epoch 11 , step 1780 : 0.621430\n",
      "loss in epoch 11 , step 1800 : 0.029379\n",
      "loss in epoch 11 , step 1820 : 1.686720\n",
      "loss in epoch 11 , step 1840 : 0.412324\n",
      "loss in epoch 11 , step 1860 : 1.389703\n",
      "loss in epoch 11 , step 1880 : 0.030415\n",
      "loss in epoch 11 , step 1900 : 1.629021\n",
      "loss in epoch 11 , step 1920 : 0.028030\n",
      "loss in epoch 11 , step 1940 : 1.112179\n",
      "loss in epoch 11 , step 1960 : 1.287083\n",
      "loss in epoch 11 , step 1980 : 1.211165\n",
      "loss in epoch 11 , step 2000 : 0.902697\n",
      "loss in epoch 11 , step 2020 : 0.320667\n",
      "loss in epoch 11 , step 2040 : 1.196665\n",
      "loss in epoch 11 , step 2060 : 2.439496\n",
      "loss in epoch 11 , step 2080 : 0.582816\n",
      "loss in epoch 11 , step 2100 : 2.819899\n",
      "loss in epoch 11 , step 2120 : 0.068097\n",
      "loss in epoch 11 , step 2140 : 0.776330\n",
      "loss in epoch 11 , step 2160 : 1.415424\n",
      "loss in epoch 11 , step 2180 : 1.137877\n",
      "loss in epoch 11 , step 2200 : 0.806991\n",
      "loss in epoch 11 , step 2220 : 1.720386\n",
      "loss in epoch 11 , step 2240 : 1.657966\n",
      "loss in epoch 11 , step 2260 : 1.463520\n",
      "loss in epoch 11 , step 2280 : 0.816332\n",
      "loss in epoch 11 , step 2300 : 3.690415\n",
      "loss in epoch 11 , step 2320 : 1.506210\n",
      "loss in epoch 11 , step 2340 : 2.226269\n",
      "loss in epoch 11 , step 2360 : 0.013828\n",
      "loss in epoch 11 , step 2380 : 0.056828\n",
      "loss in epoch 11 , step 2400 : 1.637605\n",
      "loss in epoch 11 , step 2420 : 1.333366\n",
      "loss in epoch 11 , step 2440 : 0.438328\n",
      "loss in epoch 11 , step 2460 : 0.004261\n",
      "loss in epoch 11 , step 2480 : 0.459289\n",
      "loss in epoch 11 , step 2500 : 0.747572\n",
      "loss in epoch 11 , step 2520 : 0.784887\n",
      "loss in epoch 11 , step 2540 : 1.613776\n",
      "loss in epoch 11 , step 2560 : 0.048007\n",
      "loss in epoch 11 , step 2580 : 0.017435\n",
      "loss in epoch 11 , step 2600 : 0.922601\n",
      "loss in epoch 11 , step 2620 : 2.070257\n",
      "loss in epoch 11 , step 2640 : 0.183644\n",
      "loss in epoch 11 , step 2660 : 1.139319\n",
      "loss in epoch 11 , step 2680 : 0.055755\n",
      "loss in epoch 11 , step 2700 : 0.993633\n",
      "loss in epoch 11 , step 2720 : 2.413083\n",
      "loss in epoch 11 , step 2740 : 0.493261\n",
      "loss in epoch 11 , step 2760 : 0.253359\n",
      "loss in epoch 11 , step 2780 : 0.797792\n",
      "loss in epoch 11 , step 2800 : 0.465921\n",
      "loss in epoch 11 , step 2820 : 0.848329\n",
      "loss in epoch 11 , step 2840 : 0.096494\n",
      "loss in epoch 11 , step 2860 : 0.904187\n",
      "loss in epoch 11 , step 2880 : 0.914673\n",
      "loss in epoch 11 , step 2900 : 2.495925\n",
      "loss in epoch 11 , step 2920 : 1.887887\n",
      "loss in epoch 11 , step 2940 : 1.372340\n",
      "loss in epoch 11 , step 2960 : 1.455329\n",
      "loss in epoch 11 , step 2980 : 0.549159\n",
      "loss in epoch 11 , step 3000 : 0.305151\n",
      "loss in epoch 11 , step 3020 : 2.695359\n",
      "loss in epoch 11 , step 3040 : 0.326809\n",
      "loss in epoch 11 , step 3060 : 0.131666\n",
      "loss in epoch 11 , step 3080 : 0.488981\n",
      "loss in epoch 11 , step 3100 : 0.463039\n",
      "loss in epoch 11 , step 3120 : 0.050469\n",
      "loss in epoch 11 , step 3140 : 1.508598\n",
      "loss in epoch 11 , step 3160 : 0.675894\n",
      "loss in epoch 11 , step 3180 : 2.180397\n",
      "loss in epoch 11 , step 3200 : 2.222902\n",
      "loss in epoch 11 , step 3220 : 1.174273\n",
      "loss in epoch 11 , step 3240 : 0.722635\n",
      "loss in epoch 11 , step 3260 : 2.016405\n",
      "loss in epoch 11 , step 3280 : 1.622867\n",
      "loss in epoch 11 , step 3300 : 1.401888\n",
      "loss in epoch 11 , step 3320 : 1.309602\n",
      "loss in epoch 11 , step 3340 : 0.125737\n",
      "loss in epoch 11 , step 3360 : 1.398987\n",
      "loss in epoch 11 , step 3380 : 0.072275\n",
      "loss in epoch 11 , step 3400 : 1.307474\n",
      "loss in epoch 11 , step 3420 : 0.384651\n",
      "loss in epoch 11 , step 3440 : 0.812694\n",
      "loss in epoch 11 , step 3460 : 2.476095\n",
      "loss in epoch 11 , step 3480 : 1.448039\n",
      "loss in epoch 11 , step 3500 : 1.183713\n",
      "loss in epoch 11 , step 3520 : 1.519849\n",
      "loss in epoch 11 , step 3540 : 0.040295\n",
      "loss in epoch 11 , step 3560 : 1.424555\n",
      "loss in epoch 11 , step 3580 : 0.006722\n",
      "loss in epoch 11 , step 3600 : 0.007047\n",
      "loss in epoch 11 , step 3620 : 1.998446\n",
      "loss in epoch 11 , step 3640 : 1.526499\n",
      "loss in epoch 11 , step 3660 : 0.002401\n",
      "loss in epoch 11 , step 3680 : 1.033139\n",
      "loss in epoch 11 , step 3700 : 0.377782\n",
      "loss in epoch 11 , step 3720 : 0.652596\n",
      "loss in epoch 11 , step 3740 : 0.055926\n",
      "loss in epoch 11 , step 3760 : 1.596766\n",
      "loss in epoch 11 , step 3780 : 1.702567\n",
      "loss in epoch 11 , step 3800 : 0.800367\n",
      "loss in epoch 11 , step 3820 : 1.037853\n",
      "loss in epoch 11 , step 3840 : 2.584688\n",
      "loss in epoch 11 , step 3860 : 0.661990\n",
      "loss in epoch 11 , step 3880 : 0.200538\n",
      "loss in epoch 11 , step 3900 : 0.945904\n",
      "loss in epoch 11 , step 3920 : 0.670783\n",
      "loss in epoch 11 , step 3940 : 0.378750\n",
      "loss in epoch 11 , step 3960 : 0.799031\n",
      "loss in epoch 11 , step 3980 : 1.969196\n",
      "loss in epoch 11 , step 4000 : 0.689629\n",
      "loss in epoch 11 , step 4020 : 0.436261\n",
      "loss in epoch 11 , step 4040 : 1.966127\n",
      "loss in epoch 11 , step 4060 : 1.327107\n",
      "loss in epoch 11 , step 4080 : 0.687935\n",
      "loss in epoch 11 , step 4100 : 0.922099\n",
      "loss in epoch 11 , step 4120 : 0.414876\n",
      "loss in epoch 11 , step 4140 : 0.011803\n",
      "loss in epoch 11 , step 4160 : 0.218289\n",
      "loss in epoch 11 , step 4180 : 0.190666\n",
      "loss in epoch 11 , step 4200 : 2.107883\n",
      "loss in epoch 11 , step 4220 : 1.136483\n",
      "loss in epoch 11 , step 4240 : 1.220324\n",
      "loss in epoch 11 , step 4260 : 0.771315\n",
      "loss in epoch 11 , step 4280 : 1.839595\n",
      "loss in epoch 11 , step 4300 : 0.640932\n",
      "loss in epoch 11 , step 4320 : 1.299654\n",
      "loss in epoch 11 , step 4340 : 0.051013\n",
      "loss in epoch 11 , step 4360 : 1.783962\n",
      "loss in epoch 11 , step 4380 : 1.439048\n",
      "loss in epoch 11 , step 4400 : 0.359798\n",
      "loss in epoch 11 , step 4420 : 0.515252\n",
      "loss in epoch 11 , step 4440 : 1.178748\n",
      "loss in epoch 11 , step 4460 : 0.294349\n",
      "loss in epoch 11 , step 4480 : 1.000202\n",
      "loss in epoch 11 , step 4500 : 1.198939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 11 , step 4520 : 1.241538\n",
      "loss in epoch 11 , step 4540 : 0.912686\n",
      "loss in epoch 11 , step 4560 : 0.054335\n",
      "loss in epoch 11 , step 4580 : 1.694286\n",
      "loss in epoch 11 , step 4600 : 1.440692\n",
      "loss in epoch 11 , step 4620 : 0.356726\n",
      "loss in epoch 11 , step 4640 : 0.006363\n",
      "loss in epoch 11 , step 4660 : 1.392707\n",
      "loss in epoch 11 , step 4680 : 1.481360\n",
      "loss in epoch 11 , step 4700 : 0.005642\n",
      "loss in epoch 11 , step 4720 : 1.519000\n",
      "loss in epoch 11 , step 4740 : 0.740118\n",
      "loss in epoch 11 , step 4760 : 0.936255\n",
      "loss in epoch 11 , step 4780 : 0.378662\n",
      "loss in epoch 11 , step 4800 : 0.357829\n",
      "loss in epoch 11 , step 4820 : 0.111876\n",
      "loss in epoch 11 , step 4840 : 0.076958\n",
      "loss in epoch 11 , step 4860 : 2.953421\n",
      "loss in epoch 11 , step 4880 : 0.160817\n",
      "loss in epoch 11 , step 4900 : 0.669381\n",
      "loss in epoch 11 , step 4920 : 0.728897\n",
      "loss in epoch 11 , step 4940 : 0.243774\n",
      "loss in epoch 11 , step 4960 : 0.918050\n",
      "loss in epoch 11 , step 4980 : 0.183705\n",
      "loss in epoch 11 , step 5000 : 2.630828\n",
      "loss in epoch 11 , step 5020 : 0.842766\n",
      "loss in epoch 11 , step 5040 : 1.561433\n",
      "loss in epoch 11 , step 5060 : 1.689350\n",
      "loss in epoch 11 , step 5080 : 0.010752\n",
      "loss in epoch 11 , step 5100 : 0.057070\n",
      "loss in epoch 11 , step 5120 : 0.011904\n",
      "loss in epoch 11 , step 5140 : 1.164144\n",
      "loss in epoch 11 , step 5160 : 1.173383\n",
      "loss in epoch 11 , step 5180 : 0.347978\n",
      "loss in epoch 11 , step 5200 : 0.276687\n",
      "loss in epoch 11 , step 5220 : 1.038935\n",
      "loss in epoch 11 , step 5240 : 3.987185\n",
      "loss in epoch 11 , step 5260 : 1.455876\n",
      "loss in epoch 11 , step 5280 : 0.489284\n",
      "loss in epoch 11 , step 5300 : 0.077474\n",
      "loss in epoch 11 , step 5320 : 0.630571\n",
      "loss in epoch 11 , step 5340 : 0.120883\n",
      "loss in epoch 11 , step 5360 : 1.383240\n",
      "loss in epoch 11 , step 5380 : 0.079605\n",
      "loss in epoch 11 , step 5400 : 0.997655\n",
      "loss in epoch 11 , step 5420 : 0.034826\n",
      "loss in epoch 11 , step 5440 : 0.370398\n",
      "loss in epoch 11 , step 5460 : 1.897468\n",
      "loss in epoch 11 , step 5480 : 0.051725\n",
      "loss in epoch 11 , step 5500 : 0.475165\n",
      "loss in epoch 11 , step 5520 : 1.297778\n",
      "loss in epoch 11 , step 5540 : 0.010741\n",
      "loss in epoch 11 , step 5560 : 0.176827\n",
      "loss in epoch 11 , step 5580 : 0.152710\n",
      "loss in epoch 11 , step 5600 : 1.331191\n",
      "loss in epoch 11 , step 5620 : 0.152812\n",
      "loss in epoch 11 , step 5640 : 1.065375\n",
      "loss in epoch 11 , step 5660 : 1.796290\n",
      "loss in epoch 11 , step 5680 : 1.979504\n",
      "loss in epoch 11 , step 5700 : 0.975547\n",
      "loss in epoch 11 , step 5720 : 1.701280\n",
      "loss in epoch 11 , step 5740 : 0.944897\n",
      "loss in epoch 11 , step 5760 : 0.655098\n",
      "loss in epoch 11 , step 5780 : 1.523786\n",
      "loss in epoch 11 , step 5800 : 0.026103\n",
      "loss in epoch 11 , step 5820 : 0.054601\n",
      "loss in epoch 11 , step 5840 : 0.017049\n",
      "loss in epoch 11 , step 5860 : 1.440258\n",
      "loss in epoch 11 , step 5880 : 0.050830\n",
      "loss in epoch 11 , step 5900 : 0.944835\n",
      "loss in epoch 11 , step 5920 : 1.677556\n",
      "loss in epoch 11 , step 5940 : 2.358992\n",
      "loss in epoch 11 , step 5960 : 2.165393\n",
      "loss in epoch 11 , step 5980 : 0.530766\n",
      "loss in epoch 11 , step 6000 : 0.663350\n",
      "loss in epoch 11 , step 6020 : 0.446054\n",
      "loss in epoch 11 , step 6040 : 1.352713\n",
      "loss in epoch 11 , step 6060 : 1.813852\n",
      "loss in epoch 11 , step 6080 : 1.064922\n",
      "loss in epoch 11 , step 6100 : 0.419111\n",
      "loss in epoch 11 , step 6120 : 1.966035\n",
      "loss in epoch 11 , step 6140 : 0.308464\n",
      "loss in epoch 11 , step 6160 : 0.019087\n",
      "loss in epoch 11 , step 6180 : 2.534817\n",
      "loss in epoch 11 , step 6200 : 1.723775\n",
      "loss in epoch 11 , step 6220 : 0.026371\n",
      "loss in epoch 11 , step 6240 : 1.454039\n",
      "loss in epoch 11 , step 6260 : 0.631361\n",
      "loss in epoch 11 , step 6280 : 2.225048\n",
      "loss in epoch 11 , step 6300 : 1.013287\n",
      "loss in epoch 11 , step 6320 : 2.498569\n",
      "loss in epoch 11 , step 6340 : 0.684959\n",
      "loss in epoch 11 , step 6360 : 2.731971\n",
      "loss in epoch 11 , step 6380 : 1.169251\n",
      "loss in epoch 11 , step 6400 : 1.250963\n",
      "loss in epoch 11 , step 6420 : 0.044245\n",
      "loss in epoch 11 , step 6440 : 0.070593\n",
      "loss in epoch 11 , step 6460 : 0.092770\n",
      "loss in epoch 11 , step 6480 : 0.557246\n",
      "loss in epoch 11 , step 6500 : 1.283467\n",
      "loss in epoch 11 , step 6520 : 1.280738\n",
      "loss in epoch 11 , step 6540 : 0.838957\n",
      "loss in epoch 11 , step 6560 : 1.841781\n",
      "loss in epoch 11 , step 6580 : 1.161036\n",
      "loss in epoch 11 , step 6600 : 0.670410\n",
      "loss in epoch 11 , step 6620 : 3.357775\n",
      "loss in epoch 11 , step 6640 : 1.470585\n",
      "loss in epoch 11 , step 6660 : 0.711902\n",
      "loss in epoch 11 , step 6680 : 0.299378\n",
      "loss in epoch 11 , step 6700 : 0.012079\n",
      "loss in epoch 11 , step 6720 : 1.497776\n",
      "loss in epoch 11 , step 6740 : 0.950130\n",
      "loss in epoch 11 , step 6760 : 0.817874\n",
      "loss in epoch 11 , step 6780 : 1.662617\n",
      "loss in epoch 11 , step 6800 : 0.527781\n",
      "loss in epoch 11 , step 6820 : 0.046302\n",
      "loss in epoch 11 , step 6840 : 1.362836\n",
      "loss in epoch 11 , step 6860 : 2.203281\n",
      "loss in epoch 11 , step 6880 : 0.604386\n",
      "loss in epoch 11 , step 6900 : 5.145644\n",
      "loss in epoch 11 , step 6920 : 1.267622\n",
      "loss in epoch 11 , step 6940 : 1.163728\n",
      "loss in epoch 11 , step 6960 : 0.046755\n",
      "loss in epoch 11 , step 6980 : 1.239042\n",
      "loss in epoch 11 , step 7000 : 0.105100\n",
      "loss in epoch 11 , step 7020 : 1.671131\n",
      "loss in epoch 11 , step 7040 : 0.926289\n",
      "loss in epoch 11 , step 7060 : 0.107750\n",
      "loss in epoch 11 , step 7080 : 1.068817\n",
      "loss in epoch 11 , step 7100 : 1.681813\n",
      "loss in epoch 11 , step 7120 : 0.690294\n",
      "loss in epoch 11 , step 7140 : 0.529564\n",
      "loss in epoch 11 , step 7160 : 0.730568\n",
      "loss in epoch 11 , step 7180 : 1.310073\n",
      "loss in epoch 11 , step 7200 : 1.140662\n",
      "loss in epoch 11 , step 7220 : 1.400988\n",
      "loss in epoch 11 , step 7240 : 1.114565\n",
      "loss in epoch 11 , step 7260 : 0.643819\n",
      "loss in epoch 11 , step 7280 : 1.177219\n",
      "loss in epoch 11 , step 7300 : 0.494886\n",
      "loss in epoch 11 , step 7320 : 1.060009\n",
      "loss in epoch 11 , step 7340 : 0.698845\n",
      "loss in epoch 11 , step 7360 : 3.447086\n",
      "loss in epoch 11 , step 7380 : 1.199144\n",
      "loss in epoch 11 , step 7400 : 1.440107\n",
      "loss in epoch 11 , step 7420 : 0.003586\n",
      "loss in epoch 11 , step 7440 : 1.831695\n",
      "loss in epoch 11 , step 7460 : 0.656736\n",
      "loss in epoch 11 , step 7480 : 0.959968\n",
      "loss in epoch 11 , step 7500 : 1.260614\n",
      "loss in epoch 11 , step 7520 : 2.656577\n",
      "loss in epoch 11 , step 7540 : 0.727300\n",
      "loss in epoch 11 , step 7560 : 2.033899\n",
      "loss in epoch 11 , step 7580 : 0.982624\n",
      "loss in epoch 11 , step 7600 : 1.555887\n",
      "loss in epoch 11 , step 7620 : 1.441125\n",
      "loss in epoch 11 , step 7640 : 1.289036\n",
      "loss in epoch 11 , step 7660 : 0.749439\n",
      "loss in epoch 11 , step 7680 : 0.155317\n",
      "loss in epoch 11 , step 7700 : 0.207350\n",
      "loss in epoch 11 , step 7720 : 1.053181\n",
      "loss in epoch 11 , step 7740 : 3.747255\n",
      "loss in epoch 11 , step 7760 : 0.039930\n",
      "loss in epoch 11 , step 7780 : 0.740561\n",
      "loss in epoch 11 , step 7800 : 0.459619\n",
      "loss in epoch 11 , step 7820 : 0.111262\n",
      "loss in epoch 11 , step 7840 : 2.716455\n",
      "loss in epoch 11 , step 7860 : 0.020484\n",
      "loss in epoch 11 , step 7880 : 1.035665\n",
      "loss in epoch 11 , step 7900 : 0.065187\n",
      "loss in epoch 11 , step 7920 : 1.712345\n",
      "loss in epoch 11 , step 7940 : 1.772214\n",
      "loss in epoch 11 , step 7960 : 0.956310\n",
      "loss in epoch 11 , step 7980 : 1.815589\n",
      "loss in epoch 11 , step 8000 : 1.100837\n",
      "loss in epoch 11 , step 8020 : 1.111881\n",
      "loss in epoch 11 , step 8040 : 0.622883\n",
      "loss in epoch 11 , step 8060 : 1.655588\n",
      "loss in epoch 11 , step 8080 : 0.018231\n",
      "loss in epoch 11 , step 8100 : 0.646939\n",
      "loss in epoch 11 , step 8120 : 2.543397\n",
      "loss in epoch 11 , step 8140 : 1.037885\n",
      "loss in epoch 11 , step 8160 : 0.993345\n",
      "loss in epoch 11 , step 8180 : 0.210853\n",
      "loss in epoch 11 , step 8200 : 0.871843\n",
      "loss in epoch 11 , step 8220 : 0.554168\n",
      "loss in epoch 11 , step 8240 : 1.479981\n",
      "loss in epoch 11 , step 8260 : 1.258827\n",
      "loss in epoch 11 , step 8280 : 1.422775\n",
      "loss in epoch 11 , step 8300 : 0.392769\n",
      "loss in epoch 11 , step 8320 : 0.014628\n",
      "loss in epoch 11 , step 8340 : 1.136305\n",
      "loss in epoch 11 , step 8360 : 0.315908\n",
      "loss in epoch 11 , step 8380 : 1.308761\n",
      "loss in epoch 11 , step 8400 : 1.313946\n",
      "loss in epoch 11 , step 8420 : 2.713127\n",
      "loss in epoch 11 , step 8440 : 0.695436\n",
      "loss in epoch 11 , step 8460 : 2.475234\n",
      "loss in epoch 11 , step 8480 : 0.693839\n",
      "loss in epoch 11 , step 8500 : 2.733283\n",
      "loss in epoch 11 , step 8520 : 1.103175\n",
      "loss in epoch 11 , step 8540 : 1.637192\n",
      "loss in epoch 11 , step 8560 : 4.587820\n",
      "loss in epoch 11 , step 8580 : 0.587272\n",
      "loss in epoch 11 , step 8600 : 1.132848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 11 , step 8620 : 0.100348\n",
      "loss in epoch 11 , step 8640 : 2.162047\n",
      "loss in epoch 11 , step 8660 : 1.583325\n",
      "loss in epoch 11 , step 8680 : 0.940533\n",
      "loss in epoch 11 , step 8700 : 1.838881\n",
      "loss in epoch 11 , step 8720 : 0.427461\n",
      "loss in epoch 11 , step 8740 : 1.517478\n",
      "loss in epoch 11 , step 8760 : 0.300610\n",
      "loss in epoch 11 , step 8780 : 1.439418\n",
      "loss in epoch 11 , step 8800 : 1.150910\n",
      "loss in epoch 11 , step 8820 : 1.005572\n",
      "loss in epoch 11 , step 8840 : 0.745486\n",
      "loss in epoch 11 , step 8860 : 0.097528\n",
      "loss in epoch 11 , step 8880 : 0.200917\n",
      "loss in epoch 11 , step 8900 : 2.729613\n",
      "loss in epoch 11 , step 8920 : 0.464755\n",
      "loss in epoch 11 , step 8940 : 0.014616\n",
      "loss in epoch 11 , step 8960 : 0.309722\n",
      "loss in epoch 11 , step 8980 : 2.062891\n",
      "loss in epoch 11 , step 9000 : 1.684954\n",
      "loss in epoch 11 , step 9020 : 1.537205\n",
      "loss in epoch 11 , step 9040 : 0.906367\n",
      "loss in epoch 11 , step 9060 : 0.414531\n",
      "loss in epoch 11 , step 9080 : 0.046808\n",
      "loss in epoch 11 , step 9100 : 0.336662\n",
      "loss in epoch 11 , step 9120 : 2.173554\n",
      "loss in epoch 11 , step 9140 : 1.640893\n",
      "loss in epoch 11 , step 9160 : 1.718418\n",
      "loss in epoch 11 , step 9180 : 0.019187\n",
      "loss in epoch 11 , step 9200 : 2.517558\n",
      "loss in epoch 11 , step 9220 : 0.244637\n",
      "loss in epoch 11 , step 9240 : 0.010363\n",
      "loss in epoch 11 , step 9260 : 0.941989\n",
      "loss in epoch 11 , step 9280 : 0.299471\n",
      "loss in epoch 11 , step 9300 : 2.799197\n",
      "loss in epoch 11 , step 9320 : 2.302223\n",
      "loss in epoch 11 , step 9340 : 1.922236\n",
      "loss in epoch 11 , step 9360 : 1.492106\n",
      "loss in epoch 11 , step 9380 : 0.713294\n",
      "loss in epoch 11 , step 9400 : 0.555219\n",
      "loss in epoch 11 , step 9420 : 0.821649\n",
      "loss in epoch 11 , step 9440 : 0.677820\n",
      "loss in epoch 11 , step 9460 : 0.996074\n",
      "loss in epoch 11 , step 9480 : 0.743715\n",
      "loss in epoch 11 , step 9500 : 1.752631\n",
      "loss in epoch 11 , step 9520 : 1.387880\n",
      "loss in epoch 11 , step 9540 : 2.277102\n",
      "loss in epoch 11 , step 9560 : 0.044749\n",
      "loss in epoch 11 , step 9580 : 0.191127\n",
      "loss in epoch 11 , step 9600 : 2.058311\n",
      "loss in epoch 11 , step 9620 : 1.296104\n",
      "loss in epoch 11 , step 9640 : 1.307817\n",
      "loss in epoch 11 , step 9660 : 1.099993\n",
      "loss in epoch 11 , step 9680 : 0.068049\n",
      "loss in epoch 11 , step 9700 : 0.158453\n",
      "loss in epoch 11 , step 9720 : 1.863950\n",
      "loss in epoch 11 , step 9740 : 1.737557\n",
      "loss in epoch 11 , step 9760 : 0.526994\n",
      "loss in epoch 11 , step 9780 : 2.115216\n",
      "loss in epoch 11 , step 9800 : 0.282730\n",
      "loss in epoch 11 , step 9820 : 0.656450\n",
      "loss in epoch 11 , step 9840 : 0.031840\n",
      "loss in epoch 11 , step 9860 : 2.076475\n",
      "loss in epoch 11 , step 9880 : 0.397607\n",
      "loss in epoch 11 , step 9900 : 0.101375\n",
      "loss in epoch 11 , step 9920 : 0.015757\n",
      "loss in epoch 11 , step 9940 : 1.920934\n",
      "loss in epoch 11 , step 9960 : 0.850631\n",
      "loss in epoch 11 , step 9980 : 0.066224\n",
      "loss in epoch 11 , step 10000 : 1.480074\n",
      "loss in epoch 11 , step 10020 : 0.157012\n",
      "loss in epoch 11 , step 10040 : 0.964095\n",
      "loss in epoch 11 , step 10060 : 1.850989\n",
      "loss in epoch 11 , step 10080 : 1.774848\n",
      "loss in epoch 11 , step 10100 : 0.007382\n",
      "loss in epoch 11 , step 10120 : 1.129793\n",
      "loss in epoch 11 , step 10140 : 1.431418\n",
      "loss in epoch 11 , step 10160 : 0.164330\n",
      "loss in epoch 11 , step 10180 : 0.557642\n",
      "loss in epoch 11 , step 10200 : 1.057897\n",
      "loss in epoch 11 , step 10220 : 0.290405\n",
      "loss in epoch 11 , step 10240 : 1.559801\n",
      "loss in epoch 11 , step 10260 : 1.009240\n",
      "loss in epoch 11 , step 10280 : 0.332855\n",
      "loss in epoch 11 , step 10300 : 1.493943\n",
      "loss in epoch 11 , step 10320 : 1.547549\n",
      "loss in epoch 11 , step 10340 : 1.631628\n",
      "loss in epoch 11 , step 10360 : 0.126000\n",
      "loss in epoch 11 , step 10380 : 2.707391\n",
      "loss in epoch 11 , step 10400 : 2.159979\n",
      "loss in epoch 11 , step 10420 : 0.065850\n",
      "loss in epoch 11 , step 10440 : 0.632026\n",
      "loss in epoch 11 , step 10460 : 0.053439\n",
      "loss in epoch 11 , step 10480 : 0.159508\n",
      "loss in epoch 11 , step 10500 : 0.410553\n",
      "loss in epoch 11 , step 10520 : 0.377942\n",
      "loss in epoch 11 , step 10540 : 1.095783\n",
      "loss in epoch 11 , step 10560 : 2.051486\n",
      "loss in epoch 11 , step 10580 : 1.022578\n",
      "loss in epoch 11 , step 10600 : 2.090454\n",
      "loss in epoch 11 , step 10620 : 0.665621\n",
      "loss in epoch 11 , step 10640 : 0.240893\n",
      "loss in epoch 11 , step 10660 : 2.144121\n",
      "loss in epoch 11 , step 10680 : 1.256698\n",
      "loss in epoch 11 , step 10700 : 2.120751\n",
      "loss in epoch 11 , step 10720 : 1.575972\n",
      "loss in epoch 11 , step 10740 : 1.122039\n",
      "loss in epoch 11 , step 10760 : 2.146332\n",
      "loss in epoch 11 , step 10780 : 0.210447\n",
      "loss in epoch 11 , step 10800 : 0.845170\n",
      "loss in epoch 11 , step 10820 : 0.122325\n",
      "loss in epoch 11 , step 10840 : 1.461850\n",
      "loss in epoch 11 , step 10860 : 0.235430\n",
      "loss in epoch 11 , step 10880 : 2.080272\n",
      "loss in epoch 11 , step 10900 : 0.484982\n",
      "loss in epoch 11 , step 10920 : 2.156184\n",
      "loss in epoch 11 , step 10940 : 1.177594\n",
      "loss in epoch 11 , step 10960 : 0.070388\n",
      "loss in epoch 11 , step 10980 : 0.698574\n",
      "loss in epoch 11 , step 11000 : 0.018804\n",
      "loss in epoch 11 , step 11020 : 0.002991\n",
      "loss in epoch 11 , step 11040 : 0.550626\n",
      "loss in epoch 11 , step 11060 : 2.252598\n",
      "loss in epoch 11 , step 11080 : 1.334139\n",
      "loss in epoch 11 , step 11100 : 2.756148\n",
      "loss in epoch 11 , step 11120 : 1.861625\n",
      "loss in epoch 11 , step 11140 : 2.470461\n",
      "loss in epoch 11 , step 11160 : 0.003347\n",
      "loss in epoch 11 , step 11180 : 1.446936\n",
      "loss in epoch 11 , step 11200 : 0.024851\n",
      "loss in epoch 11 , step 11220 : 0.448387\n",
      "loss in epoch 11 , step 11240 : 1.785472\n",
      "loss in epoch 11 , step 11260 : 1.126834\n",
      "loss in epoch 11 , step 11280 : 1.813420\n",
      "loss in epoch 11 , step 11300 : 3.691044\n",
      "loss in epoch 11 , step 11320 : 1.113134\n",
      "loss in epoch 11 , step 11340 : 0.078078\n",
      "loss in epoch 11 , step 11360 : 0.914053\n",
      "loss in epoch 11 , step 11380 : 0.833457\n",
      "loss in epoch 11 , step 11400 : 3.301062\n",
      "loss in epoch 11 , step 11420 : 2.316385\n",
      "loss in epoch 11 , step 11440 : 1.278322\n",
      "loss in epoch 11 , step 11460 : 2.625539\n",
      "loss in epoch 11 , step 11480 : 1.155412\n",
      "loss in epoch 11 , step 11500 : 1.137021\n",
      "loss in epoch 11 , step 11520 : 1.856043\n",
      "loss in epoch 11 , step 11540 : 1.174203\n",
      "loss in epoch 11 , step 11560 : 0.015439\n",
      "loss in epoch 11 , step 11580 : 1.148733\n",
      "loss in epoch 11 , step 11600 : 1.651748\n",
      "loss in epoch 11 , step 11620 : 0.023254\n",
      "loss in epoch 11 , step 11640 : 0.670095\n",
      "loss in epoch 11 , step 11660 : 0.500662\n",
      "loss in epoch 11 , step 11680 : 1.957232\n",
      "loss in epoch 11 , step 11700 : 0.381497\n",
      "loss in epoch 11 , step 11720 : 2.272635\n",
      "loss in epoch 11 , step 11740 : 1.068149\n",
      "loss in epoch 11 , step 11760 : 0.605432\n",
      "loss in epoch 11 , step 11780 : 1.825487\n",
      "loss in epoch 11 , step 11800 : 1.131457\n",
      "loss in epoch 11 , step 11820 : 1.583554\n",
      "loss in epoch 11 , step 11840 : 0.582909\n",
      "loss in epoch 11 , step 11860 : 1.214492\n",
      "loss in epoch 11 , step 11880 : 0.872004\n",
      "loss in epoch 11 , step 11900 : 0.028919\n",
      "loss in epoch 11 , step 11920 : 1.037759\n",
      "loss in epoch 11 , step 11940 : 0.413937\n",
      "loss in epoch 11 , step 11960 : 0.171962\n",
      "loss in epoch 11 , step 11980 : 1.016762\n",
      "loss in epoch 11 , step 12000 : 0.157395\n",
      "loss in epoch 11 , step 12020 : 0.851057\n",
      "loss in epoch 11 , step 12040 : 0.755856\n",
      "loss in epoch 11 , step 12060 : 0.950743\n",
      "loss in epoch 11 , step 12080 : 0.661677\n",
      "loss in epoch 11 , step 12100 : 1.311418\n",
      "loss in epoch 11 , step 12120 : 2.893239\n",
      "loss in epoch 11 , step 12140 : 1.069577\n",
      "loss in epoch 11 , step 12160 : 1.556651\n",
      "loss in epoch 11 , step 12180 : 0.146397\n",
      "loss in epoch 11 , step 12200 : 1.612858\n",
      "loss in epoch 11 , step 12220 : 1.028530\n",
      "loss in epoch 11 , step 12240 : 0.910858\n",
      "loss in epoch 11 , step 12260 : 3.616193\n",
      "loss in epoch 11 , step 12280 : 0.116958\n",
      "loss in epoch 11 , step 12300 : 1.852770\n",
      "loss in epoch 11 , step 12320 : 0.813736\n",
      "loss in epoch 11 , step 12340 : 1.298276\n",
      "loss in epoch 11 , step 12360 : 1.161550\n",
      "loss in epoch 11 , step 12380 : 1.321466\n",
      "loss in epoch 11 , step 12400 : 1.111216\n",
      "loss in epoch 11 , step 12420 : 0.590541\n",
      "loss in epoch 11 , step 12440 : 2.618890\n",
      "loss in epoch 11 , step 12460 : 0.627822\n",
      "loss in epoch 11 , step 12480 : 1.875079\n",
      "loss in epoch 11 , step 12500 : 0.037708\n",
      "loss in epoch 11 , step 12520 : 1.920033\n",
      "loss in epoch 11 , step 12540 : 1.260315\n",
      "loss in epoch 11 , step 12560 : 0.106372\n",
      "loss in epoch 11 , step 12580 : 0.605318\n",
      "loss in epoch 11 , step 12600 : 1.030817\n",
      "loss in epoch 11 , step 12620 : 0.022249\n",
      "loss in epoch 11 , step 12640 : 0.024532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 11 , step 12660 : 0.263053\n",
      "loss in epoch 11 , step 12680 : 1.140862\n",
      "loss in epoch 11 , step 12700 : 0.226443\n",
      "loss in epoch 11 , step 12720 : 0.791550\n",
      "loss in epoch 11 , step 12740 : 0.957723\n",
      "loss in epoch 11 , step 12760 : 1.900888\n",
      "loss in epoch 11 , step 12780 : 1.366311\n",
      "loss in epoch 11 , step 12800 : 0.945968\n",
      "loss in epoch 11 , step 12820 : 2.391495\n",
      "loss in epoch 11 , step 12840 : 0.005928\n",
      "loss in epoch 11 , step 12860 : 0.853336\n",
      "loss in epoch 11 , step 12880 : 0.131696\n",
      "loss in epoch 11 , step 12900 : 2.201756\n",
      "loss in epoch 11 , step 12920 : 0.546994\n",
      "loss in epoch 11 , step 12940 : 0.178491\n",
      "loss in epoch 11 , step 12960 : 0.093872\n",
      "loss in epoch 11 , step 12980 : 0.814101\n",
      "loss in epoch 11 , step 13000 : 2.143490\n",
      "loss in epoch 11 , step 13020 : 0.902247\n",
      "loss in epoch 11 , step 13040 : 1.290824\n",
      "loss in epoch 11 , step 13060 : 1.808984\n",
      "loss in epoch 11 , step 13080 : 1.704973\n",
      "loss in epoch 11 , step 13100 : 0.508003\n",
      "loss in epoch 11 , step 13120 : 0.051574\n",
      "loss in epoch 11 , step 13140 : 0.737949\n",
      "loss in epoch 11 , step 13160 : 0.522386\n",
      "loss in epoch 11 , step 13180 : 1.208406\n",
      "loss in epoch 11 , step 13200 : 0.389422\n",
      "loss in epoch 11 , step 13220 : 0.818182\n",
      "loss in epoch 11 , step 13240 : 1.156080\n",
      "loss in epoch 11 , step 13260 : 2.266788\n",
      "loss in epoch 11 , step 13280 : 1.107874\n",
      "loss in epoch 11 , step 13300 : 0.570810\n",
      "loss in epoch 11 , step 13320 : 0.060256\n",
      "loss in epoch 11 , step 13340 : 1.385375\n",
      "loss in epoch 11 , step 13360 : 0.306441\n",
      "loss in epoch 11 , step 13380 : 0.002526\n",
      "loss in epoch 11 , step 13400 : 1.043831\n",
      "loss in epoch 11 , step 13420 : 1.175447\n",
      "loss in epoch 11 , step 13440 : 0.330352\n",
      "loss in epoch 11 , step 13460 : 0.516209\n",
      "loss in epoch 11 , step 13480 : 1.963199\n",
      "loss in epoch 11 , step 13500 : 0.050171\n",
      "loss in epoch 11 , step 13520 : 0.035846\n",
      "loss in epoch 11 , step 13540 : 0.721887\n",
      "loss in epoch 11 , step 13560 : 3.882198\n",
      "loss in epoch 11 , step 13580 : 1.311606\n",
      "loss in epoch 11 , step 13600 : 1.397297\n",
      "loss in epoch 11 , step 13620 : 1.309586\n",
      "loss in epoch 11 , step 13640 : 1.452242\n",
      "loss in epoch 11 , step 13660 : 1.357096\n",
      "loss in epoch 11 , step 13680 : 0.001225\n",
      "loss in epoch 11 , step 13700 : 1.882681\n",
      "loss in epoch 11 , step 13720 : 0.942117\n",
      "loss in epoch 11 , step 13740 : 0.873411\n",
      "loss in epoch 11 , step 13760 : 0.963167\n",
      "loss in epoch 11 , step 13780 : 0.804744\n",
      "loss in epoch 11 , step 13800 : 1.831969\n",
      "loss in epoch 11 , step 13820 : 0.328065\n",
      "loss in epoch 11 , step 13840 : 0.005335\n",
      "loss in epoch 11 , step 13860 : 0.054285\n",
      "loss in epoch 11 , step 13880 : 1.096555\n",
      "loss in epoch 11 , step 13900 : 1.116359\n",
      "loss in epoch 11 , step 13920 : 2.329792\n",
      "loss in epoch 11 , step 13940 : 0.620575\n",
      "loss in epoch 11 , step 13960 : 0.923542\n",
      "loss in epoch 11 , step 13980 : 0.770357\n",
      "loss in epoch 11 , step 14000 : 1.965160\n",
      "loss in epoch 11 , step 14020 : 0.346845\n",
      "loss in epoch 11 , step 14040 : 0.025345\n",
      "loss in epoch 11 , step 14060 : 1.367501\n",
      "loss in epoch 11 , step 14080 : 1.791480\n",
      "loss in epoch 11 , step 14100 : 1.907991\n",
      "loss in epoch 11 , step 14120 : 0.020543\n",
      "loss in epoch 11 , step 14140 : 1.160971\n",
      "loss in epoch 11 , step 14160 : 0.034358\n",
      "loss in epoch 11 , step 14180 : 1.459846\n",
      "loss in epoch 11 , step 14200 : 0.559463\n",
      "loss in epoch 11 , step 14220 : 0.970311\n",
      "loss in epoch 11 , step 14240 : 0.063091\n",
      "loss in epoch 11 , step 14260 : 0.394715\n",
      "loss in epoch 11 , step 14280 : 1.234801\n",
      "loss in epoch 11 , step 14300 : 1.581424\n",
      "loss in epoch 11 , step 14320 : 0.152875\n",
      "loss in epoch 11 , step 14340 : 0.007767\n",
      "loss in epoch 11 , step 14360 : 1.167098\n",
      "loss in epoch 11 , step 14380 : 0.870100\n",
      "loss in epoch 11 , step 14400 : 0.924280\n",
      "loss in epoch 11 , step 14420 : 0.548797\n",
      "loss in epoch 11 , step 14440 : 0.764878\n",
      "loss in epoch 11 , step 14460 : 0.826196\n",
      "loss in epoch 11 , step 14480 : 0.017168\n",
      "loss in epoch 11 , step 14500 : 1.679844\n",
      "loss in epoch 11 , step 14520 : 0.043373\n",
      "loss in epoch 11 , step 14540 : 0.189248\n",
      "loss in epoch 11 , step 14560 : 1.060534\n",
      "loss in epoch 11 , step 14580 : 0.318986\n",
      "loss in epoch 11 , step 14600 : 0.045306\n",
      "loss in epoch 11 , step 14620 : 0.007818\n",
      "loss in epoch 11 , step 14640 : 2.834941\n",
      "loss in epoch 11 , step 14660 : 2.101910\n",
      "loss in epoch 11 , step 14680 : 2.197418\n",
      "loss in epoch 11 , step 14700 : 1.227965\n",
      "loss in epoch 11 , step 14720 : 0.950816\n",
      "loss in epoch 11 , step 14740 : 1.289159\n",
      "loss in epoch 11 , step 14760 : 1.149499\n",
      "loss in epoch 11 , step 14780 : 0.451356\n",
      "loss in epoch 11 , step 14800 : 3.800197\n",
      "loss in epoch 11 , step 14820 : 2.751187\n",
      "loss in epoch 11 , step 14840 : 1.138198\n",
      "loss in epoch 11 , step 14860 : 0.165531\n",
      "loss in epoch 11 , step 14880 : 0.823840\n",
      "loss in epoch 11 , step 14900 : 0.460661\n",
      "loss in epoch 11 , step 14920 : 0.532980\n",
      "loss in epoch 11 , step 14940 : 0.670310\n",
      "loss in epoch 11 , step 14960 : 2.658087\n",
      "loss in epoch 11 , step 14980 : 2.714588\n",
      "loss in epoch 11 , step 15000 : 1.362307\n",
      "loss in epoch 11 , step 15020 : 2.141395\n",
      "loss in epoch 11 , step 15040 : 1.122412\n",
      "loss in epoch 11 , step 15060 : 1.189124\n",
      "loss in epoch 11 , step 15080 : 0.176402\n",
      "loss in epoch 11 , step 15100 : 3.756064\n",
      "loss in epoch 11 , step 15120 : 1.194688\n",
      "loss in epoch 11 , step 15140 : 1.525725\n",
      "loss in epoch 11 , step 15160 : 0.232013\n",
      "loss in epoch 11 , step 15180 : 0.780310\n",
      "loss in epoch 11 , step 15200 : 0.651667\n",
      "loss in epoch 11 , step 15220 : 2.652996\n",
      "loss in epoch 11 , step 15240 : 2.054921\n",
      "loss in epoch 11 , step 15260 : 0.190962\n",
      "loss in epoch 11 , step 15280 : 0.141197\n",
      "loss in epoch 11 , step 15300 : 1.617896\n",
      "loss in epoch 11 , step 15320 : 0.068979\n",
      "loss in epoch 11 , step 15340 : 0.045456\n",
      "loss in epoch 11 , step 15360 : 2.258167\n",
      "loss in epoch 11 , step 15380 : 0.875999\n",
      "loss in epoch 11 , step 15400 : 2.353008\n",
      "loss in epoch 11 , step 15420 : 1.250064\n",
      "loss in epoch 11 , step 15440 : 1.251176\n",
      "loss in epoch 11 , step 15460 : 2.140435\n",
      "loss in epoch 11 , step 15480 : 0.911927\n",
      "loss in epoch 11 , step 15500 : 2.516685\n",
      "loss in epoch 11 , step 15520 : 1.385428\n",
      "loss in epoch 11 , step 15540 : 0.873774\n",
      "loss in epoch 11 , step 15560 : 0.235068\n",
      "loss in epoch 11 , step 15580 : 0.773196\n",
      "loss in epoch 11 , step 15600 : 0.006811\n",
      "loss in epoch 11 , step 15620 : 1.407277\n",
      "loss in epoch 11 , step 15640 : 1.089226\n",
      "loss in epoch 11 , step 15660 : 1.164617\n",
      "loss in epoch 11 , step 15680 : 2.517796\n",
      "loss in epoch 11 , step 15700 : 0.346229\n",
      "loss in epoch 11 , step 15720 : 0.402633\n",
      "loss in epoch 11 , step 15740 : 1.020121\n",
      "loss in epoch 11 , step 15760 : 0.227480\n",
      "loss in epoch 11 , step 15780 : 0.046061\n",
      "loss in epoch 11 , step 15800 : 0.556558\n",
      "loss in epoch 11 , step 15820 : 1.035182\n",
      "loss in epoch 11 , step 15840 : 2.248605\n",
      "loss in epoch 11 , step 15860 : 0.282911\n",
      "loss in epoch 11 , step 15880 : 0.367002\n",
      "loss in epoch 11 , step 15900 : 0.180687\n",
      "loss in epoch 11 , step 15920 : 0.588642\n",
      "loss in epoch 11 , step 15940 : 2.091657\n",
      "loss in epoch 11 , step 15960 : 0.055698\n",
      "loss in epoch 11 , step 15980 : 0.544319\n",
      "loss in epoch 11 , step 16000 : 1.219742\n",
      "loss in epoch 11 , step 16020 : 1.788106\n",
      "loss in epoch 11 , step 16040 : 0.904588\n",
      "loss in epoch 11 , step 16060 : 4.110127\n",
      "loss in epoch 11 , step 16080 : 3.805874\n",
      "loss in epoch 11 , step 16100 : 1.498740\n",
      "loss in epoch 11 , step 16120 : 1.431490\n",
      "loss in epoch 11 , step 16140 : 0.362981\n",
      "loss in epoch 11 , step 16160 : 0.100634\n",
      "loss in epoch 11 , step 16180 : 0.973982\n",
      "loss in epoch 11 , step 16200 : 0.832326\n",
      "loss in epoch 11 , step 16220 : 0.573511\n",
      "loss in epoch 11 , step 16240 : 0.461933\n",
      "loss in epoch 11 , step 16260 : 0.025230\n",
      "loss in epoch 11 , step 16280 : 1.620321\n",
      "loss in epoch 11 , step 16300 : 0.691680\n",
      "loss in epoch 11 , step 16320 : 1.269536\n",
      "loss in epoch 11 , step 16340 : 0.758889\n",
      "loss in epoch 11 , step 16360 : 0.080639\n",
      "loss in epoch 11 , step 16380 : 1.241917\n",
      "loss in epoch 11 , step 16400 : 0.135900\n",
      "loss in epoch 11 , step 16420 : 0.045917\n",
      "loss in epoch 11 , step 16440 : 2.406529\n",
      "loss in epoch 11 , step 16460 : 0.904514\n",
      "loss in epoch 11 , step 16480 : 1.824456\n",
      "loss in epoch 11 , step 16500 : 0.613355\n",
      "loss in epoch 11 , step 16520 : 0.299898\n",
      "loss in epoch 11 , step 16540 : 0.974736\n",
      "loss in epoch 11 , step 16560 : 0.397782\n",
      "loss in epoch 11 , step 16580 : 1.222113\n",
      "loss in epoch 11 , step 16600 : 0.318994\n",
      "loss in epoch 11 , step 16620 : 5.905002\n",
      "loss in epoch 11 , step 16640 : 1.614286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 11 , step 16660 : 0.230984\n",
      "loss in epoch 11 , step 16680 : 0.022043\n",
      "loss in epoch 11 , step 16700 : 0.699739\n",
      "loss in epoch 11 , step 16720 : 3.050415\n",
      "loss in epoch 11 , step 16740 : 0.958664\n",
      "loss in epoch 11 , step 16760 : 1.308234\n",
      "loss in epoch 11 , step 16780 : 1.395101\n",
      "loss in epoch 11 , step 16800 : 3.058448\n",
      "loss in epoch 11 , step 16820 : 0.012414\n",
      "loss in epoch 11 , step 16840 : 0.984767\n",
      "loss in epoch 11 , step 16860 : 0.501143\n",
      "loss in epoch 11 , step 16880 : 0.224705\n",
      "loss in epoch 11 , step 16900 : 2.477223\n",
      "loss in epoch 11 , step 16920 : 0.802744\n",
      "loss in epoch 11 , step 16940 : 0.916429\n",
      "loss in epoch 11 , step 16960 : 2.593868\n",
      "loss in epoch 11 , step 16980 : 0.879925\n",
      "loss in epoch 11 , step 17000 : 1.140363\n",
      "loss in epoch 11 , step 17020 : 0.382862\n",
      "loss in epoch 11 , step 17040 : 1.064958\n",
      "loss in epoch 11 , step 17060 : 0.106296\n",
      "loss in epoch 11 , step 17080 : 2.698655\n",
      "loss in epoch 11 , step 17100 : 1.815790\n",
      "loss in epoch 11 , step 17120 : 0.071768\n",
      "loss in epoch 11 , step 17140 : 0.373207\n",
      "loss in epoch 11 , step 17160 : 0.350705\n",
      "loss in epoch 11 , step 17180 : 1.418028\n",
      "loss in epoch 11 , step 17200 : 0.125132\n",
      "loss in epoch 11 , step 17220 : 0.818456\n",
      "loss in epoch 11 , step 17240 : 1.481532\n",
      "loss in epoch 11 , step 17260 : 0.784891\n",
      "loss in epoch 11 , step 17280 : 1.122638\n",
      "loss in epoch 11 , step 17300 : 0.272412\n",
      "loss in epoch 11 , step 17320 : 0.665927\n",
      "loss in epoch 11 , step 17340 : 1.200269\n",
      "loss in epoch 11 , step 17360 : 0.032159\n",
      "loss in epoch 11 , step 17380 : 0.346561\n",
      "loss in epoch 11 , step 17400 : 2.148089\n",
      "loss in epoch 11 , step 17420 : 1.167416\n",
      "loss in epoch 11 , step 17440 : 0.047285\n",
      "loss in epoch 11 , step 17460 : 2.859529\n",
      "loss in epoch 11 , step 17480 : 1.324256\n",
      "loss in epoch 11 , step 17500 : 0.041095\n",
      "loss in epoch 11 , step 17520 : 2.703209\n",
      "loss in epoch 11 , step 17540 : 1.533576\n",
      "loss in epoch 11 , step 17560 : 2.330065\n",
      "loss in epoch 11 , step 17580 : 1.347380\n",
      "loss in epoch 11 , step 17600 : 0.006009\n",
      "loss in epoch 11 , step 17620 : 1.579955\n",
      "loss in epoch 11 , step 17640 : 0.743386\n",
      "loss in epoch 11 , step 17660 : 0.651316\n",
      "loss in epoch 11 , step 17680 : 1.251411\n",
      "loss in epoch 11 , step 17700 : 0.142675\n",
      "loss in epoch 11 , step 17720 : 0.273872\n",
      "loss in epoch 11 , step 17740 : 0.254574\n",
      "loss in epoch 11 , step 17760 : 1.858214\n",
      "loss in epoch 11 , step 17780 : 0.091234\n",
      "loss in epoch 11 , step 17800 : 0.724871\n",
      "loss in epoch 11 , step 17820 : 0.197978\n",
      "loss in epoch 11 , step 17840 : 0.133896\n",
      "loss in epoch 11 , step 17860 : 0.599972\n",
      "loss in epoch 11 , step 17880 : 0.269119\n",
      "loss in epoch 11 , step 17900 : 0.222779\n",
      "loss in epoch 11 , step 17920 : 0.173291\n",
      "loss in epoch 11 , step 17940 : 1.665407\n",
      "loss in epoch 11 , step 17960 : 0.981649\n",
      "loss in epoch 11 , step 17980 : 0.791256\n",
      "loss in epoch 11 , step 18000 : 0.619758\n",
      "loss in epoch 11 , step 18020 : 1.207430\n",
      "loss in epoch 11 , step 18040 : 1.768234\n",
      "loss in epoch 11 , step 18060 : 1.352672\n",
      "loss in epoch 11 , step 18080 : 0.021732\n",
      "loss in epoch 11 , step 18100 : 0.823023\n",
      "loss in epoch 11 , step 18120 : 1.235702\n",
      "loss in epoch 11 , step 18140 : 3.001344\n",
      "loss in epoch 11 , step 18160 : 1.362942\n",
      "loss in epoch 11 , step 18180 : 1.656779\n",
      "loss in epoch 11 , step 18200 : 0.534075\n",
      "loss in epoch 11 , step 18220 : 0.005786\n",
      "loss in epoch 11 , step 18240 : 1.426153\n",
      "loss in epoch 11 , step 18260 : 2.382453\n",
      "loss in epoch 11 , step 18280 : 1.846095\n",
      "loss in epoch 11 , step 18300 : 0.610263\n",
      "loss in epoch 11 , step 18320 : 0.610698\n",
      "loss in epoch 11 , step 18340 : 1.168303\n",
      "loss in epoch 11 , step 18360 : 0.776781\n",
      "loss in epoch 11 , step 18380 : 1.522596\n",
      "loss in epoch 11 , step 18400 : 1.844112\n",
      "loss in epoch 11 , step 18420 : 0.983854\n",
      "loss in epoch 11 , step 18440 : 1.425148\n",
      "loss in epoch 11 , step 18460 : 0.240962\n",
      "loss in epoch 11 , step 18480 : 1.894349\n",
      "loss in epoch 11 , step 18500 : 2.981318\n",
      "loss in epoch 11 , step 18520 : 1.769526\n",
      "loss in epoch 11 , step 18540 : 0.033057\n",
      "loss in epoch 11 , step 18560 : 0.713936\n",
      "loss in epoch 11 , step 18580 : 1.035804\n",
      "loss in epoch 11 , step 18600 : 2.274875\n",
      "loss in epoch 11 , step 18620 : 0.476297\n",
      "loss in epoch 11 , step 18640 : 0.382969\n",
      "loss in epoch 11 , step 18660 : 0.708694\n",
      "loss in epoch 11 , step 18680 : 1.348145\n",
      "loss in epoch 11 , step 18700 : 1.437091\n",
      "loss in epoch 11 , step 18720 : 0.058976\n",
      "loss in epoch 11 , step 18740 : 0.046239\n",
      "loss in epoch 11 , step 18760 : 2.612816\n",
      "loss in epoch 11 , step 18780 : 2.005726\n",
      "loss in epoch 11 , step 18800 : 0.104876\n",
      "loss in epoch 11 , step 18820 : 0.754611\n",
      "loss in epoch 11 , step 18840 : 1.659915\n",
      "loss in epoch 11 , step 18860 : 0.374855\n",
      "loss in epoch 11 , step 18880 : 1.920207\n",
      "loss in epoch 11 , step 18900 : 0.147396\n",
      "loss in epoch 11 , step 18920 : 0.602803\n",
      "loss in epoch 11 , step 18940 : 0.214946\n",
      "loss in epoch 11 , step 18960 : 1.232339\n",
      "loss in epoch 11 , step 18980 : 0.768897\n",
      "loss in epoch 11 , step 19000 : 0.498689\n",
      "loss in epoch 11 , step 19020 : 0.997118\n",
      "loss in epoch 11 , step 19040 : 1.465354\n",
      "loss in epoch 11 , step 19060 : 0.989521\n",
      "loss in epoch 11 , step 19080 : 0.056241\n",
      "loss in epoch 11 , step 19100 : 3.090928\n",
      "loss in epoch 11 , step 19120 : 0.956742\n",
      "loss in epoch 11 , step 19140 : 0.470492\n",
      "loss in epoch 11 , step 19160 : 1.803875\n",
      "loss in epoch 11 , step 19180 : 0.921656\n",
      "loss in epoch 11 , step 19200 : 1.534537\n",
      "loss in epoch 11 , step 19220 : 1.281115\n",
      "loss in epoch 11 , step 19240 : 0.097082\n",
      "loss in epoch 11 , step 19260 : 1.485069\n",
      "loss in epoch 11 , step 19280 : 0.414541\n",
      "loss in epoch 11 , step 19300 : 1.678087\n",
      "loss in epoch 11 , step 19320 : 3.597198\n",
      "loss in epoch 11 , step 19340 : 0.807523\n",
      "loss in epoch 11 , step 19360 : 1.198846\n",
      "loss in epoch 11 , step 19380 : 0.746783\n",
      "loss in epoch 11 , step 19400 : 0.698180\n",
      "loss in epoch 11 , step 19420 : 1.294420\n",
      "loss in epoch 11 , step 19440 : 0.026022\n",
      "loss in epoch 11 , step 19460 : 1.138851\n",
      "loss in epoch 11 , step 19480 : 0.630286\n",
      "loss in epoch 11 , step 19500 : 0.154531\n",
      "loss in epoch 11 , step 19520 : 1.266685\n",
      "loss in epoch 11 , step 19540 : 1.748584\n",
      "loss in epoch 11 , step 19560 : 0.516022\n",
      "loss in epoch 11 , step 19580 : 2.080237\n",
      "loss in epoch 11 , step 19600 : 1.047622\n",
      "loss in epoch 11 , step 19620 : 1.151669\n",
      "loss in epoch 11 , step 19640 : 1.198529\n",
      "loss in epoch 11 , step 19660 : 3.110905\n",
      "loss in epoch 11 , step 19680 : 0.551495\n",
      "loss in epoch 11 , step 19700 : 1.854406\n",
      "loss in epoch 11 , step 19720 : 0.288014\n",
      "loss in epoch 11 , step 19740 : 0.290275\n",
      "loss in epoch 11 , step 19760 : 1.250486\n",
      "loss in epoch 11 , step 19780 : 0.930946\n",
      "loss in epoch 11 , step 19800 : 1.157509\n",
      "loss in epoch 11 , step 19820 : 1.029167\n",
      "loss in epoch 11 , step 19840 : 0.995865\n",
      "loss in epoch 11 , step 19860 : 0.708042\n",
      "loss in epoch 11 , step 19880 : 0.689814\n",
      "loss in epoch 11 , step 19900 : 0.824372\n",
      "loss in epoch 11 , step 19920 : 1.794602\n",
      "loss in epoch 11 , step 19940 : 1.094252\n",
      "Accuracy in epoch 11 : 30.563986\n",
      "loss in epoch 12 , step 0 : 2.859440\n",
      "loss in epoch 12 , step 20 : 1.060591\n",
      "loss in epoch 12 , step 40 : 0.783031\n",
      "loss in epoch 12 , step 60 : 2.070087\n",
      "loss in epoch 12 , step 80 : 2.217723\n",
      "loss in epoch 12 , step 100 : 1.748173\n",
      "loss in epoch 12 , step 120 : 0.525303\n",
      "loss in epoch 12 , step 140 : 0.002078\n",
      "loss in epoch 12 , step 160 : 0.165583\n",
      "loss in epoch 12 , step 180 : 1.678816\n",
      "loss in epoch 12 , step 200 : 0.022701\n",
      "loss in epoch 12 , step 220 : 0.266989\n",
      "loss in epoch 12 , step 240 : 2.129306\n",
      "loss in epoch 12 , step 260 : 0.631772\n",
      "loss in epoch 12 , step 280 : 0.691044\n",
      "loss in epoch 12 , step 300 : 0.130382\n",
      "loss in epoch 12 , step 320 : 0.616661\n",
      "loss in epoch 12 , step 340 : 1.544440\n",
      "loss in epoch 12 , step 360 : 1.017709\n",
      "loss in epoch 12 , step 380 : 1.500644\n",
      "loss in epoch 12 , step 400 : 1.025424\n",
      "loss in epoch 12 , step 420 : 0.984215\n",
      "loss in epoch 12 , step 440 : 1.373131\n",
      "loss in epoch 12 , step 460 : 1.680889\n",
      "loss in epoch 12 , step 480 : 0.352303\n",
      "loss in epoch 12 , step 500 : 1.423304\n",
      "loss in epoch 12 , step 520 : 1.402613\n",
      "loss in epoch 12 , step 540 : 0.105058\n",
      "loss in epoch 12 , step 560 : 2.521590\n",
      "loss in epoch 12 , step 580 : 0.436905\n",
      "loss in epoch 12 , step 600 : 0.460350\n",
      "loss in epoch 12 , step 620 : 0.743518\n",
      "loss in epoch 12 , step 640 : 1.154959\n",
      "loss in epoch 12 , step 660 : 2.262656\n",
      "loss in epoch 12 , step 680 : 1.081577\n",
      "loss in epoch 12 , step 700 : 1.353033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 12 , step 720 : 1.861646\n",
      "loss in epoch 12 , step 740 : 0.894136\n",
      "loss in epoch 12 , step 760 : 1.521362\n",
      "loss in epoch 12 , step 780 : 0.481957\n",
      "loss in epoch 12 , step 800 : 1.194192\n",
      "loss in epoch 12 , step 820 : 2.015231\n",
      "loss in epoch 12 , step 840 : 0.840626\n",
      "loss in epoch 12 , step 860 : 0.347792\n",
      "loss in epoch 12 , step 880 : 1.523204\n",
      "loss in epoch 12 , step 900 : 2.439374\n",
      "loss in epoch 12 , step 920 : 1.516784\n",
      "loss in epoch 12 , step 940 : 2.809037\n",
      "loss in epoch 12 , step 960 : 1.213948\n",
      "loss in epoch 12 , step 980 : 0.401816\n",
      "loss in epoch 12 , step 1000 : 1.315289\n",
      "loss in epoch 12 , step 1020 : 1.965288\n",
      "loss in epoch 12 , step 1040 : 0.012055\n",
      "loss in epoch 12 , step 1060 : 0.917434\n",
      "loss in epoch 12 , step 1080 : 3.123485\n",
      "loss in epoch 12 , step 1100 : 1.466474\n",
      "loss in epoch 12 , step 1120 : 1.769333\n",
      "loss in epoch 12 , step 1140 : 1.824665\n",
      "loss in epoch 12 , step 1160 : 2.022707\n",
      "loss in epoch 12 , step 1180 : 1.554889\n",
      "loss in epoch 12 , step 1200 : 0.657032\n",
      "loss in epoch 12 , step 1220 : 0.399591\n",
      "loss in epoch 12 , step 1240 : 0.762828\n",
      "loss in epoch 12 , step 1260 : 0.087434\n",
      "loss in epoch 12 , step 1280 : 0.938166\n",
      "loss in epoch 12 , step 1300 : 0.728828\n",
      "loss in epoch 12 , step 1320 : 0.182197\n",
      "loss in epoch 12 , step 1340 : 6.700898\n",
      "loss in epoch 12 , step 1360 : 0.650362\n",
      "loss in epoch 12 , step 1380 : 0.499342\n",
      "loss in epoch 12 , step 1400 : 0.603006\n",
      "loss in epoch 12 , step 1420 : 0.258113\n",
      "loss in epoch 12 , step 1440 : 0.317642\n",
      "loss in epoch 12 , step 1460 : 0.555221\n",
      "loss in epoch 12 , step 1480 : 0.949541\n",
      "loss in epoch 12 , step 1500 : 1.936119\n",
      "loss in epoch 12 , step 1520 : 1.319792\n",
      "loss in epoch 12 , step 1540 : 0.657629\n",
      "loss in epoch 12 , step 1560 : 0.025707\n",
      "loss in epoch 12 , step 1580 : 0.161008\n",
      "loss in epoch 12 , step 1600 : 1.380684\n",
      "loss in epoch 12 , step 1620 : 1.428609\n",
      "loss in epoch 12 , step 1640 : 1.441820\n",
      "loss in epoch 12 , step 1660 : 2.897467\n",
      "loss in epoch 12 , step 1680 : 0.202358\n",
      "loss in epoch 12 , step 1700 : 0.082761\n",
      "loss in epoch 12 , step 1720 : 0.030743\n",
      "loss in epoch 12 , step 1740 : 1.604214\n",
      "loss in epoch 12 , step 1760 : 1.115619\n",
      "loss in epoch 12 , step 1780 : 0.497871\n",
      "loss in epoch 12 , step 1800 : 0.562651\n",
      "loss in epoch 12 , step 1820 : 1.026618\n",
      "loss in epoch 12 , step 1840 : 0.541005\n",
      "loss in epoch 12 , step 1860 : 0.239037\n",
      "loss in epoch 12 , step 1880 : 0.017280\n",
      "loss in epoch 12 , step 1900 : 0.299867\n",
      "loss in epoch 12 , step 1920 : 4.393173\n",
      "loss in epoch 12 , step 1940 : 0.684348\n",
      "loss in epoch 12 , step 1960 : 0.716339\n",
      "loss in epoch 12 , step 1980 : 0.973650\n",
      "loss in epoch 12 , step 2000 : 0.906993\n",
      "loss in epoch 12 , step 2020 : 2.829872\n",
      "loss in epoch 12 , step 2040 : 0.095947\n",
      "loss in epoch 12 , step 2060 : 0.537080\n",
      "loss in epoch 12 , step 2080 : 1.914238\n",
      "loss in epoch 12 , step 2100 : 0.449969\n",
      "loss in epoch 12 , step 2120 : 2.302089\n",
      "loss in epoch 12 , step 2140 : 0.992705\n",
      "loss in epoch 12 , step 2160 : 0.075042\n",
      "loss in epoch 12 , step 2180 : 0.971823\n",
      "loss in epoch 12 , step 2200 : 0.196933\n",
      "loss in epoch 12 , step 2220 : 0.588433\n",
      "loss in epoch 12 , step 2240 : 0.975426\n",
      "loss in epoch 12 , step 2260 : 1.144992\n",
      "loss in epoch 12 , step 2280 : 0.038632\n",
      "loss in epoch 12 , step 2300 : 1.080636\n",
      "loss in epoch 12 , step 2320 : 2.248057\n",
      "loss in epoch 12 , step 2340 : 0.015975\n",
      "loss in epoch 12 , step 2360 : 0.431739\n",
      "loss in epoch 12 , step 2380 : 0.703999\n",
      "loss in epoch 12 , step 2400 : 1.957899\n",
      "loss in epoch 12 , step 2420 : 0.602053\n",
      "loss in epoch 12 , step 2440 : 2.654678\n",
      "loss in epoch 12 , step 2460 : 1.583682\n",
      "loss in epoch 12 , step 2480 : 0.971664\n",
      "loss in epoch 12 , step 2500 : 0.778788\n",
      "loss in epoch 12 , step 2520 : 0.706895\n",
      "loss in epoch 12 , step 2540 : 1.388829\n",
      "loss in epoch 12 , step 2560 : 1.110204\n",
      "loss in epoch 12 , step 2580 : 0.637259\n",
      "loss in epoch 12 , step 2600 : 1.635663\n",
      "loss in epoch 12 , step 2620 : 1.077013\n",
      "loss in epoch 12 , step 2640 : 1.017129\n",
      "loss in epoch 12 , step 2660 : 0.827253\n",
      "loss in epoch 12 , step 2680 : 0.607401\n",
      "loss in epoch 12 , step 2700 : 0.814319\n",
      "loss in epoch 12 , step 2720 : 0.190884\n",
      "loss in epoch 12 , step 2740 : 1.440899\n",
      "loss in epoch 12 , step 2760 : 1.933057\n",
      "loss in epoch 12 , step 2780 : 1.129036\n",
      "loss in epoch 12 , step 2800 : 1.041349\n",
      "loss in epoch 12 , step 2820 : 0.432345\n",
      "loss in epoch 12 , step 2840 : 0.037493\n",
      "loss in epoch 12 , step 2860 : 2.175322\n",
      "loss in epoch 12 , step 2880 : 0.678306\n",
      "loss in epoch 12 , step 2900 : 1.625994\n",
      "loss in epoch 12 , step 2920 : 0.761668\n",
      "loss in epoch 12 , step 2940 : 0.946203\n",
      "loss in epoch 12 , step 2960 : 0.272703\n",
      "loss in epoch 12 , step 2980 : 0.495809\n",
      "loss in epoch 12 , step 3000 : 0.981072\n",
      "loss in epoch 12 , step 3020 : 0.125613\n",
      "loss in epoch 12 , step 3040 : 2.278356\n",
      "loss in epoch 12 , step 3060 : 1.494201\n",
      "loss in epoch 12 , step 3080 : 0.246802\n",
      "loss in epoch 12 , step 3100 : 0.533518\n",
      "loss in epoch 12 , step 3120 : 2.750110\n",
      "loss in epoch 12 , step 3140 : 1.129290\n",
      "loss in epoch 12 , step 3160 : 0.038665\n",
      "loss in epoch 12 , step 3180 : 0.269698\n",
      "loss in epoch 12 , step 3200 : 1.204492\n",
      "loss in epoch 12 , step 3220 : 3.189241\n",
      "loss in epoch 12 , step 3240 : 1.713559\n",
      "loss in epoch 12 , step 3260 : 1.691365\n",
      "loss in epoch 12 , step 3280 : 1.396186\n",
      "loss in epoch 12 , step 3300 : 1.980985\n",
      "loss in epoch 12 , step 3320 : 0.820425\n",
      "loss in epoch 12 , step 3340 : 0.377155\n",
      "loss in epoch 12 , step 3360 : 0.676004\n",
      "loss in epoch 12 , step 3380 : 1.148667\n",
      "loss in epoch 12 , step 3400 : 0.067070\n",
      "loss in epoch 12 , step 3420 : 0.811824\n",
      "loss in epoch 12 , step 3440 : 1.452615\n",
      "loss in epoch 12 , step 3460 : 1.032344\n",
      "loss in epoch 12 , step 3480 : 0.725553\n",
      "loss in epoch 12 , step 3500 : 0.003818\n",
      "loss in epoch 12 , step 3520 : 2.577947\n",
      "loss in epoch 12 , step 3540 : 3.014733\n",
      "loss in epoch 12 , step 3560 : 0.130389\n",
      "loss in epoch 12 , step 3580 : 0.105356\n",
      "loss in epoch 12 , step 3600 : 1.439313\n",
      "loss in epoch 12 , step 3620 : 1.236363\n",
      "loss in epoch 12 , step 3640 : 1.007182\n",
      "loss in epoch 12 , step 3660 : 0.265289\n",
      "loss in epoch 12 , step 3680 : 0.658387\n",
      "loss in epoch 12 , step 3700 : 0.420104\n",
      "loss in epoch 12 , step 3720 : 2.193734\n",
      "loss in epoch 12 , step 3740 : 1.799407\n",
      "loss in epoch 12 , step 3760 : 3.433661\n",
      "loss in epoch 12 , step 3780 : 1.393929\n",
      "loss in epoch 12 , step 3800 : 1.482273\n",
      "loss in epoch 12 , step 3820 : 0.705784\n",
      "loss in epoch 12 , step 3840 : 2.377939\n",
      "loss in epoch 12 , step 3860 : 0.002885\n",
      "loss in epoch 12 , step 3880 : 0.304407\n",
      "loss in epoch 12 , step 3900 : 0.222039\n",
      "loss in epoch 12 , step 3920 : 0.436814\n",
      "loss in epoch 12 , step 3940 : 0.383002\n",
      "loss in epoch 12 , step 3960 : 1.263842\n",
      "loss in epoch 12 , step 3980 : 0.466572\n",
      "loss in epoch 12 , step 4000 : 0.167825\n",
      "loss in epoch 12 , step 4020 : 0.654407\n",
      "loss in epoch 12 , step 4040 : 1.196984\n",
      "loss in epoch 12 , step 4060 : 0.040443\n",
      "loss in epoch 12 , step 4080 : 2.616334\n",
      "loss in epoch 12 , step 4100 : 0.003731\n",
      "loss in epoch 12 , step 4120 : 0.945037\n",
      "loss in epoch 12 , step 4140 : 1.468199\n",
      "loss in epoch 12 , step 4160 : 0.062369\n",
      "loss in epoch 12 , step 4180 : 0.059812\n",
      "loss in epoch 12 , step 4200 : 0.451219\n",
      "loss in epoch 12 , step 4220 : 0.694825\n",
      "loss in epoch 12 , step 4240 : 0.852428\n",
      "loss in epoch 12 , step 4260 : 1.361721\n",
      "loss in epoch 12 , step 4280 : 0.530803\n",
      "loss in epoch 12 , step 4300 : 1.392801\n",
      "loss in epoch 12 , step 4320 : 1.199180\n",
      "loss in epoch 12 , step 4340 : 2.038962\n",
      "loss in epoch 12 , step 4360 : 1.871459\n",
      "loss in epoch 12 , step 4380 : 1.217900\n",
      "loss in epoch 12 , step 4400 : 1.062800\n",
      "loss in epoch 12 , step 4420 : 0.034437\n",
      "loss in epoch 12 , step 4440 : 1.085480\n",
      "loss in epoch 12 , step 4460 : 0.480028\n",
      "loss in epoch 12 , step 4480 : 1.330655\n",
      "loss in epoch 12 , step 4500 : 1.238382\n",
      "loss in epoch 12 , step 4520 : 0.720287\n",
      "loss in epoch 12 , step 4540 : 1.314914\n",
      "loss in epoch 12 , step 4560 : 0.812353\n",
      "loss in epoch 12 , step 4580 : 1.086392\n",
      "loss in epoch 12 , step 4600 : 2.227267\n",
      "loss in epoch 12 , step 4620 : 1.317949\n",
      "loss in epoch 12 , step 4640 : 3.624819\n",
      "loss in epoch 12 , step 4660 : 0.777858\n",
      "loss in epoch 12 , step 4680 : 1.732888\n",
      "loss in epoch 12 , step 4700 : 0.971994\n",
      "loss in epoch 12 , step 4720 : 0.448273\n",
      "loss in epoch 12 , step 4740 : 0.725640\n",
      "loss in epoch 12 , step 4760 : 1.180748\n",
      "loss in epoch 12 , step 4780 : 0.403139\n",
      "loss in epoch 12 , step 4800 : 0.101742\n",
      "loss in epoch 12 , step 4820 : 0.650595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 12 , step 4840 : 1.171976\n",
      "loss in epoch 12 , step 4860 : 0.776782\n",
      "loss in epoch 12 , step 4880 : 5.024597\n",
      "loss in epoch 12 , step 4900 : 2.709132\n",
      "loss in epoch 12 , step 4920 : 1.371034\n",
      "loss in epoch 12 , step 4940 : 2.942675\n",
      "loss in epoch 12 , step 4960 : 1.998146\n",
      "loss in epoch 12 , step 4980 : 0.400166\n",
      "loss in epoch 12 , step 5000 : 0.154513\n",
      "loss in epoch 12 , step 5020 : 0.751911\n",
      "loss in epoch 12 , step 5040 : 0.192827\n",
      "loss in epoch 12 , step 5060 : 1.894553\n",
      "loss in epoch 12 , step 5080 : 0.146614\n",
      "loss in epoch 12 , step 5100 : 1.821988\n",
      "loss in epoch 12 , step 5120 : 1.086405\n",
      "loss in epoch 12 , step 5140 : 0.315673\n",
      "loss in epoch 12 , step 5160 : 1.191386\n",
      "loss in epoch 12 , step 5180 : 0.536272\n",
      "loss in epoch 12 , step 5200 : 2.181705\n",
      "loss in epoch 12 , step 5220 : 0.160603\n",
      "loss in epoch 12 , step 5240 : 1.933999\n",
      "loss in epoch 12 , step 5260 : 2.669171\n",
      "loss in epoch 12 , step 5280 : 0.009007\n",
      "loss in epoch 12 , step 5300 : 0.539649\n",
      "loss in epoch 12 , step 5320 : 0.006752\n",
      "loss in epoch 12 , step 5340 : 0.563383\n",
      "loss in epoch 12 , step 5360 : 0.115245\n",
      "loss in epoch 12 , step 5380 : 1.690605\n",
      "loss in epoch 12 , step 5400 : 1.374790\n",
      "loss in epoch 12 , step 5420 : 0.147178\n",
      "loss in epoch 12 , step 5440 : 0.513355\n",
      "loss in epoch 12 , step 5460 : 1.665197\n",
      "loss in epoch 12 , step 5480 : 0.446310\n",
      "loss in epoch 12 , step 5500 : 0.114008\n",
      "loss in epoch 12 , step 5520 : 1.474424\n",
      "loss in epoch 12 , step 5540 : 0.615555\n",
      "loss in epoch 12 , step 5560 : 2.489654\n",
      "loss in epoch 12 , step 5580 : 0.355120\n",
      "loss in epoch 12 , step 5600 : 0.042421\n",
      "loss in epoch 12 , step 5620 : 0.006277\n",
      "loss in epoch 12 , step 5640 : 2.003947\n",
      "loss in epoch 12 , step 5660 : 1.553108\n",
      "loss in epoch 12 , step 5680 : 0.798308\n",
      "loss in epoch 12 , step 5700 : 0.862961\n",
      "loss in epoch 12 , step 5720 : 0.051957\n",
      "loss in epoch 12 , step 5740 : 1.495556\n",
      "loss in epoch 12 , step 5760 : 1.631814\n",
      "loss in epoch 12 , step 5780 : 0.641182\n",
      "loss in epoch 12 , step 5800 : 0.048239\n",
      "loss in epoch 12 , step 5820 : 0.229723\n",
      "loss in epoch 12 , step 5840 : 0.498911\n",
      "loss in epoch 12 , step 5860 : 0.130144\n",
      "loss in epoch 12 , step 5880 : 1.940413\n",
      "loss in epoch 12 , step 5900 : 0.005104\n",
      "loss in epoch 12 , step 5920 : 0.277285\n",
      "loss in epoch 12 , step 5940 : 1.144949\n",
      "loss in epoch 12 , step 5960 : 2.089590\n",
      "loss in epoch 12 , step 5980 : 1.088136\n",
      "loss in epoch 12 , step 6000 : 0.129546\n",
      "loss in epoch 12 , step 6020 : 1.108343\n",
      "loss in epoch 12 , step 6040 : 1.220461\n",
      "loss in epoch 12 , step 6060 : 2.039588\n",
      "loss in epoch 12 , step 6080 : 1.242593\n",
      "loss in epoch 12 , step 6100 : 2.773653\n",
      "loss in epoch 12 , step 6120 : 0.122708\n",
      "loss in epoch 12 , step 6140 : 0.009040\n",
      "loss in epoch 12 , step 6160 : 1.867471\n",
      "loss in epoch 12 , step 6180 : 3.448937\n",
      "loss in epoch 12 , step 6200 : 0.621305\n",
      "loss in epoch 12 , step 6220 : 0.009457\n",
      "loss in epoch 12 , step 6240 : 2.814799\n",
      "loss in epoch 12 , step 6260 : 1.773264\n",
      "loss in epoch 12 , step 6280 : 1.350995\n",
      "loss in epoch 12 , step 6300 : 0.094936\n",
      "loss in epoch 12 , step 6320 : 0.125361\n",
      "loss in epoch 12 , step 6340 : 0.713307\n",
      "loss in epoch 12 , step 6360 : 1.459797\n",
      "loss in epoch 12 , step 6380 : 1.907999\n",
      "loss in epoch 12 , step 6400 : 0.010558\n",
      "loss in epoch 12 , step 6420 : 0.788463\n",
      "loss in epoch 12 , step 6440 : 0.385818\n",
      "loss in epoch 12 , step 6460 : 0.648690\n",
      "loss in epoch 12 , step 6480 : 2.160866\n",
      "loss in epoch 12 , step 6500 : 3.901155\n",
      "loss in epoch 12 , step 6520 : 0.050597\n",
      "loss in epoch 12 , step 6540 : 0.488412\n",
      "loss in epoch 12 , step 6560 : 1.021333\n",
      "loss in epoch 12 , step 6580 : 0.014505\n",
      "loss in epoch 12 , step 6600 : 0.454118\n",
      "loss in epoch 12 , step 6620 : 0.453434\n",
      "loss in epoch 12 , step 6640 : 1.178854\n",
      "loss in epoch 12 , step 6660 : 0.145532\n",
      "loss in epoch 12 , step 6680 : 2.442171\n",
      "loss in epoch 12 , step 6700 : 0.986539\n",
      "loss in epoch 12 , step 6720 : 0.617015\n",
      "loss in epoch 12 , step 6740 : 1.719612\n",
      "loss in epoch 12 , step 6760 : 0.005037\n",
      "loss in epoch 12 , step 6780 : 0.114464\n",
      "loss in epoch 12 , step 6800 : 0.848006\n",
      "loss in epoch 12 , step 6820 : 3.627311\n",
      "loss in epoch 12 , step 6840 : 0.341072\n",
      "loss in epoch 12 , step 6860 : 0.219239\n",
      "loss in epoch 12 , step 6880 : 1.961798\n",
      "loss in epoch 12 , step 6900 : 0.320979\n",
      "loss in epoch 12 , step 6920 : 1.260426\n",
      "loss in epoch 12 , step 6940 : 0.113840\n",
      "loss in epoch 12 , step 6960 : 0.696967\n",
      "loss in epoch 12 , step 6980 : 1.698250\n",
      "loss in epoch 12 , step 7000 : 2.129776\n",
      "loss in epoch 12 , step 7020 : 0.907339\n",
      "loss in epoch 12 , step 7040 : 2.106792\n",
      "loss in epoch 12 , step 7060 : 1.400809\n",
      "loss in epoch 12 , step 7080 : 0.263585\n",
      "loss in epoch 12 , step 7100 : 0.339802\n",
      "loss in epoch 12 , step 7120 : 0.849729\n",
      "loss in epoch 12 , step 7140 : 0.828018\n",
      "loss in epoch 12 , step 7160 : 0.030462\n",
      "loss in epoch 12 , step 7180 : 1.167585\n",
      "loss in epoch 12 , step 7200 : 1.226211\n",
      "loss in epoch 12 , step 7220 : 1.461951\n",
      "loss in epoch 12 , step 7240 : 1.583406\n",
      "loss in epoch 12 , step 7260 : 1.924944\n",
      "loss in epoch 12 , step 7280 : 1.517686\n",
      "loss in epoch 12 , step 7300 : 0.983067\n",
      "loss in epoch 12 , step 7320 : 0.057050\n",
      "loss in epoch 12 , step 7340 : 0.039317\n",
      "loss in epoch 12 , step 7360 : 1.801306\n",
      "loss in epoch 12 , step 7380 : 0.019845\n",
      "loss in epoch 12 , step 7400 : 1.389526\n",
      "loss in epoch 12 , step 7420 : 0.477856\n",
      "loss in epoch 12 , step 7440 : 0.697288\n",
      "loss in epoch 12 , step 7460 : 2.743865\n",
      "loss in epoch 12 , step 7480 : 0.841455\n",
      "loss in epoch 12 , step 7500 : 1.505491\n",
      "loss in epoch 12 , step 7520 : 1.358113\n",
      "loss in epoch 12 , step 7540 : 0.005749\n",
      "loss in epoch 12 , step 7560 : 0.858315\n",
      "loss in epoch 12 , step 7580 : 1.114568\n",
      "loss in epoch 12 , step 7600 : 0.080783\n",
      "loss in epoch 12 , step 7620 : 0.129421\n",
      "loss in epoch 12 , step 7640 : 3.971139\n",
      "loss in epoch 12 , step 7660 : 0.017216\n",
      "loss in epoch 12 , step 7680 : 2.709467\n",
      "loss in epoch 12 , step 7700 : 1.479580\n",
      "loss in epoch 12 , step 7720 : 1.236181\n",
      "loss in epoch 12 , step 7740 : 0.230937\n",
      "loss in epoch 12 , step 7760 : 0.676419\n",
      "loss in epoch 12 , step 7780 : 0.210183\n",
      "loss in epoch 12 , step 7800 : 2.216349\n",
      "loss in epoch 12 , step 7820 : 2.027178\n",
      "loss in epoch 12 , step 7840 : 1.839543\n",
      "loss in epoch 12 , step 7860 : 1.267496\n",
      "loss in epoch 12 , step 7880 : 0.631071\n",
      "loss in epoch 12 , step 7900 : 1.484167\n",
      "loss in epoch 12 , step 7920 : 0.097437\n",
      "loss in epoch 12 , step 7940 : 1.790992\n",
      "loss in epoch 12 , step 7960 : 0.555813\n",
      "loss in epoch 12 , step 7980 : 1.524426\n",
      "loss in epoch 12 , step 8000 : 0.416764\n",
      "loss in epoch 12 , step 8020 : 1.035800\n",
      "loss in epoch 12 , step 8040 : 0.002263\n",
      "loss in epoch 12 , step 8060 : 0.628397\n",
      "loss in epoch 12 , step 8080 : 0.111430\n",
      "loss in epoch 12 , step 8100 : 1.113546\n",
      "loss in epoch 12 , step 8120 : 0.020333\n",
      "loss in epoch 12 , step 8140 : 1.890636\n",
      "loss in epoch 12 , step 8160 : 0.247973\n",
      "loss in epoch 12 , step 8180 : 1.291091\n",
      "loss in epoch 12 , step 8200 : 1.159260\n",
      "loss in epoch 12 , step 8220 : 0.802945\n",
      "loss in epoch 12 , step 8240 : 1.065098\n",
      "loss in epoch 12 , step 8260 : 0.265021\n",
      "loss in epoch 12 , step 8280 : 0.005638\n",
      "loss in epoch 12 , step 8300 : 0.155871\n",
      "loss in epoch 12 , step 8320 : 1.800585\n",
      "loss in epoch 12 , step 8340 : 0.873231\n",
      "loss in epoch 12 , step 8360 : 2.608951\n",
      "loss in epoch 12 , step 8380 : 1.949734\n",
      "loss in epoch 12 , step 8400 : 1.423470\n",
      "loss in epoch 12 , step 8420 : 0.314023\n",
      "loss in epoch 12 , step 8440 : 0.255377\n",
      "loss in epoch 12 , step 8460 : 1.296825\n",
      "loss in epoch 12 , step 8480 : 3.212176\n",
      "loss in epoch 12 , step 8500 : 0.006403\n",
      "loss in epoch 12 , step 8520 : 0.936160\n",
      "loss in epoch 12 , step 8540 : 0.081558\n",
      "loss in epoch 12 , step 8560 : 2.258447\n",
      "loss in epoch 12 , step 8580 : 0.450938\n",
      "loss in epoch 12 , step 8600 : 0.988301\n",
      "loss in epoch 12 , step 8620 : 0.008237\n",
      "loss in epoch 12 , step 8640 : 0.116920\n",
      "loss in epoch 12 , step 8660 : 2.039779\n",
      "loss in epoch 12 , step 8680 : 1.656875\n",
      "loss in epoch 12 , step 8700 : 1.561493\n",
      "loss in epoch 12 , step 8720 : 0.031099\n",
      "loss in epoch 12 , step 8740 : 0.959862\n",
      "loss in epoch 12 , step 8760 : 1.055625\n",
      "loss in epoch 12 , step 8780 : 1.478259\n",
      "loss in epoch 12 , step 8800 : 0.862941\n",
      "loss in epoch 12 , step 8820 : 0.380860\n",
      "loss in epoch 12 , step 8840 : 0.071766\n",
      "loss in epoch 12 , step 8860 : 0.950206\n",
      "loss in epoch 12 , step 8880 : 0.797703\n",
      "loss in epoch 12 , step 8900 : 0.230359\n",
      "loss in epoch 12 , step 8920 : 2.582840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 12 , step 8940 : 0.497051\n",
      "loss in epoch 12 , step 8960 : 0.012329\n",
      "loss in epoch 12 , step 8980 : 1.044441\n",
      "loss in epoch 12 , step 9000 : 2.017799\n",
      "loss in epoch 12 , step 9020 : 1.809935\n",
      "loss in epoch 12 , step 9040 : 0.004736\n",
      "loss in epoch 12 , step 9060 : 0.018987\n",
      "loss in epoch 12 , step 9080 : 0.806652\n",
      "loss in epoch 12 , step 9100 : 0.593948\n",
      "loss in epoch 12 , step 9120 : 0.493874\n",
      "loss in epoch 12 , step 9140 : 0.906672\n",
      "loss in epoch 12 , step 9160 : 1.368956\n",
      "loss in epoch 12 , step 9180 : 1.673136\n",
      "loss in epoch 12 , step 9200 : 1.527807\n",
      "loss in epoch 12 , step 9220 : 0.960630\n",
      "loss in epoch 12 , step 9240 : 0.839971\n",
      "loss in epoch 12 , step 9260 : 0.897548\n",
      "loss in epoch 12 , step 9280 : 1.341199\n",
      "loss in epoch 12 , step 9300 : 0.723763\n",
      "loss in epoch 12 , step 9320 : 0.201110\n",
      "loss in epoch 12 , step 9340 : 1.207347\n",
      "loss in epoch 12 , step 9360 : 0.018644\n",
      "loss in epoch 12 , step 9380 : 1.473272\n",
      "loss in epoch 12 , step 9400 : 1.269853\n",
      "loss in epoch 12 , step 9420 : 1.109944\n",
      "loss in epoch 12 , step 9440 : 1.139647\n",
      "loss in epoch 12 , step 9460 : 0.144577\n",
      "loss in epoch 12 , step 9480 : 1.851804\n",
      "loss in epoch 12 , step 9500 : 1.858432\n",
      "loss in epoch 12 , step 9520 : 2.497126\n",
      "loss in epoch 12 , step 9540 : 1.176179\n",
      "loss in epoch 12 , step 9560 : 2.645072\n",
      "loss in epoch 12 , step 9580 : 1.305355\n",
      "loss in epoch 12 , step 9600 : 2.498899\n",
      "loss in epoch 12 , step 9620 : 1.257574\n",
      "loss in epoch 12 , step 9640 : 1.157923\n",
      "loss in epoch 12 , step 9660 : 0.513336\n",
      "loss in epoch 12 , step 9680 : 0.880860\n",
      "loss in epoch 12 , step 9700 : 0.088893\n",
      "loss in epoch 12 , step 9720 : 1.951779\n",
      "loss in epoch 12 , step 9740 : 1.531852\n",
      "loss in epoch 12 , step 9760 : 1.974598\n",
      "loss in epoch 12 , step 9780 : 0.010015\n",
      "loss in epoch 12 , step 9800 : 2.119416\n",
      "loss in epoch 12 , step 9820 : 0.305672\n",
      "loss in epoch 12 , step 9840 : 0.014564\n",
      "loss in epoch 12 , step 9860 : 0.755262\n",
      "loss in epoch 12 , step 9880 : 0.103404\n",
      "loss in epoch 12 , step 9900 : 1.462443\n",
      "loss in epoch 12 , step 9920 : 1.944091\n",
      "loss in epoch 12 , step 9940 : 0.597410\n",
      "loss in epoch 12 , step 9960 : 0.779041\n",
      "loss in epoch 12 , step 9980 : 1.805762\n",
      "loss in epoch 12 , step 10000 : 1.240844\n",
      "loss in epoch 12 , step 10020 : 0.372610\n",
      "loss in epoch 12 , step 10040 : 2.124559\n",
      "loss in epoch 12 , step 10060 : 0.082555\n",
      "loss in epoch 12 , step 10080 : 2.798210\n",
      "loss in epoch 12 , step 10100 : 2.142894\n",
      "loss in epoch 12 , step 10120 : 0.364693\n",
      "loss in epoch 12 , step 10140 : 2.553487\n",
      "loss in epoch 12 , step 10160 : 1.974278\n",
      "loss in epoch 12 , step 10180 : 0.030904\n",
      "loss in epoch 12 , step 10200 : 0.976477\n",
      "loss in epoch 12 , step 10220 : 0.889772\n",
      "loss in epoch 12 , step 10240 : 0.118300\n",
      "loss in epoch 12 , step 10260 : 1.584122\n",
      "loss in epoch 12 , step 10280 : 1.003567\n",
      "loss in epoch 12 , step 10300 : 1.667739\n",
      "loss in epoch 12 , step 10320 : 0.817368\n",
      "loss in epoch 12 , step 10340 : 1.734530\n",
      "loss in epoch 12 , step 10360 : 1.332088\n",
      "loss in epoch 12 , step 10380 : 1.312505\n",
      "loss in epoch 12 , step 10400 : 0.180660\n",
      "loss in epoch 12 , step 10420 : 1.115228\n",
      "loss in epoch 12 , step 10440 : 0.887862\n",
      "loss in epoch 12 , step 10460 : 1.860100\n",
      "loss in epoch 12 , step 10480 : 2.052450\n",
      "loss in epoch 12 , step 10500 : 0.110945\n",
      "loss in epoch 12 , step 10520 : 0.091488\n",
      "loss in epoch 12 , step 10540 : 1.397023\n",
      "loss in epoch 12 , step 10560 : 0.080826\n",
      "loss in epoch 12 , step 10580 : 1.079608\n",
      "loss in epoch 12 , step 10600 : 1.019482\n",
      "loss in epoch 12 , step 10620 : 0.144238\n",
      "loss in epoch 12 , step 10640 : 1.168572\n",
      "loss in epoch 12 , step 10660 : 0.718400\n",
      "loss in epoch 12 , step 10680 : 2.376911\n",
      "loss in epoch 12 , step 10700 : 1.830341\n",
      "loss in epoch 12 , step 10720 : 0.871710\n",
      "loss in epoch 12 , step 10740 : 0.614269\n",
      "loss in epoch 12 , step 10760 : 1.205129\n",
      "loss in epoch 12 , step 10780 : 2.159569\n",
      "loss in epoch 12 , step 10800 : 1.210632\n",
      "loss in epoch 12 , step 10820 : 0.455745\n",
      "loss in epoch 12 , step 10840 : 1.699430\n",
      "loss in epoch 12 , step 10860 : 0.956643\n",
      "loss in epoch 12 , step 10880 : 3.640072\n",
      "loss in epoch 12 , step 10900 : 1.031044\n",
      "loss in epoch 12 , step 10920 : 0.863680\n",
      "loss in epoch 12 , step 10940 : 0.922645\n",
      "loss in epoch 12 , step 10960 : 0.197815\n",
      "loss in epoch 12 , step 10980 : 1.354020\n",
      "loss in epoch 12 , step 11000 : 0.028622\n",
      "loss in epoch 12 , step 11020 : 1.885049\n",
      "loss in epoch 12 , step 11040 : 0.059255\n",
      "loss in epoch 12 , step 11060 : 0.239274\n",
      "loss in epoch 12 , step 11080 : 2.516398\n",
      "loss in epoch 12 , step 11100 : 1.478440\n",
      "loss in epoch 12 , step 11120 : 1.095746\n",
      "loss in epoch 12 , step 11140 : 1.183563\n",
      "loss in epoch 12 , step 11160 : 0.769965\n",
      "loss in epoch 12 , step 11180 : 1.452274\n",
      "loss in epoch 12 , step 11200 : 3.374861\n",
      "loss in epoch 12 , step 11220 : 1.672442\n",
      "loss in epoch 12 , step 11240 : 2.341272\n",
      "loss in epoch 12 , step 11260 : 1.098004\n",
      "loss in epoch 12 , step 11280 : 2.530317\n",
      "loss in epoch 12 , step 11300 : 0.668951\n",
      "loss in epoch 12 , step 11320 : 1.258729\n",
      "loss in epoch 12 , step 11340 : 3.395944\n",
      "loss in epoch 12 , step 11360 : 2.116888\n",
      "loss in epoch 12 , step 11380 : 0.040271\n",
      "loss in epoch 12 , step 11400 : 2.372326\n",
      "loss in epoch 12 , step 11420 : 1.489580\n",
      "loss in epoch 12 , step 11440 : 0.463513\n",
      "loss in epoch 12 , step 11460 : 1.482658\n",
      "loss in epoch 12 , step 11480 : 0.888591\n",
      "loss in epoch 12 , step 11500 : 2.821727\n",
      "loss in epoch 12 , step 11520 : 1.813395\n",
      "loss in epoch 12 , step 11540 : 0.783029\n",
      "loss in epoch 12 , step 11560 : 0.777929\n",
      "loss in epoch 12 , step 11580 : 0.839776\n",
      "loss in epoch 12 , step 11600 : 0.532270\n",
      "loss in epoch 12 , step 11620 : 1.703729\n",
      "loss in epoch 12 , step 11640 : 0.892645\n",
      "loss in epoch 12 , step 11660 : 1.973193\n",
      "loss in epoch 12 , step 11680 : 1.106374\n",
      "loss in epoch 12 , step 11700 : 2.324521\n",
      "loss in epoch 12 , step 11720 : 0.792178\n",
      "loss in epoch 12 , step 11740 : 2.765187\n",
      "loss in epoch 12 , step 11760 : 0.011268\n",
      "loss in epoch 12 , step 11780 : 0.369154\n",
      "loss in epoch 12 , step 11800 : 0.011060\n",
      "loss in epoch 12 , step 11820 : 1.370116\n",
      "loss in epoch 12 , step 11840 : 0.082943\n",
      "loss in epoch 12 , step 11860 : 0.291028\n",
      "loss in epoch 12 , step 11880 : 1.693152\n",
      "loss in epoch 12 , step 11900 : 2.626596\n",
      "loss in epoch 12 , step 11920 : 1.161388\n",
      "loss in epoch 12 , step 11940 : 0.378378\n",
      "loss in epoch 12 , step 11960 : 0.725100\n",
      "loss in epoch 12 , step 11980 : 1.922674\n",
      "loss in epoch 12 , step 12000 : 2.999145\n",
      "loss in epoch 12 , step 12020 : 0.163088\n",
      "loss in epoch 12 , step 12040 : 0.053642\n",
      "loss in epoch 12 , step 12060 : 1.573804\n",
      "loss in epoch 12 , step 12080 : 1.837211\n",
      "loss in epoch 12 , step 12100 : 0.571818\n",
      "loss in epoch 12 , step 12120 : 0.463902\n",
      "loss in epoch 12 , step 12140 : 2.361812\n",
      "loss in epoch 12 , step 12160 : 1.580532\n",
      "loss in epoch 12 , step 12180 : 1.414783\n",
      "loss in epoch 12 , step 12200 : 0.064386\n",
      "loss in epoch 12 , step 12220 : 0.057483\n",
      "loss in epoch 12 , step 12240 : 1.057953\n",
      "loss in epoch 12 , step 12260 : 0.334270\n",
      "loss in epoch 12 , step 12280 : 0.165048\n",
      "loss in epoch 12 , step 12300 : 0.529234\n",
      "loss in epoch 12 , step 12320 : 0.022116\n",
      "loss in epoch 12 , step 12340 : 0.992936\n",
      "loss in epoch 12 , step 12360 : 1.667457\n",
      "loss in epoch 12 , step 12380 : 1.874144\n",
      "loss in epoch 12 , step 12400 : 2.816715\n",
      "loss in epoch 12 , step 12420 : 2.277296\n",
      "loss in epoch 12 , step 12440 : 0.675612\n",
      "loss in epoch 12 , step 12460 : 1.033030\n",
      "loss in epoch 12 , step 12480 : 0.462652\n",
      "loss in epoch 12 , step 12500 : 0.038341\n",
      "loss in epoch 12 , step 12520 : 0.005802\n",
      "loss in epoch 12 , step 12540 : 1.626197\n",
      "loss in epoch 12 , step 12560 : 0.323542\n",
      "loss in epoch 12 , step 12580 : 0.745199\n",
      "loss in epoch 12 , step 12600 : 0.371355\n",
      "loss in epoch 12 , step 12620 : 0.403109\n",
      "loss in epoch 12 , step 12640 : 0.060047\n",
      "loss in epoch 12 , step 12660 : 1.229815\n",
      "loss in epoch 12 , step 12680 : 1.229540\n",
      "loss in epoch 12 , step 12700 : 3.416172\n",
      "loss in epoch 12 , step 12720 : 0.966762\n",
      "loss in epoch 12 , step 12740 : 1.129149\n",
      "loss in epoch 12 , step 12760 : 1.441792\n",
      "loss in epoch 12 , step 12780 : 1.507549\n",
      "loss in epoch 12 , step 12800 : 0.182002\n",
      "loss in epoch 12 , step 12820 : 1.023598\n",
      "loss in epoch 12 , step 12840 : 1.687575\n",
      "loss in epoch 12 , step 12860 : 0.023682\n",
      "loss in epoch 12 , step 12880 : 0.068988\n",
      "loss in epoch 12 , step 12900 : 0.419149\n",
      "loss in epoch 12 , step 12920 : 1.480950\n",
      "loss in epoch 12 , step 12940 : 1.409476\n",
      "loss in epoch 12 , step 12960 : 1.571459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 12 , step 12980 : 0.041122\n",
      "loss in epoch 12 , step 13000 : 1.526467\n",
      "loss in epoch 12 , step 13020 : 0.636393\n",
      "loss in epoch 12 , step 13040 : 0.442603\n",
      "loss in epoch 12 , step 13060 : 0.896853\n",
      "loss in epoch 12 , step 13080 : 2.215476\n",
      "loss in epoch 12 , step 13100 : 2.288805\n",
      "loss in epoch 12 , step 13120 : 1.095281\n",
      "loss in epoch 12 , step 13140 : 1.168496\n",
      "loss in epoch 12 , step 13160 : 1.087516\n",
      "loss in epoch 12 , step 13180 : 2.202711\n",
      "loss in epoch 12 , step 13200 : 0.117995\n",
      "loss in epoch 12 , step 13220 : 1.019696\n",
      "loss in epoch 12 , step 13240 : 0.834422\n",
      "loss in epoch 12 , step 13260 : 0.759059\n",
      "loss in epoch 12 , step 13280 : 1.476724\n",
      "loss in epoch 12 , step 13300 : 0.418362\n",
      "loss in epoch 12 , step 13320 : 0.625539\n",
      "loss in epoch 12 , step 13340 : 0.126760\n",
      "loss in epoch 12 , step 13360 : 3.224895\n",
      "loss in epoch 12 , step 13380 : 0.922093\n",
      "loss in epoch 12 , step 13400 : 0.606734\n",
      "loss in epoch 12 , step 13420 : 1.818327\n",
      "loss in epoch 12 , step 13440 : 1.490559\n",
      "loss in epoch 12 , step 13460 : 1.530890\n",
      "loss in epoch 12 , step 13480 : 3.279481\n",
      "loss in epoch 12 , step 13500 : 0.959634\n",
      "loss in epoch 12 , step 13520 : 1.892164\n",
      "loss in epoch 12 , step 13540 : 1.548602\n",
      "loss in epoch 12 , step 13560 : 0.962933\n",
      "loss in epoch 12 , step 13580 : 0.483142\n",
      "loss in epoch 12 , step 13600 : 1.963846\n",
      "loss in epoch 12 , step 13620 : 1.129682\n",
      "loss in epoch 12 , step 13640 : 2.358917\n",
      "loss in epoch 12 , step 13660 : 0.999703\n",
      "loss in epoch 12 , step 13680 : 1.375396\n",
      "loss in epoch 12 , step 13700 : 0.013528\n",
      "loss in epoch 12 , step 13720 : 0.010617\n",
      "loss in epoch 12 , step 13740 : 0.162694\n",
      "loss in epoch 12 , step 13760 : 0.376837\n",
      "loss in epoch 12 , step 13780 : 0.234191\n",
      "loss in epoch 12 , step 13800 : 1.671022\n",
      "loss in epoch 12 , step 13820 : 2.311334\n",
      "loss in epoch 12 , step 13840 : 1.168507\n",
      "loss in epoch 12 , step 13860 : 1.149916\n",
      "loss in epoch 12 , step 13880 : 1.259856\n",
      "loss in epoch 12 , step 13900 : 1.147432\n",
      "loss in epoch 12 , step 13920 : 0.974993\n",
      "loss in epoch 12 , step 13940 : 0.482093\n",
      "loss in epoch 12 , step 13960 : 0.105927\n",
      "loss in epoch 12 , step 13980 : 0.613627\n",
      "loss in epoch 12 , step 14000 : 1.772822\n",
      "loss in epoch 12 , step 14020 : 0.593498\n",
      "loss in epoch 12 , step 14040 : 0.707204\n",
      "loss in epoch 12 , step 14060 : 0.669910\n",
      "loss in epoch 12 , step 14080 : 0.465346\n",
      "loss in epoch 12 , step 14100 : 0.991219\n",
      "loss in epoch 12 , step 14120 : 1.809863\n",
      "loss in epoch 12 , step 14140 : 0.031353\n",
      "loss in epoch 12 , step 14160 : 0.013950\n",
      "loss in epoch 12 , step 14180 : 0.337871\n",
      "loss in epoch 12 , step 14200 : 1.655476\n",
      "loss in epoch 12 , step 14220 : 0.059905\n",
      "loss in epoch 12 , step 14240 : 1.628871\n",
      "loss in epoch 12 , step 14260 : 2.248435\n",
      "loss in epoch 12 , step 14280 : 0.987139\n",
      "loss in epoch 12 , step 14300 : 0.867514\n",
      "loss in epoch 12 , step 14320 : 0.083388\n",
      "loss in epoch 12 , step 14340 : 2.583014\n",
      "loss in epoch 12 , step 14360 : 0.093473\n",
      "loss in epoch 12 , step 14380 : 1.380492\n",
      "loss in epoch 12 , step 14400 : 1.468160\n",
      "loss in epoch 12 , step 14420 : 1.320870\n",
      "loss in epoch 12 , step 14440 : 1.028556\n",
      "loss in epoch 12 , step 14460 : 0.018281\n",
      "loss in epoch 12 , step 14480 : 2.280244\n",
      "loss in epoch 12 , step 14500 : 0.023266\n",
      "loss in epoch 12 , step 14520 : 0.092867\n",
      "loss in epoch 12 , step 14540 : 1.078406\n",
      "loss in epoch 12 , step 14560 : 1.230959\n",
      "loss in epoch 12 , step 14580 : 1.878581\n",
      "loss in epoch 12 , step 14600 : 1.339399\n",
      "loss in epoch 12 , step 14620 : 0.624202\n",
      "loss in epoch 12 , step 14640 : 0.684920\n",
      "loss in epoch 12 , step 14660 : 0.729392\n",
      "loss in epoch 12 , step 14680 : 0.657383\n",
      "loss in epoch 12 , step 14700 : 2.299241\n",
      "loss in epoch 12 , step 14720 : 1.757164\n",
      "loss in epoch 12 , step 14740 : 0.085709\n",
      "loss in epoch 12 , step 14760 : 0.104718\n",
      "loss in epoch 12 , step 14780 : 0.030773\n",
      "loss in epoch 12 , step 14800 : 0.069155\n",
      "loss in epoch 12 , step 14820 : 0.008555\n",
      "loss in epoch 12 , step 14840 : 1.663767\n",
      "loss in epoch 12 , step 14860 : 1.330351\n",
      "loss in epoch 12 , step 14880 : 1.642471\n",
      "loss in epoch 12 , step 14900 : 0.839182\n",
      "loss in epoch 12 , step 14920 : 1.827177\n",
      "loss in epoch 12 , step 14940 : 0.812569\n",
      "loss in epoch 12 , step 14960 : 0.602836\n",
      "loss in epoch 12 , step 14980 : 1.856979\n",
      "loss in epoch 12 , step 15000 : 2.251678\n",
      "loss in epoch 12 , step 15020 : 0.080951\n",
      "loss in epoch 12 , step 15040 : 2.263841\n",
      "loss in epoch 12 , step 15060 : 0.965328\n",
      "loss in epoch 12 , step 15080 : 0.405968\n",
      "loss in epoch 12 , step 15100 : 0.638434\n",
      "loss in epoch 12 , step 15120 : 1.383617\n",
      "loss in epoch 12 , step 15140 : 0.687146\n",
      "loss in epoch 12 , step 15160 : 3.215810\n",
      "loss in epoch 12 , step 15180 : 0.792968\n",
      "loss in epoch 12 , step 15200 : 1.445432\n",
      "loss in epoch 12 , step 15220 : 1.796214\n",
      "loss in epoch 12 , step 15240 : 0.398161\n",
      "loss in epoch 12 , step 15260 : 0.504883\n",
      "loss in epoch 12 , step 15280 : 0.720130\n",
      "loss in epoch 12 , step 15300 : 0.958592\n",
      "loss in epoch 12 , step 15320 : 1.777161\n",
      "loss in epoch 12 , step 15340 : 2.640638\n",
      "loss in epoch 12 , step 15360 : 2.418649\n",
      "loss in epoch 12 , step 15380 : 0.070653\n",
      "loss in epoch 12 , step 15400 : 0.068679\n",
      "loss in epoch 12 , step 15420 : 1.635340\n",
      "loss in epoch 12 , step 15440 : 0.595656\n",
      "loss in epoch 12 , step 15460 : 1.162591\n",
      "loss in epoch 12 , step 15480 : 0.123194\n",
      "loss in epoch 12 , step 15500 : 0.453570\n",
      "loss in epoch 12 , step 15520 : 1.277609\n",
      "loss in epoch 12 , step 15540 : 1.158170\n",
      "loss in epoch 12 , step 15560 : 0.328158\n",
      "loss in epoch 12 , step 15580 : 0.400097\n",
      "loss in epoch 12 , step 15600 : 1.908960\n",
      "loss in epoch 12 , step 15620 : 2.978508\n",
      "loss in epoch 12 , step 15640 : 0.602975\n",
      "loss in epoch 12 , step 15660 : 1.198964\n",
      "loss in epoch 12 , step 15680 : 3.643044\n",
      "loss in epoch 12 , step 15700 : 0.519620\n",
      "loss in epoch 12 , step 15720 : 0.938315\n",
      "loss in epoch 12 , step 15740 : 0.013492\n",
      "loss in epoch 12 , step 15760 : 0.979620\n",
      "loss in epoch 12 , step 15780 : 1.493573\n",
      "loss in epoch 12 , step 15800 : 0.396882\n",
      "loss in epoch 12 , step 15820 : 0.820487\n",
      "loss in epoch 12 , step 15840 : 0.538366\n",
      "loss in epoch 12 , step 15860 : 2.645962\n",
      "loss in epoch 12 , step 15880 : 1.538955\n",
      "loss in epoch 12 , step 15900 : 0.023904\n",
      "loss in epoch 12 , step 15920 : 1.271129\n",
      "loss in epoch 12 , step 15940 : 2.133358\n",
      "loss in epoch 12 , step 15960 : 0.084587\n",
      "loss in epoch 12 , step 15980 : 0.760521\n",
      "loss in epoch 12 , step 16000 : 0.901055\n",
      "loss in epoch 12 , step 16020 : 0.350146\n",
      "loss in epoch 12 , step 16040 : 2.149007\n",
      "loss in epoch 12 , step 16060 : 2.094775\n",
      "loss in epoch 12 , step 16080 : 1.463845\n",
      "loss in epoch 12 , step 16100 : 1.090857\n",
      "loss in epoch 12 , step 16120 : 0.969243\n",
      "loss in epoch 12 , step 16140 : 0.487190\n",
      "loss in epoch 12 , step 16160 : 1.351938\n",
      "loss in epoch 12 , step 16180 : 1.023966\n",
      "loss in epoch 12 , step 16200 : 0.760758\n",
      "loss in epoch 12 , step 16220 : 0.028194\n",
      "loss in epoch 12 , step 16240 : 2.318856\n",
      "loss in epoch 12 , step 16260 : 0.530060\n",
      "loss in epoch 12 , step 16280 : 0.787239\n",
      "loss in epoch 12 , step 16300 : 0.547061\n",
      "loss in epoch 12 , step 16320 : 0.551041\n",
      "loss in epoch 12 , step 16340 : 2.141561\n",
      "loss in epoch 12 , step 16360 : 0.802032\n",
      "loss in epoch 12 , step 16380 : 1.475933\n",
      "loss in epoch 12 , step 16400 : 0.319921\n",
      "loss in epoch 12 , step 16420 : 0.083267\n",
      "loss in epoch 12 , step 16440 : 0.350456\n",
      "loss in epoch 12 , step 16460 : 2.298238\n",
      "loss in epoch 12 , step 16480 : 1.612658\n",
      "loss in epoch 12 , step 16500 : 1.452216\n",
      "loss in epoch 12 , step 16520 : 0.212435\n",
      "loss in epoch 12 , step 16540 : 0.869938\n",
      "loss in epoch 12 , step 16560 : 0.509692\n",
      "loss in epoch 12 , step 16580 : 3.806018\n",
      "loss in epoch 12 , step 16600 : 1.094088\n",
      "loss in epoch 12 , step 16620 : 0.482895\n",
      "loss in epoch 12 , step 16640 : 0.448842\n",
      "loss in epoch 12 , step 16660 : 1.056692\n",
      "loss in epoch 12 , step 16680 : 0.598042\n",
      "loss in epoch 12 , step 16700 : 0.683035\n",
      "loss in epoch 12 , step 16720 : 1.085872\n",
      "loss in epoch 12 , step 16740 : 1.380489\n",
      "loss in epoch 12 , step 16760 : 0.003935\n",
      "loss in epoch 12 , step 16780 : 1.291733\n",
      "loss in epoch 12 , step 16800 : 1.436688\n",
      "loss in epoch 12 , step 16820 : 0.243096\n",
      "loss in epoch 12 , step 16840 : 0.440762\n",
      "loss in epoch 12 , step 16860 : 0.114014\n",
      "loss in epoch 12 , step 16880 : 0.295489\n",
      "loss in epoch 12 , step 16900 : 0.658053\n",
      "loss in epoch 12 , step 16920 : 0.513312\n",
      "loss in epoch 12 , step 16940 : 0.900226\n",
      "loss in epoch 12 , step 16960 : 0.089853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 12 , step 16980 : 0.131774\n",
      "loss in epoch 12 , step 17000 : 0.401696\n",
      "loss in epoch 12 , step 17020 : 1.080253\n",
      "loss in epoch 12 , step 17040 : 0.041881\n",
      "loss in epoch 12 , step 17060 : 2.979509\n",
      "loss in epoch 12 , step 17080 : 1.355727\n",
      "loss in epoch 12 , step 17100 : 0.516272\n",
      "loss in epoch 12 , step 17120 : 0.006941\n",
      "loss in epoch 12 , step 17140 : 2.351499\n",
      "loss in epoch 12 , step 17160 : 0.017957\n",
      "loss in epoch 12 , step 17180 : 0.220839\n",
      "loss in epoch 12 , step 17200 : 0.665677\n",
      "loss in epoch 12 , step 17220 : 1.355219\n",
      "loss in epoch 12 , step 17240 : 0.935761\n",
      "loss in epoch 12 , step 17260 : 0.362447\n",
      "loss in epoch 12 , step 17280 : 0.805264\n",
      "loss in epoch 12 , step 17300 : 1.526533\n",
      "loss in epoch 12 , step 17320 : 0.354998\n",
      "loss in epoch 12 , step 17340 : 0.690018\n",
      "loss in epoch 12 , step 17360 : 2.002968\n",
      "loss in epoch 12 , step 17380 : 2.167078\n",
      "loss in epoch 12 , step 17400 : 0.069379\n",
      "loss in epoch 12 , step 17420 : 0.432687\n",
      "loss in epoch 12 , step 17440 : 2.213598\n",
      "loss in epoch 12 , step 17460 : 0.495150\n",
      "loss in epoch 12 , step 17480 : 0.522782\n",
      "loss in epoch 12 , step 17500 : 0.670675\n",
      "loss in epoch 12 , step 17520 : 1.250873\n",
      "loss in epoch 12 , step 17540 : 0.301855\n",
      "loss in epoch 12 , step 17560 : 0.655899\n",
      "loss in epoch 12 , step 17580 : 0.020180\n",
      "loss in epoch 12 , step 17600 : 0.453544\n",
      "loss in epoch 12 , step 17620 : 0.533530\n",
      "loss in epoch 12 , step 17640 : 4.477890\n",
      "loss in epoch 12 , step 17660 : 2.171625\n",
      "loss in epoch 12 , step 17680 : 0.753075\n",
      "loss in epoch 12 , step 17700 : 1.726442\n",
      "loss in epoch 12 , step 17720 : 0.013499\n",
      "loss in epoch 12 , step 17740 : 2.123028\n",
      "loss in epoch 12 , step 17760 : 0.637461\n",
      "loss in epoch 12 , step 17780 : 0.710749\n",
      "loss in epoch 12 , step 17800 : 2.552722\n",
      "loss in epoch 12 , step 17820 : 0.726071\n",
      "loss in epoch 12 , step 17840 : 2.132421\n",
      "loss in epoch 12 , step 17860 : 0.008183\n",
      "loss in epoch 12 , step 17880 : 1.575084\n",
      "loss in epoch 12 , step 17900 : 0.040391\n",
      "loss in epoch 12 , step 17920 : 2.338556\n",
      "loss in epoch 12 , step 17940 : 3.324021\n",
      "loss in epoch 12 , step 17960 : 0.895985\n",
      "loss in epoch 12 , step 17980 : 2.799106\n",
      "loss in epoch 12 , step 18000 : 0.792347\n",
      "loss in epoch 12 , step 18020 : 0.358359\n",
      "loss in epoch 12 , step 18040 : 0.339301\n",
      "loss in epoch 12 , step 18060 : 0.162668\n",
      "loss in epoch 12 , step 18080 : 1.198230\n",
      "loss in epoch 12 , step 18100 : 2.006858\n",
      "loss in epoch 12 , step 18120 : 0.498463\n",
      "loss in epoch 12 , step 18140 : 1.231987\n",
      "loss in epoch 12 , step 18160 : 2.168892\n",
      "loss in epoch 12 , step 18180 : 0.053963\n",
      "loss in epoch 12 , step 18200 : 0.228209\n",
      "loss in epoch 12 , step 18220 : 1.156147\n",
      "loss in epoch 12 , step 18240 : 1.663679\n",
      "loss in epoch 12 , step 18260 : 0.629533\n",
      "loss in epoch 12 , step 18280 : 0.922504\n",
      "loss in epoch 12 , step 18300 : 0.023253\n",
      "loss in epoch 12 , step 18320 : 2.660514\n",
      "loss in epoch 12 , step 18340 : 0.995677\n",
      "loss in epoch 12 , step 18360 : 1.913146\n",
      "loss in epoch 12 , step 18380 : 0.205168\n",
      "loss in epoch 12 , step 18400 : 3.055400\n",
      "loss in epoch 12 , step 18420 : 0.929273\n",
      "loss in epoch 12 , step 18440 : 2.272267\n",
      "loss in epoch 12 , step 18460 : 0.021118\n",
      "loss in epoch 12 , step 18480 : 0.093359\n",
      "loss in epoch 12 , step 18500 : 1.228608\n",
      "loss in epoch 12 , step 18520 : 0.512210\n",
      "loss in epoch 12 , step 18540 : 1.295558\n",
      "loss in epoch 12 , step 18560 : 1.751681\n",
      "loss in epoch 12 , step 18580 : 1.514481\n",
      "loss in epoch 12 , step 18600 : 1.987085\n",
      "loss in epoch 12 , step 18620 : 1.661393\n",
      "loss in epoch 12 , step 18640 : 4.924080\n",
      "loss in epoch 12 , step 18660 : 0.058645\n",
      "loss in epoch 12 , step 18680 : 0.855840\n",
      "loss in epoch 12 , step 18700 : 0.638275\n",
      "loss in epoch 12 , step 18720 : 0.226769\n",
      "loss in epoch 12 , step 18740 : 0.781595\n",
      "loss in epoch 12 , step 18760 : 0.180197\n",
      "loss in epoch 12 , step 18780 : 1.498130\n",
      "loss in epoch 12 , step 18800 : 0.148241\n",
      "loss in epoch 12 , step 18820 : 1.359002\n",
      "loss in epoch 12 , step 18840 : 1.200151\n",
      "loss in epoch 12 , step 18860 : 0.614548\n",
      "loss in epoch 12 , step 18880 : 2.327571\n",
      "loss in epoch 12 , step 18900 : 1.547109\n",
      "loss in epoch 12 , step 18920 : 1.384315\n",
      "loss in epoch 12 , step 18940 : 0.787312\n",
      "loss in epoch 12 , step 18960 : 0.454879\n",
      "loss in epoch 12 , step 18980 : 1.691832\n",
      "loss in epoch 12 , step 19000 : 1.708296\n",
      "loss in epoch 12 , step 19020 : 0.924999\n",
      "loss in epoch 12 , step 19040 : 1.953272\n",
      "loss in epoch 12 , step 19060 : 1.772682\n",
      "loss in epoch 12 , step 19080 : 1.201226\n",
      "loss in epoch 12 , step 19100 : 0.484223\n",
      "loss in epoch 12 , step 19120 : 0.100845\n",
      "loss in epoch 12 , step 19140 : 0.545488\n",
      "loss in epoch 12 , step 19160 : 0.528022\n",
      "loss in epoch 12 , step 19180 : 1.429289\n",
      "loss in epoch 12 , step 19200 : 1.805178\n",
      "loss in epoch 12 , step 19220 : 1.196402\n",
      "loss in epoch 12 , step 19240 : 0.815830\n",
      "loss in epoch 12 , step 19260 : 1.162260\n",
      "loss in epoch 12 , step 19280 : 1.152193\n",
      "loss in epoch 12 , step 19300 : 0.927350\n",
      "loss in epoch 12 , step 19320 : 0.741602\n",
      "loss in epoch 12 , step 19340 : 0.351564\n",
      "loss in epoch 12 , step 19360 : 1.157445\n",
      "loss in epoch 12 , step 19380 : 3.726638\n",
      "loss in epoch 12 , step 19400 : 1.953301\n",
      "loss in epoch 12 , step 19420 : 2.112753\n",
      "loss in epoch 12 , step 19440 : 2.273327\n",
      "loss in epoch 12 , step 19460 : 0.921619\n",
      "loss in epoch 12 , step 19480 : 1.220186\n",
      "loss in epoch 12 , step 19500 : 1.602674\n",
      "loss in epoch 12 , step 19520 : 0.062558\n",
      "loss in epoch 12 , step 19540 : 2.592188\n",
      "loss in epoch 12 , step 19560 : 0.687696\n",
      "loss in epoch 12 , step 19580 : 0.392443\n",
      "loss in epoch 12 , step 19600 : 2.092802\n",
      "loss in epoch 12 , step 19620 : 1.010712\n",
      "loss in epoch 12 , step 19640 : 1.703379\n",
      "loss in epoch 12 , step 19660 : 2.249491\n",
      "loss in epoch 12 , step 19680 : 0.596691\n",
      "loss in epoch 12 , step 19700 : 2.780209\n",
      "loss in epoch 12 , step 19720 : 0.886493\n",
      "loss in epoch 12 , step 19740 : 1.355243\n",
      "loss in epoch 12 , step 19760 : 1.011126\n",
      "loss in epoch 12 , step 19780 : 0.962683\n",
      "loss in epoch 12 , step 19800 : 0.006995\n",
      "loss in epoch 12 , step 19820 : 1.581650\n",
      "loss in epoch 12 , step 19840 : 0.776015\n",
      "loss in epoch 12 , step 19860 : 0.013354\n",
      "loss in epoch 12 , step 19880 : 0.645466\n",
      "loss in epoch 12 , step 19900 : 2.173705\n",
      "loss in epoch 12 , step 19920 : 1.681430\n",
      "loss in epoch 12 , step 19940 : 0.630774\n",
      "Accuracy in epoch 12 : 29.350025\n",
      "loss in epoch 13 , step 0 : 0.399077\n",
      "loss in epoch 13 , step 20 : 0.523245\n",
      "loss in epoch 13 , step 40 : 0.031176\n",
      "loss in epoch 13 , step 60 : 1.058899\n",
      "loss in epoch 13 , step 80 : 2.012289\n",
      "loss in epoch 13 , step 100 : 0.462166\n",
      "loss in epoch 13 , step 120 : 0.013757\n",
      "loss in epoch 13 , step 140 : 2.160152\n",
      "loss in epoch 13 , step 160 : 0.012139\n",
      "loss in epoch 13 , step 180 : 0.008052\n",
      "loss in epoch 13 , step 200 : 1.880995\n",
      "loss in epoch 13 , step 220 : 1.974440\n",
      "loss in epoch 13 , step 240 : 0.285172\n",
      "loss in epoch 13 , step 260 : 0.274468\n",
      "loss in epoch 13 , step 280 : 1.466178\n",
      "loss in epoch 13 , step 300 : 1.373736\n",
      "loss in epoch 13 , step 320 : 1.368587\n",
      "loss in epoch 13 , step 340 : 0.977202\n",
      "loss in epoch 13 , step 360 : 2.087723\n",
      "loss in epoch 13 , step 380 : 0.551820\n",
      "loss in epoch 13 , step 400 : 1.603602\n",
      "loss in epoch 13 , step 420 : 1.746866\n",
      "loss in epoch 13 , step 440 : 1.315786\n",
      "loss in epoch 13 , step 460 : 0.006141\n",
      "loss in epoch 13 , step 480 : 0.348305\n",
      "loss in epoch 13 , step 500 : 1.004245\n",
      "loss in epoch 13 , step 520 : 0.176508\n",
      "loss in epoch 13 , step 540 : 0.767923\n",
      "loss in epoch 13 , step 560 : 0.497769\n",
      "loss in epoch 13 , step 580 : 0.016681\n",
      "loss in epoch 13 , step 600 : 0.003970\n",
      "loss in epoch 13 , step 620 : 0.067653\n",
      "loss in epoch 13 , step 640 : 1.834167\n",
      "loss in epoch 13 , step 660 : 2.070433\n",
      "loss in epoch 13 , step 680 : 1.696998\n",
      "loss in epoch 13 , step 700 : 0.067049\n",
      "loss in epoch 13 , step 720 : 0.304833\n",
      "loss in epoch 13 , step 740 : 0.861073\n",
      "loss in epoch 13 , step 760 : 0.125216\n",
      "loss in epoch 13 , step 780 : 1.999210\n",
      "loss in epoch 13 , step 800 : 0.087505\n",
      "loss in epoch 13 , step 820 : 3.349588\n",
      "loss in epoch 13 , step 840 : 0.095066\n",
      "loss in epoch 13 , step 860 : 2.281888\n",
      "loss in epoch 13 , step 880 : 0.815952\n",
      "loss in epoch 13 , step 900 : 1.912573\n",
      "loss in epoch 13 , step 920 : 1.493839\n",
      "loss in epoch 13 , step 940 : 1.736394\n",
      "loss in epoch 13 , step 960 : 0.925690\n",
      "loss in epoch 13 , step 980 : 2.101367\n",
      "loss in epoch 13 , step 1000 : 3.061615\n",
      "loss in epoch 13 , step 1020 : 1.683428\n",
      "loss in epoch 13 , step 1040 : 0.013189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 13 , step 1060 : 0.012014\n",
      "loss in epoch 13 , step 1080 : 1.354881\n",
      "loss in epoch 13 , step 1100 : 0.945217\n",
      "loss in epoch 13 , step 1120 : 3.097337\n",
      "loss in epoch 13 , step 1140 : 0.807732\n",
      "loss in epoch 13 , step 1160 : 0.442729\n",
      "loss in epoch 13 , step 1180 : 0.392283\n",
      "loss in epoch 13 , step 1200 : 0.061481\n",
      "loss in epoch 13 , step 1220 : 0.662154\n",
      "loss in epoch 13 , step 1240 : 1.979722\n",
      "loss in epoch 13 , step 1260 : 0.016443\n",
      "loss in epoch 13 , step 1280 : 1.824222\n",
      "loss in epoch 13 , step 1300 : 1.301580\n",
      "loss in epoch 13 , step 1320 : 0.177740\n",
      "loss in epoch 13 , step 1340 : 1.072842\n",
      "loss in epoch 13 , step 1360 : 2.083823\n",
      "loss in epoch 13 , step 1380 : 0.958083\n",
      "loss in epoch 13 , step 1400 : 1.985731\n",
      "loss in epoch 13 , step 1420 : 1.940418\n",
      "loss in epoch 13 , step 1440 : 2.413651\n",
      "loss in epoch 13 , step 1460 : 0.076296\n",
      "loss in epoch 13 , step 1480 : 1.729590\n",
      "loss in epoch 13 , step 1500 : 1.285414\n",
      "loss in epoch 13 , step 1520 : 0.476139\n",
      "loss in epoch 13 , step 1540 : 0.747052\n",
      "loss in epoch 13 , step 1560 : 1.246431\n",
      "loss in epoch 13 , step 1580 : 1.261497\n",
      "loss in epoch 13 , step 1600 : 0.007305\n",
      "loss in epoch 13 , step 1620 : 0.932423\n",
      "loss in epoch 13 , step 1640 : 2.304295\n",
      "loss in epoch 13 , step 1660 : 0.821852\n",
      "loss in epoch 13 , step 1680 : 1.073259\n",
      "loss in epoch 13 , step 1700 : 0.880618\n",
      "loss in epoch 13 , step 1720 : 0.772194\n",
      "loss in epoch 13 , step 1740 : 0.350384\n",
      "loss in epoch 13 , step 1760 : 1.138837\n",
      "loss in epoch 13 , step 1780 : 0.760935\n",
      "loss in epoch 13 , step 1800 : 0.865424\n",
      "loss in epoch 13 , step 1820 : 0.015951\n",
      "loss in epoch 13 , step 1840 : 0.895930\n",
      "loss in epoch 13 , step 1860 : 0.016361\n",
      "loss in epoch 13 , step 1880 : 0.816274\n",
      "loss in epoch 13 , step 1900 : 1.253446\n",
      "loss in epoch 13 , step 1920 : 0.024310\n",
      "loss in epoch 13 , step 1940 : 0.741115\n",
      "loss in epoch 13 , step 1960 : 2.405477\n",
      "loss in epoch 13 , step 1980 : 0.391768\n",
      "loss in epoch 13 , step 2000 : 0.251657\n",
      "loss in epoch 13 , step 2020 : 4.114935\n",
      "loss in epoch 13 , step 2040 : 0.633661\n",
      "loss in epoch 13 , step 2060 : 0.032553\n",
      "loss in epoch 13 , step 2080 : 0.025349\n",
      "loss in epoch 13 , step 2100 : 1.295798\n",
      "loss in epoch 13 , step 2120 : 2.254168\n",
      "loss in epoch 13 , step 2140 : 2.992612\n",
      "loss in epoch 13 , step 2160 : 1.309461\n",
      "loss in epoch 13 , step 2180 : 0.130834\n",
      "loss in epoch 13 , step 2200 : 0.573311\n",
      "loss in epoch 13 , step 2220 : 2.450799\n",
      "loss in epoch 13 , step 2240 : 1.378370\n",
      "loss in epoch 13 , step 2260 : 1.499911\n",
      "loss in epoch 13 , step 2280 : 0.963514\n",
      "loss in epoch 13 , step 2300 : 1.366541\n",
      "loss in epoch 13 , step 2320 : 0.661384\n",
      "loss in epoch 13 , step 2340 : 1.146054\n",
      "loss in epoch 13 , step 2360 : 0.456246\n",
      "loss in epoch 13 , step 2380 : 0.032466\n",
      "loss in epoch 13 , step 2400 : 1.948764\n",
      "loss in epoch 13 , step 2420 : 0.006519\n",
      "loss in epoch 13 , step 2440 : 1.349144\n",
      "loss in epoch 13 , step 2460 : 1.171280\n",
      "loss in epoch 13 , step 2480 : 0.086767\n",
      "loss in epoch 13 , step 2500 : 0.157816\n",
      "loss in epoch 13 , step 2520 : 1.198058\n",
      "loss in epoch 13 , step 2540 : 0.403217\n",
      "loss in epoch 13 , step 2560 : 1.471557\n",
      "loss in epoch 13 , step 2580 : 0.885693\n",
      "loss in epoch 13 , step 2600 : 0.164612\n",
      "loss in epoch 13 , step 2620 : 0.759403\n",
      "loss in epoch 13 , step 2640 : 1.418595\n",
      "loss in epoch 13 , step 2660 : 0.084422\n",
      "loss in epoch 13 , step 2680 : 1.968815\n",
      "loss in epoch 13 , step 2700 : 0.173050\n",
      "loss in epoch 13 , step 2720 : 0.271927\n",
      "loss in epoch 13 , step 2740 : 0.014669\n",
      "loss in epoch 13 , step 2760 : 0.178841\n",
      "loss in epoch 13 , step 2780 : 0.441925\n",
      "loss in epoch 13 , step 2800 : 0.723587\n",
      "loss in epoch 13 , step 2820 : 0.023598\n",
      "loss in epoch 13 , step 2840 : 1.883551\n",
      "loss in epoch 13 , step 2860 : 0.978343\n",
      "loss in epoch 13 , step 2880 : 2.995958\n",
      "loss in epoch 13 , step 2900 : 0.712356\n",
      "loss in epoch 13 , step 2920 : 0.034189\n",
      "loss in epoch 13 , step 2940 : 0.744301\n",
      "loss in epoch 13 , step 2960 : 0.769185\n",
      "loss in epoch 13 , step 2980 : 1.243841\n",
      "loss in epoch 13 , step 3000 : 0.090717\n",
      "loss in epoch 13 , step 3020 : 1.950827\n",
      "loss in epoch 13 , step 3040 : 0.083577\n",
      "loss in epoch 13 , step 3060 : 0.162964\n",
      "loss in epoch 13 , step 3080 : 1.063175\n",
      "loss in epoch 13 , step 3100 : 0.935170\n",
      "loss in epoch 13 , step 3120 : 0.008038\n",
      "loss in epoch 13 , step 3140 : 1.923593\n",
      "loss in epoch 13 , step 3160 : 0.553653\n",
      "loss in epoch 13 , step 3180 : 1.501956\n",
      "loss in epoch 13 , step 3200 : 0.221345\n",
      "loss in epoch 13 , step 3220 : 0.242402\n",
      "loss in epoch 13 , step 3240 : 1.628644\n",
      "loss in epoch 13 , step 3260 : 0.486366\n",
      "loss in epoch 13 , step 3280 : 0.443161\n",
      "loss in epoch 13 , step 3300 : 0.067489\n",
      "loss in epoch 13 , step 3320 : 2.372606\n",
      "loss in epoch 13 , step 3340 : 0.821433\n",
      "loss in epoch 13 , step 3360 : 0.638808\n",
      "loss in epoch 13 , step 3380 : 1.130281\n",
      "loss in epoch 13 , step 3400 : 0.092877\n",
      "loss in epoch 13 , step 3420 : 0.137032\n",
      "loss in epoch 13 , step 3440 : 0.947842\n",
      "loss in epoch 13 , step 3460 : 0.112818\n",
      "loss in epoch 13 , step 3480 : 3.270149\n",
      "loss in epoch 13 , step 3500 : 2.536053\n",
      "loss in epoch 13 , step 3520 : 0.009345\n",
      "loss in epoch 13 , step 3540 : 0.945778\n",
      "loss in epoch 13 , step 3560 : 0.010564\n",
      "loss in epoch 13 , step 3580 : 1.082347\n",
      "loss in epoch 13 , step 3600 : 0.032408\n",
      "loss in epoch 13 , step 3620 : 4.001434\n",
      "loss in epoch 13 , step 3640 : 2.009613\n",
      "loss in epoch 13 , step 3660 : 1.110264\n",
      "loss in epoch 13 , step 3680 : 0.418265\n",
      "loss in epoch 13 , step 3700 : 1.903637\n",
      "loss in epoch 13 , step 3720 : 1.865985\n",
      "loss in epoch 13 , step 3740 : 0.032940\n",
      "loss in epoch 13 , step 3760 : 0.052589\n",
      "loss in epoch 13 , step 3780 : 0.071648\n",
      "loss in epoch 13 , step 3800 : 0.538059\n",
      "loss in epoch 13 , step 3820 : 0.523657\n",
      "loss in epoch 13 , step 3840 : 0.132442\n",
      "loss in epoch 13 , step 3860 : 0.918139\n",
      "loss in epoch 13 , step 3880 : 1.577141\n",
      "loss in epoch 13 , step 3900 : 1.770119\n",
      "loss in epoch 13 , step 3920 : 0.150752\n",
      "loss in epoch 13 , step 3940 : 3.241543\n",
      "loss in epoch 13 , step 3960 : 0.093414\n",
      "loss in epoch 13 , step 3980 : 1.691725\n",
      "loss in epoch 13 , step 4000 : 1.051255\n",
      "loss in epoch 13 , step 4020 : 1.482479\n",
      "loss in epoch 13 , step 4040 : 2.491056\n",
      "loss in epoch 13 , step 4060 : 0.094817\n",
      "loss in epoch 13 , step 4080 : 0.111119\n",
      "loss in epoch 13 , step 4100 : 0.790752\n",
      "loss in epoch 13 , step 4120 : 0.049788\n",
      "loss in epoch 13 , step 4140 : 1.440927\n",
      "loss in epoch 13 , step 4160 : 1.716687\n",
      "loss in epoch 13 , step 4180 : 1.134229\n",
      "loss in epoch 13 , step 4200 : 0.938619\n",
      "loss in epoch 13 , step 4220 : 0.994198\n",
      "loss in epoch 13 , step 4240 : 0.189178\n",
      "loss in epoch 13 , step 4260 : 0.135601\n",
      "loss in epoch 13 , step 4280 : 2.234956\n",
      "loss in epoch 13 , step 4300 : 0.218704\n",
      "loss in epoch 13 , step 4320 : 2.463612\n",
      "loss in epoch 13 , step 4340 : 1.597179\n",
      "loss in epoch 13 , step 4360 : 0.068409\n",
      "loss in epoch 13 , step 4380 : 0.399113\n",
      "loss in epoch 13 , step 4400 : 0.574319\n",
      "loss in epoch 13 , step 4420 : 3.154438\n",
      "loss in epoch 13 , step 4440 : 1.089000\n",
      "loss in epoch 13 , step 4460 : 0.185657\n",
      "loss in epoch 13 , step 4480 : 0.635985\n",
      "loss in epoch 13 , step 4500 : 0.450956\n",
      "loss in epoch 13 , step 4520 : 0.983952\n",
      "loss in epoch 13 , step 4540 : 0.785600\n",
      "loss in epoch 13 , step 4560 : 0.646522\n",
      "loss in epoch 13 , step 4580 : 0.336905\n",
      "loss in epoch 13 , step 4600 : 0.005367\n",
      "loss in epoch 13 , step 4620 : 1.162181\n",
      "loss in epoch 13 , step 4640 : 0.269549\n",
      "loss in epoch 13 , step 4660 : 0.930665\n",
      "loss in epoch 13 , step 4680 : 1.157825\n",
      "loss in epoch 13 , step 4700 : 0.243464\n",
      "loss in epoch 13 , step 4720 : 0.883814\n",
      "loss in epoch 13 , step 4740 : 1.132638\n",
      "loss in epoch 13 , step 4760 : 1.343565\n",
      "loss in epoch 13 , step 4780 : 0.865066\n",
      "loss in epoch 13 , step 4800 : 0.008331\n",
      "loss in epoch 13 , step 4820 : 0.155346\n",
      "loss in epoch 13 , step 4840 : 0.546498\n",
      "loss in epoch 13 , step 4860 : 0.002181\n",
      "loss in epoch 13 , step 4880 : 1.446715\n",
      "loss in epoch 13 , step 4900 : 0.962156\n",
      "loss in epoch 13 , step 4920 : 0.028072\n",
      "loss in epoch 13 , step 4940 : 0.111276\n",
      "loss in epoch 13 , step 4960 : 0.206228\n",
      "loss in epoch 13 , step 4980 : 1.220631\n",
      "loss in epoch 13 , step 5000 : 1.871146\n",
      "loss in epoch 13 , step 5020 : 0.012486\n",
      "loss in epoch 13 , step 5040 : 2.731704\n",
      "loss in epoch 13 , step 5060 : 0.996139\n",
      "loss in epoch 13 , step 5080 : 2.157984\n",
      "loss in epoch 13 , step 5100 : 0.987858\n",
      "loss in epoch 13 , step 5120 : 1.480743\n",
      "loss in epoch 13 , step 5140 : 0.010233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 13 , step 5160 : 1.079294\n",
      "loss in epoch 13 , step 5180 : 1.362201\n",
      "loss in epoch 13 , step 5200 : 3.022478\n",
      "loss in epoch 13 , step 5220 : 0.757227\n",
      "loss in epoch 13 , step 5240 : 0.044820\n",
      "loss in epoch 13 , step 5260 : 0.729305\n",
      "loss in epoch 13 , step 5280 : 0.530430\n",
      "loss in epoch 13 , step 5300 : 1.764083\n",
      "loss in epoch 13 , step 5320 : 2.288986\n",
      "loss in epoch 13 , step 5340 : 0.124350\n",
      "loss in epoch 13 , step 5360 : 0.458579\n",
      "loss in epoch 13 , step 5380 : 1.088999\n",
      "loss in epoch 13 , step 5400 : 0.084122\n",
      "loss in epoch 13 , step 5420 : 1.983350\n",
      "loss in epoch 13 , step 5440 : 1.822287\n",
      "loss in epoch 13 , step 5460 : 3.167593\n",
      "loss in epoch 13 , step 5480 : 1.510445\n",
      "loss in epoch 13 , step 5500 : 0.519204\n",
      "loss in epoch 13 , step 5520 : 0.518640\n",
      "loss in epoch 13 , step 5540 : 0.388695\n",
      "loss in epoch 13 , step 5560 : 1.087321\n",
      "loss in epoch 13 , step 5580 : 1.099271\n",
      "loss in epoch 13 , step 5600 : 1.724905\n",
      "loss in epoch 13 , step 5620 : 0.707648\n",
      "loss in epoch 13 , step 5640 : 0.947626\n",
      "loss in epoch 13 , step 5660 : 1.056749\n",
      "loss in epoch 13 , step 5680 : 0.500977\n",
      "loss in epoch 13 , step 5700 : 1.241011\n",
      "loss in epoch 13 , step 5720 : 2.004302\n",
      "loss in epoch 13 , step 5740 : 1.751154\n",
      "loss in epoch 13 , step 5760 : 1.585696\n",
      "loss in epoch 13 , step 5780 : 1.766444\n",
      "loss in epoch 13 , step 5800 : 1.593154\n",
      "loss in epoch 13 , step 5820 : 0.738869\n",
      "loss in epoch 13 , step 5840 : 1.050360\n",
      "loss in epoch 13 , step 5860 : 1.125533\n",
      "loss in epoch 13 , step 5880 : 1.066895\n",
      "loss in epoch 13 , step 5900 : 0.020915\n",
      "loss in epoch 13 , step 5920 : 0.805585\n",
      "loss in epoch 13 , step 5940 : 1.060510\n",
      "loss in epoch 13 , step 5960 : 1.293723\n",
      "loss in epoch 13 , step 5980 : 0.740661\n",
      "loss in epoch 13 , step 6000 : 0.106518\n",
      "loss in epoch 13 , step 6020 : 0.608800\n",
      "loss in epoch 13 , step 6040 : 1.336071\n",
      "loss in epoch 13 , step 6060 : 0.586065\n",
      "loss in epoch 13 , step 6080 : 1.293847\n",
      "loss in epoch 13 , step 6100 : 0.036195\n",
      "loss in epoch 13 , step 6120 : 1.508825\n",
      "loss in epoch 13 , step 6140 : 1.273644\n",
      "loss in epoch 13 , step 6160 : 0.007207\n",
      "loss in epoch 13 , step 6180 : 1.314467\n",
      "loss in epoch 13 , step 6200 : 0.255476\n",
      "loss in epoch 13 , step 6220 : 3.590663\n",
      "loss in epoch 13 , step 6240 : 1.761119\n",
      "loss in epoch 13 , step 6260 : 1.130112\n",
      "loss in epoch 13 , step 6280 : 1.582995\n",
      "loss in epoch 13 , step 6300 : 0.986782\n",
      "loss in epoch 13 , step 6320 : 0.960183\n",
      "loss in epoch 13 , step 6340 : 2.618368\n",
      "loss in epoch 13 , step 6360 : 0.609946\n",
      "loss in epoch 13 , step 6380 : 0.008932\n",
      "loss in epoch 13 , step 6400 : 2.909501\n",
      "loss in epoch 13 , step 6420 : 1.256284\n",
      "loss in epoch 13 , step 6440 : 2.579354\n",
      "loss in epoch 13 , step 6460 : 0.119719\n",
      "loss in epoch 13 , step 6480 : 1.819181\n",
      "loss in epoch 13 , step 6500 : 0.043613\n",
      "loss in epoch 13 , step 6520 : 2.602741\n",
      "loss in epoch 13 , step 6540 : 1.617853\n",
      "loss in epoch 13 , step 6560 : 1.282318\n",
      "loss in epoch 13 , step 6580 : 0.525885\n",
      "loss in epoch 13 , step 6600 : 1.291885\n",
      "loss in epoch 13 , step 6620 : 0.402048\n",
      "loss in epoch 13 , step 6640 : 0.192247\n",
      "loss in epoch 13 , step 6660 : 3.088855\n",
      "loss in epoch 13 , step 6680 : 0.566640\n",
      "loss in epoch 13 , step 6700 : 0.929481\n",
      "loss in epoch 13 , step 6720 : 0.007485\n",
      "loss in epoch 13 , step 6740 : 0.382436\n",
      "loss in epoch 13 , step 6760 : 0.021576\n",
      "loss in epoch 13 , step 6780 : 1.201616\n",
      "loss in epoch 13 , step 6800 : 1.560648\n",
      "loss in epoch 13 , step 6820 : 0.877777\n",
      "loss in epoch 13 , step 6840 : 2.231471\n",
      "loss in epoch 13 , step 6860 : 0.059844\n",
      "loss in epoch 13 , step 6880 : 2.079935\n",
      "loss in epoch 13 , step 6900 : 0.294655\n",
      "loss in epoch 13 , step 6920 : 0.011210\n",
      "loss in epoch 13 , step 6940 : 0.965364\n",
      "loss in epoch 13 , step 6960 : 1.482786\n",
      "loss in epoch 13 , step 6980 : 0.007491\n",
      "loss in epoch 13 , step 7000 : 1.518120\n",
      "loss in epoch 13 , step 7020 : 0.733594\n",
      "loss in epoch 13 , step 7040 : 0.697655\n",
      "loss in epoch 13 , step 7060 : 3.151649\n",
      "loss in epoch 13 , step 7080 : 1.224865\n",
      "loss in epoch 13 , step 7100 : 1.240498\n",
      "loss in epoch 13 , step 7120 : 0.001928\n",
      "loss in epoch 13 , step 7140 : 0.716026\n",
      "loss in epoch 13 , step 7160 : 0.670996\n",
      "loss in epoch 13 , step 7180 : 0.605842\n",
      "loss in epoch 13 , step 7200 : 0.395010\n",
      "loss in epoch 13 , step 7220 : 1.816060\n",
      "loss in epoch 13 , step 7240 : 1.135630\n",
      "loss in epoch 13 , step 7260 : 1.941822\n",
      "loss in epoch 13 , step 7280 : 3.578105\n",
      "loss in epoch 13 , step 7300 : 1.051811\n",
      "loss in epoch 13 , step 7320 : 0.527854\n",
      "loss in epoch 13 , step 7340 : 1.877498\n",
      "loss in epoch 13 , step 7360 : 1.190193\n",
      "loss in epoch 13 , step 7380 : 0.202529\n",
      "loss in epoch 13 , step 7400 : 2.463286\n",
      "loss in epoch 13 , step 7420 : 0.043996\n",
      "loss in epoch 13 , step 7440 : 0.850072\n",
      "loss in epoch 13 , step 7460 : 3.269257\n",
      "loss in epoch 13 , step 7480 : 0.310437\n",
      "loss in epoch 13 , step 7500 : 0.008088\n",
      "loss in epoch 13 , step 7520 : 1.340800\n",
      "loss in epoch 13 , step 7540 : 2.696440\n",
      "loss in epoch 13 , step 7560 : 1.075059\n",
      "loss in epoch 13 , step 7580 : 1.982395\n",
      "loss in epoch 13 , step 7600 : 1.624294\n",
      "loss in epoch 13 , step 7620 : 0.480984\n",
      "loss in epoch 13 , step 7640 : 1.316492\n",
      "loss in epoch 13 , step 7660 : 0.101896\n",
      "loss in epoch 13 , step 7680 : 0.005513\n",
      "loss in epoch 13 , step 7700 : 1.478121\n",
      "loss in epoch 13 , step 7720 : 0.010320\n",
      "loss in epoch 13 , step 7740 : 0.861842\n",
      "loss in epoch 13 , step 7760 : 0.538251\n",
      "loss in epoch 13 , step 7780 : 0.022272\n",
      "loss in epoch 13 , step 7800 : 0.004450\n",
      "loss in epoch 13 , step 7820 : 0.357332\n",
      "loss in epoch 13 , step 7840 : 0.936702\n",
      "loss in epoch 13 , step 7860 : 0.539141\n",
      "loss in epoch 13 , step 7880 : 2.152348\n",
      "loss in epoch 13 , step 7900 : 1.197639\n",
      "loss in epoch 13 , step 7920 : 1.703838\n",
      "loss in epoch 13 , step 7940 : 1.697994\n",
      "loss in epoch 13 , step 7960 : 2.231015\n",
      "loss in epoch 13 , step 7980 : 0.012368\n",
      "loss in epoch 13 , step 8000 : 2.821007\n",
      "loss in epoch 13 , step 8020 : 0.771719\n",
      "loss in epoch 13 , step 8040 : 0.977980\n",
      "loss in epoch 13 , step 8060 : 2.527868\n",
      "loss in epoch 13 , step 8080 : 0.999836\n",
      "loss in epoch 13 , step 8100 : 1.088859\n",
      "loss in epoch 13 , step 8120 : 4.156462\n",
      "loss in epoch 13 , step 8140 : 0.238976\n",
      "loss in epoch 13 , step 8160 : 1.523786\n",
      "loss in epoch 13 , step 8180 : 2.550134\n",
      "loss in epoch 13 , step 8200 : 0.427193\n",
      "loss in epoch 13 , step 8220 : 1.254935\n",
      "loss in epoch 13 , step 8240 : 1.807546\n",
      "loss in epoch 13 , step 8260 : 2.813460\n",
      "loss in epoch 13 , step 8280 : 0.160438\n",
      "loss in epoch 13 , step 8300 : 0.833901\n",
      "loss in epoch 13 , step 8320 : 2.645432\n",
      "loss in epoch 13 , step 8340 : 0.461648\n",
      "loss in epoch 13 , step 8360 : 0.582816\n",
      "loss in epoch 13 , step 8380 : 1.204265\n",
      "loss in epoch 13 , step 8400 : 1.882705\n",
      "loss in epoch 13 , step 8420 : 0.563172\n",
      "loss in epoch 13 , step 8440 : 0.948618\n",
      "loss in epoch 13 , step 8460 : 1.468128\n",
      "loss in epoch 13 , step 8480 : 0.163068\n",
      "loss in epoch 13 , step 8500 : 0.212185\n",
      "loss in epoch 13 , step 8520 : 2.470158\n",
      "loss in epoch 13 , step 8540 : 2.200626\n",
      "loss in epoch 13 , step 8560 : 0.046015\n",
      "loss in epoch 13 , step 8580 : 0.673609\n",
      "loss in epoch 13 , step 8600 : 0.285337\n",
      "loss in epoch 13 , step 8620 : 1.798003\n",
      "loss in epoch 13 , step 8640 : 0.887583\n",
      "loss in epoch 13 , step 8660 : 0.940537\n",
      "loss in epoch 13 , step 8680 : 2.140366\n",
      "loss in epoch 13 , step 8700 : 0.376168\n",
      "loss in epoch 13 , step 8720 : 0.202272\n",
      "loss in epoch 13 , step 8740 : 0.909370\n",
      "loss in epoch 13 , step 8760 : 0.114823\n",
      "loss in epoch 13 , step 8780 : 0.332931\n",
      "loss in epoch 13 , step 8800 : 0.013769\n",
      "loss in epoch 13 , step 8820 : 1.454439\n",
      "loss in epoch 13 , step 8840 : 0.337648\n",
      "loss in epoch 13 , step 8860 : 1.370260\n",
      "loss in epoch 13 , step 8880 : 1.600403\n",
      "loss in epoch 13 , step 8900 : 3.047737\n",
      "loss in epoch 13 , step 8920 : 1.585962\n",
      "loss in epoch 13 , step 8940 : 0.489532\n",
      "loss in epoch 13 , step 8960 : 2.641644\n",
      "loss in epoch 13 , step 8980 : 0.768547\n",
      "loss in epoch 13 , step 9000 : 0.531042\n",
      "loss in epoch 13 , step 9020 : 2.749918\n",
      "loss in epoch 13 , step 9040 : 0.472320\n",
      "loss in epoch 13 , step 9060 : 1.505564\n",
      "loss in epoch 13 , step 9080 : 0.100727\n",
      "loss in epoch 13 , step 9100 : 1.161280\n",
      "loss in epoch 13 , step 9120 : 1.213180\n",
      "loss in epoch 13 , step 9140 : 2.074698\n",
      "loss in epoch 13 , step 9160 : 5.352147\n",
      "loss in epoch 13 , step 9180 : 0.006015\n",
      "loss in epoch 13 , step 9200 : 1.628005\n",
      "loss in epoch 13 , step 9220 : 1.160386\n",
      "loss in epoch 13 , step 9240 : 0.752012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 13 , step 9260 : 0.878122\n",
      "loss in epoch 13 , step 9280 : 0.312015\n",
      "loss in epoch 13 , step 9300 : 0.401634\n",
      "loss in epoch 13 , step 9320 : 0.780601\n",
      "loss in epoch 13 , step 9340 : 0.010624\n",
      "loss in epoch 13 , step 9360 : 0.230230\n",
      "loss in epoch 13 , step 9380 : 0.354898\n",
      "loss in epoch 13 , step 9400 : 0.215795\n",
      "loss in epoch 13 , step 9420 : 0.598147\n",
      "loss in epoch 13 , step 9440 : 0.136194\n",
      "loss in epoch 13 , step 9460 : 1.378319\n",
      "loss in epoch 13 , step 9480 : 0.645141\n",
      "loss in epoch 13 , step 9500 : 1.007053\n",
      "loss in epoch 13 , step 9520 : 0.327181\n",
      "loss in epoch 13 , step 9540 : 1.812308\n",
      "loss in epoch 13 , step 9560 : 0.027922\n",
      "loss in epoch 13 , step 9580 : 0.701888\n",
      "loss in epoch 13 , step 9600 : 0.081731\n",
      "loss in epoch 13 , step 9620 : 0.337380\n",
      "loss in epoch 13 , step 9640 : 1.484718\n",
      "loss in epoch 13 , step 9660 : 0.441866\n",
      "loss in epoch 13 , step 9680 : 0.578331\n",
      "loss in epoch 13 , step 9700 : 0.674480\n",
      "loss in epoch 13 , step 9720 : 1.788634\n",
      "loss in epoch 13 , step 9740 : 1.384509\n",
      "loss in epoch 13 , step 9760 : 0.065116\n",
      "loss in epoch 13 , step 9780 : 0.195966\n",
      "loss in epoch 13 , step 9800 : 0.932424\n",
      "loss in epoch 13 , step 9820 : 0.989376\n",
      "loss in epoch 13 , step 9840 : 0.501349\n",
      "loss in epoch 13 , step 9860 : 3.380125\n",
      "loss in epoch 13 , step 9880 : 1.184929\n",
      "loss in epoch 13 , step 9900 : 0.264809\n",
      "loss in epoch 13 , step 9920 : 0.584320\n",
      "loss in epoch 13 , step 9940 : 0.956205\n",
      "loss in epoch 13 , step 9960 : 0.507551\n",
      "loss in epoch 13 , step 9980 : 0.241855\n",
      "loss in epoch 13 , step 10000 : 2.073867\n",
      "loss in epoch 13 , step 10020 : 0.096888\n",
      "loss in epoch 13 , step 10040 : 0.435716\n",
      "loss in epoch 13 , step 10060 : 0.345673\n",
      "loss in epoch 13 , step 10080 : 1.941982\n",
      "loss in epoch 13 , step 10100 : 0.995019\n",
      "loss in epoch 13 , step 10120 : 1.590808\n",
      "loss in epoch 13 , step 10140 : 0.001231\n",
      "loss in epoch 13 , step 10160 : 1.802270\n",
      "loss in epoch 13 , step 10180 : 2.272975\n",
      "loss in epoch 13 , step 10200 : 1.441855\n",
      "loss in epoch 13 , step 10220 : 0.415789\n",
      "loss in epoch 13 , step 10240 : 1.563324\n",
      "loss in epoch 13 , step 10260 : 0.008669\n",
      "loss in epoch 13 , step 10280 : 3.043794\n",
      "loss in epoch 13 , step 10300 : 0.481626\n",
      "loss in epoch 13 , step 10320 : 2.592484\n",
      "loss in epoch 13 , step 10340 : 1.168968\n",
      "loss in epoch 13 , step 10360 : 1.169102\n",
      "loss in epoch 13 , step 10380 : 0.144373\n",
      "loss in epoch 13 , step 10400 : 3.090714\n",
      "loss in epoch 13 , step 10420 : 0.190581\n",
      "loss in epoch 13 , step 10440 : 0.510009\n",
      "loss in epoch 13 , step 10460 : 3.059529\n",
      "loss in epoch 13 , step 10480 : 1.586238\n",
      "loss in epoch 13 , step 10500 : 0.069264\n",
      "loss in epoch 13 , step 10520 : 0.148879\n",
      "loss in epoch 13 , step 10540 : 2.107956\n",
      "loss in epoch 13 , step 10560 : 0.276882\n",
      "loss in epoch 13 , step 10580 : 0.274252\n",
      "loss in epoch 13 , step 10600 : 0.244136\n",
      "loss in epoch 13 , step 10620 : 1.366925\n",
      "loss in epoch 13 , step 10640 : 0.670290\n",
      "loss in epoch 13 , step 10660 : 1.900344\n",
      "loss in epoch 13 , step 10680 : 1.491954\n",
      "loss in epoch 13 , step 10700 : 2.422227\n",
      "loss in epoch 13 , step 10720 : 0.312734\n",
      "loss in epoch 13 , step 10740 : 1.238800\n",
      "loss in epoch 13 , step 10760 : 1.854536\n",
      "loss in epoch 13 , step 10780 : 0.007656\n",
      "loss in epoch 13 , step 10800 : 0.820146\n",
      "loss in epoch 13 , step 10820 : 2.267618\n",
      "loss in epoch 13 , step 10840 : 0.693000\n",
      "loss in epoch 13 , step 10860 : 0.994310\n",
      "loss in epoch 13 , step 10880 : 0.965799\n",
      "loss in epoch 13 , step 10900 : 1.027659\n",
      "loss in epoch 13 , step 10920 : 1.079030\n",
      "loss in epoch 13 , step 10940 : 0.956794\n",
      "loss in epoch 13 , step 10960 : 1.980936\n",
      "loss in epoch 13 , step 10980 : 0.005053\n",
      "loss in epoch 13 , step 11000 : 0.007105\n",
      "loss in epoch 13 , step 11020 : 0.480279\n",
      "loss in epoch 13 , step 11040 : 0.657225\n",
      "loss in epoch 13 , step 11060 : 2.182173\n",
      "loss in epoch 13 , step 11080 : 1.174886\n",
      "loss in epoch 13 , step 11100 : 1.510674\n",
      "loss in epoch 13 , step 11120 : 0.014019\n",
      "loss in epoch 13 , step 11140 : 1.454489\n",
      "loss in epoch 13 , step 11160 : 0.875279\n",
      "loss in epoch 13 , step 11180 : 2.209601\n",
      "loss in epoch 13 , step 11200 : 0.263424\n",
      "loss in epoch 13 , step 11220 : 1.811937\n",
      "loss in epoch 13 , step 11240 : 0.505846\n",
      "loss in epoch 13 , step 11260 : 0.039185\n",
      "loss in epoch 13 , step 11280 : 0.047641\n",
      "loss in epoch 13 , step 11300 : 0.358908\n",
      "loss in epoch 13 , step 11320 : 1.462685\n",
      "loss in epoch 13 , step 11340 : 0.016014\n",
      "loss in epoch 13 , step 11360 : 1.663441\n",
      "loss in epoch 13 , step 11380 : 0.359631\n",
      "loss in epoch 13 , step 11400 : 0.939426\n",
      "loss in epoch 13 , step 11420 : 0.672666\n",
      "loss in epoch 13 , step 11440 : 1.263646\n",
      "loss in epoch 13 , step 11460 : 0.127259\n",
      "loss in epoch 13 , step 11480 : 0.904955\n",
      "loss in epoch 13 , step 11500 : 2.090316\n",
      "loss in epoch 13 , step 11520 : 0.448575\n",
      "loss in epoch 13 , step 11540 : 0.700539\n",
      "loss in epoch 13 , step 11560 : 1.616368\n",
      "loss in epoch 13 , step 11580 : 0.230144\n",
      "loss in epoch 13 , step 11600 : 1.898816\n",
      "loss in epoch 13 , step 11620 : 0.300924\n",
      "loss in epoch 13 , step 11640 : 1.616771\n",
      "loss in epoch 13 , step 11660 : 0.486552\n",
      "loss in epoch 13 , step 11680 : 0.041016\n",
      "loss in epoch 13 , step 11700 : 1.089691\n",
      "loss in epoch 13 , step 11720 : 3.379880\n",
      "loss in epoch 13 , step 11740 : 2.290178\n",
      "loss in epoch 13 , step 11760 : 3.313244\n",
      "loss in epoch 13 , step 11780 : 1.977569\n",
      "loss in epoch 13 , step 11800 : 2.243510\n",
      "loss in epoch 13 , step 11820 : 1.377760\n",
      "loss in epoch 13 , step 11840 : 0.471330\n",
      "loss in epoch 13 , step 11860 : 0.948748\n",
      "loss in epoch 13 , step 11880 : 1.211226\n",
      "loss in epoch 13 , step 11900 : 0.316116\n",
      "loss in epoch 13 , step 11920 : 0.402790\n",
      "loss in epoch 13 , step 11940 : 0.256497\n",
      "loss in epoch 13 , step 11960 : 1.768924\n",
      "loss in epoch 13 , step 11980 : 1.569130\n",
      "loss in epoch 13 , step 12000 : 0.758974\n",
      "loss in epoch 13 , step 12020 : 1.291378\n",
      "loss in epoch 13 , step 12040 : 1.911703\n",
      "loss in epoch 13 , step 12060 : 1.909828\n",
      "loss in epoch 13 , step 12080 : 1.671569\n",
      "loss in epoch 13 , step 12100 : 0.007197\n",
      "loss in epoch 13 , step 12120 : 1.999104\n",
      "loss in epoch 13 , step 12140 : 0.359214\n",
      "loss in epoch 13 , step 12160 : 1.365100\n",
      "loss in epoch 13 , step 12180 : 1.316060\n",
      "loss in epoch 13 , step 12200 : 0.579731\n",
      "loss in epoch 13 , step 12220 : 0.008950\n",
      "loss in epoch 13 , step 12240 : 1.118930\n",
      "loss in epoch 13 , step 12260 : 1.081233\n",
      "loss in epoch 13 , step 12280 : 0.295592\n",
      "loss in epoch 13 , step 12300 : 2.307130\n",
      "loss in epoch 13 , step 12320 : 0.337126\n",
      "loss in epoch 13 , step 12340 : 1.084987\n",
      "loss in epoch 13 , step 12360 : 0.059068\n",
      "loss in epoch 13 , step 12380 : 2.499193\n",
      "loss in epoch 13 , step 12400 : 4.223491\n",
      "loss in epoch 13 , step 12420 : 2.050031\n",
      "loss in epoch 13 , step 12440 : 2.601437\n",
      "loss in epoch 13 , step 12460 : 0.755987\n",
      "loss in epoch 13 , step 12480 : 1.049903\n",
      "loss in epoch 13 , step 12500 : 0.241835\n",
      "loss in epoch 13 , step 12520 : 1.219029\n",
      "loss in epoch 13 , step 12540 : 1.900601\n",
      "loss in epoch 13 , step 12560 : 0.973307\n",
      "loss in epoch 13 , step 12580 : 0.973098\n",
      "loss in epoch 13 , step 12600 : 1.426674\n",
      "loss in epoch 13 , step 12620 : 1.131469\n",
      "loss in epoch 13 , step 12640 : 1.125160\n",
      "loss in epoch 13 , step 12660 : 0.096116\n",
      "loss in epoch 13 , step 12680 : 1.103083\n",
      "loss in epoch 13 , step 12700 : 0.013663\n",
      "loss in epoch 13 , step 12720 : 0.638004\n",
      "loss in epoch 13 , step 12740 : 0.019307\n",
      "loss in epoch 13 , step 12760 : 1.317013\n",
      "loss in epoch 13 , step 12780 : 2.167962\n",
      "loss in epoch 13 , step 12800 : 0.033328\n",
      "loss in epoch 13 , step 12820 : 0.986504\n",
      "loss in epoch 13 , step 12840 : 2.151948\n",
      "loss in epoch 13 , step 12860 : 1.529799\n",
      "loss in epoch 13 , step 12880 : 0.822828\n",
      "loss in epoch 13 , step 12900 : 2.778591\n",
      "loss in epoch 13 , step 12920 : 0.569155\n",
      "loss in epoch 13 , step 12940 : 1.189058\n",
      "loss in epoch 13 , step 12960 : 0.226110\n",
      "loss in epoch 13 , step 12980 : 0.124231\n",
      "loss in epoch 13 , step 13000 : 2.638949\n",
      "loss in epoch 13 , step 13020 : 1.214538\n",
      "loss in epoch 13 , step 13040 : 0.139072\n",
      "loss in epoch 13 , step 13060 : 3.113228\n",
      "loss in epoch 13 , step 13080 : 0.017324\n",
      "loss in epoch 13 , step 13100 : 4.048495\n",
      "loss in epoch 13 , step 13120 : 0.320910\n",
      "loss in epoch 13 , step 13140 : 0.021953\n",
      "loss in epoch 13 , step 13160 : 0.866054\n",
      "loss in epoch 13 , step 13180 : 3.253608\n",
      "loss in epoch 13 , step 13200 : 0.434532\n",
      "loss in epoch 13 , step 13220 : 0.454750\n",
      "loss in epoch 13 , step 13240 : 1.465523\n",
      "loss in epoch 13 , step 13260 : 0.990321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 13 , step 13280 : 1.466794\n",
      "loss in epoch 13 , step 13300 : 0.256636\n",
      "loss in epoch 13 , step 13320 : 1.459517\n",
      "loss in epoch 13 , step 13340 : 0.162583\n",
      "loss in epoch 13 , step 13360 : 1.495364\n",
      "loss in epoch 13 , step 13380 : 0.295453\n",
      "loss in epoch 13 , step 13400 : 0.509183\n",
      "loss in epoch 13 , step 13420 : 1.122033\n",
      "loss in epoch 13 , step 13440 : 1.121604\n",
      "loss in epoch 13 , step 13460 : 1.265899\n",
      "loss in epoch 13 , step 13480 : 0.312430\n",
      "loss in epoch 13 , step 13500 : 0.540314\n",
      "loss in epoch 13 , step 13520 : 0.682975\n",
      "loss in epoch 13 , step 13540 : 0.344618\n",
      "loss in epoch 13 , step 13560 : 0.720131\n",
      "loss in epoch 13 , step 13580 : 0.011266\n",
      "loss in epoch 13 , step 13600 : 0.030077\n",
      "loss in epoch 13 , step 13620 : 0.639701\n",
      "loss in epoch 13 , step 13640 : 0.508911\n",
      "loss in epoch 13 , step 13660 : 4.675396\n",
      "loss in epoch 13 , step 13680 : 2.013642\n",
      "loss in epoch 13 , step 13700 : 0.838540\n",
      "loss in epoch 13 , step 13720 : 1.518425\n",
      "loss in epoch 13 , step 13740 : 1.615731\n",
      "loss in epoch 13 , step 13760 : 2.948249\n",
      "loss in epoch 13 , step 13780 : 0.833067\n",
      "loss in epoch 13 , step 13800 : 0.014864\n",
      "loss in epoch 13 , step 13820 : 0.619059\n",
      "loss in epoch 13 , step 13840 : 2.022322\n",
      "loss in epoch 13 , step 13860 : 3.437887\n",
      "loss in epoch 13 , step 13880 : 0.280104\n",
      "loss in epoch 13 , step 13900 : 1.536249\n",
      "loss in epoch 13 , step 13920 : 0.844186\n",
      "loss in epoch 13 , step 13940 : 0.145981\n",
      "loss in epoch 13 , step 13960 : 1.764626\n",
      "loss in epoch 13 , step 13980 : 0.992076\n",
      "loss in epoch 13 , step 14000 : 1.085741\n",
      "loss in epoch 13 , step 14020 : 1.664954\n",
      "loss in epoch 13 , step 14040 : 0.223905\n",
      "loss in epoch 13 , step 14060 : 0.232387\n",
      "loss in epoch 13 , step 14080 : 1.898160\n",
      "loss in epoch 13 , step 14100 : 1.060450\n",
      "loss in epoch 13 , step 14120 : 0.317798\n",
      "loss in epoch 13 , step 14140 : 0.789695\n",
      "loss in epoch 13 , step 14160 : 1.334452\n",
      "loss in epoch 13 , step 14180 : 0.025772\n",
      "loss in epoch 13 , step 14200 : 1.160488\n",
      "loss in epoch 13 , step 14220 : 0.137795\n",
      "loss in epoch 13 , step 14240 : 0.853585\n",
      "loss in epoch 13 , step 14260 : 1.152908\n",
      "loss in epoch 13 , step 14280 : 1.372306\n",
      "loss in epoch 13 , step 14300 : 0.053306\n",
      "loss in epoch 13 , step 14320 : 0.970885\n",
      "loss in epoch 13 , step 14340 : 1.047892\n",
      "loss in epoch 13 , step 14360 : 0.270397\n",
      "loss in epoch 13 , step 14380 : 0.339143\n",
      "loss in epoch 13 , step 14400 : 0.424511\n",
      "loss in epoch 13 , step 14420 : 0.786264\n",
      "loss in epoch 13 , step 14440 : 0.007469\n",
      "loss in epoch 13 , step 14460 : 0.163538\n",
      "loss in epoch 13 , step 14480 : 1.883100\n",
      "loss in epoch 13 , step 14500 : 0.722181\n",
      "loss in epoch 13 , step 14520 : 0.680529\n",
      "loss in epoch 13 , step 14540 : 2.304828\n",
      "loss in epoch 13 , step 14560 : 2.346359\n",
      "loss in epoch 13 , step 14580 : 0.942250\n",
      "loss in epoch 13 , step 14600 : 0.943300\n",
      "loss in epoch 13 , step 14620 : 0.131640\n",
      "loss in epoch 13 , step 14640 : 0.740084\n",
      "loss in epoch 13 , step 14660 : 1.738417\n",
      "loss in epoch 13 , step 14680 : 0.799032\n",
      "loss in epoch 13 , step 14700 : 1.023252\n",
      "loss in epoch 13 , step 14720 : 0.549419\n",
      "loss in epoch 13 , step 14740 : 0.638603\n",
      "loss in epoch 13 , step 14760 : 0.901223\n",
      "loss in epoch 13 , step 14780 : 1.267790\n",
      "loss in epoch 13 , step 14800 : 1.858982\n",
      "loss in epoch 13 , step 14820 : 0.659737\n",
      "loss in epoch 13 , step 14840 : 3.321573\n",
      "loss in epoch 13 , step 14860 : 0.089415\n",
      "loss in epoch 13 , step 14880 : 0.101690\n",
      "loss in epoch 13 , step 14900 : 0.032850\n",
      "loss in epoch 13 , step 14920 : 0.186947\n",
      "loss in epoch 13 , step 14940 : 0.188427\n",
      "loss in epoch 13 , step 14960 : 2.081443\n",
      "loss in epoch 13 , step 14980 : 1.912035\n",
      "loss in epoch 13 , step 15000 : 0.044963\n",
      "loss in epoch 13 , step 15020 : 2.123338\n",
      "loss in epoch 13 , step 15040 : 0.710509\n",
      "loss in epoch 13 , step 15060 : 0.438893\n",
      "loss in epoch 13 , step 15080 : 0.389224\n",
      "loss in epoch 13 , step 15100 : 0.237195\n",
      "loss in epoch 13 , step 15120 : 1.110390\n",
      "loss in epoch 13 , step 15140 : 2.863084\n",
      "loss in epoch 13 , step 15160 : 0.014760\n",
      "loss in epoch 13 , step 15180 : 0.172890\n",
      "loss in epoch 13 , step 15200 : 1.155384\n",
      "loss in epoch 13 , step 15220 : 0.013818\n",
      "loss in epoch 13 , step 15240 : 2.497812\n",
      "loss in epoch 13 , step 15260 : 0.019362\n",
      "loss in epoch 13 , step 15280 : 0.008893\n",
      "loss in epoch 13 , step 15300 : 0.143874\n",
      "loss in epoch 13 , step 15320 : 1.614701\n",
      "loss in epoch 13 , step 15340 : 3.681135\n",
      "loss in epoch 13 , step 15360 : 0.118906\n",
      "loss in epoch 13 , step 15380 : 1.210663\n",
      "loss in epoch 13 , step 15400 : 1.507971\n",
      "loss in epoch 13 , step 15420 : 1.845815\n",
      "loss in epoch 13 , step 15440 : 0.568655\n",
      "loss in epoch 13 , step 15460 : 1.390804\n",
      "loss in epoch 13 , step 15480 : 0.824781\n",
      "loss in epoch 13 , step 15500 : 0.025708\n",
      "loss in epoch 13 , step 15520 : 0.638629\n",
      "loss in epoch 13 , step 15540 : 0.549089\n",
      "loss in epoch 13 , step 15560 : 1.724605\n",
      "loss in epoch 13 , step 15580 : 0.102892\n",
      "loss in epoch 13 , step 15600 : 1.278657\n",
      "loss in epoch 13 , step 15620 : 0.073789\n",
      "loss in epoch 13 , step 15640 : 0.441410\n",
      "loss in epoch 13 , step 15660 : 3.229826\n",
      "loss in epoch 13 , step 15680 : 0.125064\n",
      "loss in epoch 13 , step 15700 : 2.095907\n",
      "loss in epoch 13 , step 15720 : 0.018270\n",
      "loss in epoch 13 , step 15740 : 0.003341\n",
      "loss in epoch 13 , step 15760 : 0.634335\n",
      "loss in epoch 13 , step 15780 : 0.584912\n",
      "loss in epoch 13 , step 15800 : 1.340074\n",
      "loss in epoch 13 , step 15820 : 0.347712\n",
      "loss in epoch 13 , step 15840 : 0.455374\n",
      "loss in epoch 13 , step 15860 : 0.765041\n",
      "loss in epoch 13 , step 15880 : 0.255997\n",
      "loss in epoch 13 , step 15900 : 0.652432\n",
      "loss in epoch 13 , step 15920 : 1.952852\n",
      "loss in epoch 13 , step 15940 : 1.617967\n",
      "loss in epoch 13 , step 15960 : 0.027840\n",
      "loss in epoch 13 , step 15980 : 0.738345\n",
      "loss in epoch 13 , step 16000 : 0.140277\n",
      "loss in epoch 13 , step 16020 : 0.943247\n",
      "loss in epoch 13 , step 16040 : 1.102260\n",
      "loss in epoch 13 , step 16060 : 1.853523\n",
      "loss in epoch 13 , step 16080 : 1.251753\n",
      "loss in epoch 13 , step 16100 : 1.472730\n",
      "loss in epoch 13 , step 16120 : 0.565033\n",
      "loss in epoch 13 , step 16140 : 1.640091\n",
      "loss in epoch 13 , step 16160 : 0.479713\n",
      "loss in epoch 13 , step 16180 : 0.814969\n",
      "loss in epoch 13 , step 16200 : 1.817491\n",
      "loss in epoch 13 , step 16220 : 2.019586\n",
      "loss in epoch 13 , step 16240 : 0.614366\n",
      "loss in epoch 13 , step 16260 : 1.645563\n",
      "loss in epoch 13 , step 16280 : 0.983762\n",
      "loss in epoch 13 , step 16300 : 1.422037\n",
      "loss in epoch 13 , step 16320 : 1.037128\n",
      "loss in epoch 13 , step 16340 : 0.935476\n",
      "loss in epoch 13 , step 16360 : 0.984097\n",
      "loss in epoch 13 , step 16380 : 2.513048\n",
      "loss in epoch 13 , step 16400 : 1.574060\n",
      "loss in epoch 13 , step 16420 : 1.499327\n",
      "loss in epoch 13 , step 16440 : 1.120104\n",
      "loss in epoch 13 , step 16460 : 2.388517\n",
      "loss in epoch 13 , step 16480 : 1.196461\n",
      "loss in epoch 13 , step 16500 : 4.189167\n",
      "loss in epoch 13 , step 16520 : 0.651826\n",
      "loss in epoch 13 , step 16540 : 1.047085\n",
      "loss in epoch 13 , step 16560 : 0.061809\n",
      "loss in epoch 13 , step 16580 : 1.662070\n",
      "loss in epoch 13 , step 16600 : 0.903379\n",
      "loss in epoch 13 , step 16620 : 0.228394\n",
      "loss in epoch 13 , step 16640 : 0.603313\n",
      "loss in epoch 13 , step 16660 : 0.132280\n",
      "loss in epoch 13 , step 16680 : 1.542657\n",
      "loss in epoch 13 , step 16700 : 1.093124\n",
      "loss in epoch 13 , step 16720 : 1.438602\n",
      "loss in epoch 13 , step 16740 : 0.062120\n",
      "loss in epoch 13 , step 16760 : 0.576474\n",
      "loss in epoch 13 , step 16780 : 0.005431\n",
      "loss in epoch 13 , step 16800 : 2.223151\n",
      "loss in epoch 13 , step 16820 : 1.486560\n",
      "loss in epoch 13 , step 16840 : 1.158152\n",
      "loss in epoch 13 , step 16860 : 0.566871\n",
      "loss in epoch 13 , step 16880 : 1.070349\n",
      "loss in epoch 13 , step 16900 : 1.111491\n",
      "loss in epoch 13 , step 16920 : 0.748927\n",
      "loss in epoch 13 , step 16940 : 0.163743\n",
      "loss in epoch 13 , step 16960 : 1.127026\n",
      "loss in epoch 13 , step 16980 : 1.143092\n",
      "loss in epoch 13 , step 17000 : 0.972353\n",
      "loss in epoch 13 , step 17020 : 0.027193\n",
      "loss in epoch 13 , step 17040 : 0.443229\n",
      "loss in epoch 13 , step 17060 : 0.633050\n",
      "loss in epoch 13 , step 17080 : 1.277216\n",
      "loss in epoch 13 , step 17100 : 0.706541\n",
      "loss in epoch 13 , step 17120 : 0.860438\n",
      "loss in epoch 13 , step 17140 : 1.386861\n",
      "loss in epoch 13 , step 17160 : 0.001784\n",
      "loss in epoch 13 , step 17180 : 1.143715\n",
      "loss in epoch 13 , step 17200 : 0.954555\n",
      "loss in epoch 13 , step 17220 : 0.041780\n",
      "loss in epoch 13 , step 17240 : 0.592602\n",
      "loss in epoch 13 , step 17260 : 1.208497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 13 , step 17280 : 0.834874\n",
      "loss in epoch 13 , step 17300 : 0.662367\n",
      "loss in epoch 13 , step 17320 : 0.145751\n",
      "loss in epoch 13 , step 17340 : 0.651764\n",
      "loss in epoch 13 , step 17360 : 1.240269\n",
      "loss in epoch 13 , step 17380 : 1.294546\n",
      "loss in epoch 13 , step 17400 : 1.095277\n",
      "loss in epoch 13 , step 17420 : 2.510690\n",
      "loss in epoch 13 , step 17440 : 0.847843\n",
      "loss in epoch 13 , step 17460 : 2.155836\n",
      "loss in epoch 13 , step 17480 : 0.844836\n",
      "loss in epoch 13 , step 17500 : 0.906430\n",
      "loss in epoch 13 , step 17520 : 2.547163\n",
      "loss in epoch 13 , step 17540 : 1.433983\n",
      "loss in epoch 13 , step 17560 : 1.401287\n",
      "loss in epoch 13 , step 17580 : 0.924791\n",
      "loss in epoch 13 , step 17600 : 1.798070\n",
      "loss in epoch 13 , step 17620 : 2.066690\n",
      "loss in epoch 13 , step 17640 : 0.115411\n",
      "loss in epoch 13 , step 17660 : 0.606214\n",
      "loss in epoch 13 , step 17680 : 0.007713\n",
      "loss in epoch 13 , step 17700 : 1.047933\n",
      "loss in epoch 13 , step 17720 : 2.242430\n",
      "loss in epoch 13 , step 17740 : 0.904163\n",
      "loss in epoch 13 , step 17760 : 2.759185\n",
      "loss in epoch 13 , step 17780 : 2.673048\n",
      "loss in epoch 13 , step 17800 : 1.714052\n",
      "loss in epoch 13 , step 17820 : 1.861111\n",
      "loss in epoch 13 , step 17840 : 1.293070\n",
      "loss in epoch 13 , step 17860 : 3.274745\n",
      "loss in epoch 13 , step 17880 : 0.371739\n",
      "loss in epoch 13 , step 17900 : 0.278402\n",
      "loss in epoch 13 , step 17920 : 0.372568\n",
      "loss in epoch 13 , step 17940 : 2.882504\n",
      "loss in epoch 13 , step 17960 : 1.076070\n",
      "loss in epoch 13 , step 17980 : 0.125889\n",
      "loss in epoch 13 , step 18000 : 0.651478\n",
      "loss in epoch 13 , step 18020 : 1.291135\n",
      "loss in epoch 13 , step 18040 : 1.708838\n",
      "loss in epoch 13 , step 18060 : 0.215029\n",
      "loss in epoch 13 , step 18080 : 1.205261\n",
      "loss in epoch 13 , step 18100 : 1.826527\n",
      "loss in epoch 13 , step 18120 : 0.650909\n",
      "loss in epoch 13 , step 18140 : 0.468227\n",
      "loss in epoch 13 , step 18160 : 0.025324\n",
      "loss in epoch 13 , step 18180 : 0.984713\n",
      "loss in epoch 13 , step 18200 : 0.522250\n",
      "loss in epoch 13 , step 18220 : 0.708659\n",
      "loss in epoch 13 , step 18240 : 0.066361\n",
      "loss in epoch 13 , step 18260 : 1.608468\n",
      "loss in epoch 13 , step 18280 : 0.016619\n",
      "loss in epoch 13 , step 18300 : 0.483770\n",
      "loss in epoch 13 , step 18320 : 0.934401\n",
      "loss in epoch 13 , step 18340 : 2.696953\n",
      "loss in epoch 13 , step 18360 : 0.025986\n",
      "loss in epoch 13 , step 18380 : 0.261617\n",
      "loss in epoch 13 , step 18400 : 0.182322\n",
      "loss in epoch 13 , step 18420 : 0.238041\n",
      "loss in epoch 13 , step 18440 : 2.178878\n",
      "loss in epoch 13 , step 18460 : 1.919938\n",
      "loss in epoch 13 , step 18480 : 1.229946\n",
      "loss in epoch 13 , step 18500 : 2.177711\n",
      "loss in epoch 13 , step 18520 : 0.081830\n",
      "loss in epoch 13 , step 18540 : 0.403267\n",
      "loss in epoch 13 , step 18560 : 0.490275\n",
      "loss in epoch 13 , step 18580 : 2.050334\n",
      "loss in epoch 13 , step 18600 : 0.611215\n",
      "loss in epoch 13 , step 18620 : 0.279061\n",
      "loss in epoch 13 , step 18640 : 0.399639\n",
      "loss in epoch 13 , step 18660 : 2.022088\n",
      "loss in epoch 13 , step 18680 : 1.192882\n",
      "loss in epoch 13 , step 18700 : 0.167571\n",
      "loss in epoch 13 , step 18720 : 1.050798\n",
      "loss in epoch 13 , step 18740 : 1.454595\n",
      "loss in epoch 13 , step 18760 : 1.570506\n",
      "loss in epoch 13 , step 18780 : 0.739125\n",
      "loss in epoch 13 , step 18800 : 0.008222\n",
      "loss in epoch 13 , step 18820 : 2.970969\n",
      "loss in epoch 13 , step 18840 : 0.866432\n",
      "loss in epoch 13 , step 18860 : 0.287423\n",
      "loss in epoch 13 , step 18880 : 0.765101\n",
      "loss in epoch 13 , step 18900 : 0.198870\n",
      "loss in epoch 13 , step 18920 : 1.489201\n",
      "loss in epoch 13 , step 18940 : 0.832836\n",
      "loss in epoch 13 , step 18960 : 1.713270\n",
      "loss in epoch 13 , step 18980 : 1.127260\n",
      "loss in epoch 13 , step 19000 : 0.421296\n",
      "loss in epoch 13 , step 19020 : 0.486479\n",
      "loss in epoch 13 , step 19040 : 0.276630\n",
      "loss in epoch 13 , step 19060 : 0.787149\n",
      "loss in epoch 13 , step 19080 : 0.004679\n",
      "loss in epoch 13 , step 19100 : 0.111726\n",
      "loss in epoch 13 , step 19120 : 0.084997\n",
      "loss in epoch 13 , step 19140 : 0.551508\n",
      "loss in epoch 13 , step 19160 : 0.871293\n",
      "loss in epoch 13 , step 19180 : 2.233172\n",
      "loss in epoch 13 , step 19200 : 0.158484\n",
      "loss in epoch 13 , step 19220 : 0.020964\n",
      "loss in epoch 13 , step 19240 : 1.637264\n",
      "loss in epoch 13 , step 19260 : 0.019024\n",
      "loss in epoch 13 , step 19280 : 1.563855\n",
      "loss in epoch 13 , step 19300 : 0.068800\n",
      "loss in epoch 13 , step 19320 : 1.025053\n",
      "loss in epoch 13 , step 19340 : 0.100969\n",
      "loss in epoch 13 , step 19360 : 0.119992\n",
      "loss in epoch 13 , step 19380 : 0.262873\n",
      "loss in epoch 13 , step 19400 : 0.846662\n",
      "loss in epoch 13 , step 19420 : 0.052923\n",
      "loss in epoch 13 , step 19440 : 0.810476\n",
      "loss in epoch 13 , step 19460 : 0.350912\n",
      "loss in epoch 13 , step 19480 : 1.195444\n",
      "loss in epoch 13 , step 19500 : 0.904864\n",
      "loss in epoch 13 , step 19520 : 0.796416\n",
      "loss in epoch 13 , step 19540 : 1.187131\n",
      "loss in epoch 13 , step 19560 : 0.363949\n",
      "loss in epoch 13 , step 19580 : 1.994127\n",
      "loss in epoch 13 , step 19600 : 0.718685\n",
      "loss in epoch 13 , step 19620 : 1.236226\n",
      "loss in epoch 13 , step 19640 : 1.573272\n",
      "loss in epoch 13 , step 19660 : 0.156270\n",
      "loss in epoch 13 , step 19680 : 1.822366\n",
      "loss in epoch 13 , step 19700 : 0.844361\n",
      "loss in epoch 13 , step 19720 : 0.202693\n",
      "loss in epoch 13 , step 19740 : 2.182219\n",
      "loss in epoch 13 , step 19760 : 0.028467\n",
      "loss in epoch 13 , step 19780 : 0.186994\n",
      "loss in epoch 13 , step 19800 : 0.302058\n",
      "loss in epoch 13 , step 19820 : 0.036456\n",
      "loss in epoch 13 , step 19840 : 1.767004\n",
      "loss in epoch 13 , step 19860 : 0.895574\n",
      "loss in epoch 13 , step 19880 : 3.498339\n",
      "loss in epoch 13 , step 19900 : 0.963969\n",
      "loss in epoch 13 , step 19920 : 0.021297\n",
      "loss in epoch 13 , step 19940 : 1.206810\n",
      "Accuracy in epoch 13 : 32.043499\n",
      "loss in epoch 14 , step 0 : 0.039923\n",
      "loss in epoch 14 , step 20 : 0.426349\n",
      "loss in epoch 14 , step 40 : 0.637314\n",
      "loss in epoch 14 , step 60 : 1.044678\n",
      "loss in epoch 14 , step 80 : 2.279409\n",
      "loss in epoch 14 , step 100 : 0.731217\n",
      "loss in epoch 14 , step 120 : 1.406743\n",
      "loss in epoch 14 , step 140 : 1.781287\n",
      "loss in epoch 14 , step 160 : 0.543962\n",
      "loss in epoch 14 , step 180 : 0.124289\n",
      "loss in epoch 14 , step 200 : 1.608932\n",
      "loss in epoch 14 , step 220 : 1.001099\n",
      "loss in epoch 14 , step 240 : 1.097196\n",
      "loss in epoch 14 , step 260 : 3.200045\n",
      "loss in epoch 14 , step 280 : 0.040212\n",
      "loss in epoch 14 , step 300 : 0.325925\n",
      "loss in epoch 14 , step 320 : 2.672249\n",
      "loss in epoch 14 , step 340 : 0.028103\n",
      "loss in epoch 14 , step 360 : 0.753228\n",
      "loss in epoch 14 , step 380 : 1.297336\n",
      "loss in epoch 14 , step 400 : 0.501252\n",
      "loss in epoch 14 , step 420 : 0.740312\n",
      "loss in epoch 14 , step 440 : 0.031133\n",
      "loss in epoch 14 , step 460 : 0.019100\n",
      "loss in epoch 14 , step 480 : 1.464592\n",
      "loss in epoch 14 , step 500 : 1.294456\n",
      "loss in epoch 14 , step 520 : 1.533009\n",
      "loss in epoch 14 , step 540 : 0.343363\n",
      "loss in epoch 14 , step 560 : 1.840237\n",
      "loss in epoch 14 , step 580 : 0.051911\n",
      "loss in epoch 14 , step 600 : 2.023185\n",
      "loss in epoch 14 , step 620 : 0.115710\n",
      "loss in epoch 14 , step 640 : 1.743034\n",
      "loss in epoch 14 , step 660 : 0.008703\n",
      "loss in epoch 14 , step 680 : 2.517595\n",
      "loss in epoch 14 , step 700 : 2.574517\n",
      "loss in epoch 14 , step 720 : 0.400419\n",
      "loss in epoch 14 , step 740 : 0.940921\n",
      "loss in epoch 14 , step 760 : 2.124705\n",
      "loss in epoch 14 , step 780 : 1.446493\n",
      "loss in epoch 14 , step 800 : 0.609718\n",
      "loss in epoch 14 , step 820 : 0.562124\n",
      "loss in epoch 14 , step 840 : 1.210799\n",
      "loss in epoch 14 , step 860 : 0.363347\n",
      "loss in epoch 14 , step 880 : 0.198445\n",
      "loss in epoch 14 , step 900 : 0.944618\n",
      "loss in epoch 14 , step 920 : 1.776605\n",
      "loss in epoch 14 , step 940 : 1.300970\n",
      "loss in epoch 14 , step 960 : 0.025888\n",
      "loss in epoch 14 , step 980 : 0.006758\n",
      "loss in epoch 14 , step 1000 : 0.751801\n",
      "loss in epoch 14 , step 1020 : 0.470892\n",
      "loss in epoch 14 , step 1040 : 0.427992\n",
      "loss in epoch 14 , step 1060 : 0.236967\n",
      "loss in epoch 14 , step 1080 : 1.773510\n",
      "loss in epoch 14 , step 1100 : 0.431653\n",
      "loss in epoch 14 , step 1120 : 1.468575\n",
      "loss in epoch 14 , step 1140 : 0.950115\n",
      "loss in epoch 14 , step 1160 : 1.600803\n",
      "loss in epoch 14 , step 1180 : 0.556182\n",
      "loss in epoch 14 , step 1200 : 1.354651\n",
      "loss in epoch 14 , step 1220 : 0.010853\n",
      "loss in epoch 14 , step 1240 : 0.995644\n",
      "loss in epoch 14 , step 1260 : 1.999026\n",
      "loss in epoch 14 , step 1280 : 0.905749\n",
      "loss in epoch 14 , step 1300 : 3.568944\n",
      "loss in epoch 14 , step 1320 : 1.400133\n",
      "loss in epoch 14 , step 1340 : 1.937680\n",
      "loss in epoch 14 , step 1360 : 1.522599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 14 , step 1380 : 0.403548\n",
      "loss in epoch 14 , step 1400 : 0.191564\n",
      "loss in epoch 14 , step 1420 : 0.055873\n",
      "loss in epoch 14 , step 1440 : 0.097453\n",
      "loss in epoch 14 , step 1460 : 0.557739\n",
      "loss in epoch 14 , step 1480 : 0.153227\n",
      "loss in epoch 14 , step 1500 : 1.948787\n",
      "loss in epoch 14 , step 1520 : 0.609725\n",
      "loss in epoch 14 , step 1540 : 1.041053\n",
      "loss in epoch 14 , step 1560 : 2.863553\n",
      "loss in epoch 14 , step 1580 : 1.232679\n",
      "loss in epoch 14 , step 1600 : 0.159909\n",
      "loss in epoch 14 , step 1620 : 0.308110\n",
      "loss in epoch 14 , step 1640 : 1.491568\n",
      "loss in epoch 14 , step 1660 : 0.962194\n",
      "loss in epoch 14 , step 1680 : 0.124304\n",
      "loss in epoch 14 , step 1700 : 1.883323\n",
      "loss in epoch 14 , step 1720 : 0.476372\n",
      "loss in epoch 14 , step 1740 : 1.526230\n",
      "loss in epoch 14 , step 1760 : 1.063438\n",
      "loss in epoch 14 , step 1780 : 0.069779\n",
      "loss in epoch 14 , step 1800 : 0.313010\n",
      "loss in epoch 14 , step 1820 : 1.269718\n",
      "loss in epoch 14 , step 1840 : 1.743330\n",
      "loss in epoch 14 , step 1860 : 0.951476\n",
      "loss in epoch 14 , step 1880 : 0.916143\n",
      "loss in epoch 14 , step 1900 : 2.074116\n",
      "loss in epoch 14 , step 1920 : 0.571569\n",
      "loss in epoch 14 , step 1940 : 0.522168\n",
      "loss in epoch 14 , step 1960 : 0.878174\n",
      "loss in epoch 14 , step 1980 : 0.265836\n",
      "loss in epoch 14 , step 2000 : 0.364621\n",
      "loss in epoch 14 , step 2020 : 0.314771\n",
      "loss in epoch 14 , step 2040 : 0.851642\n",
      "loss in epoch 14 , step 2060 : 0.155956\n",
      "loss in epoch 14 , step 2080 : 0.859523\n",
      "loss in epoch 14 , step 2100 : 0.139507\n",
      "loss in epoch 14 , step 2120 : 1.120963\n",
      "loss in epoch 14 , step 2140 : 1.294677\n",
      "loss in epoch 14 , step 2160 : 0.545461\n",
      "loss in epoch 14 , step 2180 : 0.054953\n",
      "loss in epoch 14 , step 2200 : 0.003310\n",
      "loss in epoch 14 , step 2220 : 0.324250\n",
      "loss in epoch 14 , step 2240 : 1.509665\n",
      "loss in epoch 14 , step 2260 : 3.538665\n",
      "loss in epoch 14 , step 2280 : 1.632862\n",
      "loss in epoch 14 , step 2300 : 0.723510\n",
      "loss in epoch 14 , step 2320 : 0.905387\n",
      "loss in epoch 14 , step 2340 : 1.486943\n",
      "loss in epoch 14 , step 2360 : 2.821252\n",
      "loss in epoch 14 , step 2380 : 0.986772\n",
      "loss in epoch 14 , step 2400 : 0.781374\n",
      "loss in epoch 14 , step 2420 : 2.037995\n",
      "loss in epoch 14 , step 2440 : 0.044450\n",
      "loss in epoch 14 , step 2460 : 1.533355\n",
      "loss in epoch 14 , step 2480 : 0.195852\n",
      "loss in epoch 14 , step 2500 : 1.608270\n",
      "loss in epoch 14 , step 2520 : 0.684037\n",
      "loss in epoch 14 , step 2540 : 1.086865\n",
      "loss in epoch 14 , step 2560 : 0.198597\n",
      "loss in epoch 14 , step 2580 : 0.435184\n",
      "loss in epoch 14 , step 2600 : 0.944320\n",
      "loss in epoch 14 , step 2620 : 1.203454\n",
      "loss in epoch 14 , step 2640 : 1.759273\n",
      "loss in epoch 14 , step 2660 : 4.607783\n",
      "loss in epoch 14 , step 2680 : 2.162081\n",
      "loss in epoch 14 , step 2700 : 1.067793\n",
      "loss in epoch 14 , step 2720 : 1.091506\n",
      "loss in epoch 14 , step 2740 : 2.845056\n",
      "loss in epoch 14 , step 2760 : 0.001841\n",
      "loss in epoch 14 , step 2780 : 0.718723\n",
      "loss in epoch 14 , step 2800 : 0.829784\n",
      "loss in epoch 14 , step 2820 : 0.790557\n",
      "loss in epoch 14 , step 2840 : 2.976527\n",
      "loss in epoch 14 , step 2860 : 1.578247\n",
      "loss in epoch 14 , step 2880 : 0.805503\n",
      "loss in epoch 14 , step 2900 : 0.576013\n",
      "loss in epoch 14 , step 2920 : 2.436549\n",
      "loss in epoch 14 , step 2940 : 1.674394\n",
      "loss in epoch 14 , step 2960 : 2.503470\n",
      "loss in epoch 14 , step 2980 : 0.004392\n",
      "loss in epoch 14 , step 3000 : 0.094094\n",
      "loss in epoch 14 , step 3020 : 2.531881\n",
      "loss in epoch 14 , step 3040 : 0.334862\n",
      "loss in epoch 14 , step 3060 : 1.013299\n",
      "loss in epoch 14 , step 3080 : 0.678873\n",
      "loss in epoch 14 , step 3100 : 1.135777\n",
      "loss in epoch 14 , step 3120 : 0.357241\n",
      "loss in epoch 14 , step 3140 : 1.313471\n",
      "loss in epoch 14 , step 3160 : 1.322914\n",
      "loss in epoch 14 , step 3180 : 1.898994\n",
      "loss in epoch 14 , step 3200 : 1.303588\n",
      "loss in epoch 14 , step 3220 : 1.035296\n",
      "loss in epoch 14 , step 3240 : 2.916588\n",
      "loss in epoch 14 , step 3260 : 2.263851\n",
      "loss in epoch 14 , step 3280 : 0.346899\n",
      "loss in epoch 14 , step 3300 : 0.396854\n",
      "loss in epoch 14 , step 3320 : 0.787479\n",
      "loss in epoch 14 , step 3340 : 4.512202\n",
      "loss in epoch 14 , step 3360 : 1.147524\n",
      "loss in epoch 14 , step 3380 : 1.482611\n",
      "loss in epoch 14 , step 3400 : 0.687948\n",
      "loss in epoch 14 , step 3420 : 1.252906\n",
      "loss in epoch 14 , step 3440 : 1.786762\n",
      "loss in epoch 14 , step 3460 : 6.121667\n",
      "loss in epoch 14 , step 3480 : 0.215405\n",
      "loss in epoch 14 , step 3500 : 2.151471\n",
      "loss in epoch 14 , step 3520 : 2.323765\n",
      "loss in epoch 14 , step 3540 : 1.272868\n",
      "loss in epoch 14 , step 3560 : 1.863029\n",
      "loss in epoch 14 , step 3580 : 0.902531\n",
      "loss in epoch 14 , step 3600 : 1.038397\n",
      "loss in epoch 14 , step 3620 : 0.279296\n",
      "loss in epoch 14 , step 3640 : 3.048676\n",
      "loss in epoch 14 , step 3660 : 1.372415\n",
      "loss in epoch 14 , step 3680 : 0.529921\n",
      "loss in epoch 14 , step 3700 : 0.006093\n",
      "loss in epoch 14 , step 3720 : 1.247033\n",
      "loss in epoch 14 , step 3740 : 0.205758\n",
      "loss in epoch 14 , step 3760 : 2.067741\n",
      "loss in epoch 14 , step 3780 : 0.779925\n",
      "loss in epoch 14 , step 3800 : 3.455040\n",
      "loss in epoch 14 , step 3820 : 1.085817\n",
      "loss in epoch 14 , step 3840 : 0.837163\n",
      "loss in epoch 14 , step 3860 : 0.123285\n",
      "loss in epoch 14 , step 3880 : 1.538139\n",
      "loss in epoch 14 , step 3900 : 0.092814\n",
      "loss in epoch 14 , step 3920 : 0.334020\n",
      "loss in epoch 14 , step 3940 : 0.376797\n",
      "loss in epoch 14 , step 3960 : 1.892461\n",
      "loss in epoch 14 , step 3980 : 1.070372\n",
      "loss in epoch 14 , step 4000 : 0.415978\n",
      "loss in epoch 14 , step 4020 : 3.025876\n",
      "loss in epoch 14 , step 4040 : 0.052290\n",
      "loss in epoch 14 , step 4060 : 0.453911\n",
      "loss in epoch 14 , step 4080 : 0.035078\n",
      "loss in epoch 14 , step 4100 : 2.563793\n",
      "loss in epoch 14 , step 4120 : 0.747379\n",
      "loss in epoch 14 , step 4140 : 1.329351\n",
      "loss in epoch 14 , step 4160 : 2.019830\n",
      "loss in epoch 14 , step 4180 : 0.005984\n",
      "loss in epoch 14 , step 4200 : 0.358611\n",
      "loss in epoch 14 , step 4220 : 0.912353\n",
      "loss in epoch 14 , step 4240 : 0.115989\n",
      "loss in epoch 14 , step 4260 : 0.932319\n",
      "loss in epoch 14 , step 4280 : 1.169789\n",
      "loss in epoch 14 , step 4300 : 0.674707\n",
      "loss in epoch 14 , step 4320 : 0.107087\n",
      "loss in epoch 14 , step 4340 : 1.408257\n",
      "loss in epoch 14 , step 4360 : 0.390445\n",
      "loss in epoch 14 , step 4380 : 1.582454\n",
      "loss in epoch 14 , step 4400 : 0.038367\n",
      "loss in epoch 14 , step 4420 : 1.023949\n",
      "loss in epoch 14 , step 4440 : 0.016766\n",
      "loss in epoch 14 , step 4460 : 1.332493\n",
      "loss in epoch 14 , step 4480 : 0.030618\n",
      "loss in epoch 14 , step 4500 : 0.001472\n",
      "loss in epoch 14 , step 4520 : 0.519747\n",
      "loss in epoch 14 , step 4540 : 0.041274\n",
      "loss in epoch 14 , step 4560 : 1.067903\n",
      "loss in epoch 14 , step 4580 : 0.006930\n",
      "loss in epoch 14 , step 4600 : 1.337394\n",
      "loss in epoch 14 , step 4620 : 0.006669\n",
      "loss in epoch 14 , step 4640 : 1.155450\n",
      "loss in epoch 14 , step 4660 : 1.292576\n",
      "loss in epoch 14 , step 4680 : 0.572629\n",
      "loss in epoch 14 , step 4700 : 0.167333\n",
      "loss in epoch 14 , step 4720 : 0.579971\n",
      "loss in epoch 14 , step 4740 : 1.915892\n",
      "loss in epoch 14 , step 4760 : 0.574283\n",
      "loss in epoch 14 , step 4780 : 0.472603\n",
      "loss in epoch 14 , step 4800 : 0.068075\n",
      "loss in epoch 14 , step 4820 : 0.081976\n",
      "loss in epoch 14 , step 4840 : 1.586357\n",
      "loss in epoch 14 , step 4860 : 0.543164\n",
      "loss in epoch 14 , step 4880 : 0.079134\n",
      "loss in epoch 14 , step 4900 : 0.127146\n",
      "loss in epoch 14 , step 4920 : 3.427828\n",
      "loss in epoch 14 , step 4940 : 0.401678\n",
      "loss in epoch 14 , step 4960 : 2.465413\n",
      "loss in epoch 14 , step 4980 : 1.299257\n",
      "loss in epoch 14 , step 5000 : 0.214307\n",
      "loss in epoch 14 , step 5020 : 2.314738\n",
      "loss in epoch 14 , step 5040 : 2.006872\n",
      "loss in epoch 14 , step 5060 : 0.291324\n",
      "loss in epoch 14 , step 5080 : 0.910345\n",
      "loss in epoch 14 , step 5100 : 1.839969\n",
      "loss in epoch 14 , step 5120 : 1.113635\n",
      "loss in epoch 14 , step 5140 : 1.535623\n",
      "loss in epoch 14 , step 5160 : 0.249298\n",
      "loss in epoch 14 , step 5180 : 3.213198\n",
      "loss in epoch 14 , step 5200 : 1.411937\n",
      "loss in epoch 14 , step 5220 : 1.601980\n",
      "loss in epoch 14 , step 5240 : 0.001593\n",
      "loss in epoch 14 , step 5260 : 1.037252\n",
      "loss in epoch 14 , step 5280 : 1.401658\n",
      "loss in epoch 14 , step 5300 : 0.016472\n",
      "loss in epoch 14 , step 5320 : 0.097197\n",
      "loss in epoch 14 , step 5340 : 2.709580\n",
      "loss in epoch 14 , step 5360 : 0.419845\n",
      "loss in epoch 14 , step 5380 : 0.007734\n",
      "loss in epoch 14 , step 5400 : 0.683799\n",
      "loss in epoch 14 , step 5420 : 0.309975\n",
      "loss in epoch 14 , step 5440 : 0.001389\n",
      "loss in epoch 14 , step 5460 : 0.687536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 14 , step 5480 : 0.265157\n",
      "loss in epoch 14 , step 5500 : 0.507344\n",
      "loss in epoch 14 , step 5520 : 0.090343\n",
      "loss in epoch 14 , step 5540 : 1.736754\n",
      "loss in epoch 14 , step 5560 : 0.006946\n",
      "loss in epoch 14 , step 5580 : 0.005385\n",
      "loss in epoch 14 , step 5600 : 0.358292\n",
      "loss in epoch 14 , step 5620 : 3.623349\n",
      "loss in epoch 14 , step 5640 : 0.524078\n",
      "loss in epoch 14 , step 5660 : 0.321941\n",
      "loss in epoch 14 , step 5680 : 1.944972\n",
      "loss in epoch 14 , step 5700 : 0.254648\n",
      "loss in epoch 14 , step 5720 : 0.857857\n",
      "loss in epoch 14 , step 5740 : 0.943726\n",
      "loss in epoch 14 , step 5760 : 0.833105\n",
      "loss in epoch 14 , step 5780 : 0.042888\n",
      "loss in epoch 14 , step 5800 : 0.064321\n",
      "loss in epoch 14 , step 5820 : 0.680787\n",
      "loss in epoch 14 , step 5840 : 1.135930\n",
      "loss in epoch 14 , step 5860 : 0.622351\n",
      "loss in epoch 14 , step 5880 : 0.999142\n",
      "loss in epoch 14 , step 5900 : 0.000735\n",
      "loss in epoch 14 , step 5920 : 0.710698\n",
      "loss in epoch 14 , step 5940 : 0.077513\n",
      "loss in epoch 14 , step 5960 : 3.134776\n",
      "loss in epoch 14 , step 5980 : 0.922620\n",
      "loss in epoch 14 , step 6000 : 0.491332\n",
      "loss in epoch 14 , step 6020 : 1.395350\n",
      "loss in epoch 14 , step 6040 : 0.387408\n",
      "loss in epoch 14 , step 6060 : 0.374061\n",
      "loss in epoch 14 , step 6080 : 1.141463\n",
      "loss in epoch 14 , step 6100 : 0.299153\n",
      "loss in epoch 14 , step 6120 : 0.055686\n",
      "loss in epoch 14 , step 6140 : 0.358038\n",
      "loss in epoch 14 , step 6160 : 3.814699\n",
      "loss in epoch 14 , step 6180 : 0.271512\n",
      "loss in epoch 14 , step 6200 : 1.525673\n",
      "loss in epoch 14 , step 6220 : 0.013629\n",
      "loss in epoch 14 , step 6240 : 1.704560\n",
      "loss in epoch 14 , step 6260 : 0.001846\n",
      "loss in epoch 14 , step 6280 : 0.211413\n",
      "loss in epoch 14 , step 6300 : 0.678624\n",
      "loss in epoch 14 , step 6320 : 2.159363\n",
      "loss in epoch 14 , step 6340 : 1.970504\n",
      "loss in epoch 14 , step 6360 : 0.386456\n",
      "loss in epoch 14 , step 6380 : 0.019663\n",
      "loss in epoch 14 , step 6400 : 0.306691\n",
      "loss in epoch 14 , step 6420 : 1.625590\n",
      "loss in epoch 14 , step 6440 : 0.579507\n",
      "loss in epoch 14 , step 6460 : 0.860076\n",
      "loss in epoch 14 , step 6480 : 2.900365\n",
      "loss in epoch 14 , step 6500 : 0.570808\n",
      "loss in epoch 14 , step 6520 : 1.165674\n",
      "loss in epoch 14 , step 6540 : 1.477720\n",
      "loss in epoch 14 , step 6560 : 2.000214\n",
      "loss in epoch 14 , step 6580 : 1.118741\n",
      "loss in epoch 14 , step 6600 : 1.299458\n",
      "loss in epoch 14 , step 6620 : 0.391581\n",
      "loss in epoch 14 , step 6640 : 0.409313\n",
      "loss in epoch 14 , step 6660 : 0.512264\n",
      "loss in epoch 14 , step 6680 : 0.943007\n",
      "loss in epoch 14 , step 6700 : 1.101862\n",
      "loss in epoch 14 , step 6720 : 1.686676\n",
      "loss in epoch 14 , step 6740 : 0.421181\n",
      "loss in epoch 14 , step 6760 : 1.689524\n",
      "loss in epoch 14 , step 6780 : 0.069824\n",
      "loss in epoch 14 , step 6800 : 2.054821\n",
      "loss in epoch 14 , step 6820 : 1.065664\n",
      "loss in epoch 14 , step 6840 : 3.161592\n",
      "loss in epoch 14 , step 6860 : 0.243014\n",
      "loss in epoch 14 , step 6880 : 0.103256\n",
      "loss in epoch 14 , step 6900 : 1.029558\n",
      "loss in epoch 14 , step 6920 : 1.728368\n",
      "loss in epoch 14 , step 6940 : 1.958943\n",
      "loss in epoch 14 , step 6960 : 0.533193\n",
      "loss in epoch 14 , step 6980 : 2.196163\n",
      "loss in epoch 14 , step 7000 : 0.660599\n",
      "loss in epoch 14 , step 7020 : 1.513371\n",
      "loss in epoch 14 , step 7040 : 0.375966\n",
      "loss in epoch 14 , step 7060 : 4.625915\n",
      "loss in epoch 14 , step 7080 : 0.141192\n",
      "loss in epoch 14 , step 7100 : 0.002151\n",
      "loss in epoch 14 , step 7120 : 1.094848\n",
      "loss in epoch 14 , step 7140 : 1.182200\n",
      "loss in epoch 14 , step 7160 : 0.668925\n",
      "loss in epoch 14 , step 7180 : 2.534143\n",
      "loss in epoch 14 , step 7200 : 0.005264\n",
      "loss in epoch 14 , step 7220 : 0.014452\n",
      "loss in epoch 14 , step 7240 : 0.507422\n",
      "loss in epoch 14 , step 7260 : 0.260531\n",
      "loss in epoch 14 , step 7280 : 0.662930\n",
      "loss in epoch 14 , step 7300 : 1.117638\n",
      "loss in epoch 14 , step 7320 : 0.231397\n",
      "loss in epoch 14 , step 7340 : 0.194768\n",
      "loss in epoch 14 , step 7360 : 1.183125\n",
      "loss in epoch 14 , step 7380 : 0.857208\n",
      "loss in epoch 14 , step 7400 : 0.665751\n",
      "loss in epoch 14 , step 7420 : 0.547074\n",
      "loss in epoch 14 , step 7440 : 0.571809\n",
      "loss in epoch 14 , step 7460 : 1.526952\n",
      "loss in epoch 14 , step 7480 : 0.364721\n",
      "loss in epoch 14 , step 7500 : 3.129481\n",
      "loss in epoch 14 , step 7520 : 0.072523\n",
      "loss in epoch 14 , step 7540 : 1.373639\n",
      "loss in epoch 14 , step 7560 : 1.180576\n",
      "loss in epoch 14 , step 7580 : 2.776448\n",
      "loss in epoch 14 , step 7600 : 2.720785\n",
      "loss in epoch 14 , step 7620 : 1.325658\n",
      "loss in epoch 14 , step 7640 : 2.844309\n",
      "loss in epoch 14 , step 7660 : 2.665322\n",
      "loss in epoch 14 , step 7680 : 0.323477\n",
      "loss in epoch 14 , step 7700 : 0.063250\n",
      "loss in epoch 14 , step 7720 : 0.219816\n",
      "loss in epoch 14 , step 7740 : 0.099978\n",
      "loss in epoch 14 , step 7760 : 0.184950\n",
      "loss in epoch 14 , step 7780 : 0.003808\n",
      "loss in epoch 14 , step 7800 : 3.360934\n",
      "loss in epoch 14 , step 7820 : 0.171715\n",
      "loss in epoch 14 , step 7840 : 0.073383\n",
      "loss in epoch 14 , step 7860 : 0.089587\n",
      "loss in epoch 14 , step 7880 : 0.758866\n",
      "loss in epoch 14 , step 7900 : 3.346408\n",
      "loss in epoch 14 , step 7920 : 2.311158\n",
      "loss in epoch 14 , step 7940 : 1.114893\n",
      "loss in epoch 14 , step 7960 : 0.494360\n",
      "loss in epoch 14 , step 7980 : 3.879838\n",
      "loss in epoch 14 , step 8000 : 0.084542\n",
      "loss in epoch 14 , step 8020 : 0.409721\n",
      "loss in epoch 14 , step 8040 : 1.823099\n",
      "loss in epoch 14 , step 8060 : 0.951383\n",
      "loss in epoch 14 , step 8080 : 0.628609\n",
      "loss in epoch 14 , step 8100 : 0.960288\n",
      "loss in epoch 14 , step 8120 : 0.520170\n",
      "loss in epoch 14 , step 8140 : 0.757232\n",
      "loss in epoch 14 , step 8160 : 1.757220\n",
      "loss in epoch 14 , step 8180 : 1.380552\n",
      "loss in epoch 14 , step 8200 : 0.068939\n",
      "loss in epoch 14 , step 8220 : 0.444690\n",
      "loss in epoch 14 , step 8240 : 0.572812\n",
      "loss in epoch 14 , step 8260 : 1.826448\n",
      "loss in epoch 14 , step 8280 : 0.643288\n",
      "loss in epoch 14 , step 8300 : 0.097948\n",
      "loss in epoch 14 , step 8320 : 1.267795\n",
      "loss in epoch 14 , step 8340 : 1.181674\n",
      "loss in epoch 14 , step 8360 : 0.237361\n",
      "loss in epoch 14 , step 8380 : 0.077138\n",
      "loss in epoch 14 , step 8400 : 1.877095\n",
      "loss in epoch 14 , step 8420 : 0.353332\n",
      "loss in epoch 14 , step 8440 : 0.013382\n",
      "loss in epoch 14 , step 8460 : 5.114471\n",
      "loss in epoch 14 , step 8480 : 0.079023\n",
      "loss in epoch 14 , step 8500 : 0.880957\n",
      "loss in epoch 14 , step 8520 : 0.968326\n",
      "loss in epoch 14 , step 8540 : 0.091731\n",
      "loss in epoch 14 , step 8560 : 1.129280\n",
      "loss in epoch 14 , step 8580 : 1.042919\n",
      "loss in epoch 14 , step 8600 : 1.677595\n",
      "loss in epoch 14 , step 8620 : 1.457820\n",
      "loss in epoch 14 , step 8640 : 1.371893\n",
      "loss in epoch 14 , step 8660 : 0.512490\n",
      "loss in epoch 14 , step 8680 : 0.600608\n",
      "loss in epoch 14 , step 8700 : 2.081563\n",
      "loss in epoch 14 , step 8720 : 0.961505\n",
      "loss in epoch 14 , step 8740 : 1.437842\n",
      "loss in epoch 14 , step 8760 : 0.477286\n",
      "loss in epoch 14 , step 8780 : 0.643827\n",
      "loss in epoch 14 , step 8800 : 0.422886\n",
      "loss in epoch 14 , step 8820 : 0.043972\n",
      "loss in epoch 14 , step 8840 : 0.256025\n",
      "loss in epoch 14 , step 8860 : 2.196671\n",
      "loss in epoch 14 , step 8880 : 0.617285\n",
      "loss in epoch 14 , step 8900 : 0.008980\n",
      "loss in epoch 14 , step 8920 : 2.085877\n",
      "loss in epoch 14 , step 8940 : 2.687040\n",
      "loss in epoch 14 , step 8960 : 0.754614\n",
      "loss in epoch 14 , step 8980 : 3.316369\n",
      "loss in epoch 14 , step 9000 : 0.356646\n",
      "loss in epoch 14 , step 9020 : 0.958511\n",
      "loss in epoch 14 , step 9040 : 1.284730\n",
      "loss in epoch 14 , step 9060 : 1.280705\n",
      "loss in epoch 14 , step 9080 : 3.584524\n",
      "loss in epoch 14 , step 9100 : 2.484416\n",
      "loss in epoch 14 , step 9120 : 3.133424\n",
      "loss in epoch 14 , step 9140 : 0.036695\n",
      "loss in epoch 14 , step 9160 : 0.700731\n",
      "loss in epoch 14 , step 9180 : 0.530401\n",
      "loss in epoch 14 , step 9200 : 0.944142\n",
      "loss in epoch 14 , step 9220 : 0.775686\n",
      "loss in epoch 14 , step 9240 : 1.781905\n",
      "loss in epoch 14 , step 9260 : 1.508806\n",
      "loss in epoch 14 , step 9280 : 0.023656\n",
      "loss in epoch 14 , step 9300 : 0.112394\n",
      "loss in epoch 14 , step 9320 : 1.042581\n",
      "loss in epoch 14 , step 9340 : 0.713849\n",
      "loss in epoch 14 , step 9360 : 0.555376\n",
      "loss in epoch 14 , step 9380 : 0.951334\n",
      "loss in epoch 14 , step 9400 : 1.857000\n",
      "loss in epoch 14 , step 9420 : 0.760152\n",
      "loss in epoch 14 , step 9440 : 1.307798\n",
      "loss in epoch 14 , step 9460 : 1.483976\n",
      "loss in epoch 14 , step 9480 : 2.145062\n",
      "loss in epoch 14 , step 9500 : 1.183130\n",
      "loss in epoch 14 , step 9520 : 0.804974\n",
      "loss in epoch 14 , step 9540 : 2.746437\n",
      "loss in epoch 14 , step 9560 : 0.737794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 14 , step 9580 : 0.003296\n",
      "loss in epoch 14 , step 9600 : 1.349248\n",
      "loss in epoch 14 , step 9620 : 1.151333\n",
      "loss in epoch 14 , step 9640 : 0.918497\n",
      "loss in epoch 14 , step 9660 : 0.113750\n",
      "loss in epoch 14 , step 9680 : 0.031877\n",
      "loss in epoch 14 , step 9700 : 3.031692\n",
      "loss in epoch 14 , step 9720 : 0.006431\n",
      "loss in epoch 14 , step 9740 : 0.183309\n",
      "loss in epoch 14 , step 9760 : 1.958082\n",
      "loss in epoch 14 , step 9780 : 1.783348\n",
      "loss in epoch 14 , step 9800 : 2.006251\n",
      "loss in epoch 14 , step 9820 : 2.086224\n",
      "loss in epoch 14 , step 9840 : 0.251912\n",
      "loss in epoch 14 , step 9860 : 0.843245\n",
      "loss in epoch 14 , step 9880 : 3.524378\n",
      "loss in epoch 14 , step 9900 : 3.529861\n",
      "loss in epoch 14 , step 9920 : 0.033998\n",
      "loss in epoch 14 , step 9940 : 3.035872\n",
      "loss in epoch 14 , step 9960 : 0.005138\n",
      "loss in epoch 14 , step 9980 : 1.382411\n",
      "loss in epoch 14 , step 10000 : 0.601685\n",
      "loss in epoch 14 , step 10020 : 0.015311\n",
      "loss in epoch 14 , step 10040 : 0.033296\n",
      "loss in epoch 14 , step 10060 : 0.781279\n",
      "loss in epoch 14 , step 10080 : 0.762357\n",
      "loss in epoch 14 , step 10100 : 1.979718\n",
      "loss in epoch 14 , step 10120 : 3.071104\n",
      "loss in epoch 14 , step 10140 : 2.381523\n",
      "loss in epoch 14 , step 10160 : 0.573183\n",
      "loss in epoch 14 , step 10180 : 1.202834\n",
      "loss in epoch 14 , step 10200 : 4.808212\n",
      "loss in epoch 14 , step 10220 : 1.671817\n",
      "loss in epoch 14 , step 10240 : 0.313420\n",
      "loss in epoch 14 , step 10260 : 1.222737\n",
      "loss in epoch 14 , step 10280 : 2.230663\n",
      "loss in epoch 14 , step 10300 : 1.904501\n",
      "loss in epoch 14 , step 10320 : 0.800472\n",
      "loss in epoch 14 , step 10340 : 0.692714\n",
      "loss in epoch 14 , step 10360 : 0.550285\n",
      "loss in epoch 14 , step 10380 : 0.027019\n",
      "loss in epoch 14 , step 10400 : 0.304182\n",
      "loss in epoch 14 , step 10420 : 0.014321\n",
      "loss in epoch 14 , step 10440 : 0.071762\n",
      "loss in epoch 14 , step 10460 : 1.600384\n",
      "loss in epoch 14 , step 10480 : 0.863793\n",
      "loss in epoch 14 , step 10500 : 2.723532\n",
      "loss in epoch 14 , step 10520 : 1.937699\n",
      "loss in epoch 14 , step 10540 : 1.710082\n",
      "loss in epoch 14 , step 10560 : 1.048084\n",
      "loss in epoch 14 , step 10580 : 1.469158\n",
      "loss in epoch 14 , step 10600 : 0.249419\n",
      "loss in epoch 14 , step 10620 : 1.112779\n",
      "loss in epoch 14 , step 10640 : 1.439927\n",
      "loss in epoch 14 , step 10660 : 1.146460\n",
      "loss in epoch 14 , step 10680 : 1.218286\n",
      "loss in epoch 14 , step 10700 : 0.156703\n",
      "loss in epoch 14 , step 10720 : 0.062650\n",
      "loss in epoch 14 , step 10740 : 0.713004\n",
      "loss in epoch 14 , step 10760 : 0.317473\n",
      "loss in epoch 14 , step 10780 : 0.298865\n",
      "loss in epoch 14 , step 10800 : 0.510801\n",
      "loss in epoch 14 , step 10820 : 0.251584\n",
      "loss in epoch 14 , step 10840 : 1.114002\n",
      "loss in epoch 14 , step 10860 : 0.044364\n",
      "loss in epoch 14 , step 10880 : 1.986742\n",
      "loss in epoch 14 , step 10900 : 0.006704\n",
      "loss in epoch 14 , step 10920 : 2.338167\n",
      "loss in epoch 14 , step 10940 : 1.393096\n",
      "loss in epoch 14 , step 10960 : 1.695930\n",
      "loss in epoch 14 , step 10980 : 0.082153\n",
      "loss in epoch 14 , step 11000 : 1.138138\n",
      "loss in epoch 14 , step 11020 : 1.679820\n",
      "loss in epoch 14 , step 11040 : 1.850735\n",
      "loss in epoch 14 , step 11060 : 0.601674\n",
      "loss in epoch 14 , step 11080 : 0.003004\n",
      "loss in epoch 14 , step 11100 : 1.662808\n",
      "loss in epoch 14 , step 11120 : 2.260952\n",
      "loss in epoch 14 , step 11140 : 1.451138\n",
      "loss in epoch 14 , step 11160 : 2.436619\n",
      "loss in epoch 14 , step 11180 : 2.389719\n",
      "loss in epoch 14 , step 11200 : 2.166910\n",
      "loss in epoch 14 , step 11220 : 1.016673\n",
      "loss in epoch 14 , step 11240 : 1.379753\n",
      "loss in epoch 14 , step 11260 : 0.700491\n",
      "loss in epoch 14 , step 11280 : 0.009505\n",
      "loss in epoch 14 , step 11300 : 0.894908\n",
      "loss in epoch 14 , step 11320 : 1.012926\n",
      "loss in epoch 14 , step 11340 : 0.171512\n",
      "loss in epoch 14 , step 11360 : 0.005449\n",
      "loss in epoch 14 , step 11380 : 0.803860\n",
      "loss in epoch 14 , step 11400 : 1.149400\n",
      "loss in epoch 14 , step 11420 : 2.588157\n",
      "loss in epoch 14 , step 11440 : 0.914456\n",
      "loss in epoch 14 , step 11460 : 0.986667\n",
      "loss in epoch 14 , step 11480 : 1.516814\n",
      "loss in epoch 14 , step 11500 : 0.016592\n",
      "loss in epoch 14 , step 11520 : 1.662058\n",
      "loss in epoch 14 , step 11540 : 0.914764\n",
      "loss in epoch 14 , step 11560 : 1.903265\n",
      "loss in epoch 14 , step 11580 : 1.775240\n",
      "loss in epoch 14 , step 11600 : 2.041505\n",
      "loss in epoch 14 , step 11620 : 0.626276\n",
      "loss in epoch 14 , step 11640 : 0.864055\n",
      "loss in epoch 14 , step 11660 : 0.106223\n",
      "loss in epoch 14 , step 11680 : 0.053102\n",
      "loss in epoch 14 , step 11700 : 0.495718\n",
      "loss in epoch 14 , step 11720 : 1.026261\n",
      "loss in epoch 14 , step 11740 : 1.285406\n",
      "loss in epoch 14 , step 11760 : 0.057425\n",
      "loss in epoch 14 , step 11780 : 1.758430\n",
      "loss in epoch 14 , step 11800 : 0.032220\n",
      "loss in epoch 14 , step 11820 : 0.022611\n",
      "loss in epoch 14 , step 11840 : 4.936995\n",
      "loss in epoch 14 , step 11860 : 0.021054\n",
      "loss in epoch 14 , step 11880 : 1.369383\n",
      "loss in epoch 14 , step 11900 : 1.319403\n",
      "loss in epoch 14 , step 11920 : 0.985781\n",
      "loss in epoch 14 , step 11940 : 3.353460\n",
      "loss in epoch 14 , step 11960 : 1.238487\n",
      "loss in epoch 14 , step 11980 : 1.191330\n",
      "loss in epoch 14 , step 12000 : 2.423508\n",
      "loss in epoch 14 , step 12020 : 1.151719\n",
      "loss in epoch 14 , step 12040 : 4.017105\n",
      "loss in epoch 14 , step 12060 : 0.671086\n",
      "loss in epoch 14 , step 12080 : 0.013827\n",
      "loss in epoch 14 , step 12100 : 0.377759\n",
      "loss in epoch 14 , step 12120 : 1.486604\n",
      "loss in epoch 14 , step 12140 : 0.400718\n",
      "loss in epoch 14 , step 12160 : 1.376310\n",
      "loss in epoch 14 , step 12180 : 0.654840\n",
      "loss in epoch 14 , step 12200 : 1.090763\n",
      "loss in epoch 14 , step 12220 : 1.129292\n",
      "loss in epoch 14 , step 12240 : 0.210187\n",
      "loss in epoch 14 , step 12260 : 0.889174\n",
      "loss in epoch 14 , step 12280 : 2.022334\n",
      "loss in epoch 14 , step 12300 : 0.510369\n",
      "loss in epoch 14 , step 12320 : 2.332312\n",
      "loss in epoch 14 , step 12340 : 2.017171\n",
      "loss in epoch 14 , step 12360 : 0.410475\n",
      "loss in epoch 14 , step 12380 : 0.257566\n",
      "loss in epoch 14 , step 12400 : 0.185702\n",
      "loss in epoch 14 , step 12420 : 0.085326\n",
      "loss in epoch 14 , step 12440 : 0.004159\n",
      "loss in epoch 14 , step 12460 : 0.543210\n",
      "loss in epoch 14 , step 12480 : 0.226424\n",
      "loss in epoch 14 , step 12500 : 1.641695\n",
      "loss in epoch 14 , step 12520 : 0.247180\n",
      "loss in epoch 14 , step 12540 : 0.001982\n",
      "loss in epoch 14 , step 12560 : 0.455374\n",
      "loss in epoch 14 , step 12580 : 0.999811\n",
      "loss in epoch 14 , step 12600 : 1.581802\n",
      "loss in epoch 14 , step 12620 : 1.378733\n",
      "loss in epoch 14 , step 12640 : 1.831770\n",
      "loss in epoch 14 , step 12660 : 1.324044\n",
      "loss in epoch 14 , step 12680 : 1.399352\n",
      "loss in epoch 14 , step 12700 : 0.028552\n",
      "loss in epoch 14 , step 12720 : 0.922312\n",
      "loss in epoch 14 , step 12740 : 1.263410\n",
      "loss in epoch 14 , step 12760 : 1.422713\n",
      "loss in epoch 14 , step 12780 : 0.099066\n",
      "loss in epoch 14 , step 12800 : 1.270192\n",
      "loss in epoch 14 , step 12820 : 1.443073\n",
      "loss in epoch 14 , step 12840 : 0.011755\n",
      "loss in epoch 14 , step 12860 : 1.403669\n",
      "loss in epoch 14 , step 12880 : 0.717952\n",
      "loss in epoch 14 , step 12900 : 1.574028\n",
      "loss in epoch 14 , step 12920 : 0.041341\n",
      "loss in epoch 14 , step 12940 : 0.028420\n",
      "loss in epoch 14 , step 12960 : 0.004382\n",
      "loss in epoch 14 , step 12980 : 2.439926\n",
      "loss in epoch 14 , step 13000 : 0.033838\n",
      "loss in epoch 14 , step 13020 : 0.452684\n",
      "loss in epoch 14 , step 13040 : 0.149918\n",
      "loss in epoch 14 , step 13060 : 0.099754\n",
      "loss in epoch 14 , step 13080 : 0.860834\n",
      "loss in epoch 14 , step 13100 : 3.414786\n",
      "loss in epoch 14 , step 13120 : 1.044519\n",
      "loss in epoch 14 , step 13140 : 1.915351\n",
      "loss in epoch 14 , step 13160 : 0.013627\n",
      "loss in epoch 14 , step 13180 : 1.671571\n",
      "loss in epoch 14 , step 13200 : 0.387254\n",
      "loss in epoch 14 , step 13220 : 0.144450\n",
      "loss in epoch 14 , step 13240 : 1.625946\n",
      "loss in epoch 14 , step 13260 : 0.934695\n",
      "loss in epoch 14 , step 13280 : 0.014952\n",
      "loss in epoch 14 , step 13300 : 0.506505\n",
      "loss in epoch 14 , step 13320 : 0.311357\n",
      "loss in epoch 14 , step 13340 : 1.174554\n",
      "loss in epoch 14 , step 13360 : 1.778448\n",
      "loss in epoch 14 , step 13380 : 0.037665\n",
      "loss in epoch 14 , step 13400 : 0.388459\n",
      "loss in epoch 14 , step 13420 : 1.649683\n",
      "loss in epoch 14 , step 13440 : 1.098448\n",
      "loss in epoch 14 , step 13460 : 0.002708\n",
      "loss in epoch 14 , step 13480 : 0.030888\n",
      "loss in epoch 14 , step 13500 : 0.086328\n",
      "loss in epoch 14 , step 13520 : 0.045846\n",
      "loss in epoch 14 , step 13540 : 0.010850\n",
      "loss in epoch 14 , step 13560 : 0.357883\n",
      "loss in epoch 14 , step 13580 : 0.155213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 14 , step 13600 : 0.603320\n",
      "loss in epoch 14 , step 13620 : 1.698002\n",
      "loss in epoch 14 , step 13640 : 0.297716\n",
      "loss in epoch 14 , step 13660 : 0.866419\n",
      "loss in epoch 14 , step 13680 : 0.076038\n",
      "loss in epoch 14 , step 13700 : 0.018495\n",
      "loss in epoch 14 , step 13720 : 0.006237\n",
      "loss in epoch 14 , step 13740 : 1.687970\n",
      "loss in epoch 14 , step 13760 : 0.218932\n",
      "loss in epoch 14 , step 13780 : 0.995677\n",
      "loss in epoch 14 , step 13800 : 1.677280\n",
      "loss in epoch 14 , step 13820 : 0.960339\n",
      "loss in epoch 14 , step 13840 : 0.333824\n",
      "loss in epoch 14 , step 13860 : 1.423588\n",
      "loss in epoch 14 , step 13880 : 1.389369\n",
      "loss in epoch 14 , step 13900 : 4.075866\n",
      "loss in epoch 14 , step 13920 : 0.017901\n",
      "loss in epoch 14 , step 13940 : 1.412702\n",
      "loss in epoch 14 , step 13960 : 0.154146\n",
      "loss in epoch 14 , step 13980 : 3.798291\n",
      "loss in epoch 14 , step 14000 : 1.354915\n",
      "loss in epoch 14 , step 14020 : 1.101187\n",
      "loss in epoch 14 , step 14040 : 1.693711\n",
      "loss in epoch 14 , step 14060 : 0.102735\n",
      "loss in epoch 14 , step 14080 : 0.964530\n",
      "loss in epoch 14 , step 14100 : 2.261130\n",
      "loss in epoch 14 , step 14120 : 1.313510\n",
      "loss in epoch 14 , step 14140 : 1.226268\n",
      "loss in epoch 14 , step 14160 : 0.209974\n",
      "loss in epoch 14 , step 14180 : 1.849900\n",
      "loss in epoch 14 , step 14200 : 1.330334\n",
      "loss in epoch 14 , step 14220 : 0.017662\n",
      "loss in epoch 14 , step 14240 : 0.468488\n",
      "loss in epoch 14 , step 14260 : 1.443671\n",
      "loss in epoch 14 , step 14280 : 1.419866\n",
      "loss in epoch 14 , step 14300 : 0.290975\n",
      "loss in epoch 14 , step 14320 : 1.509128\n",
      "loss in epoch 14 , step 14340 : 1.313896\n",
      "loss in epoch 14 , step 14360 : 1.319177\n",
      "loss in epoch 14 , step 14380 : 2.259480\n",
      "loss in epoch 14 , step 14400 : 0.139904\n",
      "loss in epoch 14 , step 14420 : 1.047366\n",
      "loss in epoch 14 , step 14440 : 1.439919\n",
      "loss in epoch 14 , step 14460 : 0.219054\n",
      "loss in epoch 14 , step 14480 : 0.155848\n",
      "loss in epoch 14 , step 14500 : 1.616703\n",
      "loss in epoch 14 , step 14520 : 0.285310\n",
      "loss in epoch 14 , step 14540 : 3.145900\n",
      "loss in epoch 14 , step 14560 : 0.376941\n",
      "loss in epoch 14 , step 14580 : 0.720735\n",
      "loss in epoch 14 , step 14600 : 1.334809\n",
      "loss in epoch 14 , step 14620 : 1.290105\n",
      "loss in epoch 14 , step 14640 : 4.535037\n",
      "loss in epoch 14 , step 14660 : 1.126079\n",
      "loss in epoch 14 , step 14680 : 0.747484\n",
      "loss in epoch 14 , step 14700 : 1.110294\n",
      "loss in epoch 14 , step 14720 : 1.894007\n",
      "loss in epoch 14 , step 14740 : 0.083551\n",
      "loss in epoch 14 , step 14760 : 0.577066\n",
      "loss in epoch 14 , step 14780 : 0.434608\n",
      "loss in epoch 14 , step 14800 : 1.426961\n",
      "loss in epoch 14 , step 14820 : 1.693061\n",
      "loss in epoch 14 , step 14840 : 0.963744\n",
      "loss in epoch 14 , step 14860 : 2.733683\n",
      "loss in epoch 14 , step 14880 : 0.382197\n",
      "loss in epoch 14 , step 14900 : 4.039764\n",
      "loss in epoch 14 , step 14920 : 2.238183\n",
      "loss in epoch 14 , step 14940 : 0.347168\n",
      "loss in epoch 14 , step 14960 : 0.785296\n",
      "loss in epoch 14 , step 14980 : 2.935577\n",
      "loss in epoch 14 , step 15000 : 2.965593\n",
      "loss in epoch 14 , step 15020 : 1.137269\n",
      "loss in epoch 14 , step 15040 : 1.191420\n",
      "loss in epoch 14 , step 15060 : 0.730263\n",
      "loss in epoch 14 , step 15080 : 0.022083\n",
      "loss in epoch 14 , step 15100 : 0.014247\n",
      "loss in epoch 14 , step 15120 : 1.638785\n",
      "loss in epoch 14 , step 15140 : 1.350421\n",
      "loss in epoch 14 , step 15160 : 0.967478\n",
      "loss in epoch 14 , step 15180 : 1.529529\n",
      "loss in epoch 14 , step 15200 : 1.413540\n",
      "loss in epoch 14 , step 15220 : 0.508223\n",
      "loss in epoch 14 , step 15240 : 1.595612\n",
      "loss in epoch 14 , step 15260 : 1.288268\n",
      "loss in epoch 14 , step 15280 : 0.230732\n",
      "loss in epoch 14 , step 15300 : 0.042566\n",
      "loss in epoch 14 , step 15320 : 0.655459\n",
      "loss in epoch 14 , step 15340 : 2.688868\n",
      "loss in epoch 14 , step 15360 : 0.081796\n",
      "loss in epoch 14 , step 15380 : 0.942045\n",
      "loss in epoch 14 , step 15400 : 1.122905\n",
      "loss in epoch 14 , step 15420 : 0.882035\n",
      "loss in epoch 14 , step 15440 : 0.757505\n",
      "loss in epoch 14 , step 15460 : 1.544529\n",
      "loss in epoch 14 , step 15480 : 0.016042\n",
      "loss in epoch 14 , step 15500 : 0.468309\n",
      "loss in epoch 14 , step 15520 : 0.027728\n",
      "loss in epoch 14 , step 15540 : 0.558660\n",
      "loss in epoch 14 , step 15560 : 0.247389\n",
      "loss in epoch 14 , step 15580 : 0.163448\n",
      "loss in epoch 14 , step 15600 : 1.042040\n",
      "loss in epoch 14 , step 15620 : 1.162719\n",
      "loss in epoch 14 , step 15640 : 2.567144\n",
      "loss in epoch 14 , step 15660 : 1.477125\n",
      "loss in epoch 14 , step 15680 : 0.038500\n",
      "loss in epoch 14 , step 15700 : 0.083654\n",
      "loss in epoch 14 , step 15720 : 1.679224\n",
      "loss in epoch 14 , step 15740 : 0.375550\n",
      "loss in epoch 14 , step 15760 : 0.825721\n",
      "loss in epoch 14 , step 15780 : 2.663108\n",
      "loss in epoch 14 , step 15800 : 0.827482\n",
      "loss in epoch 14 , step 15820 : 2.073815\n",
      "loss in epoch 14 , step 15840 : 0.348246\n",
      "loss in epoch 14 , step 15860 : 0.682529\n",
      "loss in epoch 14 , step 15880 : 0.305760\n",
      "loss in epoch 14 , step 15900 : 0.461759\n",
      "loss in epoch 14 , step 15920 : 1.827244\n",
      "loss in epoch 14 , step 15940 : 0.616430\n",
      "loss in epoch 14 , step 15960 : 0.836236\n",
      "loss in epoch 14 , step 15980 : 0.558853\n",
      "loss in epoch 14 , step 16000 : 1.066423\n",
      "loss in epoch 14 , step 16020 : 2.036294\n",
      "loss in epoch 14 , step 16040 : 0.334895\n",
      "loss in epoch 14 , step 16060 : 2.079104\n",
      "loss in epoch 14 , step 16080 : 0.171215\n",
      "loss in epoch 14 , step 16100 : 0.467008\n",
      "loss in epoch 14 , step 16120 : 1.282310\n",
      "loss in epoch 14 , step 16140 : 0.085570\n",
      "loss in epoch 14 , step 16160 : 0.054197\n",
      "loss in epoch 14 , step 16180 : 0.687078\n",
      "loss in epoch 14 , step 16200 : 0.432262\n",
      "loss in epoch 14 , step 16220 : 0.015233\n",
      "loss in epoch 14 , step 16240 : 1.114768\n",
      "loss in epoch 14 , step 16260 : 0.006389\n",
      "loss in epoch 14 , step 16280 : 1.734809\n",
      "loss in epoch 14 , step 16300 : 0.932318\n",
      "loss in epoch 14 , step 16320 : 0.306467\n",
      "loss in epoch 14 , step 16340 : 0.625544\n",
      "loss in epoch 14 , step 16360 : 0.047954\n",
      "loss in epoch 14 , step 16380 : 0.943587\n",
      "loss in epoch 14 , step 16400 : 1.044316\n",
      "loss in epoch 14 , step 16420 : 1.574953\n",
      "loss in epoch 14 , step 16440 : 0.336510\n",
      "loss in epoch 14 , step 16460 : 0.888767\n",
      "loss in epoch 14 , step 16480 : 0.543621\n",
      "loss in epoch 14 , step 16500 : 1.293787\n",
      "loss in epoch 14 , step 16520 : 1.266696\n",
      "loss in epoch 14 , step 16540 : 4.136631\n",
      "loss in epoch 14 , step 16560 : 0.351172\n",
      "loss in epoch 14 , step 16580 : 0.994485\n",
      "loss in epoch 14 , step 16600 : 0.251678\n",
      "loss in epoch 14 , step 16620 : 0.070864\n",
      "loss in epoch 14 , step 16640 : 1.332538\n",
      "loss in epoch 14 , step 16660 : 0.804172\n",
      "loss in epoch 14 , step 16680 : 0.510029\n",
      "loss in epoch 14 , step 16700 : 0.771144\n",
      "loss in epoch 14 , step 16720 : 0.011616\n",
      "loss in epoch 14 , step 16740 : 0.236545\n",
      "loss in epoch 14 , step 16760 : 0.929211\n",
      "loss in epoch 14 , step 16780 : 1.156818\n",
      "loss in epoch 14 , step 16800 : 0.920648\n",
      "loss in epoch 14 , step 16820 : 0.609424\n",
      "loss in epoch 14 , step 16840 : 0.761033\n",
      "loss in epoch 14 , step 16860 : 2.921031\n",
      "loss in epoch 14 , step 16880 : 1.362325\n",
      "loss in epoch 14 , step 16900 : 1.622769\n",
      "loss in epoch 14 , step 16920 : 0.810480\n",
      "loss in epoch 14 , step 16940 : 1.176862\n",
      "loss in epoch 14 , step 16960 : 2.314923\n",
      "loss in epoch 14 , step 16980 : 0.462834\n",
      "loss in epoch 14 , step 17000 : 0.646016\n",
      "loss in epoch 14 , step 17020 : 0.048958\n",
      "loss in epoch 14 , step 17040 : 0.571796\n",
      "loss in epoch 14 , step 17060 : 0.642015\n",
      "loss in epoch 14 , step 17080 : 1.177295\n",
      "loss in epoch 14 , step 17100 : 0.399496\n",
      "loss in epoch 14 , step 17120 : 0.556760\n",
      "loss in epoch 14 , step 17140 : 1.812209\n",
      "loss in epoch 14 , step 17160 : 0.517934\n",
      "loss in epoch 14 , step 17180 : 0.710472\n",
      "loss in epoch 14 , step 17200 : 0.507699\n",
      "loss in epoch 14 , step 17220 : 0.661793\n",
      "loss in epoch 14 , step 17240 : 0.015766\n",
      "loss in epoch 14 , step 17260 : 2.266324\n",
      "loss in epoch 14 , step 17280 : 1.798949\n",
      "loss in epoch 14 , step 17300 : 0.830932\n",
      "loss in epoch 14 , step 17320 : 0.728690\n",
      "loss in epoch 14 , step 17340 : 1.836836\n",
      "loss in epoch 14 , step 17360 : 1.123746\n",
      "loss in epoch 14 , step 17380 : 0.032501\n",
      "loss in epoch 14 , step 17400 : 0.747088\n",
      "loss in epoch 14 , step 17420 : 1.774013\n",
      "loss in epoch 14 , step 17440 : 0.852403\n",
      "loss in epoch 14 , step 17460 : 0.079627\n",
      "loss in epoch 14 , step 17480 : 1.992369\n",
      "loss in epoch 14 , step 17500 : 0.005012\n",
      "loss in epoch 14 , step 17520 : 1.996746\n",
      "loss in epoch 14 , step 17540 : 0.577188\n",
      "loss in epoch 14 , step 17560 : 0.714004\n",
      "loss in epoch 14 , step 17580 : 0.623481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 14 , step 17600 : 0.550815\n",
      "loss in epoch 14 , step 17620 : 4.009039\n",
      "loss in epoch 14 , step 17640 : 2.296684\n",
      "loss in epoch 14 , step 17660 : 0.941152\n",
      "loss in epoch 14 , step 17680 : 2.864108\n",
      "loss in epoch 14 , step 17700 : 0.123556\n",
      "loss in epoch 14 , step 17720 : 1.529798\n",
      "loss in epoch 14 , step 17740 : 0.249680\n",
      "loss in epoch 14 , step 17760 : 0.003051\n",
      "loss in epoch 14 , step 17780 : 1.992612\n",
      "loss in epoch 14 , step 17800 : 1.898039\n",
      "loss in epoch 14 , step 17820 : 0.351591\n",
      "loss in epoch 14 , step 17840 : 1.364622\n",
      "loss in epoch 14 , step 17860 : 0.684867\n",
      "loss in epoch 14 , step 17880 : 0.075759\n",
      "loss in epoch 14 , step 17900 : 1.571547\n",
      "loss in epoch 14 , step 17920 : 1.756301\n",
      "loss in epoch 14 , step 17940 : 1.358017\n",
      "loss in epoch 14 , step 17960 : 0.747587\n",
      "loss in epoch 14 , step 17980 : 0.788592\n",
      "loss in epoch 14 , step 18000 : 0.564227\n",
      "loss in epoch 14 , step 18020 : 0.963303\n",
      "loss in epoch 14 , step 18040 : 0.690738\n",
      "loss in epoch 14 , step 18060 : 1.584312\n",
      "loss in epoch 14 , step 18080 : 0.768707\n",
      "loss in epoch 14 , step 18100 : 3.121382\n",
      "loss in epoch 14 , step 18120 : 0.353956\n",
      "loss in epoch 14 , step 18140 : 0.008569\n",
      "loss in epoch 14 , step 18160 : 0.015305\n",
      "loss in epoch 14 , step 18180 : 2.176451\n",
      "loss in epoch 14 , step 18200 : 0.605738\n",
      "loss in epoch 14 , step 18220 : 0.722627\n",
      "loss in epoch 14 , step 18240 : 0.469931\n",
      "loss in epoch 14 , step 18260 : 0.795726\n",
      "loss in epoch 14 , step 18280 : 1.574773\n",
      "loss in epoch 14 , step 18300 : 0.446356\n",
      "loss in epoch 14 , step 18320 : 0.078874\n",
      "loss in epoch 14 , step 18340 : 1.013299\n",
      "loss in epoch 14 , step 18360 : 0.142050\n",
      "loss in epoch 14 , step 18380 : 0.961634\n",
      "loss in epoch 14 , step 18400 : 2.091843\n",
      "loss in epoch 14 , step 18420 : 0.013195\n",
      "loss in epoch 14 , step 18440 : 0.731764\n",
      "loss in epoch 14 , step 18460 : 0.666200\n",
      "loss in epoch 14 , step 18480 : 2.796598\n",
      "loss in epoch 14 , step 18500 : 2.117255\n",
      "loss in epoch 14 , step 18520 : 0.154466\n",
      "loss in epoch 14 , step 18540 : 3.522885\n",
      "loss in epoch 14 , step 18560 : 1.210381\n",
      "loss in epoch 14 , step 18580 : 1.681550\n",
      "loss in epoch 14 , step 18600 : 0.441888\n",
      "loss in epoch 14 , step 18620 : 0.008793\n",
      "loss in epoch 14 , step 18640 : 3.270142\n",
      "loss in epoch 14 , step 18660 : 1.232927\n",
      "loss in epoch 14 , step 18680 : 0.411036\n",
      "loss in epoch 14 , step 18700 : 0.975048\n",
      "loss in epoch 14 , step 18720 : 3.871741\n",
      "loss in epoch 14 , step 18740 : 1.230067\n",
      "loss in epoch 14 , step 18760 : 0.491656\n",
      "loss in epoch 14 , step 18780 : 1.305821\n",
      "loss in epoch 14 , step 18800 : 1.349201\n",
      "loss in epoch 14 , step 18820 : 0.841952\n",
      "loss in epoch 14 , step 18840 : 0.619670\n",
      "loss in epoch 14 , step 18860 : 1.525136\n",
      "loss in epoch 14 , step 18880 : 1.921542\n",
      "loss in epoch 14 , step 18900 : 3.010078\n",
      "loss in epoch 14 , step 18920 : 2.420481\n",
      "loss in epoch 14 , step 18940 : 1.026031\n",
      "loss in epoch 14 , step 18960 : 0.296195\n",
      "loss in epoch 14 , step 18980 : 0.743064\n",
      "loss in epoch 14 , step 19000 : 0.373717\n",
      "loss in epoch 14 , step 19020 : 1.236407\n",
      "loss in epoch 14 , step 19040 : 0.941627\n",
      "loss in epoch 14 , step 19060 : 2.236111\n",
      "loss in epoch 14 , step 19080 : 0.017173\n",
      "loss in epoch 14 , step 19100 : 1.538773\n",
      "loss in epoch 14 , step 19120 : 0.575741\n",
      "loss in epoch 14 , step 19140 : 0.824504\n",
      "loss in epoch 14 , step 19160 : 1.308809\n",
      "loss in epoch 14 , step 19180 : 1.028697\n",
      "loss in epoch 14 , step 19200 : 0.951100\n",
      "loss in epoch 14 , step 19220 : 1.549994\n",
      "loss in epoch 14 , step 19240 : 0.218507\n",
      "loss in epoch 14 , step 19260 : 0.111518\n",
      "loss in epoch 14 , step 19280 : 6.402201\n",
      "loss in epoch 14 , step 19300 : 0.149142\n",
      "loss in epoch 14 , step 19320 : 0.402337\n",
      "loss in epoch 14 , step 19340 : 2.064934\n",
      "loss in epoch 14 , step 19360 : 0.105733\n",
      "loss in epoch 14 , step 19380 : 3.520190\n",
      "loss in epoch 14 , step 19400 : 0.213719\n",
      "loss in epoch 14 , step 19420 : 1.287435\n",
      "loss in epoch 14 , step 19440 : 1.193103\n",
      "loss in epoch 14 , step 19460 : 0.036638\n",
      "loss in epoch 14 , step 19480 : 0.802877\n",
      "loss in epoch 14 , step 19500 : 0.695549\n",
      "loss in epoch 14 , step 19520 : 0.502209\n",
      "loss in epoch 14 , step 19540 : 3.697041\n",
      "loss in epoch 14 , step 19560 : 0.020415\n",
      "loss in epoch 14 , step 19580 : 1.180852\n",
      "loss in epoch 14 , step 19600 : 0.701228\n",
      "loss in epoch 14 , step 19620 : 0.755684\n",
      "loss in epoch 14 , step 19640 : 0.013793\n",
      "loss in epoch 14 , step 19660 : 2.147818\n",
      "loss in epoch 14 , step 19680 : 0.830862\n",
      "loss in epoch 14 , step 19700 : 3.177088\n",
      "loss in epoch 14 , step 19720 : 0.395438\n",
      "loss in epoch 14 , step 19740 : 1.468979\n",
      "loss in epoch 14 , step 19760 : 0.789178\n",
      "loss in epoch 14 , step 19780 : 0.141197\n",
      "loss in epoch 14 , step 19800 : 0.361749\n",
      "loss in epoch 14 , step 19820 : 0.050344\n",
      "loss in epoch 14 , step 19840 : 0.003521\n",
      "loss in epoch 14 , step 19860 : 0.830042\n",
      "loss in epoch 14 , step 19880 : 0.396471\n",
      "loss in epoch 14 , step 19900 : 2.725796\n",
      "loss in epoch 14 , step 19920 : 0.037087\n",
      "loss in epoch 14 , step 19940 : 1.280019\n",
      "Accuracy in epoch 14 : 29.286798\n",
      "loss in epoch 15 , step 0 : 1.282414\n",
      "loss in epoch 15 , step 20 : 1.440677\n",
      "loss in epoch 15 , step 40 : 0.340583\n",
      "loss in epoch 15 , step 60 : 1.512312\n",
      "loss in epoch 15 , step 80 : 1.269104\n",
      "loss in epoch 15 , step 100 : 1.701794\n",
      "loss in epoch 15 , step 120 : 0.136754\n",
      "loss in epoch 15 , step 140 : 0.024508\n",
      "loss in epoch 15 , step 160 : 0.717950\n",
      "loss in epoch 15 , step 180 : 0.717185\n",
      "loss in epoch 15 , step 200 : 0.934185\n",
      "loss in epoch 15 , step 220 : 0.903205\n",
      "loss in epoch 15 , step 240 : 0.046398\n",
      "loss in epoch 15 , step 260 : 0.862854\n",
      "loss in epoch 15 , step 280 : 0.092535\n",
      "loss in epoch 15 , step 300 : 0.357651\n",
      "loss in epoch 15 , step 320 : 1.889637\n",
      "loss in epoch 15 , step 340 : 0.352688\n",
      "loss in epoch 15 , step 360 : 0.069875\n",
      "loss in epoch 15 , step 380 : 1.152367\n",
      "loss in epoch 15 , step 400 : 0.909385\n",
      "loss in epoch 15 , step 420 : 0.457615\n",
      "loss in epoch 15 , step 440 : 0.226308\n",
      "loss in epoch 15 , step 460 : 2.320199\n",
      "loss in epoch 15 , step 480 : 0.730246\n",
      "loss in epoch 15 , step 500 : 0.832736\n",
      "loss in epoch 15 , step 520 : 1.647570\n",
      "loss in epoch 15 , step 540 : 0.009722\n",
      "loss in epoch 15 , step 560 : 0.757457\n",
      "loss in epoch 15 , step 580 : 0.587104\n",
      "loss in epoch 15 , step 600 : 0.257355\n",
      "loss in epoch 15 , step 620 : 0.438005\n",
      "loss in epoch 15 , step 640 : 0.051118\n",
      "loss in epoch 15 , step 660 : 0.059966\n",
      "loss in epoch 15 , step 680 : 0.370622\n",
      "loss in epoch 15 , step 700 : 0.737029\n",
      "loss in epoch 15 , step 720 : 0.011652\n",
      "loss in epoch 15 , step 740 : 1.236703\n",
      "loss in epoch 15 , step 760 : 0.043714\n",
      "loss in epoch 15 , step 780 : 2.439954\n",
      "loss in epoch 15 , step 800 : 0.346156\n",
      "loss in epoch 15 , step 820 : 0.833612\n",
      "loss in epoch 15 , step 840 : 0.989184\n",
      "loss in epoch 15 , step 860 : 0.043959\n",
      "loss in epoch 15 , step 880 : 0.388397\n",
      "loss in epoch 15 , step 900 : 0.571738\n",
      "loss in epoch 15 , step 920 : 0.614130\n",
      "loss in epoch 15 , step 940 : 0.942847\n",
      "loss in epoch 15 , step 960 : 1.203361\n",
      "loss in epoch 15 , step 980 : 0.001509\n",
      "loss in epoch 15 , step 1000 : 0.017269\n",
      "loss in epoch 15 , step 1020 : 0.846404\n",
      "loss in epoch 15 , step 1040 : 0.493216\n",
      "loss in epoch 15 , step 1060 : 0.650936\n",
      "loss in epoch 15 , step 1080 : 0.017133\n",
      "loss in epoch 15 , step 1100 : 0.718566\n",
      "loss in epoch 15 , step 1120 : 0.873139\n",
      "loss in epoch 15 , step 1140 : 0.926240\n",
      "loss in epoch 15 , step 1160 : 1.434608\n",
      "loss in epoch 15 , step 1180 : 0.121830\n",
      "loss in epoch 15 , step 1200 : 0.006820\n",
      "loss in epoch 15 , step 1220 : 1.121821\n",
      "loss in epoch 15 , step 1240 : 1.366733\n",
      "loss in epoch 15 , step 1260 : 1.207241\n",
      "loss in epoch 15 , step 1280 : 0.159197\n",
      "loss in epoch 15 , step 1300 : 1.119542\n",
      "loss in epoch 15 , step 1320 : 0.945848\n",
      "loss in epoch 15 , step 1340 : 1.835795\n",
      "loss in epoch 15 , step 1360 : 1.341119\n",
      "loss in epoch 15 , step 1380 : 2.264586\n",
      "loss in epoch 15 , step 1400 : 0.030803\n",
      "loss in epoch 15 , step 1420 : 0.925927\n",
      "loss in epoch 15 , step 1440 : 0.319688\n",
      "loss in epoch 15 , step 1460 : 1.311591\n",
      "loss in epoch 15 , step 1480 : 1.927418\n",
      "loss in epoch 15 , step 1500 : 0.018321\n",
      "loss in epoch 15 , step 1520 : 0.010244\n",
      "loss in epoch 15 , step 1540 : 0.757671\n",
      "loss in epoch 15 , step 1560 : 1.378182\n",
      "loss in epoch 15 , step 1580 : 0.091918\n",
      "loss in epoch 15 , step 1600 : 1.721611\n",
      "loss in epoch 15 , step 1620 : 1.727488\n",
      "loss in epoch 15 , step 1640 : 0.018857\n",
      "loss in epoch 15 , step 1660 : 0.006621\n",
      "loss in epoch 15 , step 1680 : 1.291697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 15 , step 1700 : 0.416615\n",
      "loss in epoch 15 , step 1720 : 0.547402\n",
      "loss in epoch 15 , step 1740 : 1.892255\n",
      "loss in epoch 15 , step 1760 : 0.517280\n",
      "loss in epoch 15 , step 1780 : 2.150737\n",
      "loss in epoch 15 , step 1800 : 0.008352\n",
      "loss in epoch 15 , step 1820 : 0.205468\n",
      "loss in epoch 15 , step 1840 : 1.033967\n",
      "loss in epoch 15 , step 1860 : 0.425099\n",
      "loss in epoch 15 , step 1880 : 2.282328\n",
      "loss in epoch 15 , step 1900 : 0.043687\n",
      "loss in epoch 15 , step 1920 : 0.445091\n",
      "loss in epoch 15 , step 1940 : 0.557107\n",
      "loss in epoch 15 , step 1960 : 0.769212\n",
      "loss in epoch 15 , step 1980 : 0.807160\n",
      "loss in epoch 15 , step 2000 : 2.150247\n",
      "loss in epoch 15 , step 2020 : 0.284899\n",
      "loss in epoch 15 , step 2040 : 0.832290\n",
      "loss in epoch 15 , step 2060 : 1.329540\n",
      "loss in epoch 15 , step 2080 : 0.703658\n",
      "loss in epoch 15 , step 2100 : 0.790084\n",
      "loss in epoch 15 , step 2120 : 0.009119\n",
      "loss in epoch 15 , step 2140 : 2.533909\n",
      "loss in epoch 15 , step 2160 : 1.610391\n",
      "loss in epoch 15 , step 2180 : 1.058389\n",
      "loss in epoch 15 , step 2200 : 0.084968\n",
      "loss in epoch 15 , step 2220 : 0.179952\n",
      "loss in epoch 15 , step 2240 : 0.013566\n",
      "loss in epoch 15 , step 2260 : 0.153053\n",
      "loss in epoch 15 , step 2280 : 0.994571\n",
      "loss in epoch 15 , step 2300 : 0.056107\n",
      "loss in epoch 15 , step 2320 : 1.142242\n",
      "loss in epoch 15 , step 2340 : 0.974583\n",
      "loss in epoch 15 , step 2360 : 0.169020\n",
      "loss in epoch 15 , step 2380 : 0.963655\n",
      "loss in epoch 15 , step 2400 : 0.712792\n",
      "loss in epoch 15 , step 2420 : 0.091966\n",
      "loss in epoch 15 , step 2440 : 0.534806\n",
      "loss in epoch 15 , step 2460 : 0.004734\n",
      "loss in epoch 15 , step 2480 : 1.249382\n",
      "loss in epoch 15 , step 2500 : 0.415495\n",
      "loss in epoch 15 , step 2520 : 0.478451\n",
      "loss in epoch 15 , step 2540 : 0.785638\n",
      "loss in epoch 15 , step 2560 : 1.366614\n",
      "loss in epoch 15 , step 2580 : 0.854388\n",
      "loss in epoch 15 , step 2600 : 1.725881\n",
      "loss in epoch 15 , step 2620 : 1.532768\n",
      "loss in epoch 15 , step 2640 : 0.494256\n",
      "loss in epoch 15 , step 2660 : 0.949520\n",
      "loss in epoch 15 , step 2680 : 0.964300\n",
      "loss in epoch 15 , step 2700 : 0.044385\n",
      "loss in epoch 15 , step 2720 : 1.700890\n",
      "loss in epoch 15 , step 2740 : 1.830052\n",
      "loss in epoch 15 , step 2760 : 1.370011\n",
      "loss in epoch 15 , step 2780 : 0.071896\n",
      "loss in epoch 15 , step 2800 : 2.162937\n",
      "loss in epoch 15 , step 2820 : 0.432047\n",
      "loss in epoch 15 , step 2840 : 0.018089\n",
      "loss in epoch 15 , step 2860 : 1.712768\n",
      "loss in epoch 15 , step 2880 : 0.494835\n",
      "loss in epoch 15 , step 2900 : 0.385584\n",
      "loss in epoch 15 , step 2920 : 0.018933\n",
      "loss in epoch 15 , step 2940 : 1.477996\n",
      "loss in epoch 15 , step 2960 : 0.001493\n",
      "loss in epoch 15 , step 2980 : 0.008270\n",
      "loss in epoch 15 , step 3000 : 0.357671\n",
      "loss in epoch 15 , step 3020 : 0.002268\n",
      "loss in epoch 15 , step 3040 : 0.637377\n",
      "loss in epoch 15 , step 3060 : 1.127478\n",
      "loss in epoch 15 , step 3080 : 2.397336\n",
      "loss in epoch 15 , step 3100 : 0.857761\n",
      "loss in epoch 15 , step 3120 : 0.027330\n",
      "loss in epoch 15 , step 3140 : 0.505514\n",
      "loss in epoch 15 , step 3160 : 1.682183\n",
      "loss in epoch 15 , step 3180 : 2.489231\n",
      "loss in epoch 15 , step 3200 : 0.060778\n",
      "loss in epoch 15 , step 3220 : 0.300898\n",
      "loss in epoch 15 , step 3240 : 0.018155\n",
      "loss in epoch 15 , step 3260 : 0.124440\n",
      "loss in epoch 15 , step 3280 : 1.320791\n",
      "loss in epoch 15 , step 3300 : 0.722609\n",
      "loss in epoch 15 , step 3320 : 0.339032\n",
      "loss in epoch 15 , step 3340 : 1.024256\n",
      "loss in epoch 15 , step 3360 : 0.741295\n",
      "loss in epoch 15 , step 3380 : 0.112952\n",
      "loss in epoch 15 , step 3400 : 0.199148\n",
      "loss in epoch 15 , step 3420 : 1.022764\n",
      "loss in epoch 15 , step 3440 : 0.799887\n",
      "loss in epoch 15 , step 3460 : 0.002952\n",
      "loss in epoch 15 , step 3480 : 0.014258\n",
      "loss in epoch 15 , step 3500 : 0.793813\n",
      "loss in epoch 15 , step 3520 : 0.094347\n",
      "loss in epoch 15 , step 3540 : 2.787828\n",
      "loss in epoch 15 , step 3560 : 0.957829\n",
      "loss in epoch 15 , step 3580 : 0.414649\n",
      "loss in epoch 15 , step 3600 : 0.547318\n",
      "loss in epoch 15 , step 3620 : 0.001684\n",
      "loss in epoch 15 , step 3640 : 0.004588\n",
      "loss in epoch 15 , step 3660 : 0.559527\n",
      "loss in epoch 15 , step 3680 : 1.416501\n",
      "loss in epoch 15 , step 3700 : 0.828116\n",
      "loss in epoch 15 , step 3720 : 0.175760\n",
      "loss in epoch 15 , step 3740 : 2.243776\n",
      "loss in epoch 15 , step 3760 : 1.377904\n",
      "loss in epoch 15 , step 3780 : 1.321598\n",
      "loss in epoch 15 , step 3800 : 1.403254\n",
      "loss in epoch 15 , step 3820 : 0.129118\n",
      "loss in epoch 15 , step 3840 : 1.395412\n",
      "loss in epoch 15 , step 3860 : 0.008617\n",
      "loss in epoch 15 , step 3880 : 0.221866\n",
      "loss in epoch 15 , step 3900 : 0.202281\n",
      "loss in epoch 15 , step 3920 : 0.346079\n",
      "loss in epoch 15 , step 3940 : 0.342005\n",
      "loss in epoch 15 , step 3960 : 0.081766\n",
      "loss in epoch 15 , step 3980 : 0.017967\n",
      "loss in epoch 15 , step 4000 : 0.227410\n",
      "loss in epoch 15 , step 4020 : 1.061094\n",
      "loss in epoch 15 , step 4040 : 1.803316\n",
      "loss in epoch 15 , step 4060 : 0.649936\n",
      "loss in epoch 15 , step 4080 : 1.602871\n",
      "loss in epoch 15 , step 4100 : 0.308576\n",
      "loss in epoch 15 , step 4120 : 0.850742\n",
      "loss in epoch 15 , step 4140 : 0.104734\n",
      "loss in epoch 15 , step 4160 : 0.878386\n",
      "loss in epoch 15 , step 4180 : 0.112842\n",
      "loss in epoch 15 , step 4200 : 0.742225\n",
      "loss in epoch 15 , step 4220 : 0.131147\n",
      "loss in epoch 15 , step 4240 : 0.176723\n",
      "loss in epoch 15 , step 4260 : 1.555440\n",
      "loss in epoch 15 , step 4280 : 0.231465\n",
      "loss in epoch 15 , step 4300 : 0.054107\n",
      "loss in epoch 15 , step 4320 : 0.518655\n",
      "loss in epoch 15 , step 4340 : 0.680431\n",
      "loss in epoch 15 , step 4360 : 0.790199\n",
      "loss in epoch 15 , step 4380 : 1.205595\n",
      "loss in epoch 15 , step 4400 : 1.102087\n",
      "loss in epoch 15 , step 4420 : 1.061334\n",
      "loss in epoch 15 , step 4440 : 0.009315\n",
      "loss in epoch 15 , step 4460 : 0.723276\n",
      "loss in epoch 15 , step 4480 : 0.347823\n",
      "loss in epoch 15 , step 4500 : 1.974332\n",
      "loss in epoch 15 , step 4520 : 0.012440\n",
      "loss in epoch 15 , step 4540 : 0.572175\n",
      "loss in epoch 15 , step 4560 : 2.042241\n",
      "loss in epoch 15 , step 4580 : 0.005627\n",
      "loss in epoch 15 , step 4600 : 0.143096\n",
      "loss in epoch 15 , step 4620 : 0.007138\n",
      "loss in epoch 15 , step 4640 : 0.940535\n",
      "loss in epoch 15 , step 4660 : 0.013234\n",
      "loss in epoch 15 , step 4680 : 0.005694\n",
      "loss in epoch 15 , step 4700 : 0.311694\n",
      "loss in epoch 15 , step 4720 : 1.773943\n",
      "loss in epoch 15 , step 4740 : 0.556023\n",
      "loss in epoch 15 , step 4760 : 0.497278\n",
      "loss in epoch 15 , step 4780 : 0.006032\n",
      "loss in epoch 15 , step 4800 : 0.691989\n",
      "loss in epoch 15 , step 4820 : 1.278297\n",
      "loss in epoch 15 , step 4840 : 1.120862\n",
      "loss in epoch 15 , step 4860 : 0.701785\n",
      "loss in epoch 15 , step 4880 : 2.605217\n",
      "loss in epoch 15 , step 4900 : 2.904169\n",
      "loss in epoch 15 , step 4920 : 0.044108\n",
      "loss in epoch 15 , step 4940 : 0.045642\n",
      "loss in epoch 15 , step 4960 : 0.178762\n",
      "loss in epoch 15 , step 4980 : 1.607298\n",
      "loss in epoch 15 , step 5000 : 0.007420\n",
      "loss in epoch 15 , step 5020 : 1.528038\n",
      "loss in epoch 15 , step 5040 : 0.345817\n",
      "loss in epoch 15 , step 5060 : 0.033526\n",
      "loss in epoch 15 , step 5080 : 1.553423\n",
      "loss in epoch 15 , step 5100 : 0.893471\n",
      "loss in epoch 15 , step 5120 : 0.521503\n",
      "loss in epoch 15 , step 5140 : 0.087932\n",
      "loss in epoch 15 , step 5160 : 0.798523\n",
      "loss in epoch 15 , step 5180 : 0.283907\n",
      "loss in epoch 15 , step 5200 : 0.361770\n",
      "loss in epoch 15 , step 5220 : 1.216627\n",
      "loss in epoch 15 , step 5240 : 0.797987\n",
      "loss in epoch 15 , step 5260 : 0.697374\n",
      "loss in epoch 15 , step 5280 : 0.249386\n",
      "loss in epoch 15 , step 5300 : 0.807354\n",
      "loss in epoch 15 , step 5320 : 0.011753\n",
      "loss in epoch 15 , step 5340 : 0.588825\n",
      "loss in epoch 15 , step 5360 : 0.035577\n",
      "loss in epoch 15 , step 5380 : 0.859558\n",
      "loss in epoch 15 , step 5400 : 0.014067\n",
      "loss in epoch 15 , step 5420 : 0.217799\n",
      "loss in epoch 15 , step 5440 : 0.027492\n",
      "loss in epoch 15 , step 5460 : 0.174158\n",
      "loss in epoch 15 , step 5480 : 0.400551\n",
      "loss in epoch 15 , step 5500 : 0.422938\n",
      "loss in epoch 15 , step 5520 : 4.232350\n",
      "loss in epoch 15 , step 5540 : 0.047944\n",
      "loss in epoch 15 , step 5560 : 0.173121\n",
      "loss in epoch 15 , step 5580 : 0.397382\n",
      "loss in epoch 15 , step 5600 : 0.175281\n",
      "loss in epoch 15 , step 5620 : 1.381162\n",
      "loss in epoch 15 , step 5640 : 0.003237\n",
      "loss in epoch 15 , step 5660 : 0.365908\n",
      "loss in epoch 15 , step 5680 : 0.870380\n",
      "loss in epoch 15 , step 5700 : 0.713654\n",
      "loss in epoch 15 , step 5720 : 0.568547\n",
      "loss in epoch 15 , step 5740 : 1.047623\n",
      "loss in epoch 15 , step 5760 : 0.621602\n",
      "loss in epoch 15 , step 5780 : 0.093134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 15 , step 5800 : 0.710002\n",
      "loss in epoch 15 , step 5820 : 0.627578\n",
      "loss in epoch 15 , step 5840 : 0.012235\n",
      "loss in epoch 15 , step 5860 : 0.401566\n",
      "loss in epoch 15 , step 5880 : 0.301852\n",
      "loss in epoch 15 , step 5900 : 0.691189\n",
      "loss in epoch 15 , step 5920 : 0.357490\n",
      "loss in epoch 15 , step 5940 : 1.164928\n",
      "loss in epoch 15 , step 5960 : 2.100707\n",
      "loss in epoch 15 , step 5980 : 0.007463\n",
      "loss in epoch 15 , step 6000 : 0.001484\n",
      "loss in epoch 15 , step 6020 : 0.006986\n",
      "loss in epoch 15 , step 6040 : 2.746641\n",
      "loss in epoch 15 , step 6060 : 0.027113\n",
      "loss in epoch 15 , step 6080 : 0.929033\n",
      "loss in epoch 15 , step 6100 : 0.566128\n",
      "loss in epoch 15 , step 6120 : 0.752615\n",
      "loss in epoch 15 , step 6140 : 0.004286\n",
      "loss in epoch 15 , step 6160 : 1.479924\n",
      "loss in epoch 15 , step 6180 : 0.160654\n",
      "loss in epoch 15 , step 6200 : 0.271335\n",
      "loss in epoch 15 , step 6220 : 1.009010\n",
      "loss in epoch 15 , step 6240 : 0.589422\n",
      "loss in epoch 15 , step 6260 : 0.045405\n",
      "loss in epoch 15 , step 6280 : 0.299570\n",
      "loss in epoch 15 , step 6300 : 0.493965\n",
      "loss in epoch 15 , step 6320 : 0.172538\n",
      "loss in epoch 15 , step 6340 : 0.248417\n",
      "loss in epoch 15 , step 6360 : 1.160029\n",
      "loss in epoch 15 , step 6380 : 0.655959\n",
      "loss in epoch 15 , step 6400 : 1.045014\n",
      "loss in epoch 15 , step 6420 : 1.852712\n",
      "loss in epoch 15 , step 6440 : 0.089972\n",
      "loss in epoch 15 , step 6460 : 0.986793\n",
      "loss in epoch 15 , step 6480 : 0.892138\n",
      "loss in epoch 15 , step 6500 : 0.735152\n",
      "loss in epoch 15 , step 6520 : 0.056554\n",
      "loss in epoch 15 , step 6540 : 0.060430\n",
      "loss in epoch 15 , step 6560 : 0.007283\n",
      "loss in epoch 15 , step 6580 : 1.472654\n",
      "loss in epoch 15 , step 6600 : 0.635040\n",
      "loss in epoch 15 , step 6620 : 1.332201\n",
      "loss in epoch 15 , step 6640 : 0.801866\n",
      "loss in epoch 15 , step 6660 : 0.600374\n",
      "loss in epoch 15 , step 6680 : 0.060679\n",
      "loss in epoch 15 , step 6700 : 0.000831\n",
      "loss in epoch 15 , step 6720 : 0.889554\n",
      "loss in epoch 15 , step 6740 : 0.018494\n",
      "loss in epoch 15 , step 6760 : 0.547075\n",
      "loss in epoch 15 , step 6780 : 1.049549\n",
      "loss in epoch 15 , step 6800 : 0.402716\n",
      "loss in epoch 15 , step 6820 : 0.148083\n",
      "loss in epoch 15 , step 6840 : 0.889943\n",
      "loss in epoch 15 , step 6860 : 0.359841\n",
      "loss in epoch 15 , step 6880 : 1.032651\n",
      "loss in epoch 15 , step 6900 : 1.520780\n",
      "loss in epoch 15 , step 6920 : 0.006056\n",
      "loss in epoch 15 , step 6940 : 0.170500\n",
      "loss in epoch 15 , step 6960 : 1.333827\n",
      "loss in epoch 15 , step 6980 : 0.513130\n",
      "loss in epoch 15 , step 7000 : 0.012506\n",
      "loss in epoch 15 , step 7020 : 0.915616\n",
      "loss in epoch 15 , step 7040 : 0.629121\n",
      "loss in epoch 15 , step 7060 : 1.926254\n",
      "loss in epoch 15 , step 7080 : 0.003232\n",
      "loss in epoch 15 , step 7100 : 2.051201\n",
      "loss in epoch 15 , step 7120 : 0.018099\n",
      "loss in epoch 15 , step 7140 : 0.747971\n",
      "loss in epoch 15 , step 7160 : 1.817772\n",
      "loss in epoch 15 , step 7180 : 0.935848\n",
      "loss in epoch 15 , step 7200 : 0.012224\n",
      "loss in epoch 15 , step 7220 : 4.472545\n",
      "loss in epoch 15 , step 7240 : 0.578241\n",
      "loss in epoch 15 , step 7260 : 0.044629\n",
      "loss in epoch 15 , step 7280 : 0.173449\n",
      "loss in epoch 15 , step 7300 : 0.769775\n",
      "loss in epoch 15 , step 7320 : 0.774778\n",
      "loss in epoch 15 , step 7340 : 0.318451\n",
      "loss in epoch 15 , step 7360 : 2.798251\n",
      "loss in epoch 15 , step 7380 : 0.506872\n",
      "loss in epoch 15 , step 7400 : 1.118760\n",
      "loss in epoch 15 , step 7420 : 0.341363\n",
      "loss in epoch 15 , step 7440 : 0.076149\n",
      "loss in epoch 15 , step 7460 : 0.660991\n",
      "loss in epoch 15 , step 7480 : 0.287305\n",
      "loss in epoch 15 , step 7500 : 0.043062\n",
      "loss in epoch 15 , step 7520 : 0.655264\n",
      "loss in epoch 15 , step 7540 : 0.850109\n",
      "loss in epoch 15 , step 7560 : 0.011398\n",
      "loss in epoch 15 , step 7580 : 0.077225\n",
      "loss in epoch 15 , step 7600 : 0.883405\n",
      "loss in epoch 15 , step 7620 : 1.168105\n",
      "loss in epoch 15 , step 7640 : 1.410363\n",
      "loss in epoch 15 , step 7660 : 0.039462\n",
      "loss in epoch 15 , step 7680 : 0.152305\n",
      "loss in epoch 15 , step 7700 : 0.741646\n",
      "loss in epoch 15 , step 7720 : 0.025693\n",
      "loss in epoch 15 , step 7740 : 1.460703\n",
      "loss in epoch 15 , step 7760 : 1.044493\n",
      "loss in epoch 15 , step 7780 : 1.830328\n",
      "loss in epoch 15 , step 7800 : 0.099585\n",
      "loss in epoch 15 , step 7820 : 0.298983\n",
      "loss in epoch 15 , step 7840 : 0.811481\n",
      "loss in epoch 15 , step 7860 : 0.367099\n",
      "loss in epoch 15 , step 7880 : 0.017674\n",
      "loss in epoch 15 , step 7900 : 0.015442\n",
      "loss in epoch 15 , step 7920 : 0.054186\n",
      "loss in epoch 15 , step 7940 : 0.027612\n",
      "loss in epoch 15 , step 7960 : 4.771257\n",
      "loss in epoch 15 , step 7980 : 2.493985\n",
      "loss in epoch 15 , step 8000 : 0.331124\n",
      "loss in epoch 15 , step 8020 : 1.077771\n",
      "loss in epoch 15 , step 8040 : 0.371431\n",
      "loss in epoch 15 , step 8060 : 0.024909\n",
      "loss in epoch 15 , step 8080 : 0.706082\n",
      "loss in epoch 15 , step 8100 : 0.808003\n",
      "loss in epoch 15 , step 8120 : 0.791335\n",
      "loss in epoch 15 , step 8140 : 0.126508\n",
      "loss in epoch 15 , step 8160 : 1.327040\n",
      "loss in epoch 15 , step 8180 : 1.358917\n",
      "loss in epoch 15 , step 8200 : 1.525392\n",
      "loss in epoch 15 , step 8220 : 0.369629\n",
      "loss in epoch 15 , step 8240 : 1.577181\n",
      "loss in epoch 15 , step 8260 : 0.723688\n",
      "loss in epoch 15 , step 8280 : 0.085968\n",
      "loss in epoch 15 , step 8300 : 1.884568\n",
      "loss in epoch 15 , step 8320 : 0.925155\n",
      "loss in epoch 15 , step 8340 : 0.074253\n",
      "loss in epoch 15 , step 8360 : 2.074414\n",
      "loss in epoch 15 , step 8380 : 0.596703\n",
      "loss in epoch 15 , step 8400 : 0.258312\n",
      "loss in epoch 15 , step 8420 : 1.134462\n",
      "loss in epoch 15 , step 8440 : 0.989048\n",
      "loss in epoch 15 , step 8460 : 0.012595\n",
      "loss in epoch 15 , step 8480 : 0.431075\n",
      "loss in epoch 15 , step 8500 : 0.558290\n",
      "loss in epoch 15 , step 8520 : 2.315145\n",
      "loss in epoch 15 , step 8540 : 0.365717\n",
      "loss in epoch 15 , step 8560 : 0.392145\n",
      "loss in epoch 15 , step 8580 : 1.710439\n",
      "loss in epoch 15 , step 8600 : 0.213613\n",
      "loss in epoch 15 , step 8620 : 1.504763\n",
      "loss in epoch 15 , step 8640 : 2.468837\n",
      "loss in epoch 15 , step 8660 : 1.244437\n",
      "loss in epoch 15 , step 8680 : 0.005560\n",
      "loss in epoch 15 , step 8700 : 1.268276\n",
      "loss in epoch 15 , step 8720 : 0.021806\n",
      "loss in epoch 15 , step 8740 : 0.779910\n",
      "loss in epoch 15 , step 8760 : 0.485465\n",
      "loss in epoch 15 , step 8780 : 1.445953\n",
      "loss in epoch 15 , step 8800 : 0.119340\n",
      "loss in epoch 15 , step 8820 : 0.163794\n",
      "loss in epoch 15 , step 8840 : 0.039892\n",
      "loss in epoch 15 , step 8860 : 0.472115\n",
      "loss in epoch 15 , step 8880 : 0.241530\n",
      "loss in epoch 15 , step 8900 : 0.347270\n",
      "loss in epoch 15 , step 8920 : 1.242772\n",
      "loss in epoch 15 , step 8940 : 0.379515\n",
      "loss in epoch 15 , step 8960 : 1.735917\n",
      "loss in epoch 15 , step 8980 : 1.004335\n",
      "loss in epoch 15 , step 9000 : 0.738022\n",
      "loss in epoch 15 , step 9020 : 0.959739\n",
      "loss in epoch 15 , step 9040 : 1.345677\n",
      "loss in epoch 15 , step 9060 : 0.263170\n",
      "loss in epoch 15 , step 9080 : 0.273083\n",
      "loss in epoch 15 , step 9100 : 1.143686\n",
      "loss in epoch 15 , step 9120 : 1.963206\n",
      "loss in epoch 15 , step 9140 : 0.024652\n",
      "loss in epoch 15 , step 9160 : 0.361351\n",
      "loss in epoch 15 , step 9180 : 0.159946\n",
      "loss in epoch 15 , step 9200 : 0.465845\n",
      "loss in epoch 15 , step 9220 : 2.494143\n",
      "loss in epoch 15 , step 9240 : 0.330283\n",
      "loss in epoch 15 , step 9260 : 0.139750\n",
      "loss in epoch 15 , step 9280 : 0.004949\n",
      "loss in epoch 15 , step 9300 : 1.081312\n",
      "loss in epoch 15 , step 9320 : 1.114807\n",
      "loss in epoch 15 , step 9340 : 0.111304\n",
      "loss in epoch 15 , step 9360 : 0.467537\n",
      "loss in epoch 15 , step 9380 : 0.269506\n",
      "loss in epoch 15 , step 9400 : 1.631732\n",
      "loss in epoch 15 , step 9420 : 0.014777\n",
      "loss in epoch 15 , step 9440 : 1.177213\n",
      "loss in epoch 15 , step 9460 : 0.215575\n",
      "loss in epoch 15 , step 9480 : 0.838846\n",
      "loss in epoch 15 , step 9500 : 3.285992\n",
      "loss in epoch 15 , step 9520 : 0.377714\n",
      "loss in epoch 15 , step 9540 : 0.155010\n",
      "loss in epoch 15 , step 9560 : 0.235688\n",
      "loss in epoch 15 , step 9580 : 0.040380\n",
      "loss in epoch 15 , step 9600 : 0.489912\n",
      "loss in epoch 15 , step 9620 : 2.151783\n",
      "loss in epoch 15 , step 9640 : 0.004101\n",
      "loss in epoch 15 , step 9660 : 0.258315\n",
      "loss in epoch 15 , step 9680 : 1.360898\n",
      "loss in epoch 15 , step 9700 : 3.192991\n",
      "loss in epoch 15 , step 9720 : 0.660117\n",
      "loss in epoch 15 , step 9740 : 2.694378\n",
      "loss in epoch 15 , step 9760 : 2.657382\n",
      "loss in epoch 15 , step 9780 : 1.002179\n",
      "loss in epoch 15 , step 9800 : 0.381963\n",
      "loss in epoch 15 , step 9820 : 1.199473\n",
      "loss in epoch 15 , step 9840 : 0.197780\n",
      "loss in epoch 15 , step 9860 : 1.067232\n",
      "loss in epoch 15 , step 9880 : 0.997050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 15 , step 9900 : 1.451741\n",
      "loss in epoch 15 , step 9920 : 0.021194\n",
      "loss in epoch 15 , step 9940 : 0.984077\n",
      "loss in epoch 15 , step 9960 : 1.048781\n",
      "loss in epoch 15 , step 9980 : 0.388719\n",
      "loss in epoch 15 , step 10000 : 0.002376\n",
      "loss in epoch 15 , step 10020 : 0.687736\n",
      "loss in epoch 15 , step 10040 : 1.188417\n",
      "loss in epoch 15 , step 10060 : 2.748339\n",
      "loss in epoch 15 , step 10080 : 0.750766\n",
      "loss in epoch 15 , step 10100 : 0.614372\n",
      "loss in epoch 15 , step 10120 : 0.088583\n",
      "loss in epoch 15 , step 10140 : 0.539450\n",
      "loss in epoch 15 , step 10160 : 0.765240\n",
      "loss in epoch 15 , step 10180 : 0.190916\n",
      "loss in epoch 15 , step 10200 : 0.394586\n",
      "loss in epoch 15 , step 10220 : 0.110664\n",
      "loss in epoch 15 , step 10240 : 0.525881\n",
      "loss in epoch 15 , step 10260 : 1.529510\n",
      "loss in epoch 15 , step 10280 : 1.808240\n",
      "loss in epoch 15 , step 10300 : 0.090221\n",
      "loss in epoch 15 , step 10320 : 0.192114\n",
      "loss in epoch 15 , step 10340 : 1.275499\n",
      "loss in epoch 15 , step 10360 : 0.775431\n",
      "loss in epoch 15 , step 10380 : 0.482614\n",
      "loss in epoch 15 , step 10400 : 0.626908\n",
      "loss in epoch 15 , step 10420 : 1.659080\n",
      "loss in epoch 15 , step 10440 : 1.533735\n",
      "loss in epoch 15 , step 10460 : 0.780205\n",
      "loss in epoch 15 , step 10480 : 0.934619\n",
      "loss in epoch 15 , step 10500 : 1.718297\n",
      "loss in epoch 15 , step 10520 : 0.390823\n",
      "loss in epoch 15 , step 10540 : 0.527181\n",
      "loss in epoch 15 , step 10560 : 0.341693\n",
      "loss in epoch 15 , step 10580 : 0.006800\n",
      "loss in epoch 15 , step 10600 : 0.207547\n",
      "loss in epoch 15 , step 10620 : 0.008856\n",
      "loss in epoch 15 , step 10640 : 0.751920\n",
      "loss in epoch 15 , step 10660 : 0.528765\n",
      "loss in epoch 15 , step 10680 : 0.004436\n",
      "loss in epoch 15 , step 10700 : 0.947929\n",
      "loss in epoch 15 , step 10720 : 1.642502\n",
      "loss in epoch 15 , step 10740 : 0.249656\n",
      "loss in epoch 15 , step 10760 : 0.153176\n",
      "loss in epoch 15 , step 10780 : 0.986126\n",
      "loss in epoch 15 , step 10800 : 0.734693\n",
      "loss in epoch 15 , step 10820 : 0.963064\n",
      "loss in epoch 15 , step 10840 : 0.972031\n",
      "loss in epoch 15 , step 10860 : 0.727179\n",
      "loss in epoch 15 , step 10880 : 0.059654\n",
      "loss in epoch 15 , step 10900 : 0.798707\n",
      "loss in epoch 15 , step 10920 : 0.578816\n",
      "loss in epoch 15 , step 10940 : 0.707454\n",
      "loss in epoch 15 , step 10960 : 0.031251\n",
      "loss in epoch 15 , step 10980 : 0.979818\n",
      "loss in epoch 15 , step 11000 : 0.520314\n",
      "loss in epoch 15 , step 11020 : 1.257594\n",
      "loss in epoch 15 , step 11040 : 0.461242\n",
      "loss in epoch 15 , step 11060 : 0.753068\n",
      "loss in epoch 15 , step 11080 : 1.561785\n",
      "loss in epoch 15 , step 11100 : 0.005935\n",
      "loss in epoch 15 , step 11120 : 1.306117\n",
      "loss in epoch 15 , step 11140 : 0.562703\n",
      "loss in epoch 15 , step 11160 : 0.249546\n",
      "loss in epoch 15 , step 11180 : 0.117368\n",
      "loss in epoch 15 , step 11200 : 0.004860\n",
      "loss in epoch 15 , step 11220 : 0.618459\n",
      "loss in epoch 15 , step 11240 : 1.274912\n",
      "loss in epoch 15 , step 11260 : 0.832315\n",
      "loss in epoch 15 , step 11280 : 1.881435\n",
      "loss in epoch 15 , step 11300 : 0.574402\n",
      "loss in epoch 15 , step 11320 : 0.332197\n",
      "loss in epoch 15 , step 11340 : 0.012670\n",
      "loss in epoch 15 , step 11360 : 0.816672\n",
      "loss in epoch 15 , step 11380 : 0.171228\n",
      "loss in epoch 15 , step 11400 : 2.179397\n",
      "loss in epoch 15 , step 11420 : 1.360808\n",
      "loss in epoch 15 , step 11440 : 0.853593\n",
      "loss in epoch 15 , step 11460 : 0.558851\n",
      "loss in epoch 15 , step 11480 : 0.253346\n",
      "loss in epoch 15 , step 11500 : 0.193050\n",
      "loss in epoch 15 , step 11520 : 0.356924\n",
      "loss in epoch 15 , step 11540 : 1.269847\n",
      "loss in epoch 15 , step 11560 : 0.021892\n",
      "loss in epoch 15 , step 11580 : 1.828561\n",
      "loss in epoch 15 , step 11600 : 0.480239\n",
      "loss in epoch 15 , step 11620 : 1.232103\n",
      "loss in epoch 15 , step 11640 : 2.743643\n",
      "loss in epoch 15 , step 11660 : 0.263210\n",
      "loss in epoch 15 , step 11680 : 0.973881\n",
      "loss in epoch 15 , step 11700 : 0.587724\n",
      "loss in epoch 15 , step 11720 : 1.452859\n",
      "loss in epoch 15 , step 11740 : 1.359938\n",
      "loss in epoch 15 , step 11760 : 2.132617\n",
      "loss in epoch 15 , step 11780 : 0.514260\n",
      "loss in epoch 15 , step 11800 : 0.002631\n",
      "loss in epoch 15 , step 11820 : 1.315470\n",
      "loss in epoch 15 , step 11840 : 0.338139\n",
      "loss in epoch 15 , step 11860 : 0.005056\n",
      "loss in epoch 15 , step 11880 : 0.706648\n",
      "loss in epoch 15 , step 11900 : 1.098954\n",
      "loss in epoch 15 , step 11920 : 0.002891\n",
      "loss in epoch 15 , step 11940 : 0.813900\n",
      "loss in epoch 15 , step 11960 : 1.111976\n",
      "loss in epoch 15 , step 11980 : 0.930465\n",
      "loss in epoch 15 , step 12000 : 0.039074\n",
      "loss in epoch 15 , step 12020 : 0.921149\n",
      "loss in epoch 15 , step 12040 : 0.734141\n",
      "loss in epoch 15 , step 12060 : 0.543714\n",
      "loss in epoch 15 , step 12080 : 0.970143\n",
      "loss in epoch 15 , step 12100 : 0.950880\n",
      "loss in epoch 15 , step 12120 : 0.040555\n",
      "loss in epoch 15 , step 12140 : 0.945743\n",
      "loss in epoch 15 , step 12160 : 0.909748\n",
      "loss in epoch 15 , step 12180 : 0.807305\n",
      "loss in epoch 15 , step 12200 : 0.007334\n",
      "loss in epoch 15 , step 12220 : 0.028543\n",
      "loss in epoch 15 , step 12240 : 0.098138\n",
      "loss in epoch 15 , step 12260 : 1.939539\n",
      "loss in epoch 15 , step 12280 : 1.231974\n",
      "loss in epoch 15 , step 12300 : 1.313954\n",
      "loss in epoch 15 , step 12320 : 0.174210\n",
      "loss in epoch 15 , step 12340 : 1.009937\n",
      "loss in epoch 15 , step 12360 : 0.178633\n",
      "loss in epoch 15 , step 12380 : 0.069184\n",
      "loss in epoch 15 , step 12400 : 0.695244\n",
      "loss in epoch 15 , step 12420 : 1.364461\n",
      "loss in epoch 15 , step 12440 : 0.727727\n",
      "loss in epoch 15 , step 12460 : 0.938133\n",
      "loss in epoch 15 , step 12480 : 5.148466\n",
      "loss in epoch 15 , step 12500 : 0.373099\n",
      "loss in epoch 15 , step 12520 : 1.396233\n",
      "loss in epoch 15 , step 12540 : 0.593461\n",
      "loss in epoch 15 , step 12560 : 0.402370\n",
      "loss in epoch 15 , step 12580 : 0.774285\n",
      "loss in epoch 15 , step 12600 : 0.908500\n",
      "loss in epoch 15 , step 12620 : 0.034652\n",
      "loss in epoch 15 , step 12640 : 1.428973\n",
      "loss in epoch 15 , step 12660 : 0.688066\n",
      "loss in epoch 15 , step 12680 : 0.169244\n",
      "loss in epoch 15 , step 12700 : 0.044192\n",
      "loss in epoch 15 , step 12720 : 0.004062\n",
      "loss in epoch 15 , step 12740 : 0.503468\n",
      "loss in epoch 15 , step 12760 : 1.835719\n",
      "loss in epoch 15 , step 12780 : 1.372376\n",
      "loss in epoch 15 , step 12800 : 0.762077\n",
      "loss in epoch 15 , step 12820 : 1.746651\n",
      "loss in epoch 15 , step 12840 : 0.117825\n",
      "loss in epoch 15 , step 12860 : 1.213024\n",
      "loss in epoch 15 , step 12880 : 0.264032\n",
      "loss in epoch 15 , step 12900 : 0.005809\n",
      "loss in epoch 15 , step 12920 : 0.004119\n",
      "loss in epoch 15 , step 12940 : 0.001502\n",
      "loss in epoch 15 , step 12960 : 0.015132\n",
      "loss in epoch 15 , step 12980 : 0.184613\n",
      "loss in epoch 15 , step 13000 : 0.325899\n",
      "loss in epoch 15 , step 13020 : 0.083819\n",
      "loss in epoch 15 , step 13040 : 0.005052\n",
      "loss in epoch 15 , step 13060 : 2.286417\n",
      "loss in epoch 15 , step 13080 : 1.960688\n",
      "loss in epoch 15 , step 13100 : 2.795991\n",
      "loss in epoch 15 , step 13120 : 0.032393\n",
      "loss in epoch 15 , step 13140 : 0.471499\n",
      "loss in epoch 15 , step 13160 : 0.796355\n",
      "loss in epoch 15 , step 13180 : 0.637624\n",
      "loss in epoch 15 , step 13200 : 1.768615\n",
      "loss in epoch 15 , step 13220 : 0.016057\n",
      "loss in epoch 15 , step 13240 : 0.309577\n",
      "loss in epoch 15 , step 13260 : 0.712816\n",
      "loss in epoch 15 , step 13280 : 1.859211\n",
      "loss in epoch 15 , step 13300 : 0.051489\n",
      "loss in epoch 15 , step 13320 : 1.472527\n",
      "loss in epoch 15 , step 13340 : 0.745875\n",
      "loss in epoch 15 , step 13360 : 0.402902\n",
      "loss in epoch 15 , step 13380 : 0.210019\n",
      "loss in epoch 15 , step 13400 : 0.461185\n",
      "loss in epoch 15 , step 13420 : 0.146998\n",
      "loss in epoch 15 , step 13440 : 0.320122\n",
      "loss in epoch 15 , step 13460 : 1.050013\n",
      "loss in epoch 15 , step 13480 : 0.336501\n",
      "loss in epoch 15 , step 13500 : 0.491004\n",
      "loss in epoch 15 , step 13520 : 0.063866\n",
      "loss in epoch 15 , step 13540 : 0.523274\n",
      "loss in epoch 15 , step 13560 : 0.702755\n",
      "loss in epoch 15 , step 13580 : 1.290353\n",
      "loss in epoch 15 , step 13600 : 2.678705\n",
      "loss in epoch 15 , step 13620 : 1.659056\n",
      "loss in epoch 15 , step 13640 : 1.022159\n",
      "loss in epoch 15 , step 13660 : 0.013159\n",
      "loss in epoch 15 , step 13680 : 0.460455\n",
      "loss in epoch 15 , step 13700 : 0.673117\n",
      "loss in epoch 15 , step 13720 : 0.084868\n",
      "loss in epoch 15 , step 13740 : 0.006697\n",
      "loss in epoch 15 , step 13760 : 0.068419\n",
      "loss in epoch 15 , step 13780 : 0.082474\n",
      "loss in epoch 15 , step 13800 : 0.181762\n",
      "loss in epoch 15 , step 13820 : 0.184070\n",
      "loss in epoch 15 , step 13840 : 0.411966\n",
      "loss in epoch 15 , step 13860 : 0.326213\n",
      "loss in epoch 15 , step 13880 : 1.147969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 15 , step 13900 : 0.695736\n",
      "loss in epoch 15 , step 13920 : 0.770097\n",
      "loss in epoch 15 , step 13940 : 0.519620\n",
      "loss in epoch 15 , step 13960 : 0.305249\n",
      "loss in epoch 15 , step 13980 : 0.069002\n",
      "loss in epoch 15 , step 14000 : 0.114702\n",
      "loss in epoch 15 , step 14020 : 0.630512\n",
      "loss in epoch 15 , step 14040 : 1.265040\n",
      "loss in epoch 15 , step 14060 : 0.088169\n",
      "loss in epoch 15 , step 14080 : 1.726300\n",
      "loss in epoch 15 , step 14100 : 1.732453\n",
      "loss in epoch 15 , step 14120 : 0.684802\n",
      "loss in epoch 15 , step 14140 : 2.799584\n",
      "loss in epoch 15 , step 14160 : 1.171663\n",
      "loss in epoch 15 , step 14180 : 1.550370\n",
      "loss in epoch 15 , step 14200 : 2.818577\n",
      "loss in epoch 15 , step 14220 : 0.006881\n",
      "loss in epoch 15 , step 14240 : 0.002130\n",
      "loss in epoch 15 , step 14260 : 0.354947\n",
      "loss in epoch 15 , step 14280 : 0.863329\n",
      "loss in epoch 15 , step 14300 : 1.025662\n",
      "loss in epoch 15 , step 14320 : 0.937068\n",
      "loss in epoch 15 , step 14340 : 0.148532\n",
      "loss in epoch 15 , step 14360 : 0.852155\n",
      "loss in epoch 15 , step 14380 : 0.755425\n",
      "loss in epoch 15 , step 14400 : 1.967520\n",
      "loss in epoch 15 , step 14420 : 1.107773\n",
      "loss in epoch 15 , step 14440 : 0.469696\n",
      "loss in epoch 15 , step 14460 : 2.940931\n",
      "loss in epoch 15 , step 14480 : 1.025268\n",
      "loss in epoch 15 , step 14500 : 0.077690\n",
      "loss in epoch 15 , step 14520 : 1.228205\n",
      "loss in epoch 15 , step 14540 : 1.666757\n",
      "loss in epoch 15 , step 14560 : 2.065452\n",
      "loss in epoch 15 , step 14580 : 0.105347\n",
      "loss in epoch 15 , step 14600 : 0.113337\n",
      "loss in epoch 15 , step 14620 : 0.786723\n",
      "loss in epoch 15 , step 14640 : 1.276816\n",
      "loss in epoch 15 , step 14660 : 1.186085\n",
      "loss in epoch 15 , step 14680 : 0.521362\n",
      "loss in epoch 15 , step 14700 : 0.691722\n",
      "loss in epoch 15 , step 14720 : 1.485202\n",
      "loss in epoch 15 , step 14740 : 0.592555\n",
      "loss in epoch 15 , step 14760 : 0.962792\n",
      "loss in epoch 15 , step 14780 : 0.006745\n",
      "loss in epoch 15 , step 14800 : 0.011314\n",
      "loss in epoch 15 , step 14820 : 2.007930\n",
      "loss in epoch 15 , step 14840 : 0.015332\n",
      "loss in epoch 15 , step 14860 : 0.275513\n",
      "loss in epoch 15 , step 14880 : 0.029590\n",
      "loss in epoch 15 , step 14900 : 0.505906\n",
      "loss in epoch 15 , step 14920 : 0.086209\n",
      "loss in epoch 15 , step 14940 : 1.408053\n",
      "loss in epoch 15 , step 14960 : 0.037876\n",
      "loss in epoch 15 , step 14980 : 1.324381\n",
      "loss in epoch 15 , step 15000 : 0.681373\n",
      "loss in epoch 15 , step 15020 : 0.179765\n",
      "loss in epoch 15 , step 15040 : 0.066511\n",
      "loss in epoch 15 , step 15060 : 0.146567\n",
      "loss in epoch 15 , step 15080 : 0.587176\n",
      "loss in epoch 15 , step 15100 : 0.385652\n",
      "loss in epoch 15 , step 15120 : 1.247813\n",
      "loss in epoch 15 , step 15140 : 0.667735\n",
      "loss in epoch 15 , step 15160 : 0.963751\n",
      "loss in epoch 15 , step 15180 : 0.169813\n",
      "loss in epoch 15 , step 15200 : 0.005878\n",
      "loss in epoch 15 , step 15220 : 1.665503\n",
      "loss in epoch 15 , step 15240 : 0.514343\n",
      "loss in epoch 15 , step 15260 : 0.350821\n",
      "loss in epoch 15 , step 15280 : 0.035513\n",
      "loss in epoch 15 , step 15300 : 2.324945\n",
      "loss in epoch 15 , step 15320 : 1.560285\n",
      "loss in epoch 15 , step 15340 : 0.003312\n",
      "loss in epoch 15 , step 15360 : 0.986384\n",
      "loss in epoch 15 , step 15380 : 2.312911\n",
      "loss in epoch 15 , step 15400 : 2.156758\n",
      "loss in epoch 15 , step 15420 : 3.061125\n",
      "loss in epoch 15 , step 15440 : 1.857700\n",
      "loss in epoch 15 , step 15460 : 1.603944\n",
      "loss in epoch 15 , step 15480 : 0.023601\n",
      "loss in epoch 15 , step 15500 : 0.219431\n",
      "loss in epoch 15 , step 15520 : 0.293596\n",
      "loss in epoch 15 , step 15540 : 0.166739\n",
      "loss in epoch 15 , step 15560 : 0.520714\n",
      "loss in epoch 15 , step 15580 : 0.002378\n",
      "loss in epoch 15 , step 15600 : 0.537247\n",
      "loss in epoch 15 , step 15620 : 0.203960\n",
      "loss in epoch 15 , step 15640 : 0.073883\n",
      "loss in epoch 15 , step 15660 : 0.580181\n",
      "loss in epoch 15 , step 15680 : 1.043141\n",
      "loss in epoch 15 , step 15700 : 1.966635\n",
      "loss in epoch 15 , step 15720 : 0.089531\n",
      "loss in epoch 15 , step 15740 : 0.324222\n",
      "loss in epoch 15 , step 15760 : 0.005338\n",
      "loss in epoch 15 , step 15780 : 2.203535\n",
      "loss in epoch 15 , step 15800 : 0.855937\n",
      "loss in epoch 15 , step 15820 : 0.032526\n",
      "loss in epoch 15 , step 15840 : 0.141999\n",
      "loss in epoch 15 , step 15860 : 0.384823\n",
      "loss in epoch 15 , step 15880 : 0.155648\n",
      "loss in epoch 15 , step 15900 : 0.003530\n",
      "loss in epoch 15 , step 15920 : 0.004067\n",
      "loss in epoch 15 , step 15940 : 0.339476\n",
      "loss in epoch 15 , step 15960 : 0.260236\n",
      "loss in epoch 15 , step 15980 : 1.524982\n",
      "loss in epoch 15 , step 16000 : 0.939893\n",
      "loss in epoch 15 , step 16020 : 0.823274\n",
      "loss in epoch 15 , step 16040 : 0.001906\n",
      "loss in epoch 15 , step 16060 : 1.236174\n",
      "loss in epoch 15 , step 16080 : 0.164327\n",
      "loss in epoch 15 , step 16100 : 1.155376\n",
      "loss in epoch 15 , step 16120 : 0.390611\n",
      "loss in epoch 15 , step 16140 : 2.207774\n",
      "loss in epoch 15 , step 16160 : 0.562144\n",
      "loss in epoch 15 , step 16180 : 0.465640\n",
      "loss in epoch 15 , step 16200 : 1.224084\n",
      "loss in epoch 15 , step 16220 : 0.382763\n",
      "loss in epoch 15 , step 16240 : 2.524565\n",
      "loss in epoch 15 , step 16260 : 1.676498\n",
      "loss in epoch 15 , step 16280 : 0.083681\n",
      "loss in epoch 15 , step 16300 : 0.361886\n",
      "loss in epoch 15 , step 16320 : 0.561180\n",
      "loss in epoch 15 , step 16340 : 0.809393\n",
      "loss in epoch 15 , step 16360 : 0.825188\n",
      "loss in epoch 15 , step 16380 : 0.877801\n",
      "loss in epoch 15 , step 16400 : 0.203642\n",
      "loss in epoch 15 , step 16420 : 0.602879\n",
      "loss in epoch 15 , step 16440 : 0.899155\n",
      "loss in epoch 15 , step 16460 : 0.419127\n",
      "loss in epoch 15 , step 16480 : 0.575668\n",
      "loss in epoch 15 , step 16500 : 2.345659\n",
      "loss in epoch 15 , step 16520 : 1.354208\n",
      "loss in epoch 15 , step 16540 : 0.811179\n",
      "loss in epoch 15 , step 16560 : 0.747149\n",
      "loss in epoch 15 , step 16580 : 0.152295\n",
      "loss in epoch 15 , step 16600 : 2.468109\n",
      "loss in epoch 15 , step 16620 : 0.545251\n",
      "loss in epoch 15 , step 16640 : 0.070651\n",
      "loss in epoch 15 , step 16660 : 0.184854\n",
      "loss in epoch 15 , step 16680 : 0.109787\n",
      "loss in epoch 15 , step 16700 : 0.026826\n",
      "loss in epoch 15 , step 16720 : 1.617220\n",
      "loss in epoch 15 , step 16740 : 0.754519\n",
      "loss in epoch 15 , step 16760 : 0.033638\n",
      "loss in epoch 15 , step 16780 : 4.674821\n",
      "loss in epoch 15 , step 16800 : 0.252295\n",
      "loss in epoch 15 , step 16820 : 0.076448\n",
      "loss in epoch 15 , step 16840 : 0.353166\n",
      "loss in epoch 15 , step 16860 : 0.829733\n",
      "loss in epoch 15 , step 16880 : 0.999463\n",
      "loss in epoch 15 , step 16900 : 1.201267\n",
      "loss in epoch 15 , step 16920 : 0.387712\n",
      "loss in epoch 15 , step 16940 : 2.632395\n",
      "loss in epoch 15 , step 16960 : 0.994235\n",
      "loss in epoch 15 , step 16980 : 0.006129\n",
      "loss in epoch 15 , step 17000 : 0.380383\n",
      "loss in epoch 15 , step 17020 : 0.050913\n",
      "loss in epoch 15 , step 17040 : 0.561336\n",
      "loss in epoch 15 , step 17060 : 0.003467\n",
      "loss in epoch 15 , step 17080 : 0.778066\n",
      "loss in epoch 15 , step 17100 : 1.814875\n",
      "loss in epoch 15 , step 17120 : 0.007963\n",
      "loss in epoch 15 , step 17140 : 0.039826\n",
      "loss in epoch 15 , step 17160 : 0.011165\n",
      "loss in epoch 15 , step 17180 : 1.738675\n",
      "loss in epoch 15 , step 17200 : 0.497151\n",
      "loss in epoch 15 , step 17220 : 0.873930\n",
      "loss in epoch 15 , step 17240 : 0.554833\n",
      "loss in epoch 15 , step 17260 : 0.166150\n",
      "loss in epoch 15 , step 17280 : 0.966430\n",
      "loss in epoch 15 , step 17300 : 0.447765\n",
      "loss in epoch 15 , step 17320 : 0.656316\n",
      "loss in epoch 15 , step 17340 : 0.379095\n",
      "loss in epoch 15 , step 17360 : 1.245362\n",
      "loss in epoch 15 , step 17380 : 2.162672\n",
      "loss in epoch 15 , step 17400 : 0.619789\n",
      "loss in epoch 15 , step 17420 : 0.806769\n",
      "loss in epoch 15 , step 17440 : 0.158425\n",
      "loss in epoch 15 , step 17460 : 0.826289\n",
      "loss in epoch 15 , step 17480 : 3.033587\n",
      "loss in epoch 15 , step 17500 : 1.330970\n",
      "loss in epoch 15 , step 17520 : 2.162860\n",
      "loss in epoch 15 , step 17540 : 1.338991\n",
      "loss in epoch 15 , step 17560 : 0.002091\n",
      "loss in epoch 15 , step 17580 : 0.004649\n",
      "loss in epoch 15 , step 17600 : 0.808321\n",
      "loss in epoch 15 , step 17620 : 1.802606\n",
      "loss in epoch 15 , step 17640 : 1.521377\n",
      "loss in epoch 15 , step 17660 : 0.040251\n",
      "loss in epoch 15 , step 17680 : 0.241875\n",
      "loss in epoch 15 , step 17700 : 0.558988\n",
      "loss in epoch 15 , step 17720 : 0.280339\n",
      "loss in epoch 15 , step 17740 : 0.002454\n",
      "loss in epoch 15 , step 17760 : 0.033342\n",
      "loss in epoch 15 , step 17780 : 1.774981\n",
      "loss in epoch 15 , step 17800 : 1.200158\n",
      "loss in epoch 15 , step 17820 : 2.502704\n",
      "loss in epoch 15 , step 17840 : 0.563680\n",
      "loss in epoch 15 , step 17860 : 0.010902\n",
      "loss in epoch 15 , step 17880 : 1.508330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 15 , step 17900 : 0.529796\n",
      "loss in epoch 15 , step 17920 : 1.060580\n",
      "loss in epoch 15 , step 17940 : 1.018786\n",
      "loss in epoch 15 , step 17960 : 0.035031\n",
      "loss in epoch 15 , step 17980 : 0.010079\n",
      "loss in epoch 15 , step 18000 : 0.442117\n",
      "loss in epoch 15 , step 18020 : 0.092696\n",
      "loss in epoch 15 , step 18040 : 1.319406\n",
      "loss in epoch 15 , step 18060 : 1.814355\n",
      "loss in epoch 15 , step 18080 : 0.004407\n",
      "loss in epoch 15 , step 18100 : 0.012332\n",
      "loss in epoch 15 , step 18120 : 0.170310\n",
      "loss in epoch 15 , step 18140 : 0.853126\n",
      "loss in epoch 15 , step 18160 : 0.158083\n",
      "loss in epoch 15 , step 18180 : 0.513992\n",
      "loss in epoch 15 , step 18200 : 0.007376\n",
      "loss in epoch 15 , step 18220 : 1.065227\n",
      "loss in epoch 15 , step 18240 : 0.850457\n",
      "loss in epoch 15 , step 18260 : 0.130283\n",
      "loss in epoch 15 , step 18280 : 0.368775\n",
      "loss in epoch 15 , step 18300 : 0.029054\n",
      "loss in epoch 15 , step 18320 : 0.296621\n",
      "loss in epoch 15 , step 18340 : 0.024043\n",
      "loss in epoch 15 , step 18360 : 1.122043\n",
      "loss in epoch 15 , step 18380 : 1.477712\n",
      "loss in epoch 15 , step 18400 : 0.005689\n",
      "loss in epoch 15 , step 18420 : 0.300803\n",
      "loss in epoch 15 , step 18440 : 0.731615\n",
      "loss in epoch 15 , step 18460 : 2.226209\n",
      "loss in epoch 15 , step 18480 : 0.212025\n",
      "loss in epoch 15 , step 18500 : 1.468034\n",
      "loss in epoch 15 , step 18520 : 1.408920\n",
      "loss in epoch 15 , step 18540 : 1.217349\n",
      "loss in epoch 15 , step 18560 : 0.016664\n",
      "loss in epoch 15 , step 18580 : 0.001222\n",
      "loss in epoch 15 , step 18600 : 0.001064\n",
      "loss in epoch 15 , step 18620 : 0.072095\n",
      "loss in epoch 15 , step 18640 : 0.347460\n",
      "loss in epoch 15 , step 18660 : 1.203774\n",
      "loss in epoch 15 , step 18680 : 0.611693\n",
      "loss in epoch 15 , step 18700 : 0.029886\n",
      "loss in epoch 15 , step 18720 : 0.530926\n",
      "loss in epoch 15 , step 18740 : 0.577846\n",
      "loss in epoch 15 , step 18760 : 2.225446\n",
      "loss in epoch 15 , step 18780 : 1.125894\n",
      "loss in epoch 15 , step 18800 : 0.180128\n",
      "loss in epoch 15 , step 18820 : 0.022203\n",
      "loss in epoch 15 , step 18840 : 0.279519\n",
      "loss in epoch 15 , step 18860 : 1.386144\n",
      "loss in epoch 15 , step 18880 : 0.797684\n",
      "loss in epoch 15 , step 18900 : 0.593372\n",
      "loss in epoch 15 , step 18920 : 0.181922\n",
      "loss in epoch 15 , step 18940 : 1.322826\n",
      "loss in epoch 15 , step 18960 : 0.892124\n",
      "loss in epoch 15 , step 18980 : 1.749198\n",
      "loss in epoch 15 , step 19000 : 0.864559\n",
      "loss in epoch 15 , step 19020 : 0.860888\n",
      "loss in epoch 15 , step 19040 : 0.019638\n",
      "loss in epoch 15 , step 19060 : 0.280741\n",
      "loss in epoch 15 , step 19080 : 0.000948\n",
      "loss in epoch 15 , step 19100 : 0.712171\n",
      "loss in epoch 15 , step 19120 : 0.652319\n",
      "loss in epoch 15 , step 19140 : 0.596208\n",
      "loss in epoch 15 , step 19160 : 0.134378\n",
      "loss in epoch 15 , step 19180 : 0.344276\n",
      "loss in epoch 15 , step 19200 : 0.651583\n",
      "loss in epoch 15 , step 19220 : 0.214952\n",
      "loss in epoch 15 , step 19240 : 0.002874\n",
      "loss in epoch 15 , step 19260 : 0.945756\n",
      "loss in epoch 15 , step 19280 : 0.251080\n",
      "loss in epoch 15 , step 19300 : 0.224641\n",
      "loss in epoch 15 , step 19320 : 0.094081\n",
      "loss in epoch 15 , step 19340 : 2.450941\n",
      "loss in epoch 15 , step 19360 : 0.859001\n",
      "loss in epoch 15 , step 19380 : 0.545749\n",
      "loss in epoch 15 , step 19400 : 0.023706\n",
      "loss in epoch 15 , step 19420 : 1.139476\n",
      "loss in epoch 15 , step 19440 : 0.297119\n",
      "loss in epoch 15 , step 19460 : 0.127067\n",
      "loss in epoch 15 , step 19480 : 0.076963\n",
      "loss in epoch 15 , step 19500 : 0.006159\n",
      "loss in epoch 15 , step 19520 : 0.666989\n",
      "loss in epoch 15 , step 19540 : 0.005407\n",
      "loss in epoch 15 , step 19560 : 0.053049\n",
      "loss in epoch 15 , step 19580 : 0.389061\n",
      "loss in epoch 15 , step 19600 : 0.192799\n",
      "loss in epoch 15 , step 19620 : 0.007260\n",
      "loss in epoch 15 , step 19640 : 0.135114\n",
      "loss in epoch 15 , step 19660 : 0.003359\n",
      "loss in epoch 15 , step 19680 : 0.276036\n",
      "loss in epoch 15 , step 19700 : 0.459888\n",
      "loss in epoch 15 , step 19720 : 0.025460\n",
      "loss in epoch 15 , step 19740 : 2.003586\n",
      "loss in epoch 15 , step 19760 : 0.996774\n",
      "loss in epoch 15 , step 19780 : 0.049178\n",
      "loss in epoch 15 , step 19800 : 0.361552\n",
      "loss in epoch 15 , step 19820 : 0.081564\n",
      "loss in epoch 15 , step 19840 : 0.413327\n",
      "loss in epoch 15 , step 19860 : 0.656184\n",
      "loss in epoch 15 , step 19880 : 1.201725\n",
      "loss in epoch 15 , step 19900 : 0.171275\n",
      "loss in epoch 15 , step 19920 : 0.219544\n",
      "loss in epoch 15 , step 19940 : 0.701377\n",
      "Accuracy in epoch 15 : 31.069803\n",
      "loss in epoch 16 , step 0 : 0.399927\n",
      "loss in epoch 16 , step 20 : 0.687216\n",
      "loss in epoch 16 , step 40 : 0.579044\n",
      "loss in epoch 16 , step 60 : 0.587824\n",
      "loss in epoch 16 , step 80 : 0.113115\n",
      "loss in epoch 16 , step 100 : 0.044547\n",
      "loss in epoch 16 , step 120 : 1.239512\n",
      "loss in epoch 16 , step 140 : 0.834672\n",
      "loss in epoch 16 , step 160 : 0.061307\n",
      "loss in epoch 16 , step 180 : 0.291772\n",
      "loss in epoch 16 , step 200 : 0.212933\n",
      "loss in epoch 16 , step 220 : 0.777263\n",
      "loss in epoch 16 , step 240 : 0.630043\n",
      "loss in epoch 16 , step 260 : 0.268282\n",
      "loss in epoch 16 , step 280 : 0.003351\n",
      "loss in epoch 16 , step 300 : 1.036083\n",
      "loss in epoch 16 , step 320 : 0.326041\n",
      "loss in epoch 16 , step 340 : 1.433803\n",
      "loss in epoch 16 , step 360 : 0.006928\n",
      "loss in epoch 16 , step 380 : 0.012942\n",
      "loss in epoch 16 , step 400 : 0.139424\n",
      "loss in epoch 16 , step 420 : 3.331330\n",
      "loss in epoch 16 , step 440 : 0.007656\n",
      "loss in epoch 16 , step 460 : 2.070839\n",
      "loss in epoch 16 , step 480 : 0.541487\n",
      "loss in epoch 16 , step 500 : 0.117668\n",
      "loss in epoch 16 , step 520 : 0.221038\n",
      "loss in epoch 16 , step 540 : 0.443054\n",
      "loss in epoch 16 , step 560 : 0.090319\n",
      "loss in epoch 16 , step 580 : 1.575596\n",
      "loss in epoch 16 , step 600 : 0.141497\n",
      "loss in epoch 16 , step 620 : 0.094895\n",
      "loss in epoch 16 , step 640 : 0.023077\n",
      "loss in epoch 16 , step 660 : 0.260449\n",
      "loss in epoch 16 , step 680 : 0.869859\n",
      "loss in epoch 16 , step 700 : 0.532170\n",
      "loss in epoch 16 , step 720 : 0.599152\n",
      "loss in epoch 16 , step 740 : 1.661232\n",
      "loss in epoch 16 , step 760 : 0.969072\n",
      "loss in epoch 16 , step 780 : 0.000923\n",
      "loss in epoch 16 , step 800 : 0.094475\n",
      "loss in epoch 16 , step 820 : 1.224591\n",
      "loss in epoch 16 , step 840 : 0.947325\n",
      "loss in epoch 16 , step 860 : 0.013234\n",
      "loss in epoch 16 , step 880 : 0.974245\n",
      "loss in epoch 16 , step 900 : 0.607562\n",
      "loss in epoch 16 , step 920 : 0.310370\n",
      "loss in epoch 16 , step 940 : 1.030332\n",
      "loss in epoch 16 , step 960 : 0.002906\n",
      "loss in epoch 16 , step 980 : 1.513672\n",
      "loss in epoch 16 , step 1000 : 0.028512\n",
      "loss in epoch 16 , step 1020 : 1.227247\n",
      "loss in epoch 16 , step 1040 : 0.410466\n",
      "loss in epoch 16 , step 1060 : 0.775087\n",
      "loss in epoch 16 , step 1080 : 0.634212\n",
      "loss in epoch 16 , step 1100 : 0.176401\n",
      "loss in epoch 16 , step 1120 : 0.241942\n",
      "loss in epoch 16 , step 1140 : 0.544595\n",
      "loss in epoch 16 , step 1160 : 0.926172\n",
      "loss in epoch 16 , step 1180 : 1.085344\n",
      "loss in epoch 16 , step 1200 : 0.022303\n",
      "loss in epoch 16 , step 1220 : 0.044082\n",
      "loss in epoch 16 , step 1240 : 0.760967\n",
      "loss in epoch 16 , step 1260 : 0.844029\n",
      "loss in epoch 16 , step 1280 : 0.207764\n",
      "loss in epoch 16 , step 1300 : 0.287750\n",
      "loss in epoch 16 , step 1320 : 0.282050\n",
      "loss in epoch 16 , step 1340 : 3.017239\n",
      "loss in epoch 16 , step 1360 : 0.396690\n",
      "loss in epoch 16 , step 1380 : 0.029838\n",
      "loss in epoch 16 , step 1400 : 2.368476\n",
      "loss in epoch 16 , step 1420 : 0.095491\n",
      "loss in epoch 16 , step 1440 : 2.084908\n",
      "loss in epoch 16 , step 1460 : 0.722840\n",
      "loss in epoch 16 , step 1480 : 0.938991\n",
      "loss in epoch 16 , step 1500 : 0.598840\n",
      "loss in epoch 16 , step 1520 : 1.384011\n",
      "loss in epoch 16 , step 1540 : 0.542562\n",
      "loss in epoch 16 , step 1560 : 0.603025\n",
      "loss in epoch 16 , step 1580 : 0.420957\n",
      "loss in epoch 16 , step 1600 : 0.135044\n",
      "loss in epoch 16 , step 1620 : 1.080855\n",
      "loss in epoch 16 , step 1640 : 0.718070\n",
      "loss in epoch 16 , step 1660 : 0.694696\n",
      "loss in epoch 16 , step 1680 : 0.446328\n",
      "loss in epoch 16 , step 1700 : 2.565605\n",
      "loss in epoch 16 , step 1720 : 0.020125\n",
      "loss in epoch 16 , step 1740 : 0.082331\n",
      "loss in epoch 16 , step 1760 : 0.002352\n",
      "loss in epoch 16 , step 1780 : 1.327239\n",
      "loss in epoch 16 , step 1800 : 1.191020\n",
      "loss in epoch 16 , step 1820 : 0.383650\n",
      "loss in epoch 16 , step 1840 : 0.051103\n",
      "loss in epoch 16 , step 1860 : 1.079424\n",
      "loss in epoch 16 , step 1880 : 0.472405\n",
      "loss in epoch 16 , step 1900 : 0.534823\n",
      "loss in epoch 16 , step 1920 : 0.036230\n",
      "loss in epoch 16 , step 1940 : 0.538880\n",
      "loss in epoch 16 , step 1960 : 0.474640\n",
      "loss in epoch 16 , step 1980 : 0.115000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 16 , step 2000 : 0.097606\n",
      "loss in epoch 16 , step 2020 : 0.006487\n",
      "loss in epoch 16 , step 2040 : 0.223606\n",
      "loss in epoch 16 , step 2060 : 0.266636\n",
      "loss in epoch 16 , step 2080 : 3.570786\n",
      "loss in epoch 16 , step 2100 : 1.024724\n",
      "loss in epoch 16 , step 2120 : 0.005727\n",
      "loss in epoch 16 , step 2140 : 1.407796\n",
      "loss in epoch 16 , step 2160 : 0.000862\n",
      "loss in epoch 16 , step 2180 : 0.232646\n",
      "loss in epoch 16 , step 2200 : 0.467124\n",
      "loss in epoch 16 , step 2220 : 0.217968\n",
      "loss in epoch 16 , step 2240 : 0.138718\n",
      "loss in epoch 16 , step 2260 : 0.036060\n",
      "loss in epoch 16 , step 2280 : 1.169847\n",
      "loss in epoch 16 , step 2300 : 0.084168\n",
      "loss in epoch 16 , step 2320 : 0.032024\n",
      "loss in epoch 16 , step 2340 : 0.051573\n",
      "loss in epoch 16 , step 2360 : 0.540537\n",
      "loss in epoch 16 , step 2380 : 1.552029\n",
      "loss in epoch 16 , step 2400 : 0.221031\n",
      "loss in epoch 16 , step 2420 : 0.033782\n",
      "loss in epoch 16 , step 2440 : 1.382374\n",
      "loss in epoch 16 , step 2460 : 1.507493\n",
      "loss in epoch 16 , step 2480 : 0.258551\n",
      "loss in epoch 16 , step 2500 : 2.152394\n",
      "loss in epoch 16 , step 2520 : 0.034096\n",
      "loss in epoch 16 , step 2540 : 0.703775\n",
      "loss in epoch 16 , step 2560 : 0.354971\n",
      "loss in epoch 16 , step 2580 : 0.785136\n",
      "loss in epoch 16 , step 2600 : 0.621791\n",
      "loss in epoch 16 , step 2620 : 0.236584\n",
      "loss in epoch 16 , step 2640 : 0.037940\n",
      "loss in epoch 16 , step 2660 : 0.647761\n",
      "loss in epoch 16 , step 2680 : 0.880905\n",
      "loss in epoch 16 , step 2700 : 0.004550\n",
      "loss in epoch 16 , step 2720 : 0.711506\n",
      "loss in epoch 16 , step 2740 : 0.694414\n",
      "loss in epoch 16 , step 2760 : 0.161036\n",
      "loss in epoch 16 , step 2780 : 0.893736\n",
      "loss in epoch 16 , step 2800 : 0.048888\n",
      "loss in epoch 16 , step 2820 : 0.360057\n",
      "loss in epoch 16 , step 2840 : 0.471720\n",
      "loss in epoch 16 , step 2860 : 1.450414\n",
      "loss in epoch 16 , step 2880 : 0.097278\n",
      "loss in epoch 16 , step 2900 : 0.063678\n",
      "loss in epoch 16 , step 2920 : 0.156488\n",
      "loss in epoch 16 , step 2940 : 0.612772\n",
      "loss in epoch 16 , step 2960 : 0.986733\n",
      "loss in epoch 16 , step 2980 : 0.003249\n",
      "loss in epoch 16 , step 3000 : 0.167320\n",
      "loss in epoch 16 , step 3020 : 1.264251\n",
      "loss in epoch 16 , step 3040 : 0.773790\n",
      "loss in epoch 16 , step 3060 : 0.002556\n",
      "loss in epoch 16 , step 3080 : 2.647127\n",
      "loss in epoch 16 , step 3100 : 0.655548\n",
      "loss in epoch 16 , step 3120 : 0.490668\n",
      "loss in epoch 16 , step 3140 : 0.754168\n",
      "loss in epoch 16 , step 3160 : 0.168603\n",
      "loss in epoch 16 , step 3180 : 0.010983\n",
      "loss in epoch 16 , step 3200 : 0.181849\n",
      "loss in epoch 16 , step 3220 : 2.083663\n",
      "loss in epoch 16 , step 3240 : 0.922157\n",
      "loss in epoch 16 , step 3260 : 0.015460\n",
      "loss in epoch 16 , step 3280 : 1.665498\n",
      "loss in epoch 16 , step 3300 : 0.343774\n",
      "loss in epoch 16 , step 3320 : 1.476432\n",
      "loss in epoch 16 , step 3340 : 0.148951\n",
      "loss in epoch 16 , step 3360 : 0.164185\n",
      "loss in epoch 16 , step 3380 : 0.709147\n",
      "loss in epoch 16 , step 3400 : 0.539898\n",
      "loss in epoch 16 , step 3420 : 1.197170\n",
      "loss in epoch 16 , step 3440 : 0.194701\n",
      "loss in epoch 16 , step 3460 : 1.204088\n",
      "loss in epoch 16 , step 3480 : 0.588572\n",
      "loss in epoch 16 , step 3500 : 0.046633\n",
      "loss in epoch 16 , step 3520 : 0.487382\n",
      "loss in epoch 16 , step 3540 : 1.529467\n",
      "loss in epoch 16 , step 3560 : 1.277174\n",
      "loss in epoch 16 , step 3580 : 0.906549\n",
      "loss in epoch 16 , step 3600 : 0.003395\n",
      "loss in epoch 16 , step 3620 : 0.786298\n",
      "loss in epoch 16 , step 3640 : 0.001285\n",
      "loss in epoch 16 , step 3660 : 0.484549\n",
      "loss in epoch 16 , step 3680 : 0.424238\n",
      "loss in epoch 16 , step 3700 : 0.701722\n",
      "loss in epoch 16 , step 3720 : 0.024319\n",
      "loss in epoch 16 , step 3740 : 1.677889\n",
      "loss in epoch 16 , step 3760 : 0.868173\n",
      "loss in epoch 16 , step 3780 : 0.618359\n",
      "loss in epoch 16 , step 3800 : 0.140349\n",
      "loss in epoch 16 , step 3820 : 2.719546\n",
      "loss in epoch 16 , step 3840 : 2.026802\n",
      "loss in epoch 16 , step 3860 : 0.040112\n",
      "loss in epoch 16 , step 3880 : 0.324627\n",
      "loss in epoch 16 , step 3900 : 0.821003\n",
      "loss in epoch 16 , step 3920 : 1.188047\n",
      "loss in epoch 16 , step 3940 : 0.612817\n",
      "loss in epoch 16 , step 3960 : 0.053570\n",
      "loss in epoch 16 , step 3980 : 0.183970\n",
      "loss in epoch 16 , step 4000 : 0.014436\n",
      "loss in epoch 16 , step 4020 : 0.191884\n",
      "loss in epoch 16 , step 4040 : 0.860623\n",
      "loss in epoch 16 , step 4060 : 2.112580\n",
      "loss in epoch 16 , step 4080 : 0.081369\n",
      "loss in epoch 16 , step 4100 : 0.139591\n",
      "loss in epoch 16 , step 4120 : 0.897477\n",
      "loss in epoch 16 , step 4140 : 0.556227\n",
      "loss in epoch 16 , step 4160 : 0.525422\n",
      "loss in epoch 16 , step 4180 : 2.748877\n",
      "loss in epoch 16 , step 4200 : 0.067375\n",
      "loss in epoch 16 , step 4220 : 0.007205\n",
      "loss in epoch 16 , step 4240 : 0.614156\n",
      "loss in epoch 16 , step 4260 : 0.010285\n",
      "loss in epoch 16 , step 4280 : 1.035725\n",
      "loss in epoch 16 , step 4300 : 1.048888\n",
      "loss in epoch 16 , step 4320 : 0.002703\n",
      "loss in epoch 16 , step 4340 : 0.825497\n",
      "loss in epoch 16 , step 4360 : 0.208915\n",
      "loss in epoch 16 , step 4380 : 0.744177\n",
      "loss in epoch 16 , step 4400 : 0.438552\n",
      "loss in epoch 16 , step 4420 : 0.516852\n",
      "loss in epoch 16 , step 4440 : 0.172314\n",
      "loss in epoch 16 , step 4460 : 0.352060\n",
      "loss in epoch 16 , step 4480 : 1.169154\n",
      "loss in epoch 16 , step 4500 : 1.997273\n",
      "loss in epoch 16 , step 4520 : 1.465788\n",
      "loss in epoch 16 , step 4540 : 0.112427\n",
      "loss in epoch 16 , step 4560 : 0.747822\n",
      "loss in epoch 16 , step 4580 : 0.076897\n",
      "loss in epoch 16 , step 4600 : 1.298158\n",
      "loss in epoch 16 , step 4620 : 0.560380\n",
      "loss in epoch 16 , step 4640 : 0.024308\n",
      "loss in epoch 16 , step 4660 : 0.183171\n",
      "loss in epoch 16 , step 4680 : 0.111030\n",
      "loss in epoch 16 , step 4700 : 1.352759\n",
      "loss in epoch 16 , step 4720 : 0.870453\n",
      "loss in epoch 16 , step 4740 : 0.124648\n",
      "loss in epoch 16 , step 4760 : 0.160175\n",
      "loss in epoch 16 , step 4780 : 0.347866\n",
      "loss in epoch 16 , step 4800 : 0.011065\n",
      "loss in epoch 16 , step 4820 : 0.811838\n",
      "loss in epoch 16 , step 4840 : 0.619985\n",
      "loss in epoch 16 , step 4860 : 0.218420\n",
      "loss in epoch 16 , step 4880 : 0.005535\n",
      "loss in epoch 16 , step 4900 : 0.704296\n",
      "loss in epoch 16 , step 4920 : 0.189532\n",
      "loss in epoch 16 , step 4940 : 0.506831\n",
      "loss in epoch 16 , step 4960 : 0.706791\n",
      "loss in epoch 16 , step 4980 : 0.049764\n",
      "loss in epoch 16 , step 5000 : 1.571405\n",
      "loss in epoch 16 , step 5020 : 1.836239\n",
      "loss in epoch 16 , step 5040 : 0.826473\n",
      "loss in epoch 16 , step 5060 : 1.321498\n",
      "loss in epoch 16 , step 5080 : 0.003332\n",
      "loss in epoch 16 , step 5100 : 0.105413\n",
      "loss in epoch 16 , step 5120 : 0.793740\n",
      "loss in epoch 16 , step 5140 : 1.276698\n",
      "loss in epoch 16 , step 5160 : 0.026195\n",
      "loss in epoch 16 , step 5180 : 0.812418\n",
      "loss in epoch 16 , step 5200 : 0.255790\n",
      "loss in epoch 16 , step 5220 : 0.704067\n",
      "loss in epoch 16 , step 5240 : 0.255126\n",
      "loss in epoch 16 , step 5260 : 0.007121\n",
      "loss in epoch 16 , step 5280 : 1.047012\n",
      "loss in epoch 16 , step 5300 : 0.242296\n",
      "loss in epoch 16 , step 5320 : 0.263969\n",
      "loss in epoch 16 , step 5340 : 0.013531\n",
      "loss in epoch 16 , step 5360 : 0.223683\n",
      "loss in epoch 16 , step 5380 : 0.060233\n",
      "loss in epoch 16 , step 5400 : 0.578964\n",
      "loss in epoch 16 , step 5420 : 0.161336\n",
      "loss in epoch 16 , step 5440 : 0.119015\n",
      "loss in epoch 16 , step 5460 : 0.237952\n",
      "loss in epoch 16 , step 5480 : 0.444317\n",
      "loss in epoch 16 , step 5500 : 0.744405\n",
      "loss in epoch 16 , step 5520 : 0.085627\n",
      "loss in epoch 16 , step 5540 : 1.250121\n",
      "loss in epoch 16 , step 5560 : 0.100214\n",
      "loss in epoch 16 , step 5580 : 1.037807\n",
      "loss in epoch 16 , step 5600 : 0.008417\n",
      "loss in epoch 16 , step 5620 : 1.189325\n",
      "loss in epoch 16 , step 5640 : 0.229020\n",
      "loss in epoch 16 , step 5660 : 1.448371\n",
      "loss in epoch 16 , step 5680 : 0.244603\n",
      "loss in epoch 16 , step 5700 : 0.821401\n",
      "loss in epoch 16 , step 5720 : 0.084389\n",
      "loss in epoch 16 , step 5740 : 0.247242\n",
      "loss in epoch 16 , step 5760 : 1.724524\n",
      "loss in epoch 16 , step 5780 : 1.496807\n",
      "loss in epoch 16 , step 5800 : 1.692245\n",
      "loss in epoch 16 , step 5820 : 1.095751\n",
      "loss in epoch 16 , step 5840 : 2.417727\n",
      "loss in epoch 16 , step 5860 : 0.630687\n",
      "loss in epoch 16 , step 5880 : 1.548248\n",
      "loss in epoch 16 , step 5900 : 0.018276\n",
      "loss in epoch 16 , step 5920 : 0.090969\n",
      "loss in epoch 16 , step 5940 : 1.926333\n",
      "loss in epoch 16 , step 5960 : 1.682069\n",
      "loss in epoch 16 , step 5980 : 0.008120\n",
      "loss in epoch 16 , step 6000 : 1.065014\n",
      "loss in epoch 16 , step 6020 : 0.395801\n",
      "loss in epoch 16 , step 6040 : 1.850009\n",
      "loss in epoch 16 , step 6060 : 1.461321\n",
      "loss in epoch 16 , step 6080 : 2.407477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 16 , step 6100 : 1.804517\n",
      "loss in epoch 16 , step 6120 : 0.153382\n",
      "loss in epoch 16 , step 6140 : 0.532442\n",
      "loss in epoch 16 , step 6160 : 0.842715\n",
      "loss in epoch 16 , step 6180 : 1.019609\n",
      "loss in epoch 16 , step 6200 : 0.953988\n",
      "loss in epoch 16 , step 6220 : 0.490047\n",
      "loss in epoch 16 , step 6240 : 1.819312\n",
      "loss in epoch 16 , step 6260 : 0.152658\n",
      "loss in epoch 16 , step 6280 : 1.866874\n",
      "loss in epoch 16 , step 6300 : 0.025528\n",
      "loss in epoch 16 , step 6320 : 0.551858\n",
      "loss in epoch 16 , step 6340 : 0.003551\n",
      "loss in epoch 16 , step 6360 : 1.066124\n",
      "loss in epoch 16 , step 6380 : 0.854068\n",
      "loss in epoch 16 , step 6400 : 1.527502\n",
      "loss in epoch 16 , step 6420 : 1.297382\n",
      "loss in epoch 16 , step 6440 : 2.174222\n",
      "loss in epoch 16 , step 6460 : 0.207925\n",
      "loss in epoch 16 , step 6480 : 1.147174\n",
      "loss in epoch 16 , step 6500 : 0.004509\n",
      "loss in epoch 16 , step 6520 : 2.820167\n",
      "loss in epoch 16 , step 6540 : 0.421289\n",
      "loss in epoch 16 , step 6560 : 1.747431\n",
      "loss in epoch 16 , step 6580 : 0.510175\n",
      "loss in epoch 16 , step 6600 : 0.873478\n",
      "loss in epoch 16 , step 6620 : 0.929476\n",
      "loss in epoch 16 , step 6640 : 3.140540\n",
      "loss in epoch 16 , step 6660 : 0.258175\n",
      "loss in epoch 16 , step 6680 : 0.993879\n",
      "loss in epoch 16 , step 6700 : 1.847499\n",
      "loss in epoch 16 , step 6720 : 0.670902\n",
      "loss in epoch 16 , step 6740 : 0.697624\n",
      "loss in epoch 16 , step 6760 : 0.459515\n",
      "loss in epoch 16 , step 6780 : 0.721662\n",
      "loss in epoch 16 , step 6800 : 0.193592\n",
      "loss in epoch 16 , step 6820 : 0.002071\n",
      "loss in epoch 16 , step 6840 : 0.007094\n",
      "loss in epoch 16 , step 6860 : 0.614017\n",
      "loss in epoch 16 , step 6880 : 0.067252\n",
      "loss in epoch 16 , step 6900 : 0.010023\n",
      "loss in epoch 16 , step 6920 : 0.346151\n",
      "loss in epoch 16 , step 6940 : 0.505838\n",
      "loss in epoch 16 , step 6960 : 1.377331\n",
      "loss in epoch 16 , step 6980 : 0.324968\n",
      "loss in epoch 16 , step 7000 : 2.411071\n",
      "loss in epoch 16 , step 7020 : 0.741333\n",
      "loss in epoch 16 , step 7040 : 0.660170\n",
      "loss in epoch 16 , step 7060 : 0.651585\n",
      "loss in epoch 16 , step 7080 : 1.084826\n",
      "loss in epoch 16 , step 7100 : 0.621469\n",
      "loss in epoch 16 , step 7120 : 0.135315\n",
      "loss in epoch 16 , step 7140 : 0.474025\n",
      "loss in epoch 16 , step 7160 : 0.898042\n",
      "loss in epoch 16 , step 7180 : 0.948477\n",
      "loss in epoch 16 , step 7200 : 0.923938\n",
      "loss in epoch 16 , step 7220 : 0.050277\n",
      "loss in epoch 16 , step 7240 : 1.588105\n",
      "loss in epoch 16 , step 7260 : 0.404886\n",
      "loss in epoch 16 , step 7280 : 1.479539\n",
      "loss in epoch 16 , step 7300 : 0.140279\n",
      "loss in epoch 16 , step 7320 : 1.411882\n",
      "loss in epoch 16 , step 7340 : 0.007128\n",
      "loss in epoch 16 , step 7360 : 0.779102\n",
      "loss in epoch 16 , step 7380 : 1.877282\n",
      "loss in epoch 16 , step 7400 : 0.320987\n",
      "loss in epoch 16 , step 7420 : 0.128909\n",
      "loss in epoch 16 , step 7440 : 0.001514\n",
      "loss in epoch 16 , step 7460 : 0.997906\n",
      "loss in epoch 16 , step 7480 : 0.998958\n",
      "loss in epoch 16 , step 7500 : 3.839907\n",
      "loss in epoch 16 , step 7520 : 0.485373\n",
      "loss in epoch 16 , step 7540 : 0.007591\n",
      "loss in epoch 16 , step 7560 : 0.836621\n",
      "loss in epoch 16 , step 7580 : 0.010345\n",
      "loss in epoch 16 , step 7600 : 0.701780\n",
      "loss in epoch 16 , step 7620 : 0.744280\n",
      "loss in epoch 16 , step 7640 : 0.034296\n",
      "loss in epoch 16 , step 7660 : 0.532292\n",
      "loss in epoch 16 , step 7680 : 0.582832\n",
      "loss in epoch 16 , step 7700 : 0.426228\n",
      "loss in epoch 16 , step 7720 : 0.083689\n",
      "loss in epoch 16 , step 7740 : 1.951856\n",
      "loss in epoch 16 , step 7760 : 0.372186\n",
      "loss in epoch 16 , step 7780 : 1.188022\n",
      "loss in epoch 16 , step 7800 : 1.497655\n",
      "loss in epoch 16 , step 7820 : 0.196810\n",
      "loss in epoch 16 , step 7840 : 0.851528\n",
      "loss in epoch 16 , step 7860 : 0.679586\n",
      "loss in epoch 16 , step 7880 : 1.125800\n",
      "loss in epoch 16 , step 7900 : 1.994229\n",
      "loss in epoch 16 , step 7920 : 0.896291\n",
      "loss in epoch 16 , step 7940 : 0.582950\n",
      "loss in epoch 16 , step 7960 : 0.764524\n",
      "loss in epoch 16 , step 7980 : 0.004542\n",
      "loss in epoch 16 , step 8000 : 1.516398\n",
      "loss in epoch 16 , step 8020 : 0.279155\n",
      "loss in epoch 16 , step 8040 : 0.039169\n",
      "loss in epoch 16 , step 8060 : 0.022006\n",
      "loss in epoch 16 , step 8080 : 0.360903\n",
      "loss in epoch 16 , step 8100 : 0.204408\n",
      "loss in epoch 16 , step 8120 : 1.530783\n",
      "loss in epoch 16 , step 8140 : 0.033404\n",
      "loss in epoch 16 , step 8160 : 2.075565\n",
      "loss in epoch 16 , step 8180 : 4.413674\n",
      "loss in epoch 16 , step 8200 : 0.010161\n",
      "loss in epoch 16 , step 8220 : 0.381212\n",
      "loss in epoch 16 , step 8240 : 1.008193\n",
      "loss in epoch 16 , step 8260 : 0.109796\n",
      "loss in epoch 16 , step 8280 : 1.023053\n",
      "loss in epoch 16 , step 8300 : 1.967573\n",
      "loss in epoch 16 , step 8320 : 0.227509\n",
      "loss in epoch 16 , step 8340 : 0.228203\n",
      "loss in epoch 16 , step 8360 : 0.384945\n",
      "loss in epoch 16 , step 8380 : 0.310268\n",
      "loss in epoch 16 , step 8400 : 1.083859\n",
      "loss in epoch 16 , step 8420 : 3.046207\n",
      "loss in epoch 16 , step 8440 : 0.537186\n",
      "loss in epoch 16 , step 8460 : 0.365104\n",
      "loss in epoch 16 , step 8480 : 0.152989\n",
      "loss in epoch 16 , step 8500 : 0.733593\n",
      "loss in epoch 16 , step 8520 : 1.446616\n",
      "loss in epoch 16 , step 8540 : 0.825308\n",
      "loss in epoch 16 , step 8560 : 0.285963\n",
      "loss in epoch 16 , step 8580 : 2.497764\n",
      "loss in epoch 16 , step 8600 : 0.005649\n",
      "loss in epoch 16 , step 8620 : 0.272741\n",
      "loss in epoch 16 , step 8640 : 0.309479\n",
      "loss in epoch 16 , step 8660 : 0.146804\n",
      "loss in epoch 16 , step 8680 : 1.607880\n",
      "loss in epoch 16 , step 8700 : 0.178501\n",
      "loss in epoch 16 , step 8720 : 0.701277\n",
      "loss in epoch 16 , step 8740 : 0.885585\n",
      "loss in epoch 16 , step 8760 : 0.626543\n",
      "loss in epoch 16 , step 8780 : 0.006908\n",
      "loss in epoch 16 , step 8800 : 1.528517\n",
      "loss in epoch 16 , step 8820 : 0.393914\n",
      "loss in epoch 16 , step 8840 : 0.012551\n",
      "loss in epoch 16 , step 8860 : 0.003996\n",
      "loss in epoch 16 , step 8880 : 0.604554\n",
      "loss in epoch 16 , step 8900 : 0.903826\n",
      "loss in epoch 16 , step 8920 : 0.679819\n",
      "loss in epoch 16 , step 8940 : 0.142236\n",
      "loss in epoch 16 , step 8960 : 0.154427\n",
      "loss in epoch 16 , step 8980 : 1.040535\n",
      "loss in epoch 16 , step 9000 : 0.017749\n",
      "loss in epoch 16 , step 9020 : 0.029771\n",
      "loss in epoch 16 , step 9040 : 0.269305\n",
      "loss in epoch 16 , step 9060 : 0.241800\n",
      "loss in epoch 16 , step 9080 : 1.671760\n",
      "loss in epoch 16 , step 9100 : 0.976120\n",
      "loss in epoch 16 , step 9120 : 0.002601\n",
      "loss in epoch 16 , step 9140 : 0.008713\n",
      "loss in epoch 16 , step 9160 : 0.588390\n",
      "loss in epoch 16 , step 9180 : 0.693138\n",
      "loss in epoch 16 , step 9200 : 2.664538\n",
      "loss in epoch 16 , step 9220 : 0.798770\n",
      "loss in epoch 16 , step 9240 : 0.022176\n",
      "loss in epoch 16 , step 9260 : 0.904149\n",
      "loss in epoch 16 , step 9280 : 1.269012\n",
      "loss in epoch 16 , step 9300 : 0.788589\n",
      "loss in epoch 16 , step 9320 : 0.002531\n",
      "loss in epoch 16 , step 9340 : 0.928298\n",
      "loss in epoch 16 , step 9360 : 0.363759\n",
      "loss in epoch 16 , step 9380 : 0.795765\n",
      "loss in epoch 16 , step 9400 : 0.005485\n",
      "loss in epoch 16 , step 9420 : 0.983019\n",
      "loss in epoch 16 , step 9440 : 0.480660\n",
      "loss in epoch 16 , step 9460 : 0.013344\n",
      "loss in epoch 16 , step 9480 : 0.487530\n",
      "loss in epoch 16 , step 9500 : 1.333472\n",
      "loss in epoch 16 , step 9520 : 0.013911\n",
      "loss in epoch 16 , step 9540 : 0.109019\n",
      "loss in epoch 16 , step 9560 : 1.158988\n",
      "loss in epoch 16 , step 9580 : 0.656668\n",
      "loss in epoch 16 , step 9600 : 0.032041\n",
      "loss in epoch 16 , step 9620 : 2.593469\n",
      "loss in epoch 16 , step 9640 : 0.298865\n",
      "loss in epoch 16 , step 9660 : 0.008211\n",
      "loss in epoch 16 , step 9680 : 1.218449\n",
      "loss in epoch 16 , step 9700 : 1.734438\n",
      "loss in epoch 16 , step 9720 : 1.292158\n",
      "loss in epoch 16 , step 9740 : 1.635980\n",
      "loss in epoch 16 , step 9760 : 0.791945\n",
      "loss in epoch 16 , step 9780 : 0.044903\n",
      "loss in epoch 16 , step 9800 : 0.332918\n",
      "loss in epoch 16 , step 9820 : 1.791359\n",
      "loss in epoch 16 , step 9840 : 0.002844\n",
      "loss in epoch 16 , step 9860 : 0.316907\n",
      "loss in epoch 16 , step 9880 : 0.451341\n",
      "loss in epoch 16 , step 9900 : 0.820994\n",
      "loss in epoch 16 , step 9920 : 0.186830\n",
      "loss in epoch 16 , step 9940 : 0.396931\n",
      "loss in epoch 16 , step 9960 : 0.537878\n",
      "loss in epoch 16 , step 9980 : 0.015860\n",
      "loss in epoch 16 , step 10000 : 1.069547\n",
      "loss in epoch 16 , step 10020 : 0.683441\n",
      "loss in epoch 16 , step 10040 : 0.434743\n",
      "loss in epoch 16 , step 10060 : 0.345169\n",
      "loss in epoch 16 , step 10080 : 1.094610\n",
      "loss in epoch 16 , step 10100 : 0.111289\n",
      "loss in epoch 16 , step 10120 : 0.001309\n",
      "loss in epoch 16 , step 10140 : 2.088225\n",
      "loss in epoch 16 , step 10160 : 0.639616\n",
      "loss in epoch 16 , step 10180 : 1.808316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 16 , step 10200 : 0.087110\n",
      "loss in epoch 16 , step 10220 : 0.047593\n",
      "loss in epoch 16 , step 10240 : 0.523695\n",
      "loss in epoch 16 , step 10260 : 0.063404\n",
      "loss in epoch 16 , step 10280 : 0.119245\n",
      "loss in epoch 16 , step 10300 : 0.877573\n",
      "loss in epoch 16 , step 10320 : 0.114773\n",
      "loss in epoch 16 , step 10340 : 0.153858\n",
      "loss in epoch 16 , step 10360 : 0.049810\n",
      "loss in epoch 16 , step 10380 : 1.200849\n",
      "loss in epoch 16 , step 10400 : 0.010048\n",
      "loss in epoch 16 , step 10420 : 2.726039\n",
      "loss in epoch 16 , step 10440 : 0.615897\n",
      "loss in epoch 16 , step 10460 : 1.237600\n",
      "loss in epoch 16 , step 10480 : 0.137853\n",
      "loss in epoch 16 , step 10500 : 0.192384\n",
      "loss in epoch 16 , step 10520 : 1.229783\n",
      "loss in epoch 16 , step 10540 : 0.044906\n",
      "loss in epoch 16 , step 10560 : 0.004291\n",
      "loss in epoch 16 , step 10580 : 0.075737\n",
      "loss in epoch 16 , step 10600 : 0.821058\n",
      "loss in epoch 16 , step 10620 : 0.447195\n",
      "loss in epoch 16 , step 10640 : 1.325667\n",
      "loss in epoch 16 , step 10660 : 0.505568\n",
      "loss in epoch 16 , step 10680 : 1.334276\n",
      "loss in epoch 16 , step 10700 : 1.639855\n",
      "loss in epoch 16 , step 10720 : 0.006693\n",
      "loss in epoch 16 , step 10740 : 0.739533\n",
      "loss in epoch 16 , step 10760 : 0.087652\n",
      "loss in epoch 16 , step 10780 : 0.447575\n",
      "loss in epoch 16 , step 10800 : 0.677818\n",
      "loss in epoch 16 , step 10820 : 0.623745\n",
      "loss in epoch 16 , step 10840 : 1.203930\n",
      "loss in epoch 16 , step 10860 : 0.019162\n",
      "loss in epoch 16 , step 10880 : 0.095920\n",
      "loss in epoch 16 , step 10900 : 1.370851\n",
      "loss in epoch 16 , step 10920 : 1.232130\n",
      "loss in epoch 16 , step 10940 : 0.729945\n",
      "loss in epoch 16 , step 10960 : 0.008538\n",
      "loss in epoch 16 , step 10980 : 1.483546\n",
      "loss in epoch 16 , step 11000 : 0.530947\n",
      "loss in epoch 16 , step 11020 : 2.990861\n",
      "loss in epoch 16 , step 11040 : 2.352380\n",
      "loss in epoch 16 , step 11060 : 1.120625\n",
      "loss in epoch 16 , step 11080 : 0.004635\n",
      "loss in epoch 16 , step 11100 : 0.024035\n",
      "loss in epoch 16 , step 11120 : 0.866532\n",
      "loss in epoch 16 , step 11140 : 0.167288\n",
      "loss in epoch 16 , step 11160 : 0.611254\n",
      "loss in epoch 16 , step 11180 : 1.330637\n",
      "loss in epoch 16 , step 11200 : 0.027089\n",
      "loss in epoch 16 , step 11220 : 0.939102\n",
      "loss in epoch 16 , step 11240 : 0.122654\n",
      "loss in epoch 16 , step 11260 : 0.166719\n",
      "loss in epoch 16 , step 11280 : 0.080824\n",
      "loss in epoch 16 , step 11300 : 0.945417\n",
      "loss in epoch 16 , step 11320 : 0.562925\n",
      "loss in epoch 16 , step 11340 : 1.006613\n",
      "loss in epoch 16 , step 11360 : 0.155389\n",
      "loss in epoch 16 , step 11380 : 2.255369\n",
      "loss in epoch 16 , step 11400 : 0.390737\n",
      "loss in epoch 16 , step 11420 : 1.016173\n",
      "loss in epoch 16 , step 11440 : 0.065549\n",
      "loss in epoch 16 , step 11460 : 0.788742\n",
      "loss in epoch 16 , step 11480 : 0.364439\n",
      "loss in epoch 16 , step 11500 : 0.024007\n",
      "loss in epoch 16 , step 11520 : 1.798152\n",
      "loss in epoch 16 , step 11540 : 0.793054\n",
      "loss in epoch 16 , step 11560 : 0.970382\n",
      "loss in epoch 16 , step 11580 : 0.858013\n",
      "loss in epoch 16 , step 11600 : 0.889614\n",
      "loss in epoch 16 , step 11620 : 0.882700\n",
      "loss in epoch 16 , step 11640 : 0.464498\n",
      "loss in epoch 16 , step 11660 : 0.053161\n",
      "loss in epoch 16 , step 11680 : 1.341370\n",
      "loss in epoch 16 , step 11700 : 0.111610\n",
      "loss in epoch 16 , step 11720 : 1.077631\n",
      "loss in epoch 16 , step 11740 : 2.270623\n",
      "loss in epoch 16 , step 11760 : 0.154400\n",
      "loss in epoch 16 , step 11780 : 0.726662\n",
      "loss in epoch 16 , step 11800 : 0.039515\n",
      "loss in epoch 16 , step 11820 : 0.067363\n",
      "loss in epoch 16 , step 11840 : 3.267769\n",
      "loss in epoch 16 , step 11860 : 0.003689\n",
      "loss in epoch 16 , step 11880 : 0.308894\n",
      "loss in epoch 16 , step 11900 : 0.013474\n",
      "loss in epoch 16 , step 11920 : 0.706053\n",
      "loss in epoch 16 , step 11940 : 2.207479\n",
      "loss in epoch 16 , step 11960 : 0.695271\n",
      "loss in epoch 16 , step 11980 : 0.909616\n",
      "loss in epoch 16 , step 12000 : 2.037513\n",
      "loss in epoch 16 , step 12020 : 2.567225\n",
      "loss in epoch 16 , step 12040 : 0.431571\n",
      "loss in epoch 16 , step 12060 : 0.322979\n",
      "loss in epoch 16 , step 12080 : 1.748285\n",
      "loss in epoch 16 , step 12100 : 0.765140\n",
      "loss in epoch 16 , step 12120 : 0.576207\n",
      "loss in epoch 16 , step 12140 : 0.030037\n",
      "loss in epoch 16 , step 12160 : 2.249703\n",
      "loss in epoch 16 , step 12180 : 0.443568\n",
      "loss in epoch 16 , step 12200 : 0.943003\n",
      "loss in epoch 16 , step 12220 : 0.113056\n",
      "loss in epoch 16 , step 12240 : 0.125110\n",
      "loss in epoch 16 , step 12260 : 0.118653\n",
      "loss in epoch 16 , step 12280 : 0.449850\n",
      "loss in epoch 16 , step 12300 : 0.030441\n",
      "loss in epoch 16 , step 12320 : 0.422153\n",
      "loss in epoch 16 , step 12340 : 1.011216\n",
      "loss in epoch 16 , step 12360 : 1.733768\n",
      "loss in epoch 16 , step 12380 : 0.178602\n",
      "loss in epoch 16 , step 12400 : 0.414270\n",
      "loss in epoch 16 , step 12420 : 0.672295\n",
      "loss in epoch 16 , step 12440 : 0.999252\n",
      "loss in epoch 16 , step 12460 : 0.203429\n",
      "loss in epoch 16 , step 12480 : 0.056508\n",
      "loss in epoch 16 , step 12500 : 0.085993\n",
      "loss in epoch 16 , step 12520 : 0.005216\n",
      "loss in epoch 16 , step 12540 : 1.210059\n",
      "loss in epoch 16 , step 12560 : 1.265151\n",
      "loss in epoch 16 , step 12580 : 1.095934\n",
      "loss in epoch 16 , step 12600 : 1.224959\n",
      "loss in epoch 16 , step 12620 : 0.049711\n",
      "loss in epoch 16 , step 12640 : 0.177724\n",
      "loss in epoch 16 , step 12660 : 1.125949\n",
      "loss in epoch 16 , step 12680 : 0.368104\n",
      "loss in epoch 16 , step 12700 : 0.369795\n",
      "loss in epoch 16 , step 12720 : 0.078255\n",
      "loss in epoch 16 , step 12740 : 0.322400\n",
      "loss in epoch 16 , step 12760 : 0.014138\n",
      "loss in epoch 16 , step 12780 : 0.007921\n",
      "loss in epoch 16 , step 12800 : 0.318831\n",
      "loss in epoch 16 , step 12820 : 0.490933\n",
      "loss in epoch 16 , step 12840 : 0.002654\n",
      "loss in epoch 16 , step 12860 : 0.005152\n",
      "loss in epoch 16 , step 12880 : 0.009874\n",
      "loss in epoch 16 , step 12900 : 2.477141\n",
      "loss in epoch 16 , step 12920 : 0.583466\n",
      "loss in epoch 16 , step 12940 : 0.020784\n",
      "loss in epoch 16 , step 12960 : 0.236615\n",
      "loss in epoch 16 , step 12980 : 0.081189\n",
      "loss in epoch 16 , step 13000 : 0.004851\n",
      "loss in epoch 16 , step 13020 : 0.580373\n",
      "loss in epoch 16 , step 13040 : 0.622538\n",
      "loss in epoch 16 , step 13060 : 0.069313\n",
      "loss in epoch 16 , step 13080 : 0.107871\n",
      "loss in epoch 16 , step 13100 : 1.065869\n",
      "loss in epoch 16 , step 13120 : 0.947512\n",
      "loss in epoch 16 , step 13140 : 0.091185\n",
      "loss in epoch 16 , step 13160 : 0.932553\n",
      "loss in epoch 16 , step 13180 : 1.671084\n",
      "loss in epoch 16 , step 13200 : 0.253900\n",
      "loss in epoch 16 , step 13220 : 1.269196\n",
      "loss in epoch 16 , step 13240 : 0.029481\n",
      "loss in epoch 16 , step 13260 : 0.019516\n",
      "loss in epoch 16 , step 13280 : 0.003274\n",
      "loss in epoch 16 , step 13300 : 0.028933\n",
      "loss in epoch 16 , step 13320 : 0.315885\n",
      "loss in epoch 16 , step 13340 : 1.883864\n",
      "loss in epoch 16 , step 13360 : 1.124227\n",
      "loss in epoch 16 , step 13380 : 1.530800\n",
      "loss in epoch 16 , step 13400 : 0.364933\n",
      "loss in epoch 16 , step 13420 : 1.053205\n",
      "loss in epoch 16 , step 13440 : 0.335830\n",
      "loss in epoch 16 , step 13460 : 2.688114\n",
      "loss in epoch 16 , step 13480 : 1.751472\n",
      "loss in epoch 16 , step 13500 : 0.002970\n",
      "loss in epoch 16 , step 13520 : 0.052982\n",
      "loss in epoch 16 , step 13540 : 1.999374\n",
      "loss in epoch 16 , step 13560 : 2.229638\n",
      "loss in epoch 16 , step 13580 : 0.839248\n",
      "loss in epoch 16 , step 13600 : 0.989155\n",
      "loss in epoch 16 , step 13620 : 0.001931\n",
      "loss in epoch 16 , step 13640 : 0.127927\n",
      "loss in epoch 16 , step 13660 : 0.690271\n",
      "loss in epoch 16 , step 13680 : 2.451335\n",
      "loss in epoch 16 , step 13700 : 0.981731\n",
      "loss in epoch 16 , step 13720 : 0.010489\n",
      "loss in epoch 16 , step 13740 : 1.657949\n",
      "loss in epoch 16 , step 13760 : 0.068945\n",
      "loss in epoch 16 , step 13780 : 0.136174\n",
      "loss in epoch 16 , step 13800 : 1.299073\n",
      "loss in epoch 16 , step 13820 : 0.387393\n",
      "loss in epoch 16 , step 13840 : 0.012738\n",
      "loss in epoch 16 , step 13860 : 0.348898\n",
      "loss in epoch 16 , step 13880 : 0.481568\n",
      "loss in epoch 16 , step 13900 : 1.443164\n",
      "loss in epoch 16 , step 13920 : 0.008610\n",
      "loss in epoch 16 , step 13940 : 0.028640\n",
      "loss in epoch 16 , step 13960 : 1.186662\n",
      "loss in epoch 16 , step 13980 : 0.049347\n",
      "loss in epoch 16 , step 14000 : 0.032809\n",
      "loss in epoch 16 , step 14020 : 0.736747\n",
      "loss in epoch 16 , step 14040 : 0.663163\n",
      "loss in epoch 16 , step 14060 : 2.207939\n",
      "loss in epoch 16 , step 14080 : 0.002975\n",
      "loss in epoch 16 , step 14100 : 0.599759\n",
      "loss in epoch 16 , step 14120 : 3.261945\n",
      "loss in epoch 16 , step 14140 : 2.286664\n",
      "loss in epoch 16 , step 14160 : 0.991932\n",
      "loss in epoch 16 , step 14180 : 0.021736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 16 , step 14200 : 0.994812\n",
      "loss in epoch 16 , step 14220 : 0.485797\n",
      "loss in epoch 16 , step 14240 : 0.852699\n",
      "loss in epoch 16 , step 14260 : 1.004017\n",
      "loss in epoch 16 , step 14280 : 0.128174\n",
      "loss in epoch 16 , step 14300 : 0.053631\n",
      "loss in epoch 16 , step 14320 : 0.186069\n",
      "loss in epoch 16 , step 14340 : 1.311336\n",
      "loss in epoch 16 , step 14360 : 0.031020\n",
      "loss in epoch 16 , step 14380 : 0.010290\n",
      "loss in epoch 16 , step 14400 : 1.125294\n",
      "loss in epoch 16 , step 14420 : 1.017994\n",
      "loss in epoch 16 , step 14440 : 0.279031\n",
      "loss in epoch 16 , step 14460 : 1.644148\n",
      "loss in epoch 16 , step 14480 : 0.917677\n",
      "loss in epoch 16 , step 14500 : 0.172869\n",
      "loss in epoch 16 , step 14520 : 1.365692\n",
      "loss in epoch 16 , step 14540 : 0.602754\n",
      "loss in epoch 16 , step 14560 : 0.369636\n",
      "loss in epoch 16 , step 14580 : 1.825658\n",
      "loss in epoch 16 , step 14600 : 0.443383\n",
      "loss in epoch 16 , step 14620 : 0.656321\n",
      "loss in epoch 16 , step 14640 : 1.056250\n",
      "loss in epoch 16 , step 14660 : 0.131761\n",
      "loss in epoch 16 , step 14680 : 1.464760\n",
      "loss in epoch 16 , step 14700 : 1.503425\n",
      "loss in epoch 16 , step 14720 : 0.851576\n",
      "loss in epoch 16 , step 14740 : 1.160558\n",
      "loss in epoch 16 , step 14760 : 0.064385\n",
      "loss in epoch 16 , step 14780 : 0.440709\n",
      "loss in epoch 16 , step 14800 : 0.066539\n",
      "loss in epoch 16 , step 14820 : 1.229910\n",
      "loss in epoch 16 , step 14840 : 1.229966\n",
      "loss in epoch 16 , step 14860 : 1.470527\n",
      "loss in epoch 16 , step 14880 : 0.593530\n",
      "loss in epoch 16 , step 14900 : 0.779135\n",
      "loss in epoch 16 , step 14920 : 0.955759\n",
      "loss in epoch 16 , step 14940 : 1.759371\n",
      "loss in epoch 16 , step 14960 : 0.344400\n",
      "loss in epoch 16 , step 14980 : 0.694931\n",
      "loss in epoch 16 , step 15000 : 0.025811\n",
      "loss in epoch 16 , step 15020 : 0.667352\n",
      "loss in epoch 16 , step 15040 : 0.026531\n",
      "loss in epoch 16 , step 15060 : 0.002972\n",
      "loss in epoch 16 , step 15080 : 0.931667\n",
      "loss in epoch 16 , step 15100 : 0.745605\n",
      "loss in epoch 16 , step 15120 : 0.002477\n",
      "loss in epoch 16 , step 15140 : 1.006984\n",
      "loss in epoch 16 , step 15160 : 0.485858\n",
      "loss in epoch 16 , step 15180 : 0.771465\n",
      "loss in epoch 16 , step 15200 : 0.677538\n",
      "loss in epoch 16 , step 15220 : 2.740360\n",
      "loss in epoch 16 , step 15240 : 0.242618\n",
      "loss in epoch 16 , step 15260 : 0.011343\n",
      "loss in epoch 16 , step 15280 : 0.486516\n",
      "loss in epoch 16 , step 15300 : 2.012326\n",
      "loss in epoch 16 , step 15320 : 0.299176\n",
      "loss in epoch 16 , step 15340 : 0.140778\n",
      "loss in epoch 16 , step 15360 : 0.186856\n",
      "loss in epoch 16 , step 15380 : 0.910081\n",
      "loss in epoch 16 , step 15400 : 0.040873\n",
      "loss in epoch 16 , step 15420 : 2.667048\n",
      "loss in epoch 16 , step 15440 : 1.464162\n",
      "loss in epoch 16 , step 15460 : 0.132103\n",
      "loss in epoch 16 , step 15480 : 0.262251\n",
      "loss in epoch 16 , step 15500 : 0.034544\n",
      "loss in epoch 16 , step 15520 : 1.797784\n",
      "loss in epoch 16 , step 15540 : 0.774432\n",
      "loss in epoch 16 , step 15560 : 0.074174\n",
      "loss in epoch 16 , step 15580 : 0.882632\n",
      "loss in epoch 16 , step 15600 : 0.593823\n",
      "loss in epoch 16 , step 15620 : 0.143194\n",
      "loss in epoch 16 , step 15640 : 0.487517\n",
      "loss in epoch 16 , step 15660 : 0.063312\n",
      "loss in epoch 16 , step 15680 : 0.342043\n",
      "loss in epoch 16 , step 15700 : 0.596247\n",
      "loss in epoch 16 , step 15720 : 0.544069\n",
      "loss in epoch 16 , step 15740 : 0.341772\n",
      "loss in epoch 16 , step 15760 : 1.342148\n",
      "loss in epoch 16 , step 15780 : 1.081473\n",
      "loss in epoch 16 , step 15800 : 0.529122\n",
      "loss in epoch 16 , step 15820 : 0.608791\n",
      "loss in epoch 16 , step 15840 : 0.004508\n",
      "loss in epoch 16 , step 15860 : 0.835065\n",
      "loss in epoch 16 , step 15880 : 0.293903\n",
      "loss in epoch 16 , step 15900 : 0.048925\n",
      "loss in epoch 16 , step 15920 : 2.869103\n",
      "loss in epoch 16 , step 15940 : 0.210965\n",
      "loss in epoch 16 , step 15960 : 0.164219\n",
      "loss in epoch 16 , step 15980 : 1.108641\n",
      "loss in epoch 16 , step 16000 : 2.136527\n",
      "loss in epoch 16 , step 16020 : 0.190968\n",
      "loss in epoch 16 , step 16040 : 1.850935\n",
      "loss in epoch 16 , step 16060 : 0.975880\n",
      "loss in epoch 16 , step 16080 : 0.008064\n",
      "loss in epoch 16 , step 16100 : 0.617322\n",
      "loss in epoch 16 , step 16120 : 1.312042\n",
      "loss in epoch 16 , step 16140 : 0.242550\n",
      "loss in epoch 16 , step 16160 : 0.107108\n",
      "loss in epoch 16 , step 16180 : 1.150890\n",
      "loss in epoch 16 , step 16200 : 0.408698\n",
      "loss in epoch 16 , step 16220 : 0.138132\n",
      "loss in epoch 16 , step 16240 : 1.196107\n",
      "loss in epoch 16 , step 16260 : 0.648674\n",
      "loss in epoch 16 , step 16280 : 2.036484\n",
      "loss in epoch 16 , step 16300 : 0.023656\n",
      "loss in epoch 16 , step 16320 : 0.107528\n",
      "loss in epoch 16 , step 16340 : 0.506694\n",
      "loss in epoch 16 , step 16360 : 0.008743\n",
      "loss in epoch 16 , step 16380 : 0.016517\n",
      "loss in epoch 16 , step 16400 : 0.146640\n",
      "loss in epoch 16 , step 16420 : 0.734892\n",
      "loss in epoch 16 , step 16440 : 0.410780\n",
      "loss in epoch 16 , step 16460 : 1.921594\n",
      "loss in epoch 16 , step 16480 : 0.118504\n",
      "loss in epoch 16 , step 16500 : 0.173631\n",
      "loss in epoch 16 , step 16520 : 0.241281\n",
      "loss in epoch 16 , step 16540 : 0.980829\n",
      "loss in epoch 16 , step 16560 : 2.118141\n",
      "loss in epoch 16 , step 16580 : 1.981442\n",
      "loss in epoch 16 , step 16600 : 0.025501\n",
      "loss in epoch 16 , step 16620 : 1.206535\n",
      "loss in epoch 16 , step 16640 : 0.159373\n",
      "loss in epoch 16 , step 16660 : 0.691105\n",
      "loss in epoch 16 , step 16680 : 0.001170\n",
      "loss in epoch 16 , step 16700 : 0.680799\n",
      "loss in epoch 16 , step 16720 : 0.077298\n",
      "loss in epoch 16 , step 16740 : 0.044223\n",
      "loss in epoch 16 , step 16760 : 3.058918\n",
      "loss in epoch 16 , step 16780 : 1.214520\n",
      "loss in epoch 16 , step 16800 : 0.463241\n",
      "loss in epoch 16 , step 16820 : 0.779252\n",
      "loss in epoch 16 , step 16840 : 1.323958\n",
      "loss in epoch 16 , step 16860 : 0.911898\n",
      "loss in epoch 16 , step 16880 : 1.788896\n",
      "loss in epoch 16 , step 16900 : 0.594223\n",
      "loss in epoch 16 , step 16920 : 0.556510\n",
      "loss in epoch 16 , step 16940 : 0.740941\n",
      "loss in epoch 16 , step 16960 : 2.319207\n",
      "loss in epoch 16 , step 16980 : 0.405103\n",
      "loss in epoch 16 , step 17000 : 0.575369\n",
      "loss in epoch 16 , step 17020 : 0.253583\n",
      "loss in epoch 16 , step 17040 : 0.032186\n",
      "loss in epoch 16 , step 17060 : 0.036275\n",
      "loss in epoch 16 , step 17080 : 0.498229\n",
      "loss in epoch 16 , step 17100 : 1.015867\n",
      "loss in epoch 16 , step 17120 : 1.675416\n",
      "loss in epoch 16 , step 17140 : 0.856022\n",
      "loss in epoch 16 , step 17160 : 0.411988\n",
      "loss in epoch 16 , step 17180 : 0.345337\n",
      "loss in epoch 16 , step 17200 : 0.066229\n",
      "loss in epoch 16 , step 17220 : 0.000819\n",
      "loss in epoch 16 , step 17240 : 0.695846\n",
      "loss in epoch 16 , step 17260 : 0.158109\n",
      "loss in epoch 16 , step 17280 : 0.272046\n",
      "loss in epoch 16 , step 17300 : 1.069312\n",
      "loss in epoch 16 , step 17320 : 0.048322\n",
      "loss in epoch 16 , step 17340 : 0.016370\n",
      "loss in epoch 16 , step 17360 : 0.019391\n",
      "loss in epoch 16 , step 17380 : 0.040560\n",
      "loss in epoch 16 , step 17400 : 0.006668\n",
      "loss in epoch 16 , step 17420 : 0.074237\n",
      "loss in epoch 16 , step 17440 : 0.092886\n",
      "loss in epoch 16 , step 17460 : 0.469885\n",
      "loss in epoch 16 , step 17480 : 0.775884\n",
      "loss in epoch 16 , step 17500 : 0.817087\n",
      "loss in epoch 16 , step 17520 : 0.077114\n",
      "loss in epoch 16 , step 17540 : 0.671224\n",
      "loss in epoch 16 , step 17560 : 0.036625\n",
      "loss in epoch 16 , step 17580 : 0.083936\n",
      "loss in epoch 16 , step 17600 : 0.314197\n",
      "loss in epoch 16 , step 17620 : 0.059904\n",
      "loss in epoch 16 , step 17640 : 0.182110\n",
      "loss in epoch 16 , step 17660 : 0.103365\n",
      "loss in epoch 16 , step 17680 : 0.503120\n",
      "loss in epoch 16 , step 17700 : 0.601750\n",
      "loss in epoch 16 , step 17720 : 0.496345\n",
      "loss in epoch 16 , step 17740 : 2.041352\n",
      "loss in epoch 16 , step 17760 : 1.022503\n",
      "loss in epoch 16 , step 17780 : 0.673048\n",
      "loss in epoch 16 , step 17800 : 1.443725\n",
      "loss in epoch 16 , step 17820 : 0.930604\n",
      "loss in epoch 16 , step 17840 : 0.041832\n",
      "loss in epoch 16 , step 17860 : 1.215353\n",
      "loss in epoch 16 , step 17880 : 1.071508\n",
      "loss in epoch 16 , step 17900 : 0.008651\n",
      "loss in epoch 16 , step 17920 : 0.653697\n",
      "loss in epoch 16 , step 17940 : 0.793717\n",
      "loss in epoch 16 , step 17960 : 0.360163\n",
      "loss in epoch 16 , step 17980 : 0.506926\n",
      "loss in epoch 16 , step 18000 : 0.257304\n",
      "loss in epoch 16 , step 18020 : 0.653101\n",
      "loss in epoch 16 , step 18040 : 0.004195\n",
      "loss in epoch 16 , step 18060 : 0.579839\n",
      "loss in epoch 16 , step 18080 : 1.459464\n",
      "loss in epoch 16 , step 18100 : 0.310482\n",
      "loss in epoch 16 , step 18120 : 0.039681\n",
      "loss in epoch 16 , step 18140 : 0.858513\n",
      "loss in epoch 16 , step 18160 : 0.374418\n",
      "loss in epoch 16 , step 18180 : 0.150474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 16 , step 18200 : 0.869452\n",
      "loss in epoch 16 , step 18220 : 0.013654\n",
      "loss in epoch 16 , step 18240 : 0.016499\n",
      "loss in epoch 16 , step 18260 : 0.073803\n",
      "loss in epoch 16 , step 18280 : 0.775793\n",
      "loss in epoch 16 , step 18300 : 0.077112\n",
      "loss in epoch 16 , step 18320 : 1.983375\n",
      "loss in epoch 16 , step 18340 : 0.003749\n",
      "loss in epoch 16 , step 18360 : 0.077729\n",
      "loss in epoch 16 , step 18380 : 2.513953\n",
      "loss in epoch 16 , step 18400 : 0.022650\n",
      "loss in epoch 16 , step 18420 : 0.142232\n",
      "loss in epoch 16 , step 18440 : 1.708378\n",
      "loss in epoch 16 , step 18460 : 0.918817\n",
      "loss in epoch 16 , step 18480 : 0.584480\n",
      "loss in epoch 16 , step 18500 : 1.016051\n",
      "loss in epoch 16 , step 18520 : 0.198696\n",
      "loss in epoch 16 , step 18540 : 0.144723\n",
      "loss in epoch 16 , step 18560 : 0.817766\n",
      "loss in epoch 16 , step 18580 : 0.405157\n",
      "loss in epoch 16 , step 18600 : 0.835171\n",
      "loss in epoch 16 , step 18620 : 1.142160\n",
      "loss in epoch 16 , step 18640 : 0.128898\n",
      "loss in epoch 16 , step 18660 : 0.600989\n",
      "loss in epoch 16 , step 18680 : 0.007913\n",
      "loss in epoch 16 , step 18700 : 0.046280\n",
      "loss in epoch 16 , step 18720 : 1.091271\n",
      "loss in epoch 16 , step 18740 : 0.899026\n",
      "loss in epoch 16 , step 18760 : 0.004990\n",
      "loss in epoch 16 , step 18780 : 0.641001\n",
      "loss in epoch 16 , step 18800 : 0.775177\n",
      "loss in epoch 16 , step 18820 : 0.448408\n",
      "loss in epoch 16 , step 18840 : 0.372591\n",
      "loss in epoch 16 , step 18860 : 0.207515\n",
      "loss in epoch 16 , step 18880 : 1.790527\n",
      "loss in epoch 16 , step 18900 : 1.250021\n",
      "loss in epoch 16 , step 18920 : 1.959486\n",
      "loss in epoch 16 , step 18940 : 0.033195\n",
      "loss in epoch 16 , step 18960 : 0.106306\n",
      "loss in epoch 16 , step 18980 : 0.001414\n",
      "loss in epoch 16 , step 19000 : 0.233430\n",
      "loss in epoch 16 , step 19020 : 1.270453\n",
      "loss in epoch 16 , step 19040 : 0.603348\n",
      "loss in epoch 16 , step 19060 : 2.599049\n",
      "loss in epoch 16 , step 19080 : 0.786448\n",
      "loss in epoch 16 , step 19100 : 0.899974\n",
      "loss in epoch 16 , step 19120 : 1.250850\n",
      "loss in epoch 16 , step 19140 : 1.130470\n",
      "loss in epoch 16 , step 19160 : 1.869507\n",
      "loss in epoch 16 , step 19180 : 0.002450\n",
      "loss in epoch 16 , step 19200 : 0.010112\n",
      "loss in epoch 16 , step 19220 : 1.411123\n",
      "loss in epoch 16 , step 19240 : 0.115062\n",
      "loss in epoch 16 , step 19260 : 0.087796\n",
      "loss in epoch 16 , step 19280 : 0.467564\n",
      "loss in epoch 16 , step 19300 : 1.050916\n",
      "loss in epoch 16 , step 19320 : 0.402098\n",
      "loss in epoch 16 , step 19340 : 0.556569\n",
      "loss in epoch 16 , step 19360 : 0.221942\n",
      "loss in epoch 16 , step 19380 : 1.659615\n",
      "loss in epoch 16 , step 19400 : 0.497322\n",
      "loss in epoch 16 , step 19420 : 1.826903\n",
      "loss in epoch 16 , step 19440 : 0.004848\n",
      "loss in epoch 16 , step 19460 : 0.169994\n",
      "loss in epoch 16 , step 19480 : 0.007713\n",
      "loss in epoch 16 , step 19500 : 0.419800\n",
      "loss in epoch 16 , step 19520 : 0.545561\n",
      "loss in epoch 16 , step 19540 : 0.562004\n",
      "loss in epoch 16 , step 19560 : 1.549192\n",
      "loss in epoch 16 , step 19580 : 0.044302\n",
      "loss in epoch 16 , step 19600 : 0.104809\n",
      "loss in epoch 16 , step 19620 : 0.696043\n",
      "loss in epoch 16 , step 19640 : 0.627145\n",
      "loss in epoch 16 , step 19660 : 0.284358\n",
      "loss in epoch 16 , step 19680 : 4.517303\n",
      "loss in epoch 16 , step 19700 : 0.019474\n",
      "loss in epoch 16 , step 19720 : 2.637450\n",
      "loss in epoch 16 , step 19740 : 0.002355\n",
      "loss in epoch 16 , step 19760 : 0.218551\n",
      "loss in epoch 16 , step 19780 : 1.901339\n",
      "loss in epoch 16 , step 19800 : 0.629669\n",
      "loss in epoch 16 , step 19820 : 0.022027\n",
      "loss in epoch 16 , step 19840 : 0.899578\n",
      "loss in epoch 16 , step 19860 : 1.122701\n",
      "loss in epoch 16 , step 19880 : 0.002598\n",
      "loss in epoch 16 , step 19900 : 0.769081\n",
      "loss in epoch 16 , step 19920 : 0.638864\n",
      "loss in epoch 16 , step 19940 : 0.002984\n",
      "Accuracy in epoch 16 : 32.966618\n",
      "loss in epoch 17 , step 0 : 0.748656\n",
      "loss in epoch 17 , step 20 : 0.138038\n",
      "loss in epoch 17 , step 40 : 0.951495\n",
      "loss in epoch 17 , step 60 : 0.259057\n",
      "loss in epoch 17 , step 80 : 0.353183\n",
      "loss in epoch 17 , step 100 : 3.541281\n",
      "loss in epoch 17 , step 120 : 0.481574\n",
      "loss in epoch 17 , step 140 : 0.446679\n",
      "loss in epoch 17 , step 160 : 1.578768\n",
      "loss in epoch 17 , step 180 : 0.281229\n",
      "loss in epoch 17 , step 200 : 0.762405\n",
      "loss in epoch 17 , step 220 : 0.049916\n",
      "loss in epoch 17 , step 240 : 0.411838\n",
      "loss in epoch 17 , step 260 : 0.285950\n",
      "loss in epoch 17 , step 280 : 0.459483\n",
      "loss in epoch 17 , step 300 : 1.102403\n",
      "loss in epoch 17 , step 320 : 0.793201\n",
      "loss in epoch 17 , step 340 : 1.364966\n",
      "loss in epoch 17 , step 360 : 0.372356\n",
      "loss in epoch 17 , step 380 : 1.139268\n",
      "loss in epoch 17 , step 400 : 1.186206\n",
      "loss in epoch 17 , step 420 : 0.369313\n",
      "loss in epoch 17 , step 440 : 1.678284\n",
      "loss in epoch 17 , step 460 : 0.600268\n",
      "loss in epoch 17 , step 480 : 0.266747\n",
      "loss in epoch 17 , step 500 : 0.732861\n",
      "loss in epoch 17 , step 520 : 0.552923\n",
      "loss in epoch 17 , step 540 : 0.001182\n",
      "loss in epoch 17 , step 560 : 0.750348\n",
      "loss in epoch 17 , step 580 : 0.492570\n",
      "loss in epoch 17 , step 600 : 0.012210\n",
      "loss in epoch 17 , step 620 : 0.820743\n",
      "loss in epoch 17 , step 640 : 0.002617\n",
      "loss in epoch 17 , step 660 : 0.884598\n",
      "loss in epoch 17 , step 680 : 0.100773\n",
      "loss in epoch 17 , step 700 : 0.494830\n",
      "loss in epoch 17 , step 720 : 1.792483\n",
      "loss in epoch 17 , step 740 : 0.008511\n",
      "loss in epoch 17 , step 760 : 0.586938\n",
      "loss in epoch 17 , step 780 : 1.430873\n",
      "loss in epoch 17 , step 800 : 0.543933\n",
      "loss in epoch 17 , step 820 : 0.000793\n",
      "loss in epoch 17 , step 840 : 0.652106\n",
      "loss in epoch 17 , step 860 : 0.314759\n",
      "loss in epoch 17 , step 880 : 0.067211\n",
      "loss in epoch 17 , step 900 : 1.408689\n",
      "loss in epoch 17 , step 920 : 0.213708\n",
      "loss in epoch 17 , step 940 : 1.586115\n",
      "loss in epoch 17 , step 960 : 0.568860\n",
      "loss in epoch 17 , step 980 : 0.534136\n",
      "loss in epoch 17 , step 1000 : 0.027426\n",
      "loss in epoch 17 , step 1020 : 1.090283\n",
      "loss in epoch 17 , step 1040 : 0.330502\n",
      "loss in epoch 17 , step 1060 : 0.854545\n",
      "loss in epoch 17 , step 1080 : 0.656522\n",
      "loss in epoch 17 , step 1100 : 0.013174\n",
      "loss in epoch 17 , step 1120 : 1.449025\n",
      "loss in epoch 17 , step 1140 : 0.399264\n",
      "loss in epoch 17 , step 1160 : 0.110234\n",
      "loss in epoch 17 , step 1180 : 0.598359\n",
      "loss in epoch 17 , step 1200 : 0.814632\n",
      "loss in epoch 17 , step 1220 : 1.178523\n",
      "loss in epoch 17 , step 1240 : 0.256892\n",
      "loss in epoch 17 , step 1260 : 0.005831\n",
      "loss in epoch 17 , step 1280 : 0.139700\n",
      "loss in epoch 17 , step 1300 : 0.005433\n",
      "loss in epoch 17 , step 1320 : 0.001677\n",
      "loss in epoch 17 , step 1340 : 0.132266\n",
      "loss in epoch 17 , step 1360 : 0.415877\n",
      "loss in epoch 17 , step 1380 : 0.616442\n",
      "loss in epoch 17 , step 1400 : 0.080463\n",
      "loss in epoch 17 , step 1420 : 0.029653\n",
      "loss in epoch 17 , step 1440 : 0.009108\n",
      "loss in epoch 17 , step 1460 : 1.057912\n",
      "loss in epoch 17 , step 1480 : 0.949027\n",
      "loss in epoch 17 , step 1500 : 1.289199\n",
      "loss in epoch 17 , step 1520 : 0.767759\n",
      "loss in epoch 17 , step 1540 : 0.003833\n",
      "loss in epoch 17 , step 1560 : 1.265038\n",
      "loss in epoch 17 , step 1580 : 2.449186\n",
      "loss in epoch 17 , step 1600 : 0.085882\n",
      "loss in epoch 17 , step 1620 : 0.008407\n",
      "loss in epoch 17 , step 1640 : 0.769124\n",
      "loss in epoch 17 , step 1660 : 1.371454\n",
      "loss in epoch 17 , step 1680 : 0.226723\n",
      "loss in epoch 17 , step 1700 : 1.621966\n",
      "loss in epoch 17 , step 1720 : 0.503822\n",
      "loss in epoch 17 , step 1740 : 0.220917\n",
      "loss in epoch 17 , step 1760 : 0.979312\n",
      "loss in epoch 17 , step 1780 : 0.009335\n",
      "loss in epoch 17 , step 1800 : 0.031370\n",
      "loss in epoch 17 , step 1820 : 1.132473\n",
      "loss in epoch 17 , step 1840 : 0.386176\n",
      "loss in epoch 17 , step 1860 : 1.259613\n",
      "loss in epoch 17 , step 1880 : 2.029044\n",
      "loss in epoch 17 , step 1900 : 0.171580\n",
      "loss in epoch 17 , step 1920 : 0.540767\n",
      "loss in epoch 17 , step 1940 : 0.859918\n",
      "loss in epoch 17 , step 1960 : 0.548280\n",
      "loss in epoch 17 , step 1980 : 0.863602\n",
      "loss in epoch 17 , step 2000 : 0.001556\n",
      "loss in epoch 17 , step 2020 : 0.082602\n",
      "loss in epoch 17 , step 2040 : 0.838306\n",
      "loss in epoch 17 , step 2060 : 1.213697\n",
      "loss in epoch 17 , step 2080 : 0.520694\n",
      "loss in epoch 17 , step 2100 : 1.246136\n",
      "loss in epoch 17 , step 2120 : 0.419852\n",
      "loss in epoch 17 , step 2140 : 0.947692\n",
      "loss in epoch 17 , step 2160 : 0.090449\n",
      "loss in epoch 17 , step 2180 : 0.597125\n",
      "loss in epoch 17 , step 2200 : 0.937311\n",
      "loss in epoch 17 , step 2220 : 1.289496\n",
      "loss in epoch 17 , step 2240 : 0.065883\n",
      "loss in epoch 17 , step 2260 : 0.624123\n",
      "loss in epoch 17 , step 2280 : 0.024976\n",
      "loss in epoch 17 , step 2300 : 0.373411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 17 , step 2320 : 0.567368\n",
      "loss in epoch 17 , step 2340 : 1.127158\n",
      "loss in epoch 17 , step 2360 : 1.265745\n",
      "loss in epoch 17 , step 2380 : 0.741741\n",
      "loss in epoch 17 , step 2400 : 1.050219\n",
      "loss in epoch 17 , step 2420 : 0.196232\n",
      "loss in epoch 17 , step 2440 : 0.914763\n",
      "loss in epoch 17 , step 2460 : 0.191903\n",
      "loss in epoch 17 , step 2480 : 0.925372\n",
      "loss in epoch 17 , step 2500 : 0.064961\n",
      "loss in epoch 17 , step 2520 : 1.332994\n",
      "loss in epoch 17 , step 2540 : 1.046760\n",
      "loss in epoch 17 , step 2560 : 0.647779\n",
      "loss in epoch 17 , step 2580 : 0.451850\n",
      "loss in epoch 17 , step 2600 : 0.596717\n",
      "loss in epoch 17 , step 2620 : 0.084144\n",
      "loss in epoch 17 , step 2640 : 0.206972\n",
      "loss in epoch 17 , step 2660 : 1.867376\n",
      "loss in epoch 17 , step 2680 : 2.074327\n",
      "loss in epoch 17 , step 2700 : 0.323046\n",
      "loss in epoch 17 , step 2720 : 2.424530\n",
      "loss in epoch 17 , step 2740 : 0.729740\n",
      "loss in epoch 17 , step 2760 : 2.332869\n",
      "loss in epoch 17 , step 2780 : 0.464158\n",
      "loss in epoch 17 , step 2800 : 0.003966\n",
      "loss in epoch 17 , step 2820 : 0.152401\n",
      "loss in epoch 17 , step 2840 : 0.216394\n",
      "loss in epoch 17 , step 2860 : 0.000524\n",
      "loss in epoch 17 , step 2880 : 0.566900\n",
      "loss in epoch 17 , step 2900 : 1.113062\n",
      "loss in epoch 17 , step 2920 : 0.395309\n",
      "loss in epoch 17 , step 2940 : 0.206431\n",
      "loss in epoch 17 , step 2960 : 0.046063\n",
      "loss in epoch 17 , step 2980 : 0.620516\n",
      "loss in epoch 17 , step 3000 : 0.001720\n",
      "loss in epoch 17 , step 3020 : 0.022230\n",
      "loss in epoch 17 , step 3040 : 0.071568\n",
      "loss in epoch 17 , step 3060 : 0.244871\n",
      "loss in epoch 17 , step 3080 : 1.555727\n",
      "loss in epoch 17 , step 3100 : 0.441306\n",
      "loss in epoch 17 , step 3120 : 0.065943\n",
      "loss in epoch 17 , step 3140 : 1.083017\n",
      "loss in epoch 17 , step 3160 : 0.002852\n",
      "loss in epoch 17 , step 3180 : 0.083021\n",
      "loss in epoch 17 , step 3200 : 0.151300\n",
      "loss in epoch 17 , step 3220 : 1.466191\n",
      "loss in epoch 17 , step 3240 : 0.802455\n",
      "loss in epoch 17 , step 3260 : 0.152880\n",
      "loss in epoch 17 , step 3280 : 0.468349\n",
      "loss in epoch 17 , step 3300 : 0.013569\n",
      "loss in epoch 17 , step 3320 : 0.030438\n",
      "loss in epoch 17 , step 3340 : 0.568174\n",
      "loss in epoch 17 , step 3360 : 2.695566\n",
      "loss in epoch 17 , step 3380 : 0.828188\n",
      "loss in epoch 17 , step 3400 : 4.869065\n",
      "loss in epoch 17 , step 3420 : 0.091892\n",
      "loss in epoch 17 , step 3440 : 0.265322\n",
      "loss in epoch 17 , step 3460 : 0.144661\n",
      "loss in epoch 17 , step 3480 : 1.432454\n",
      "loss in epoch 17 , step 3500 : 0.004630\n",
      "loss in epoch 17 , step 3520 : 0.466657\n",
      "loss in epoch 17 , step 3540 : 0.024616\n",
      "loss in epoch 17 , step 3560 : 2.125242\n",
      "loss in epoch 17 , step 3580 : 0.615377\n",
      "loss in epoch 17 , step 3600 : 0.878826\n",
      "loss in epoch 17 , step 3620 : 0.038476\n",
      "loss in epoch 17 , step 3640 : 1.317715\n",
      "loss in epoch 17 , step 3660 : 0.050549\n",
      "loss in epoch 17 , step 3680 : 0.515366\n",
      "loss in epoch 17 , step 3700 : 0.168854\n",
      "loss in epoch 17 , step 3720 : 0.344508\n",
      "loss in epoch 17 , step 3740 : 0.205238\n",
      "loss in epoch 17 , step 3760 : 1.782404\n",
      "loss in epoch 17 , step 3780 : 0.253975\n",
      "loss in epoch 17 , step 3800 : 0.453456\n",
      "loss in epoch 17 , step 3820 : 0.101782\n",
      "loss in epoch 17 , step 3840 : 0.008261\n",
      "loss in epoch 17 , step 3860 : 0.988816\n",
      "loss in epoch 17 , step 3880 : 0.971204\n",
      "loss in epoch 17 , step 3900 : 0.115574\n",
      "loss in epoch 17 , step 3920 : 0.514743\n",
      "loss in epoch 17 , step 3940 : 0.211692\n",
      "loss in epoch 17 , step 3960 : 0.676835\n",
      "loss in epoch 17 , step 3980 : 1.077664\n",
      "loss in epoch 17 , step 4000 : 0.235580\n",
      "loss in epoch 17 , step 4020 : 0.216465\n",
      "loss in epoch 17 , step 4040 : 0.892364\n",
      "loss in epoch 17 , step 4060 : 0.930758\n",
      "loss in epoch 17 , step 4080 : 1.626477\n",
      "loss in epoch 17 , step 4100 : 0.732210\n",
      "loss in epoch 17 , step 4120 : 2.846657\n",
      "loss in epoch 17 , step 4140 : 0.002618\n",
      "loss in epoch 17 , step 4160 : 0.011394\n",
      "loss in epoch 17 , step 4180 : 0.070089\n",
      "loss in epoch 17 , step 4200 : 1.555508\n",
      "loss in epoch 17 , step 4220 : 0.449980\n",
      "loss in epoch 17 , step 4240 : 0.011978\n",
      "loss in epoch 17 , step 4260 : 0.126464\n",
      "loss in epoch 17 , step 4280 : 1.639388\n",
      "loss in epoch 17 , step 4300 : 0.003464\n",
      "loss in epoch 17 , step 4320 : 0.994907\n",
      "loss in epoch 17 , step 4340 : 0.017586\n",
      "loss in epoch 17 , step 4360 : 0.395967\n",
      "loss in epoch 17 , step 4380 : 0.686049\n",
      "loss in epoch 17 , step 4400 : 0.131612\n",
      "loss in epoch 17 , step 4420 : 1.201936\n",
      "loss in epoch 17 , step 4440 : 3.015247\n",
      "loss in epoch 17 , step 4460 : 0.026001\n",
      "loss in epoch 17 , step 4480 : 1.687642\n",
      "loss in epoch 17 , step 4500 : 0.349829\n",
      "loss in epoch 17 , step 4520 : 0.660547\n",
      "loss in epoch 17 , step 4540 : 1.073255\n",
      "loss in epoch 17 , step 4560 : 0.379664\n",
      "loss in epoch 17 , step 4580 : 0.743538\n",
      "loss in epoch 17 , step 4600 : 0.686743\n",
      "loss in epoch 17 , step 4620 : 0.543592\n",
      "loss in epoch 17 , step 4640 : 0.402582\n",
      "loss in epoch 17 , step 4660 : 0.795257\n",
      "loss in epoch 17 , step 4680 : 0.535873\n",
      "loss in epoch 17 , step 4700 : 1.077866\n",
      "loss in epoch 17 , step 4720 : 1.457807\n",
      "loss in epoch 17 , step 4740 : 0.148877\n",
      "loss in epoch 17 , step 4760 : 0.048219\n",
      "loss in epoch 17 , step 4780 : 0.008244\n",
      "loss in epoch 17 , step 4800 : 0.414284\n",
      "loss in epoch 17 , step 4820 : 0.687145\n",
      "loss in epoch 17 , step 4840 : 2.842017\n",
      "loss in epoch 17 , step 4860 : 0.850245\n",
      "loss in epoch 17 , step 4880 : 0.218910\n",
      "loss in epoch 17 , step 4900 : 0.884522\n",
      "loss in epoch 17 , step 4920 : 0.014553\n",
      "loss in epoch 17 , step 4940 : 0.022517\n",
      "loss in epoch 17 , step 4960 : 0.220174\n",
      "loss in epoch 17 , step 4980 : 0.531770\n",
      "loss in epoch 17 , step 5000 : 1.720190\n",
      "loss in epoch 17 , step 5020 : 0.000671\n",
      "loss in epoch 17 , step 5040 : 0.715728\n",
      "loss in epoch 17 , step 5060 : 0.003891\n",
      "loss in epoch 17 , step 5080 : 0.721002\n",
      "loss in epoch 17 , step 5100 : 0.240628\n",
      "loss in epoch 17 , step 5120 : 0.656284\n",
      "loss in epoch 17 , step 5140 : 1.973647\n",
      "loss in epoch 17 , step 5160 : 0.207758\n",
      "loss in epoch 17 , step 5180 : 1.915835\n",
      "loss in epoch 17 , step 5200 : 0.466008\n",
      "loss in epoch 17 , step 5220 : 0.943372\n",
      "loss in epoch 17 , step 5240 : 0.373579\n",
      "loss in epoch 17 , step 5260 : 1.845990\n",
      "loss in epoch 17 , step 5280 : 0.314326\n",
      "loss in epoch 17 , step 5300 : 0.068707\n",
      "loss in epoch 17 , step 5320 : 0.360907\n",
      "loss in epoch 17 , step 5340 : 0.701522\n",
      "loss in epoch 17 , step 5360 : 0.222496\n",
      "loss in epoch 17 , step 5380 : 1.557745\n",
      "loss in epoch 17 , step 5400 : 0.009640\n",
      "loss in epoch 17 , step 5420 : 0.849010\n",
      "loss in epoch 17 , step 5440 : 0.209830\n",
      "loss in epoch 17 , step 5460 : 0.684037\n",
      "loss in epoch 17 , step 5480 : 0.048364\n",
      "loss in epoch 17 , step 5500 : 0.128398\n",
      "loss in epoch 17 , step 5520 : 0.823075\n",
      "loss in epoch 17 , step 5540 : 1.351596\n",
      "loss in epoch 17 , step 5560 : 0.693687\n",
      "loss in epoch 17 , step 5580 : 0.447728\n",
      "loss in epoch 17 , step 5600 : 0.208735\n",
      "loss in epoch 17 , step 5620 : 0.125973\n",
      "loss in epoch 17 , step 5640 : 0.574111\n",
      "loss in epoch 17 , step 5660 : 0.429057\n",
      "loss in epoch 17 , step 5680 : 0.251756\n",
      "loss in epoch 17 , step 5700 : 0.907494\n",
      "loss in epoch 17 , step 5720 : 0.278421\n",
      "loss in epoch 17 , step 5740 : 0.943331\n",
      "loss in epoch 17 , step 5760 : 0.377361\n",
      "loss in epoch 17 , step 5780 : 0.468213\n",
      "loss in epoch 17 , step 5800 : 2.498698\n",
      "loss in epoch 17 , step 5820 : 0.374468\n",
      "loss in epoch 17 , step 5840 : 1.154608\n",
      "loss in epoch 17 , step 5860 : 0.481040\n",
      "loss in epoch 17 , step 5880 : 0.013977\n",
      "loss in epoch 17 , step 5900 : 0.600801\n",
      "loss in epoch 17 , step 5920 : 0.017499\n",
      "loss in epoch 17 , step 5940 : 0.221829\n",
      "loss in epoch 17 , step 5960 : 1.893825\n",
      "loss in epoch 17 , step 5980 : 0.568115\n",
      "loss in epoch 17 , step 6000 : 0.032127\n",
      "loss in epoch 17 , step 6020 : 0.147693\n",
      "loss in epoch 17 , step 6040 : 0.445267\n",
      "loss in epoch 17 , step 6060 : 2.034680\n",
      "loss in epoch 17 , step 6080 : 0.489366\n",
      "loss in epoch 17 , step 6100 : 0.171209\n",
      "loss in epoch 17 , step 6120 : 0.479545\n",
      "loss in epoch 17 , step 6140 : 0.946183\n",
      "loss in epoch 17 , step 6160 : 0.668016\n",
      "loss in epoch 17 , step 6180 : 0.402485\n",
      "loss in epoch 17 , step 6200 : 0.226079\n",
      "loss in epoch 17 , step 6220 : 1.063264\n",
      "loss in epoch 17 , step 6240 : 0.382501\n",
      "loss in epoch 17 , step 6260 : 0.587870\n",
      "loss in epoch 17 , step 6280 : 1.172682\n",
      "loss in epoch 17 , step 6300 : 0.477925\n",
      "loss in epoch 17 , step 6320 : 0.137803\n",
      "loss in epoch 17 , step 6340 : 0.024024\n",
      "loss in epoch 17 , step 6360 : 0.086526\n",
      "loss in epoch 17 , step 6380 : 0.959855\n",
      "loss in epoch 17 , step 6400 : 0.036443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 17 , step 6420 : 1.012068\n",
      "loss in epoch 17 , step 6440 : 0.076170\n",
      "loss in epoch 17 , step 6460 : 0.450662\n",
      "loss in epoch 17 , step 6480 : 0.768324\n",
      "loss in epoch 17 , step 6500 : 0.123870\n",
      "loss in epoch 17 , step 6520 : 0.490157\n",
      "loss in epoch 17 , step 6540 : 1.067071\n",
      "loss in epoch 17 , step 6560 : 0.134855\n",
      "loss in epoch 17 , step 6580 : 1.831259\n",
      "loss in epoch 17 , step 6600 : 0.688920\n",
      "loss in epoch 17 , step 6620 : 0.003044\n",
      "loss in epoch 17 , step 6640 : 0.006708\n",
      "loss in epoch 17 , step 6660 : 1.232837\n",
      "loss in epoch 17 , step 6680 : 0.330356\n",
      "loss in epoch 17 , step 6700 : 0.840082\n",
      "loss in epoch 17 , step 6720 : 0.335193\n",
      "loss in epoch 17 , step 6740 : 0.351926\n",
      "loss in epoch 17 , step 6760 : 1.401989\n",
      "loss in epoch 17 , step 6780 : 0.006057\n",
      "loss in epoch 17 , step 6800 : 0.733572\n",
      "loss in epoch 17 , step 6820 : 0.825785\n",
      "loss in epoch 17 , step 6840 : 0.172181\n",
      "loss in epoch 17 , step 6860 : 0.002417\n",
      "loss in epoch 17 , step 6880 : 1.278328\n",
      "loss in epoch 17 , step 6900 : 0.528755\n",
      "loss in epoch 17 , step 6920 : 0.206226\n",
      "loss in epoch 17 , step 6940 : 0.647930\n",
      "loss in epoch 17 , step 6960 : 0.350965\n",
      "loss in epoch 17 , step 6980 : 0.667540\n",
      "loss in epoch 17 , step 7000 : 0.092340\n",
      "loss in epoch 17 , step 7020 : 0.531900\n",
      "loss in epoch 17 , step 7040 : 0.908948\n",
      "loss in epoch 17 , step 7060 : 1.210822\n",
      "loss in epoch 17 , step 7080 : 0.633345\n",
      "loss in epoch 17 , step 7100 : 0.091847\n",
      "loss in epoch 17 , step 7120 : 1.495698\n",
      "loss in epoch 17 , step 7140 : 1.188908\n",
      "loss in epoch 17 , step 7160 : 0.035226\n",
      "loss in epoch 17 , step 7180 : 3.229833\n",
      "loss in epoch 17 , step 7200 : 1.382141\n",
      "loss in epoch 17 , step 7220 : 0.593492\n",
      "loss in epoch 17 , step 7240 : 0.818926\n",
      "loss in epoch 17 , step 7260 : 0.361388\n",
      "loss in epoch 17 , step 7280 : 0.006021\n",
      "loss in epoch 17 , step 7300 : 0.019076\n",
      "loss in epoch 17 , step 7320 : 1.201321\n",
      "loss in epoch 17 , step 7340 : 0.807761\n",
      "loss in epoch 17 , step 7360 : 0.340406\n",
      "loss in epoch 17 , step 7380 : 0.542707\n",
      "loss in epoch 17 , step 7400 : 0.040063\n",
      "loss in epoch 17 , step 7420 : 0.028094\n",
      "loss in epoch 17 , step 7440 : 0.357109\n",
      "loss in epoch 17 , step 7460 : 0.674930\n",
      "loss in epoch 17 , step 7480 : 0.927945\n",
      "loss in epoch 17 , step 7500 : 0.009875\n",
      "loss in epoch 17 , step 7520 : 0.038851\n",
      "loss in epoch 17 , step 7540 : 0.463276\n",
      "loss in epoch 17 , step 7560 : 1.153909\n",
      "loss in epoch 17 , step 7580 : 1.268825\n",
      "loss in epoch 17 , step 7600 : 0.735934\n",
      "loss in epoch 17 , step 7620 : 1.691847\n",
      "loss in epoch 17 , step 7640 : 0.080738\n",
      "loss in epoch 17 , step 7660 : 1.598188\n",
      "loss in epoch 17 , step 7680 : 0.877452\n",
      "loss in epoch 17 , step 7700 : 0.285618\n",
      "loss in epoch 17 , step 7720 : 0.486016\n",
      "loss in epoch 17 , step 7740 : 0.628236\n",
      "loss in epoch 17 , step 7760 : 0.723655\n",
      "loss in epoch 17 , step 7780 : 0.007437\n",
      "loss in epoch 17 , step 7800 : 2.127551\n",
      "loss in epoch 17 , step 7820 : 0.385366\n",
      "loss in epoch 17 , step 7840 : 1.565411\n",
      "loss in epoch 17 , step 7860 : 0.015511\n",
      "loss in epoch 17 , step 7880 : 0.011343\n",
      "loss in epoch 17 , step 7900 : 0.061982\n",
      "loss in epoch 17 , step 7920 : 0.308128\n",
      "loss in epoch 17 , step 7940 : 0.830695\n",
      "loss in epoch 17 , step 7960 : 0.005576\n",
      "loss in epoch 17 , step 7980 : 0.151288\n",
      "loss in epoch 17 , step 8000 : 0.096836\n",
      "loss in epoch 17 , step 8020 : 0.207339\n",
      "loss in epoch 17 , step 8040 : 1.279692\n",
      "loss in epoch 17 , step 8060 : 0.041268\n",
      "loss in epoch 17 , step 8080 : 0.189173\n",
      "loss in epoch 17 , step 8100 : 0.633985\n",
      "loss in epoch 17 , step 8120 : 1.020082\n",
      "loss in epoch 17 , step 8140 : 1.338720\n",
      "loss in epoch 17 , step 8160 : 0.153093\n",
      "loss in epoch 17 , step 8180 : 1.582155\n",
      "loss in epoch 17 , step 8200 : 2.396908\n",
      "loss in epoch 17 , step 8220 : 0.013204\n",
      "loss in epoch 17 , step 8240 : 2.256887\n",
      "loss in epoch 17 , step 8260 : 0.157913\n",
      "loss in epoch 17 , step 8280 : 0.938977\n",
      "loss in epoch 17 , step 8300 : 0.001726\n",
      "loss in epoch 17 , step 8320 : 0.953828\n",
      "loss in epoch 17 , step 8340 : 0.002229\n",
      "loss in epoch 17 , step 8360 : 3.638488\n",
      "loss in epoch 17 , step 8380 : 0.383188\n",
      "loss in epoch 17 , step 8400 : 1.243177\n",
      "loss in epoch 17 , step 8420 : 0.016078\n",
      "loss in epoch 17 , step 8440 : 0.012539\n",
      "loss in epoch 17 , step 8460 : 0.004879\n",
      "loss in epoch 17 , step 8480 : 0.395437\n",
      "loss in epoch 17 , step 8500 : 0.984459\n",
      "loss in epoch 17 , step 8520 : 0.003570\n",
      "loss in epoch 17 , step 8540 : 0.268999\n",
      "loss in epoch 17 , step 8560 : 0.250736\n",
      "loss in epoch 17 , step 8580 : 2.658505\n",
      "loss in epoch 17 , step 8600 : 0.586465\n",
      "loss in epoch 17 , step 8620 : 1.313072\n",
      "loss in epoch 17 , step 8640 : 0.436033\n",
      "loss in epoch 17 , step 8660 : 0.814762\n",
      "loss in epoch 17 , step 8680 : 0.018773\n",
      "loss in epoch 17 , step 8700 : 0.518041\n",
      "loss in epoch 17 , step 8720 : 0.557213\n",
      "loss in epoch 17 , step 8740 : 0.037328\n",
      "loss in epoch 17 , step 8760 : 0.320347\n",
      "loss in epoch 17 , step 8780 : 1.131672\n",
      "loss in epoch 17 , step 8800 : 1.291459\n",
      "loss in epoch 17 , step 8820 : 1.119700\n",
      "loss in epoch 17 , step 8840 : 0.703004\n",
      "loss in epoch 17 , step 8860 : 3.084424\n",
      "loss in epoch 17 , step 8880 : 0.471656\n",
      "loss in epoch 17 , step 8900 : 0.187062\n",
      "loss in epoch 17 , step 8920 : 0.858374\n",
      "loss in epoch 17 , step 8940 : 0.570940\n",
      "loss in epoch 17 , step 8960 : 0.248008\n",
      "loss in epoch 17 , step 8980 : 0.013703\n",
      "loss in epoch 17 , step 9000 : 0.498420\n",
      "loss in epoch 17 , step 9020 : 0.929903\n",
      "loss in epoch 17 , step 9040 : 0.689451\n",
      "loss in epoch 17 , step 9060 : 0.338789\n",
      "loss in epoch 17 , step 9080 : 0.580977\n",
      "loss in epoch 17 , step 9100 : 0.000978\n",
      "loss in epoch 17 , step 9120 : 0.838150\n",
      "loss in epoch 17 , step 9140 : 0.335568\n",
      "loss in epoch 17 , step 9160 : 0.004799\n",
      "loss in epoch 17 , step 9180 : 2.007015\n",
      "loss in epoch 17 , step 9200 : 0.220642\n",
      "loss in epoch 17 , step 9220 : 0.530389\n",
      "loss in epoch 17 , step 9240 : 0.213227\n",
      "loss in epoch 17 , step 9260 : 0.720163\n",
      "loss in epoch 17 , step 9280 : 0.528401\n",
      "loss in epoch 17 , step 9300 : 0.775447\n",
      "loss in epoch 17 , step 9320 : 0.352915\n",
      "loss in epoch 17 , step 9340 : 0.002838\n",
      "loss in epoch 17 , step 9360 : 0.474855\n",
      "loss in epoch 17 , step 9380 : 0.832392\n",
      "loss in epoch 17 , step 9400 : 0.022707\n",
      "loss in epoch 17 , step 9420 : 0.194342\n",
      "loss in epoch 17 , step 9440 : 0.216615\n",
      "loss in epoch 17 , step 9460 : 0.095823\n",
      "loss in epoch 17 , step 9480 : 0.096961\n",
      "loss in epoch 17 , step 9500 : 0.026102\n",
      "loss in epoch 17 , step 9520 : 1.101530\n",
      "loss in epoch 17 , step 9540 : 0.001723\n",
      "loss in epoch 17 , step 9560 : 0.249928\n",
      "loss in epoch 17 , step 9580 : 1.234040\n",
      "loss in epoch 17 , step 9600 : 0.249014\n",
      "loss in epoch 17 , step 9620 : 0.071756\n",
      "loss in epoch 17 , step 9640 : 1.062624\n",
      "loss in epoch 17 , step 9660 : 0.730205\n",
      "loss in epoch 17 , step 9680 : 2.871825\n",
      "loss in epoch 17 , step 9700 : 0.024840\n",
      "loss in epoch 17 , step 9720 : 1.388956\n",
      "loss in epoch 17 , step 9740 : 0.012339\n",
      "loss in epoch 17 , step 9760 : 0.212762\n",
      "loss in epoch 17 , step 9780 : 0.912552\n",
      "loss in epoch 17 , step 9800 : 0.043797\n",
      "loss in epoch 17 , step 9820 : 0.833758\n",
      "loss in epoch 17 , step 9840 : 0.031976\n",
      "loss in epoch 17 , step 9860 : 0.438199\n",
      "loss in epoch 17 , step 9880 : 0.030072\n",
      "loss in epoch 17 , step 9900 : 0.029240\n",
      "loss in epoch 17 , step 9920 : 1.450376\n",
      "loss in epoch 17 , step 9940 : 1.924442\n",
      "loss in epoch 17 , step 9960 : 0.298504\n",
      "loss in epoch 17 , step 9980 : 0.991423\n",
      "loss in epoch 17 , step 10000 : 0.568209\n",
      "loss in epoch 17 , step 10020 : 2.589922\n",
      "loss in epoch 17 , step 10040 : 0.037094\n",
      "loss in epoch 17 , step 10060 : 0.011434\n",
      "loss in epoch 17 , step 10080 : 1.118770\n",
      "loss in epoch 17 , step 10100 : 1.432327\n",
      "loss in epoch 17 , step 10120 : 1.157697\n",
      "loss in epoch 17 , step 10140 : 1.006401\n",
      "loss in epoch 17 , step 10160 : 0.657131\n",
      "loss in epoch 17 , step 10180 : 1.193485\n",
      "loss in epoch 17 , step 10200 : 0.003601\n",
      "loss in epoch 17 , step 10220 : 0.466777\n",
      "loss in epoch 17 , step 10240 : 0.422569\n",
      "loss in epoch 17 , step 10260 : 0.113079\n",
      "loss in epoch 17 , step 10280 : 1.170040\n",
      "loss in epoch 17 , step 10300 : 0.235933\n",
      "loss in epoch 17 , step 10320 : 0.301404\n",
      "loss in epoch 17 , step 10340 : 0.306357\n",
      "loss in epoch 17 , step 10360 : 0.013740\n",
      "loss in epoch 17 , step 10380 : 0.380041\n",
      "loss in epoch 17 , step 10400 : 0.117520\n",
      "loss in epoch 17 , step 10420 : 0.583031\n",
      "loss in epoch 17 , step 10440 : 0.143955\n",
      "loss in epoch 17 , step 10460 : 1.114965\n",
      "loss in epoch 17 , step 10480 : 0.563843\n",
      "loss in epoch 17 , step 10500 : 0.749169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 17 , step 10520 : 0.482169\n",
      "loss in epoch 17 , step 10540 : 0.166986\n",
      "loss in epoch 17 , step 10560 : 1.443088\n",
      "loss in epoch 17 , step 10580 : 0.256538\n",
      "loss in epoch 17 , step 10600 : 0.266181\n",
      "loss in epoch 17 , step 10620 : 3.366982\n",
      "loss in epoch 17 , step 10640 : 0.288917\n",
      "loss in epoch 17 , step 10660 : 0.627332\n",
      "loss in epoch 17 , step 10680 : 0.987631\n",
      "loss in epoch 17 , step 10700 : 0.057738\n",
      "loss in epoch 17 , step 10720 : 0.863838\n",
      "loss in epoch 17 , step 10740 : 0.986140\n",
      "loss in epoch 17 , step 10760 : 0.503133\n",
      "loss in epoch 17 , step 10780 : 0.715683\n",
      "loss in epoch 17 , step 10800 : 1.787592\n",
      "loss in epoch 17 , step 10820 : 0.038104\n",
      "loss in epoch 17 , step 10840 : 0.793869\n",
      "loss in epoch 17 , step 10860 : 1.642109\n",
      "loss in epoch 17 , step 10880 : 0.037247\n",
      "loss in epoch 17 , step 10900 : 0.215639\n",
      "loss in epoch 17 , step 10920 : 0.598439\n",
      "loss in epoch 17 , step 10940 : 1.931999\n",
      "loss in epoch 17 , step 10960 : 0.001237\n",
      "loss in epoch 17 , step 10980 : 0.251505\n",
      "loss in epoch 17 , step 11000 : 1.164136\n",
      "loss in epoch 17 , step 11020 : 0.415640\n",
      "loss in epoch 17 , step 11040 : 0.074078\n",
      "loss in epoch 17 , step 11060 : 0.116968\n",
      "loss in epoch 17 , step 11080 : 0.517738\n",
      "loss in epoch 17 , step 11100 : 1.001824\n",
      "loss in epoch 17 , step 11120 : 0.704325\n",
      "loss in epoch 17 , step 11140 : 0.165235\n",
      "loss in epoch 17 , step 11160 : 0.584916\n",
      "loss in epoch 17 , step 11180 : 0.770401\n",
      "loss in epoch 17 , step 11200 : 0.293382\n",
      "loss in epoch 17 , step 11220 : 1.520965\n",
      "loss in epoch 17 , step 11240 : 0.295457\n",
      "loss in epoch 17 , step 11260 : 0.000990\n",
      "loss in epoch 17 , step 11280 : 0.611118\n",
      "loss in epoch 17 , step 11300 : 1.547639\n",
      "loss in epoch 17 , step 11320 : 1.587793\n",
      "loss in epoch 17 , step 11340 : 1.750312\n",
      "loss in epoch 17 , step 11360 : 0.387972\n",
      "loss in epoch 17 , step 11380 : 0.323616\n",
      "loss in epoch 17 , step 11400 : 0.550907\n",
      "loss in epoch 17 , step 11420 : 2.759931\n",
      "loss in epoch 17 , step 11440 : 0.026549\n",
      "loss in epoch 17 , step 11460 : 0.294783\n",
      "loss in epoch 17 , step 11480 : 0.617993\n",
      "loss in epoch 17 , step 11500 : 1.215124\n",
      "loss in epoch 17 , step 11520 : 0.115541\n",
      "loss in epoch 17 , step 11540 : 0.071073\n",
      "loss in epoch 17 , step 11560 : 1.129063\n",
      "loss in epoch 17 , step 11580 : 0.465997\n",
      "loss in epoch 17 , step 11600 : 0.149190\n",
      "loss in epoch 17 , step 11620 : 0.058099\n",
      "loss in epoch 17 , step 11640 : 0.025253\n",
      "loss in epoch 17 , step 11660 : 0.159793\n",
      "loss in epoch 17 , step 11680 : 0.032172\n",
      "loss in epoch 17 , step 11700 : 0.133443\n",
      "loss in epoch 17 , step 11720 : 0.030736\n",
      "loss in epoch 17 , step 11740 : 0.267439\n",
      "loss in epoch 17 , step 11760 : 0.005321\n",
      "loss in epoch 17 , step 11780 : 0.170576\n",
      "loss in epoch 17 , step 11800 : 0.422605\n",
      "loss in epoch 17 , step 11820 : 0.012079\n",
      "loss in epoch 17 , step 11840 : 0.007709\n",
      "loss in epoch 17 , step 11860 : 0.728087\n",
      "loss in epoch 17 , step 11880 : 0.008513\n",
      "loss in epoch 17 , step 11900 : 0.000840\n",
      "loss in epoch 17 , step 11920 : 0.023162\n",
      "loss in epoch 17 , step 11940 : 0.871906\n",
      "loss in epoch 17 , step 11960 : 0.002636\n",
      "loss in epoch 17 , step 11980 : 1.088812\n",
      "loss in epoch 17 , step 12000 : 0.196727\n",
      "loss in epoch 17 , step 12020 : 2.013213\n",
      "loss in epoch 17 , step 12040 : 0.000982\n",
      "loss in epoch 17 , step 12060 : 0.712712\n",
      "loss in epoch 17 , step 12080 : 0.183190\n",
      "loss in epoch 17 , step 12100 : 0.078547\n",
      "loss in epoch 17 , step 12120 : 0.216581\n",
      "loss in epoch 17 , step 12140 : 0.636394\n",
      "loss in epoch 17 , step 12160 : 0.957169\n",
      "loss in epoch 17 , step 12180 : 0.152231\n",
      "loss in epoch 17 , step 12200 : 0.028227\n",
      "loss in epoch 17 , step 12220 : 0.046880\n",
      "loss in epoch 17 , step 12240 : 0.493356\n",
      "loss in epoch 17 , step 12260 : 0.373529\n",
      "loss in epoch 17 , step 12280 : 0.204242\n",
      "loss in epoch 17 , step 12300 : 0.910656\n",
      "loss in epoch 17 , step 12320 : 0.004260\n",
      "loss in epoch 17 , step 12340 : 0.084738\n",
      "loss in epoch 17 , step 12360 : 0.428395\n",
      "loss in epoch 17 , step 12380 : 0.303224\n",
      "loss in epoch 17 , step 12400 : 0.317593\n",
      "loss in epoch 17 , step 12420 : 0.123060\n",
      "loss in epoch 17 , step 12440 : 0.395388\n",
      "loss in epoch 17 , step 12460 : 0.016357\n",
      "loss in epoch 17 , step 12480 : 1.082884\n",
      "loss in epoch 17 , step 12500 : 1.367820\n",
      "loss in epoch 17 , step 12520 : 1.053539\n",
      "loss in epoch 17 , step 12540 : 0.666829\n",
      "loss in epoch 17 , step 12560 : 2.852527\n",
      "loss in epoch 17 , step 12580 : 1.072936\n",
      "loss in epoch 17 , step 12600 : 1.656967\n",
      "loss in epoch 17 , step 12620 : 0.432799\n",
      "loss in epoch 17 , step 12640 : 0.477413\n",
      "loss in epoch 17 , step 12660 : 1.701186\n",
      "loss in epoch 17 , step 12680 : 0.026596\n",
      "loss in epoch 17 , step 12700 : 0.790909\n",
      "loss in epoch 17 , step 12720 : 0.130772\n",
      "loss in epoch 17 , step 12740 : 1.578041\n",
      "loss in epoch 17 , step 12760 : 0.049872\n",
      "loss in epoch 17 , step 12780 : 0.537330\n",
      "loss in epoch 17 , step 12800 : 0.820205\n",
      "loss in epoch 17 , step 12820 : 1.032136\n",
      "loss in epoch 17 , step 12840 : 0.572864\n",
      "loss in epoch 17 , step 12860 : 0.549131\n",
      "loss in epoch 17 , step 12880 : 0.026598\n",
      "loss in epoch 17 , step 12900 : 0.010351\n",
      "loss in epoch 17 , step 12920 : 2.272022\n",
      "loss in epoch 17 , step 12940 : 0.517199\n",
      "loss in epoch 17 , step 12960 : 0.054119\n",
      "loss in epoch 17 , step 12980 : 0.079357\n",
      "loss in epoch 17 , step 13000 : 0.016951\n",
      "loss in epoch 17 , step 13020 : 0.971757\n",
      "loss in epoch 17 , step 13040 : 0.201458\n",
      "loss in epoch 17 , step 13060 : 0.076984\n",
      "loss in epoch 17 , step 13080 : 0.006471\n",
      "loss in epoch 17 , step 13100 : 0.535851\n",
      "loss in epoch 17 , step 13120 : 0.056004\n",
      "loss in epoch 17 , step 13140 : 0.204530\n",
      "loss in epoch 17 , step 13160 : 1.850993\n",
      "loss in epoch 17 , step 13180 : 0.877470\n",
      "loss in epoch 17 , step 13200 : 1.258911\n",
      "loss in epoch 17 , step 13220 : 2.728322\n",
      "loss in epoch 17 , step 13240 : 0.002720\n",
      "loss in epoch 17 , step 13260 : 0.002269\n",
      "loss in epoch 17 , step 13280 : 0.628186\n",
      "loss in epoch 17 , step 13300 : 0.505610\n",
      "loss in epoch 17 , step 13320 : 1.465651\n",
      "loss in epoch 17 , step 13340 : 0.021482\n",
      "loss in epoch 17 , step 13360 : 0.292205\n",
      "loss in epoch 17 , step 13380 : 0.134742\n",
      "loss in epoch 17 , step 13400 : 0.008841\n",
      "loss in epoch 17 , step 13420 : 1.735684\n",
      "loss in epoch 17 , step 13440 : 0.484941\n",
      "loss in epoch 17 , step 13460 : 1.535858\n",
      "loss in epoch 17 , step 13480 : 1.130424\n",
      "loss in epoch 17 , step 13500 : 0.136667\n",
      "loss in epoch 17 , step 13520 : 1.035450\n",
      "loss in epoch 17 , step 13540 : 0.031793\n",
      "loss in epoch 17 , step 13560 : 0.434946\n",
      "loss in epoch 17 , step 13580 : 0.073478\n",
      "loss in epoch 17 , step 13600 : 0.276583\n",
      "loss in epoch 17 , step 13620 : 0.295792\n",
      "loss in epoch 17 , step 13640 : 0.015649\n",
      "loss in epoch 17 , step 13660 : 0.028359\n",
      "loss in epoch 17 , step 13680 : 0.419619\n",
      "loss in epoch 17 , step 13700 : 0.600278\n",
      "loss in epoch 17 , step 13720 : 1.443375\n",
      "loss in epoch 17 , step 13740 : 0.242100\n",
      "loss in epoch 17 , step 13760 : 0.678073\n",
      "loss in epoch 17 , step 13780 : 0.460319\n",
      "loss in epoch 17 , step 13800 : 0.005839\n",
      "loss in epoch 17 , step 13820 : 1.030300\n",
      "loss in epoch 17 , step 13840 : 0.805441\n",
      "loss in epoch 17 , step 13860 : 1.914082\n",
      "loss in epoch 17 , step 13880 : 0.826486\n",
      "loss in epoch 17 , step 13900 : 0.140804\n",
      "loss in epoch 17 , step 13920 : 0.600730\n",
      "loss in epoch 17 , step 13940 : 0.958724\n",
      "loss in epoch 17 , step 13960 : 0.412098\n",
      "loss in epoch 17 , step 13980 : 2.915396\n",
      "loss in epoch 17 , step 14000 : 2.035970\n",
      "loss in epoch 17 , step 14020 : 0.326083\n",
      "loss in epoch 17 , step 14040 : 0.220990\n",
      "loss in epoch 17 , step 14060 : 2.682585\n",
      "loss in epoch 17 , step 14080 : 0.650282\n",
      "loss in epoch 17 , step 14100 : 0.221381\n",
      "loss in epoch 17 , step 14120 : 2.347524\n",
      "loss in epoch 17 , step 14140 : 0.037326\n",
      "loss in epoch 17 , step 14160 : 1.272719\n",
      "loss in epoch 17 , step 14180 : 0.098260\n",
      "loss in epoch 17 , step 14200 : 0.535254\n",
      "loss in epoch 17 , step 14220 : 1.516564\n",
      "loss in epoch 17 , step 14240 : 0.702403\n",
      "loss in epoch 17 , step 14260 : 0.746233\n",
      "loss in epoch 17 , step 14280 : 0.933596\n",
      "loss in epoch 17 , step 14300 : 0.003295\n",
      "loss in epoch 17 , step 14320 : 0.379402\n",
      "loss in epoch 17 , step 14340 : 0.067549\n",
      "loss in epoch 17 , step 14360 : 0.217989\n",
      "loss in epoch 17 , step 14380 : 0.496327\n",
      "loss in epoch 17 , step 14400 : 0.978103\n",
      "loss in epoch 17 , step 14420 : 0.321803\n",
      "loss in epoch 17 , step 14440 : 1.309710\n",
      "loss in epoch 17 , step 14460 : 0.121710\n",
      "loss in epoch 17 , step 14480 : 0.062168\n",
      "loss in epoch 17 , step 14500 : 0.394363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 17 , step 14520 : 4.647098\n",
      "loss in epoch 17 , step 14540 : 0.665349\n",
      "loss in epoch 17 , step 14560 : 0.562729\n",
      "loss in epoch 17 , step 14580 : 0.729905\n",
      "loss in epoch 17 , step 14600 : 0.944460\n",
      "loss in epoch 17 , step 14620 : 0.003797\n",
      "loss in epoch 17 , step 14640 : 0.732576\n",
      "loss in epoch 17 , step 14660 : 0.008506\n",
      "loss in epoch 17 , step 14680 : 0.428703\n",
      "loss in epoch 17 , step 14700 : 0.142126\n",
      "loss in epoch 17 , step 14720 : 0.768327\n",
      "loss in epoch 17 , step 14740 : 0.642280\n",
      "loss in epoch 17 , step 14760 : 0.027652\n",
      "loss in epoch 17 , step 14780 : 2.671101\n",
      "loss in epoch 17 , step 14800 : 0.803696\n",
      "loss in epoch 17 , step 14820 : 0.152627\n",
      "loss in epoch 17 , step 14840 : 0.347788\n",
      "loss in epoch 17 , step 14860 : 0.535479\n",
      "loss in epoch 17 , step 14880 : 0.130060\n",
      "loss in epoch 17 , step 14900 : 0.612994\n",
      "loss in epoch 17 , step 14920 : 1.269137\n",
      "loss in epoch 17 , step 14940 : 0.420112\n",
      "loss in epoch 17 , step 14960 : 0.789159\n",
      "loss in epoch 17 , step 14980 : 0.101860\n",
      "loss in epoch 17 , step 15000 : 1.974110\n",
      "loss in epoch 17 , step 15020 : 0.001194\n",
      "loss in epoch 17 , step 15040 : 0.035547\n",
      "loss in epoch 17 , step 15060 : 0.899997\n",
      "loss in epoch 17 , step 15080 : 0.019516\n",
      "loss in epoch 17 , step 15100 : 2.117483\n",
      "loss in epoch 17 , step 15120 : 0.071580\n",
      "loss in epoch 17 , step 15140 : 0.818382\n",
      "loss in epoch 17 , step 15160 : 0.925088\n",
      "loss in epoch 17 , step 15180 : 0.089692\n",
      "loss in epoch 17 , step 15200 : 0.163479\n",
      "loss in epoch 17 , step 15220 : 0.004615\n",
      "loss in epoch 17 , step 15240 : 0.792991\n",
      "loss in epoch 17 , step 15260 : 0.105525\n",
      "loss in epoch 17 , step 15280 : 0.459403\n",
      "loss in epoch 17 , step 15300 : 0.456624\n",
      "loss in epoch 17 , step 15320 : 0.530338\n",
      "loss in epoch 17 , step 15340 : 0.546803\n",
      "loss in epoch 17 , step 15360 : 0.146682\n",
      "loss in epoch 17 , step 15380 : 0.232402\n",
      "loss in epoch 17 , step 15400 : 0.693907\n",
      "loss in epoch 17 , step 15420 : 0.641617\n",
      "loss in epoch 17 , step 15440 : 0.906893\n",
      "loss in epoch 17 , step 15460 : 0.192053\n",
      "loss in epoch 17 , step 15480 : 0.003701\n",
      "loss in epoch 17 , step 15500 : 2.293038\n",
      "loss in epoch 17 , step 15520 : 0.001907\n",
      "loss in epoch 17 , step 15540 : 0.001437\n",
      "loss in epoch 17 , step 15560 : 0.205194\n",
      "loss in epoch 17 , step 15580 : 0.199491\n",
      "loss in epoch 17 , step 15600 : 1.435200\n",
      "loss in epoch 17 , step 15620 : 1.288536\n",
      "loss in epoch 17 , step 15640 : 0.062237\n",
      "loss in epoch 17 , step 15660 : 1.239370\n",
      "loss in epoch 17 , step 15680 : 0.005401\n",
      "loss in epoch 17 , step 15700 : 1.135908\n",
      "loss in epoch 17 , step 15720 : 1.667243\n",
      "loss in epoch 17 , step 15740 : 0.387582\n",
      "loss in epoch 17 , step 15760 : 0.032592\n",
      "loss in epoch 17 , step 15780 : 0.248525\n",
      "loss in epoch 17 , step 15800 : 0.173954\n",
      "loss in epoch 17 , step 15820 : 1.170718\n",
      "loss in epoch 17 , step 15840 : 0.002501\n",
      "loss in epoch 17 , step 15860 : 1.467154\n",
      "loss in epoch 17 , step 15880 : 0.069061\n",
      "loss in epoch 17 , step 15900 : 1.692935\n",
      "loss in epoch 17 , step 15920 : 0.557627\n",
      "loss in epoch 17 , step 15940 : 0.003003\n",
      "loss in epoch 17 , step 15960 : 0.287196\n",
      "loss in epoch 17 , step 15980 : 1.146187\n",
      "loss in epoch 17 , step 16000 : 1.448735\n",
      "loss in epoch 17 , step 16020 : 0.676889\n",
      "loss in epoch 17 , step 16040 : 0.003831\n",
      "loss in epoch 17 , step 16060 : 0.550294\n",
      "loss in epoch 17 , step 16080 : 0.210600\n",
      "loss in epoch 17 , step 16100 : 0.327740\n",
      "loss in epoch 17 , step 16120 : 0.020536\n",
      "loss in epoch 17 , step 16140 : 0.261742\n",
      "loss in epoch 17 , step 16160 : 1.364254\n",
      "loss in epoch 17 , step 16180 : 0.357846\n",
      "loss in epoch 17 , step 16200 : 0.339499\n",
      "loss in epoch 17 , step 16220 : 0.134130\n",
      "loss in epoch 17 , step 16240 : 0.041194\n",
      "loss in epoch 17 , step 16260 : 0.409229\n",
      "loss in epoch 17 , step 16280 : 0.434331\n",
      "loss in epoch 17 , step 16300 : 1.057403\n",
      "loss in epoch 17 , step 16320 : 0.997598\n",
      "loss in epoch 17 , step 16340 : 0.117049\n",
      "loss in epoch 17 , step 16360 : 0.068482\n",
      "loss in epoch 17 , step 16380 : 2.071191\n",
      "loss in epoch 17 , step 16400 : 0.339812\n",
      "loss in epoch 17 , step 16420 : 0.257731\n",
      "loss in epoch 17 , step 16440 : 0.054904\n",
      "loss in epoch 17 , step 16460 : 0.009960\n",
      "loss in epoch 17 , step 16480 : 0.001739\n",
      "loss in epoch 17 , step 16500 : 0.939983\n",
      "loss in epoch 17 , step 16520 : 0.079811\n",
      "loss in epoch 17 , step 16540 : 1.015194\n",
      "loss in epoch 17 , step 16560 : 1.452621\n",
      "loss in epoch 17 , step 16580 : 1.081279\n",
      "loss in epoch 17 , step 16600 : 0.050085\n",
      "loss in epoch 17 , step 16620 : 1.133232\n",
      "loss in epoch 17 , step 16640 : 0.014367\n",
      "loss in epoch 17 , step 16660 : 0.153831\n",
      "loss in epoch 17 , step 16680 : 0.339627\n",
      "loss in epoch 17 , step 16700 : 0.133563\n",
      "loss in epoch 17 , step 16720 : 1.344059\n",
      "loss in epoch 17 , step 16740 : 0.714358\n",
      "loss in epoch 17 , step 16760 : 0.336014\n",
      "loss in epoch 17 , step 16780 : 1.271423\n",
      "loss in epoch 17 , step 16800 : 0.578401\n",
      "loss in epoch 17 , step 16820 : 0.592110\n",
      "loss in epoch 17 , step 16840 : 0.019301\n",
      "loss in epoch 17 , step 16860 : 0.060242\n",
      "loss in epoch 17 , step 16880 : 0.105506\n",
      "loss in epoch 17 , step 16900 : 0.292715\n",
      "loss in epoch 17 , step 16920 : 0.085221\n",
      "loss in epoch 17 , step 16940 : 0.737980\n",
      "loss in epoch 17 , step 16960 : 2.297416\n",
      "loss in epoch 17 , step 16980 : 0.379064\n",
      "loss in epoch 17 , step 17000 : 0.917971\n",
      "loss in epoch 17 , step 17020 : 0.002725\n",
      "loss in epoch 17 , step 17040 : 0.104939\n",
      "loss in epoch 17 , step 17060 : 1.009287\n",
      "loss in epoch 17 , step 17080 : 2.562359\n",
      "loss in epoch 17 , step 17100 : 0.239596\n",
      "loss in epoch 17 , step 17120 : 0.094808\n",
      "loss in epoch 17 , step 17140 : 1.526877\n",
      "loss in epoch 17 , step 17160 : 1.166935\n",
      "loss in epoch 17 , step 17180 : 0.050735\n",
      "loss in epoch 17 , step 17200 : 0.876548\n",
      "loss in epoch 17 , step 17220 : 0.233868\n",
      "loss in epoch 17 , step 17240 : 0.002998\n",
      "loss in epoch 17 , step 17260 : 0.050231\n",
      "loss in epoch 17 , step 17280 : 0.428466\n",
      "loss in epoch 17 , step 17300 : 0.433018\n",
      "loss in epoch 17 , step 17320 : 0.653651\n",
      "loss in epoch 17 , step 17340 : 0.322924\n",
      "loss in epoch 17 , step 17360 : 0.657137\n",
      "loss in epoch 17 , step 17380 : 1.497381\n",
      "loss in epoch 17 , step 17400 : 0.475749\n",
      "loss in epoch 17 , step 17420 : 0.319586\n",
      "loss in epoch 17 , step 17440 : 1.409628\n",
      "loss in epoch 17 , step 17460 : 0.537794\n",
      "loss in epoch 17 , step 17480 : 0.851526\n",
      "loss in epoch 17 , step 17500 : 2.536841\n",
      "loss in epoch 17 , step 17520 : 1.378711\n",
      "loss in epoch 17 , step 17540 : 0.854957\n",
      "loss in epoch 17 , step 17560 : 0.313484\n",
      "loss in epoch 17 , step 17580 : 1.261961\n",
      "loss in epoch 17 , step 17600 : 0.004253\n",
      "loss in epoch 17 , step 17620 : 0.060098\n",
      "loss in epoch 17 , step 17640 : 0.430356\n",
      "loss in epoch 17 , step 17660 : 1.026330\n",
      "loss in epoch 17 , step 17680 : 0.003371\n",
      "loss in epoch 17 , step 17700 : 0.085626\n",
      "loss in epoch 17 , step 17720 : 1.466904\n",
      "loss in epoch 17 , step 17740 : 4.105273\n",
      "loss in epoch 17 , step 17760 : 1.600307\n",
      "loss in epoch 17 , step 17780 : 2.043601\n",
      "loss in epoch 17 , step 17800 : 1.059423\n",
      "loss in epoch 17 , step 17820 : 1.059266\n",
      "loss in epoch 17 , step 17840 : 0.016448\n",
      "loss in epoch 17 , step 17860 : 0.845959\n",
      "loss in epoch 17 , step 17880 : 0.373573\n",
      "loss in epoch 17 , step 17900 : 1.226104\n",
      "loss in epoch 17 , step 17920 : 0.144346\n",
      "loss in epoch 17 , step 17940 : 0.143504\n",
      "loss in epoch 17 , step 17960 : 0.003852\n",
      "loss in epoch 17 , step 17980 : 0.643598\n",
      "loss in epoch 17 , step 18000 : 2.134077\n",
      "loss in epoch 17 , step 18020 : 0.283265\n",
      "loss in epoch 17 , step 18040 : 1.960304\n",
      "loss in epoch 17 , step 18060 : 0.001665\n",
      "loss in epoch 17 , step 18080 : 0.301640\n",
      "loss in epoch 17 , step 18100 : 0.589133\n",
      "loss in epoch 17 , step 18120 : 0.079301\n",
      "loss in epoch 17 , step 18140 : 0.407372\n",
      "loss in epoch 17 , step 18160 : 0.647242\n",
      "loss in epoch 17 , step 18180 : 1.805274\n",
      "loss in epoch 17 , step 18200 : 0.023603\n",
      "loss in epoch 17 , step 18220 : 0.183445\n",
      "loss in epoch 17 , step 18240 : 0.189335\n",
      "loss in epoch 17 , step 18260 : 0.249545\n",
      "loss in epoch 17 , step 18280 : 0.844709\n",
      "loss in epoch 17 , step 18300 : 1.635711\n",
      "loss in epoch 17 , step 18320 : 0.157238\n",
      "loss in epoch 17 , step 18340 : 1.068033\n",
      "loss in epoch 17 , step 18360 : 0.009398\n",
      "loss in epoch 17 , step 18380 : 0.632163\n",
      "loss in epoch 17 , step 18400 : 0.004873\n",
      "loss in epoch 17 , step 18420 : 1.311519\n",
      "loss in epoch 17 , step 18440 : 0.078531\n",
      "loss in epoch 17 , step 18460 : 1.585421\n",
      "loss in epoch 17 , step 18480 : 1.399191\n",
      "loss in epoch 17 , step 18500 : 0.187325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 17 , step 18520 : 0.635663\n",
      "loss in epoch 17 , step 18540 : 1.760529\n",
      "loss in epoch 17 , step 18560 : 2.255575\n",
      "loss in epoch 17 , step 18580 : 0.651884\n",
      "loss in epoch 17 , step 18600 : 3.542938\n",
      "loss in epoch 17 , step 18620 : 0.016622\n",
      "loss in epoch 17 , step 18640 : 0.479972\n",
      "loss in epoch 17 , step 18660 : 0.617049\n",
      "loss in epoch 17 , step 18680 : 0.088605\n",
      "loss in epoch 17 , step 18700 : 0.044417\n",
      "loss in epoch 17 , step 18720 : 1.351118\n",
      "loss in epoch 17 , step 18740 : 1.759439\n",
      "loss in epoch 17 , step 18760 : 0.749810\n",
      "loss in epoch 17 , step 18780 : 0.020979\n",
      "loss in epoch 17 , step 18800 : 0.739369\n",
      "loss in epoch 17 , step 18820 : 0.290693\n",
      "loss in epoch 17 , step 18840 : 0.054873\n",
      "loss in epoch 17 , step 18860 : 0.032873\n",
      "loss in epoch 17 , step 18880 : 1.071622\n",
      "loss in epoch 17 , step 18900 : 0.116958\n",
      "loss in epoch 17 , step 18920 : 0.014586\n",
      "loss in epoch 17 , step 18940 : 0.146718\n",
      "loss in epoch 17 , step 18960 : 0.697641\n",
      "loss in epoch 17 , step 18980 : 0.880623\n",
      "loss in epoch 17 , step 19000 : 1.691694\n",
      "loss in epoch 17 , step 19020 : 0.830738\n",
      "loss in epoch 17 , step 19040 : 0.221313\n",
      "loss in epoch 17 , step 19060 : 0.114067\n",
      "loss in epoch 17 , step 19080 : 0.462562\n",
      "loss in epoch 17 , step 19100 : 0.000981\n",
      "loss in epoch 17 , step 19120 : 0.265449\n",
      "loss in epoch 17 , step 19140 : 0.004389\n",
      "loss in epoch 17 , step 19160 : 0.583421\n",
      "loss in epoch 17 , step 19180 : 0.073431\n",
      "loss in epoch 17 , step 19200 : 0.171159\n",
      "loss in epoch 17 , step 19220 : 0.392237\n",
      "loss in epoch 17 , step 19240 : 0.310621\n",
      "loss in epoch 17 , step 19260 : 0.450062\n",
      "loss in epoch 17 , step 19280 : 1.391781\n",
      "loss in epoch 17 , step 19300 : 1.671299\n",
      "loss in epoch 17 , step 19320 : 0.667091\n",
      "loss in epoch 17 , step 19340 : 0.467298\n",
      "loss in epoch 17 , step 19360 : 0.018576\n",
      "loss in epoch 17 , step 19380 : 0.043973\n",
      "loss in epoch 17 , step 19400 : 0.381520\n",
      "loss in epoch 17 , step 19420 : 0.163596\n",
      "loss in epoch 17 , step 19440 : 0.123835\n",
      "loss in epoch 17 , step 19460 : 0.065349\n",
      "loss in epoch 17 , step 19480 : 1.595482\n",
      "loss in epoch 17 , step 19500 : 1.935945\n",
      "loss in epoch 17 , step 19520 : 1.028667\n",
      "loss in epoch 17 , step 19540 : 0.099105\n",
      "loss in epoch 17 , step 19560 : 0.518619\n",
      "loss in epoch 17 , step 19580 : 1.394165\n",
      "loss in epoch 17 , step 19600 : 4.324960\n",
      "loss in epoch 17 , step 19620 : 0.651878\n",
      "loss in epoch 17 , step 19640 : 0.023435\n",
      "loss in epoch 17 , step 19660 : 0.061435\n",
      "loss in epoch 17 , step 19680 : 0.628568\n",
      "loss in epoch 17 , step 19700 : 1.510491\n",
      "loss in epoch 17 , step 19720 : 2.721093\n",
      "loss in epoch 17 , step 19740 : 1.411481\n",
      "loss in epoch 17 , step 19760 : 0.392801\n",
      "loss in epoch 17 , step 19780 : 0.755209\n",
      "loss in epoch 17 , step 19800 : 0.206345\n",
      "loss in epoch 17 , step 19820 : 0.561115\n",
      "loss in epoch 17 , step 19840 : 1.508406\n",
      "loss in epoch 17 , step 19860 : 0.188848\n",
      "loss in epoch 17 , step 19880 : 0.057950\n",
      "loss in epoch 17 , step 19900 : 1.014669\n",
      "loss in epoch 17 , step 19920 : 0.582927\n",
      "loss in epoch 17 , step 19940 : 1.677003\n",
      "Accuracy in epoch 17 : 31.929691\n",
      "loss in epoch 18 , step 0 : 0.857507\n",
      "loss in epoch 18 , step 20 : 2.248730\n",
      "loss in epoch 18 , step 40 : 0.569678\n",
      "loss in epoch 18 , step 60 : 0.356336\n",
      "loss in epoch 18 , step 80 : 1.675282\n",
      "loss in epoch 18 , step 100 : 0.239546\n",
      "loss in epoch 18 , step 120 : 0.008129\n",
      "loss in epoch 18 , step 140 : 0.064382\n",
      "loss in epoch 18 , step 160 : 0.194621\n",
      "loss in epoch 18 , step 180 : 0.859008\n",
      "loss in epoch 18 , step 200 : 0.080635\n",
      "loss in epoch 18 , step 220 : 1.281868\n",
      "loss in epoch 18 , step 240 : 0.612634\n",
      "loss in epoch 18 , step 260 : 0.655145\n",
      "loss in epoch 18 , step 280 : 0.150758\n",
      "loss in epoch 18 , step 300 : 0.567081\n",
      "loss in epoch 18 , step 320 : 0.495913\n",
      "loss in epoch 18 , step 340 : 1.830938\n",
      "loss in epoch 18 , step 360 : 1.441044\n",
      "loss in epoch 18 , step 380 : 0.161287\n",
      "loss in epoch 18 , step 400 : 1.299637\n",
      "loss in epoch 18 , step 420 : 0.016067\n",
      "loss in epoch 18 , step 440 : 0.145634\n",
      "loss in epoch 18 , step 460 : 0.380292\n",
      "loss in epoch 18 , step 480 : 0.266084\n",
      "loss in epoch 18 , step 500 : 0.053438\n",
      "loss in epoch 18 , step 520 : 0.626036\n",
      "loss in epoch 18 , step 540 : 0.237030\n",
      "loss in epoch 18 , step 560 : 0.027016\n",
      "loss in epoch 18 , step 580 : 0.169863\n",
      "loss in epoch 18 , step 600 : 1.462068\n",
      "loss in epoch 18 , step 620 : 0.016408\n",
      "loss in epoch 18 , step 640 : 0.796827\n",
      "loss in epoch 18 , step 660 : 1.058080\n",
      "loss in epoch 18 , step 680 : 0.844713\n",
      "loss in epoch 18 , step 700 : 1.041547\n",
      "loss in epoch 18 , step 720 : 0.078781\n",
      "loss in epoch 18 , step 740 : 0.067300\n",
      "loss in epoch 18 , step 760 : 1.054000\n",
      "loss in epoch 18 , step 780 : 0.344027\n",
      "loss in epoch 18 , step 800 : 0.624844\n",
      "loss in epoch 18 , step 820 : 0.024054\n",
      "loss in epoch 18 , step 840 : 0.098922\n",
      "loss in epoch 18 , step 860 : 0.098856\n",
      "loss in epoch 18 , step 880 : 0.558480\n",
      "loss in epoch 18 , step 900 : 0.772818\n",
      "loss in epoch 18 , step 920 : 0.123846\n",
      "loss in epoch 18 , step 940 : 0.412551\n",
      "loss in epoch 18 , step 960 : 0.920401\n",
      "loss in epoch 18 , step 980 : 0.927985\n",
      "loss in epoch 18 , step 1000 : 0.903218\n",
      "loss in epoch 18 , step 1020 : 0.508656\n",
      "loss in epoch 18 , step 1040 : 1.506211\n",
      "loss in epoch 18 , step 1060 : 0.685963\n",
      "loss in epoch 18 , step 1080 : 0.973643\n",
      "loss in epoch 18 , step 1100 : 0.256108\n",
      "loss in epoch 18 , step 1120 : 0.706520\n",
      "loss in epoch 18 , step 1140 : 0.514635\n",
      "loss in epoch 18 , step 1160 : 0.072759\n",
      "loss in epoch 18 , step 1180 : 1.000595\n",
      "loss in epoch 18 , step 1200 : 3.308228\n",
      "loss in epoch 18 , step 1220 : 0.043505\n",
      "loss in epoch 18 , step 1240 : 1.509974\n",
      "loss in epoch 18 , step 1260 : 0.040114\n",
      "loss in epoch 18 , step 1280 : 1.331265\n",
      "loss in epoch 18 , step 1300 : 0.630745\n",
      "loss in epoch 18 , step 1320 : 0.582718\n",
      "loss in epoch 18 , step 1340 : 0.003436\n",
      "loss in epoch 18 , step 1360 : 0.002484\n",
      "loss in epoch 18 , step 1380 : 1.267608\n",
      "loss in epoch 18 , step 1400 : 0.122429\n",
      "loss in epoch 18 , step 1420 : 1.072116\n",
      "loss in epoch 18 , step 1440 : 1.041469\n",
      "loss in epoch 18 , step 1460 : 0.532524\n",
      "loss in epoch 18 , step 1480 : 1.769651\n",
      "loss in epoch 18 , step 1500 : 0.517756\n",
      "loss in epoch 18 , step 1520 : 0.538924\n",
      "loss in epoch 18 , step 1540 : 0.356092\n",
      "loss in epoch 18 , step 1560 : 0.002502\n",
      "loss in epoch 18 , step 1580 : 0.402939\n",
      "loss in epoch 18 , step 1600 : 0.051250\n",
      "loss in epoch 18 , step 1620 : 0.304277\n",
      "loss in epoch 18 , step 1640 : 0.539073\n",
      "loss in epoch 18 , step 1660 : 1.462762\n",
      "loss in epoch 18 , step 1680 : 0.143263\n",
      "loss in epoch 18 , step 1700 : 0.169726\n",
      "loss in epoch 18 , step 1720 : 1.305022\n",
      "loss in epoch 18 , step 1740 : 0.397810\n",
      "loss in epoch 18 , step 1760 : 0.493598\n",
      "loss in epoch 18 , step 1780 : 1.059243\n",
      "loss in epoch 18 , step 1800 : 0.166235\n",
      "loss in epoch 18 , step 1820 : 0.375662\n",
      "loss in epoch 18 , step 1840 : 1.009418\n",
      "loss in epoch 18 , step 1860 : 0.283578\n",
      "loss in epoch 18 , step 1880 : 0.129482\n",
      "loss in epoch 18 , step 1900 : 0.009611\n",
      "loss in epoch 18 , step 1920 : 0.744356\n",
      "loss in epoch 18 , step 1940 : 0.303176\n",
      "loss in epoch 18 , step 1960 : 0.142966\n",
      "loss in epoch 18 , step 1980 : 1.554550\n",
      "loss in epoch 18 , step 2000 : 0.136587\n",
      "loss in epoch 18 , step 2020 : 0.009180\n",
      "loss in epoch 18 , step 2040 : 0.909123\n",
      "loss in epoch 18 , step 2060 : 0.585805\n",
      "loss in epoch 18 , step 2080 : 0.005656\n",
      "loss in epoch 18 , step 2100 : 0.429334\n",
      "loss in epoch 18 , step 2120 : 0.966551\n",
      "loss in epoch 18 , step 2140 : 0.520557\n",
      "loss in epoch 18 , step 2160 : 1.083376\n",
      "loss in epoch 18 , step 2180 : 0.054880\n",
      "loss in epoch 18 , step 2200 : 1.168407\n",
      "loss in epoch 18 , step 2220 : 0.338270\n",
      "loss in epoch 18 , step 2240 : 1.050666\n",
      "loss in epoch 18 , step 2260 : 0.046239\n",
      "loss in epoch 18 , step 2280 : 0.942009\n",
      "loss in epoch 18 , step 2300 : 0.154925\n",
      "loss in epoch 18 , step 2320 : 0.569595\n",
      "loss in epoch 18 , step 2340 : 1.332872\n",
      "loss in epoch 18 , step 2360 : 0.786206\n",
      "loss in epoch 18 , step 2380 : 2.614466\n",
      "loss in epoch 18 , step 2400 : 0.181840\n",
      "loss in epoch 18 , step 2420 : 1.858541\n",
      "loss in epoch 18 , step 2440 : 0.001508\n",
      "loss in epoch 18 , step 2460 : 0.283229\n",
      "loss in epoch 18 , step 2480 : 0.247087\n",
      "loss in epoch 18 , step 2500 : 0.412006\n",
      "loss in epoch 18 , step 2520 : 0.933003\n",
      "loss in epoch 18 , step 2540 : 0.575080\n",
      "loss in epoch 18 , step 2560 : 1.494911\n",
      "loss in epoch 18 , step 2580 : 0.279275\n",
      "loss in epoch 18 , step 2600 : 1.438093\n",
      "loss in epoch 18 , step 2620 : 0.617271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 18 , step 2640 : 0.239082\n",
      "loss in epoch 18 , step 2660 : 1.588657\n",
      "loss in epoch 18 , step 2680 : 0.005890\n",
      "loss in epoch 18 , step 2700 : 0.895512\n",
      "loss in epoch 18 , step 2720 : 0.895039\n",
      "loss in epoch 18 , step 2740 : 0.804919\n",
      "loss in epoch 18 , step 2760 : 0.799821\n",
      "loss in epoch 18 , step 2780 : 0.269660\n",
      "loss in epoch 18 , step 2800 : 0.023658\n",
      "loss in epoch 18 , step 2820 : 0.802958\n",
      "loss in epoch 18 , step 2840 : 0.117260\n",
      "loss in epoch 18 , step 2860 : 1.386681\n",
      "loss in epoch 18 , step 2880 : 0.725832\n",
      "loss in epoch 18 , step 2900 : 0.003702\n",
      "loss in epoch 18 , step 2920 : 0.550446\n",
      "loss in epoch 18 , step 2940 : 0.003807\n",
      "loss in epoch 18 , step 2960 : 0.354571\n",
      "loss in epoch 18 , step 2980 : 1.409484\n",
      "loss in epoch 18 , step 3000 : 0.012868\n",
      "loss in epoch 18 , step 3020 : 0.231738\n",
      "loss in epoch 18 , step 3040 : 0.879832\n",
      "loss in epoch 18 , step 3060 : 0.313712\n",
      "loss in epoch 18 , step 3080 : 0.938262\n",
      "loss in epoch 18 , step 3100 : 0.139821\n",
      "loss in epoch 18 , step 3120 : 0.929125\n",
      "loss in epoch 18 , step 3140 : 1.378255\n",
      "loss in epoch 18 , step 3160 : 0.303937\n",
      "loss in epoch 18 , step 3180 : 0.253360\n",
      "loss in epoch 18 , step 3200 : 1.926358\n",
      "loss in epoch 18 , step 3220 : 0.855008\n",
      "loss in epoch 18 , step 3240 : 0.138201\n",
      "loss in epoch 18 , step 3260 : 0.302010\n",
      "loss in epoch 18 , step 3280 : 0.376650\n",
      "loss in epoch 18 , step 3300 : 0.646697\n",
      "loss in epoch 18 , step 3320 : 0.497566\n",
      "loss in epoch 18 , step 3340 : 0.192364\n",
      "loss in epoch 18 , step 3360 : 4.066514\n",
      "loss in epoch 18 , step 3380 : 0.100784\n",
      "loss in epoch 18 , step 3400 : 0.094982\n",
      "loss in epoch 18 , step 3420 : 0.022567\n",
      "loss in epoch 18 , step 3440 : 1.322705\n",
      "loss in epoch 18 , step 3460 : 0.710326\n",
      "loss in epoch 18 , step 3480 : 1.064763\n",
      "loss in epoch 18 , step 3500 : 0.761194\n",
      "loss in epoch 18 , step 3520 : 0.136455\n",
      "loss in epoch 18 , step 3540 : 0.001406\n",
      "loss in epoch 18 , step 3560 : 3.314724\n",
      "loss in epoch 18 , step 3580 : 2.296417\n",
      "loss in epoch 18 , step 3600 : 0.289932\n",
      "loss in epoch 18 , step 3620 : 0.312598\n",
      "loss in epoch 18 , step 3640 : 0.827894\n",
      "loss in epoch 18 , step 3660 : 0.695045\n",
      "loss in epoch 18 , step 3680 : 0.202285\n",
      "loss in epoch 18 , step 3700 : 0.099539\n",
      "loss in epoch 18 , step 3720 : 0.027998\n",
      "loss in epoch 18 , step 3740 : 0.005024\n",
      "loss in epoch 18 , step 3760 : 1.358958\n",
      "loss in epoch 18 , step 3780 : 0.394821\n",
      "loss in epoch 18 , step 3800 : 0.008740\n",
      "loss in epoch 18 , step 3820 : 0.265662\n",
      "loss in epoch 18 , step 3840 : 0.923039\n",
      "loss in epoch 18 , step 3860 : 0.143727\n",
      "loss in epoch 18 , step 3880 : 0.013016\n",
      "loss in epoch 18 , step 3900 : 0.005981\n",
      "loss in epoch 18 , step 3920 : 1.306377\n",
      "loss in epoch 18 , step 3940 : 0.221696\n",
      "loss in epoch 18 , step 3960 : 2.865193\n",
      "loss in epoch 18 , step 3980 : 0.695812\n",
      "loss in epoch 18 , step 4000 : 1.551238\n",
      "loss in epoch 18 , step 4020 : 1.176059\n",
      "loss in epoch 18 , step 4040 : 0.041629\n",
      "loss in epoch 18 , step 4060 : 0.018397\n",
      "loss in epoch 18 , step 4080 : 0.001986\n",
      "loss in epoch 18 , step 4100 : 0.482195\n",
      "loss in epoch 18 , step 4120 : 0.258809\n",
      "loss in epoch 18 , step 4140 : 0.010977\n",
      "loss in epoch 18 , step 4160 : 0.265350\n",
      "loss in epoch 18 , step 4180 : 0.436719\n",
      "loss in epoch 18 , step 4200 : 0.753063\n",
      "loss in epoch 18 , step 4220 : 0.087199\n",
      "loss in epoch 18 , step 4240 : 0.696087\n",
      "loss in epoch 18 , step 4260 : 0.629471\n",
      "loss in epoch 18 , step 4280 : 0.370289\n",
      "loss in epoch 18 , step 4300 : 0.974490\n",
      "loss in epoch 18 , step 4320 : 0.068145\n",
      "loss in epoch 18 , step 4340 : 0.397127\n",
      "loss in epoch 18 , step 4360 : 0.332200\n",
      "loss in epoch 18 , step 4380 : 0.136311\n",
      "loss in epoch 18 , step 4400 : 0.484934\n",
      "loss in epoch 18 , step 4420 : 0.025289\n",
      "loss in epoch 18 , step 4440 : 0.592974\n",
      "loss in epoch 18 , step 4460 : 0.391362\n",
      "loss in epoch 18 , step 4480 : 0.673041\n",
      "loss in epoch 18 , step 4500 : 0.677151\n",
      "loss in epoch 18 , step 4520 : 0.844808\n",
      "loss in epoch 18 , step 4540 : 1.794844\n",
      "loss in epoch 18 , step 4560 : 0.354416\n",
      "loss in epoch 18 , step 4580 : 0.061194\n",
      "loss in epoch 18 , step 4600 : 0.224606\n",
      "loss in epoch 18 , step 4620 : 0.498692\n",
      "loss in epoch 18 , step 4640 : 0.015199\n",
      "loss in epoch 18 , step 4660 : 0.787860\n",
      "loss in epoch 18 , step 4680 : 0.533579\n",
      "loss in epoch 18 , step 4700 : 1.075604\n",
      "loss in epoch 18 , step 4720 : 0.546362\n",
      "loss in epoch 18 , step 4740 : 0.851101\n",
      "loss in epoch 18 , step 4760 : 0.306278\n",
      "loss in epoch 18 , step 4780 : 0.088104\n",
      "loss in epoch 18 , step 4800 : 0.722141\n",
      "loss in epoch 18 , step 4820 : 0.222448\n",
      "loss in epoch 18 , step 4840 : 0.340011\n",
      "loss in epoch 18 , step 4860 : 0.378895\n",
      "loss in epoch 18 , step 4880 : 0.206422\n",
      "loss in epoch 18 , step 4900 : 0.148689\n",
      "loss in epoch 18 , step 4920 : 0.684852\n",
      "loss in epoch 18 , step 4940 : 0.530212\n",
      "loss in epoch 18 , step 4960 : 0.321231\n",
      "loss in epoch 18 , step 4980 : 1.821605\n",
      "loss in epoch 18 , step 5000 : 0.068158\n",
      "loss in epoch 18 , step 5020 : 2.509557\n",
      "loss in epoch 18 , step 5040 : 1.864849\n",
      "loss in epoch 18 , step 5060 : 0.025491\n",
      "loss in epoch 18 , step 5080 : 0.133430\n",
      "loss in epoch 18 , step 5100 : 0.463645\n",
      "loss in epoch 18 , step 5120 : 0.104146\n",
      "loss in epoch 18 , step 5140 : 0.037400\n",
      "loss in epoch 18 , step 5160 : 0.095353\n",
      "loss in epoch 18 , step 5180 : 0.947056\n",
      "loss in epoch 18 , step 5200 : 0.511321\n",
      "loss in epoch 18 , step 5220 : 0.045264\n",
      "loss in epoch 18 , step 5240 : 0.760868\n",
      "loss in epoch 18 , step 5260 : 0.280629\n",
      "loss in epoch 18 , step 5280 : 0.003436\n",
      "loss in epoch 18 , step 5300 : 1.402334\n",
      "loss in epoch 18 , step 5320 : 0.176271\n",
      "loss in epoch 18 , step 5340 : 0.010177\n",
      "loss in epoch 18 , step 5360 : 0.342946\n",
      "loss in epoch 18 , step 5380 : 1.505671\n",
      "loss in epoch 18 , step 5400 : 1.553233\n",
      "loss in epoch 18 , step 5420 : 1.832640\n",
      "loss in epoch 18 , step 5440 : 1.193091\n",
      "loss in epoch 18 , step 5460 : 1.781240\n",
      "loss in epoch 18 , step 5480 : 1.179433\n",
      "loss in epoch 18 , step 5500 : 0.140924\n",
      "loss in epoch 18 , step 5520 : 0.712940\n",
      "loss in epoch 18 , step 5540 : 0.528899\n",
      "loss in epoch 18 , step 5560 : 0.332279\n",
      "loss in epoch 18 , step 5580 : 0.650324\n",
      "loss in epoch 18 , step 5600 : 0.322606\n",
      "loss in epoch 18 , step 5620 : 0.523491\n",
      "loss in epoch 18 , step 5640 : 0.002074\n",
      "loss in epoch 18 , step 5660 : 1.031520\n",
      "loss in epoch 18 , step 5680 : 1.927825\n",
      "loss in epoch 18 , step 5700 : 0.079574\n",
      "loss in epoch 18 , step 5720 : 2.009674\n",
      "loss in epoch 18 , step 5740 : 0.327380\n",
      "loss in epoch 18 , step 5760 : 1.164708\n",
      "loss in epoch 18 , step 5780 : 0.609428\n",
      "loss in epoch 18 , step 5800 : 0.003077\n",
      "loss in epoch 18 , step 5820 : 1.883928\n",
      "loss in epoch 18 , step 5840 : 0.028242\n",
      "loss in epoch 18 , step 5860 : 0.575150\n",
      "loss in epoch 18 , step 5880 : 0.919304\n",
      "loss in epoch 18 , step 5900 : 0.844855\n",
      "loss in epoch 18 , step 5920 : 1.008582\n",
      "loss in epoch 18 , step 5940 : 0.022197\n",
      "loss in epoch 18 , step 5960 : 0.503195\n",
      "loss in epoch 18 , step 5980 : 0.319858\n",
      "loss in epoch 18 , step 6000 : 0.004871\n",
      "loss in epoch 18 , step 6020 : 0.387841\n",
      "loss in epoch 18 , step 6040 : 0.970506\n",
      "loss in epoch 18 , step 6060 : 0.039226\n",
      "loss in epoch 18 , step 6080 : 0.932729\n",
      "loss in epoch 18 , step 6100 : 0.324072\n",
      "loss in epoch 18 , step 6120 : 0.413608\n",
      "loss in epoch 18 , step 6140 : 0.004096\n",
      "loss in epoch 18 , step 6160 : 0.545468\n",
      "loss in epoch 18 , step 6180 : 0.846959\n",
      "loss in epoch 18 , step 6200 : 1.229456\n",
      "loss in epoch 18 , step 6220 : 0.001992\n",
      "loss in epoch 18 , step 6240 : 0.600714\n",
      "loss in epoch 18 , step 6260 : 0.370715\n",
      "loss in epoch 18 , step 6280 : 0.875370\n",
      "loss in epoch 18 , step 6300 : 0.073928\n",
      "loss in epoch 18 , step 6320 : 0.593012\n",
      "loss in epoch 18 , step 6340 : 0.293554\n",
      "loss in epoch 18 , step 6360 : 0.909187\n",
      "loss in epoch 18 , step 6380 : 0.007211\n",
      "loss in epoch 18 , step 6400 : 1.538473\n",
      "loss in epoch 18 , step 6420 : 0.908307\n",
      "loss in epoch 18 , step 6440 : 0.811901\n",
      "loss in epoch 18 , step 6460 : 1.633394\n",
      "loss in epoch 18 , step 6480 : 0.923966\n",
      "loss in epoch 18 , step 6500 : 0.003527\n",
      "loss in epoch 18 , step 6520 : 0.725626\n",
      "loss in epoch 18 , step 6540 : 0.803362\n",
      "loss in epoch 18 , step 6560 : 0.879578\n",
      "loss in epoch 18 , step 6580 : 0.021522\n",
      "loss in epoch 18 , step 6600 : 1.339492\n",
      "loss in epoch 18 , step 6620 : 0.486835\n",
      "loss in epoch 18 , step 6640 : 3.991087\n",
      "loss in epoch 18 , step 6660 : 0.001210\n",
      "loss in epoch 18 , step 6680 : 1.157106\n",
      "loss in epoch 18 , step 6700 : 0.001823\n",
      "loss in epoch 18 , step 6720 : 2.394559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 18 , step 6740 : 0.003795\n",
      "loss in epoch 18 , step 6760 : 0.029616\n",
      "loss in epoch 18 , step 6780 : 1.419988\n",
      "loss in epoch 18 , step 6800 : 1.115862\n",
      "loss in epoch 18 , step 6820 : 0.638278\n",
      "loss in epoch 18 , step 6840 : 1.595034\n",
      "loss in epoch 18 , step 6860 : 0.010929\n",
      "loss in epoch 18 , step 6880 : 1.064174\n",
      "loss in epoch 18 , step 6900 : 2.169863\n",
      "loss in epoch 18 , step 6920 : 0.333715\n",
      "loss in epoch 18 , step 6940 : 0.268272\n",
      "loss in epoch 18 , step 6960 : 1.390696\n",
      "loss in epoch 18 , step 6980 : 2.053755\n",
      "loss in epoch 18 , step 7000 : 0.204317\n",
      "loss in epoch 18 , step 7020 : 0.085542\n",
      "loss in epoch 18 , step 7040 : 0.033386\n",
      "loss in epoch 18 , step 7060 : 1.074062\n",
      "loss in epoch 18 , step 7080 : 0.479604\n",
      "loss in epoch 18 , step 7100 : 2.756470\n",
      "loss in epoch 18 , step 7120 : 0.194910\n",
      "loss in epoch 18 , step 7140 : 1.786691\n",
      "loss in epoch 18 , step 7160 : 3.375068\n",
      "loss in epoch 18 , step 7180 : 0.369565\n",
      "loss in epoch 18 , step 7200 : 0.004793\n",
      "loss in epoch 18 , step 7220 : 0.072945\n",
      "loss in epoch 18 , step 7240 : 0.024537\n",
      "loss in epoch 18 , step 7260 : 0.683308\n",
      "loss in epoch 18 , step 7280 : 1.847711\n",
      "loss in epoch 18 , step 7300 : 0.556693\n",
      "loss in epoch 18 , step 7320 : 0.086198\n",
      "loss in epoch 18 , step 7340 : 0.012883\n",
      "loss in epoch 18 , step 7360 : 0.944311\n",
      "loss in epoch 18 , step 7380 : 0.672404\n",
      "loss in epoch 18 , step 7400 : 0.016692\n",
      "loss in epoch 18 , step 7420 : 0.376730\n",
      "loss in epoch 18 , step 7440 : 0.297110\n",
      "loss in epoch 18 , step 7460 : 0.432531\n",
      "loss in epoch 18 , step 7480 : 0.043958\n",
      "loss in epoch 18 , step 7500 : 0.156431\n",
      "loss in epoch 18 , step 7520 : 0.360543\n",
      "loss in epoch 18 , step 7540 : 0.003336\n",
      "loss in epoch 18 , step 7560 : 0.448894\n",
      "loss in epoch 18 , step 7580 : 0.587561\n",
      "loss in epoch 18 , step 7600 : 0.773159\n",
      "loss in epoch 18 , step 7620 : 1.447033\n",
      "loss in epoch 18 , step 7640 : 0.668302\n",
      "loss in epoch 18 , step 7660 : 0.081446\n",
      "loss in epoch 18 , step 7680 : 1.039196\n",
      "loss in epoch 18 , step 7700 : 1.289242\n",
      "loss in epoch 18 , step 7720 : 0.034281\n",
      "loss in epoch 18 , step 7740 : 0.251167\n",
      "loss in epoch 18 , step 7760 : 0.004540\n",
      "loss in epoch 18 , step 7780 : 0.964107\n",
      "loss in epoch 18 , step 7800 : 0.035193\n",
      "loss in epoch 18 , step 7820 : 0.015074\n",
      "loss in epoch 18 , step 7840 : 1.024651\n",
      "loss in epoch 18 , step 7860 : 0.002659\n",
      "loss in epoch 18 , step 7880 : 2.403457\n",
      "loss in epoch 18 , step 7900 : 0.012760\n",
      "loss in epoch 18 , step 7920 : 1.768154\n",
      "loss in epoch 18 , step 7940 : 1.144737\n",
      "loss in epoch 18 , step 7960 : 0.341366\n",
      "loss in epoch 18 , step 7980 : 1.406247\n",
      "loss in epoch 18 , step 8000 : 0.558876\n",
      "loss in epoch 18 , step 8020 : 0.869385\n",
      "loss in epoch 18 , step 8040 : 0.128277\n",
      "loss in epoch 18 , step 8060 : 1.290911\n",
      "loss in epoch 18 , step 8080 : 0.612960\n",
      "loss in epoch 18 , step 8100 : 0.008175\n",
      "loss in epoch 18 , step 8120 : 0.001659\n",
      "loss in epoch 18 , step 8140 : 0.026965\n",
      "loss in epoch 18 , step 8160 : 1.530767\n",
      "loss in epoch 18 , step 8180 : 0.145489\n",
      "loss in epoch 18 , step 8200 : 0.319351\n",
      "loss in epoch 18 , step 8220 : 0.471464\n",
      "loss in epoch 18 , step 8240 : 0.216275\n",
      "loss in epoch 18 , step 8260 : 1.780220\n",
      "loss in epoch 18 , step 8280 : 0.353993\n",
      "loss in epoch 18 , step 8300 : 0.127642\n",
      "loss in epoch 18 , step 8320 : 0.751815\n",
      "loss in epoch 18 , step 8340 : 0.206503\n",
      "loss in epoch 18 , step 8360 : 0.295044\n",
      "loss in epoch 18 , step 8380 : 0.000906\n",
      "loss in epoch 18 , step 8400 : 0.004273\n",
      "loss in epoch 18 , step 8420 : 1.458209\n",
      "loss in epoch 18 , step 8440 : 0.164091\n",
      "loss in epoch 18 , step 8460 : 0.246760\n",
      "loss in epoch 18 , step 8480 : 0.008012\n",
      "loss in epoch 18 , step 8500 : 0.632984\n",
      "loss in epoch 18 , step 8520 : 0.066206\n",
      "loss in epoch 18 , step 8540 : 0.375618\n",
      "loss in epoch 18 , step 8560 : 0.788376\n",
      "loss in epoch 18 , step 8580 : 0.239909\n",
      "loss in epoch 18 , step 8600 : 0.775442\n",
      "loss in epoch 18 , step 8620 : 0.412510\n",
      "loss in epoch 18 , step 8640 : 1.068394\n",
      "loss in epoch 18 , step 8660 : 2.355006\n",
      "loss in epoch 18 , step 8680 : 0.002523\n",
      "loss in epoch 18 , step 8700 : 0.087729\n",
      "loss in epoch 18 , step 8720 : 0.080018\n",
      "loss in epoch 18 , step 8740 : 0.059398\n",
      "loss in epoch 18 , step 8760 : 0.831398\n",
      "loss in epoch 18 , step 8780 : 0.217909\n",
      "loss in epoch 18 , step 8800 : 0.676002\n",
      "loss in epoch 18 , step 8820 : 0.043859\n",
      "loss in epoch 18 , step 8840 : 0.741948\n",
      "loss in epoch 18 , step 8860 : 0.851967\n",
      "loss in epoch 18 , step 8880 : 1.711960\n",
      "loss in epoch 18 , step 8900 : 0.052650\n",
      "loss in epoch 18 , step 8920 : 0.474872\n",
      "loss in epoch 18 , step 8940 : 0.615590\n",
      "loss in epoch 18 , step 8960 : 0.017520\n",
      "loss in epoch 18 , step 8980 : 0.038487\n",
      "loss in epoch 18 , step 9000 : 0.082476\n",
      "loss in epoch 18 , step 9020 : 0.015510\n",
      "loss in epoch 18 , step 9040 : 0.471370\n",
      "loss in epoch 18 , step 9060 : 0.005688\n",
      "loss in epoch 18 , step 9080 : 1.914113\n",
      "loss in epoch 18 , step 9100 : 0.011307\n",
      "loss in epoch 18 , step 9120 : 0.043356\n",
      "loss in epoch 18 , step 9140 : 0.001413\n",
      "loss in epoch 18 , step 9160 : 0.085322\n",
      "loss in epoch 18 , step 9180 : 1.788580\n",
      "loss in epoch 18 , step 9200 : 2.875586\n",
      "loss in epoch 18 , step 9220 : 0.972652\n",
      "loss in epoch 18 , step 9240 : 0.557092\n",
      "loss in epoch 18 , step 9260 : 1.146897\n",
      "loss in epoch 18 , step 9280 : 0.462451\n",
      "loss in epoch 18 , step 9300 : 0.889409\n",
      "loss in epoch 18 , step 9320 : 0.167591\n",
      "loss in epoch 18 , step 9340 : 0.310110\n",
      "loss in epoch 18 , step 9360 : 0.307359\n",
      "loss in epoch 18 , step 9380 : 1.128897\n",
      "loss in epoch 18 , step 9400 : 0.045140\n",
      "loss in epoch 18 , step 9420 : 0.547307\n",
      "loss in epoch 18 , step 9440 : 0.776066\n",
      "loss in epoch 18 , step 9460 : 0.060798\n",
      "loss in epoch 18 , step 9480 : 0.001075\n",
      "loss in epoch 18 , step 9500 : 0.488963\n",
      "loss in epoch 18 , step 9520 : 0.000858\n",
      "loss in epoch 18 , step 9540 : 1.085311\n",
      "loss in epoch 18 , step 9560 : 0.031995\n",
      "loss in epoch 18 , step 9580 : 0.047164\n",
      "loss in epoch 18 , step 9600 : 0.142529\n",
      "loss in epoch 18 , step 9620 : 0.080829\n",
      "loss in epoch 18 , step 9640 : 0.031002\n",
      "loss in epoch 18 , step 9660 : 0.603440\n",
      "loss in epoch 18 , step 9680 : 0.002370\n",
      "loss in epoch 18 , step 9700 : 0.034444\n",
      "loss in epoch 18 , step 9720 : 0.502770\n",
      "loss in epoch 18 , step 9740 : 1.570567\n",
      "loss in epoch 18 , step 9760 : 0.012261\n",
      "loss in epoch 18 , step 9780 : 0.037987\n",
      "loss in epoch 18 , step 9800 : 0.001835\n",
      "loss in epoch 18 , step 9820 : 1.891168\n",
      "loss in epoch 18 , step 9840 : 0.375856\n",
      "loss in epoch 18 , step 9860 : 0.162117\n",
      "loss in epoch 18 , step 9880 : 0.528123\n",
      "loss in epoch 18 , step 9900 : 0.012414\n",
      "loss in epoch 18 , step 9920 : 0.790648\n",
      "loss in epoch 18 , step 9940 : 0.704791\n",
      "loss in epoch 18 , step 9960 : 0.390394\n",
      "loss in epoch 18 , step 9980 : 0.564677\n",
      "loss in epoch 18 , step 10000 : 0.048210\n",
      "loss in epoch 18 , step 10020 : 0.200983\n",
      "loss in epoch 18 , step 10040 : 0.143619\n",
      "loss in epoch 18 , step 10060 : 0.867593\n",
      "loss in epoch 18 , step 10080 : 0.079226\n",
      "loss in epoch 18 , step 10100 : 1.609326\n",
      "loss in epoch 18 , step 10120 : 0.014608\n",
      "loss in epoch 18 , step 10140 : 0.403609\n",
      "loss in epoch 18 , step 10160 : 0.192219\n",
      "loss in epoch 18 , step 10180 : 0.396244\n",
      "loss in epoch 18 , step 10200 : 0.629055\n",
      "loss in epoch 18 , step 10220 : 0.006782\n",
      "loss in epoch 18 , step 10240 : 0.178895\n",
      "loss in epoch 18 , step 10260 : 0.976601\n",
      "loss in epoch 18 , step 10280 : 0.726048\n",
      "loss in epoch 18 , step 10300 : 0.463315\n",
      "loss in epoch 18 , step 10320 : 0.535328\n",
      "loss in epoch 18 , step 10340 : 0.217175\n",
      "loss in epoch 18 , step 10360 : 0.859169\n",
      "loss in epoch 18 , step 10380 : 0.012875\n",
      "loss in epoch 18 , step 10400 : 1.145479\n",
      "loss in epoch 18 , step 10420 : 1.436985\n",
      "loss in epoch 18 , step 10440 : 1.712907\n",
      "loss in epoch 18 , step 10460 : 0.001300\n",
      "loss in epoch 18 , step 10480 : 0.088789\n",
      "loss in epoch 18 , step 10500 : 0.051682\n",
      "loss in epoch 18 , step 10520 : 1.828994\n",
      "loss in epoch 18 , step 10540 : 1.288129\n",
      "loss in epoch 18 , step 10560 : 0.308677\n",
      "loss in epoch 18 , step 10580 : 0.825304\n",
      "loss in epoch 18 , step 10600 : 0.351147\n",
      "loss in epoch 18 , step 10620 : 0.054004\n",
      "loss in epoch 18 , step 10640 : 1.143614\n",
      "loss in epoch 18 , step 10660 : 1.877595\n",
      "loss in epoch 18 , step 10680 : 0.046229\n",
      "loss in epoch 18 , step 10700 : 0.207710\n",
      "loss in epoch 18 , step 10720 : 0.000685\n",
      "loss in epoch 18 , step 10740 : 0.002114\n",
      "loss in epoch 18 , step 10760 : 0.474125\n",
      "loss in epoch 18 , step 10780 : 0.604013\n",
      "loss in epoch 18 , step 10800 : 0.344213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 18 , step 10820 : 0.342429\n",
      "loss in epoch 18 , step 10840 : 0.042836\n",
      "loss in epoch 18 , step 10860 : 0.009818\n",
      "loss in epoch 18 , step 10880 : 2.791296\n",
      "loss in epoch 18 , step 10900 : 2.182693\n",
      "loss in epoch 18 , step 10920 : 1.082307\n",
      "loss in epoch 18 , step 10940 : 0.518748\n",
      "loss in epoch 18 , step 10960 : 0.223023\n",
      "loss in epoch 18 , step 10980 : 1.439998\n",
      "loss in epoch 18 , step 11000 : 0.845202\n",
      "loss in epoch 18 , step 11020 : 0.104728\n",
      "loss in epoch 18 , step 11040 : 0.180944\n",
      "loss in epoch 18 , step 11060 : 0.081296\n",
      "loss in epoch 18 , step 11080 : 1.728887\n",
      "loss in epoch 18 , step 11100 : 0.718349\n",
      "loss in epoch 18 , step 11120 : 0.007098\n",
      "loss in epoch 18 , step 11140 : 0.431175\n",
      "loss in epoch 18 , step 11160 : 0.305922\n",
      "loss in epoch 18 , step 11180 : 0.602133\n",
      "loss in epoch 18 , step 11200 : 0.043677\n",
      "loss in epoch 18 , step 11220 : 0.350124\n",
      "loss in epoch 18 , step 11240 : 0.012695\n",
      "loss in epoch 18 , step 11260 : 0.628220\n",
      "loss in epoch 18 , step 11280 : 0.295483\n",
      "loss in epoch 18 , step 11300 : 1.524683\n",
      "loss in epoch 18 , step 11320 : 0.001130\n",
      "loss in epoch 18 , step 11340 : 0.975144\n",
      "loss in epoch 18 , step 11360 : 0.647127\n",
      "loss in epoch 18 , step 11380 : 0.661961\n",
      "loss in epoch 18 , step 11400 : 0.196561\n",
      "loss in epoch 18 , step 11420 : 0.988433\n",
      "loss in epoch 18 , step 11440 : 0.093535\n",
      "loss in epoch 18 , step 11460 : 0.141057\n",
      "loss in epoch 18 , step 11480 : 0.177655\n",
      "loss in epoch 18 , step 11500 : 0.020086\n",
      "loss in epoch 18 , step 11520 : 0.003234\n",
      "loss in epoch 18 , step 11540 : 1.426989\n",
      "loss in epoch 18 , step 11560 : 0.527755\n",
      "loss in epoch 18 , step 11580 : 1.476397\n",
      "loss in epoch 18 , step 11600 : 0.388391\n",
      "loss in epoch 18 , step 11620 : 0.325964\n",
      "loss in epoch 18 , step 11640 : 1.824446\n",
      "loss in epoch 18 , step 11660 : 0.573792\n",
      "loss in epoch 18 , step 11680 : 0.306621\n",
      "loss in epoch 18 , step 11700 : 0.443007\n",
      "loss in epoch 18 , step 11720 : 1.136995\n",
      "loss in epoch 18 , step 11740 : 2.492293\n",
      "loss in epoch 18 , step 11760 : 0.027905\n",
      "loss in epoch 18 , step 11780 : 0.758155\n",
      "loss in epoch 18 , step 11800 : 0.663311\n",
      "loss in epoch 18 , step 11820 : 0.836435\n",
      "loss in epoch 18 , step 11840 : 0.470755\n",
      "loss in epoch 18 , step 11860 : 0.998827\n",
      "loss in epoch 18 , step 11880 : 0.694703\n",
      "loss in epoch 18 , step 11900 : 0.694982\n",
      "loss in epoch 18 , step 11920 : 1.368301\n",
      "loss in epoch 18 , step 11940 : 0.507879\n",
      "loss in epoch 18 , step 11960 : 1.124591\n",
      "loss in epoch 18 , step 11980 : 0.001781\n",
      "loss in epoch 18 , step 12000 : 0.300263\n",
      "loss in epoch 18 , step 12020 : 2.500298\n",
      "loss in epoch 18 , step 12040 : 0.812930\n",
      "loss in epoch 18 , step 12060 : 0.938857\n",
      "loss in epoch 18 , step 12080 : 1.320005\n",
      "loss in epoch 18 , step 12100 : 0.094316\n",
      "loss in epoch 18 , step 12120 : 1.240620\n",
      "loss in epoch 18 , step 12140 : 0.014023\n",
      "loss in epoch 18 , step 12160 : 1.003215\n",
      "loss in epoch 18 , step 12180 : 2.210368\n",
      "loss in epoch 18 , step 12200 : 0.415606\n",
      "loss in epoch 18 , step 12220 : 0.625920\n",
      "loss in epoch 18 , step 12240 : 1.388034\n",
      "loss in epoch 18 , step 12260 : 0.712860\n",
      "loss in epoch 18 , step 12280 : 0.629428\n",
      "loss in epoch 18 , step 12300 : 0.077773\n",
      "loss in epoch 18 , step 12320 : 0.046101\n",
      "loss in epoch 18 , step 12340 : 0.831088\n",
      "loss in epoch 18 , step 12360 : 2.349318\n",
      "loss in epoch 18 , step 12380 : 0.013776\n",
      "loss in epoch 18 , step 12400 : 0.794185\n",
      "loss in epoch 18 , step 12420 : 3.112911\n",
      "loss in epoch 18 , step 12440 : 0.835296\n",
      "loss in epoch 18 , step 12460 : 0.100846\n",
      "loss in epoch 18 , step 12480 : 0.422230\n",
      "loss in epoch 18 , step 12500 : 0.513017\n",
      "loss in epoch 18 , step 12520 : 0.339658\n",
      "loss in epoch 18 , step 12540 : 1.134999\n",
      "loss in epoch 18 , step 12560 : 0.140571\n",
      "loss in epoch 18 , step 12580 : 0.591205\n",
      "loss in epoch 18 , step 12600 : 0.926301\n",
      "loss in epoch 18 , step 12620 : 0.514051\n",
      "loss in epoch 18 , step 12640 : 0.814578\n",
      "loss in epoch 18 , step 12660 : 0.339303\n",
      "loss in epoch 18 , step 12680 : 0.076975\n",
      "loss in epoch 18 , step 12700 : 0.258801\n",
      "loss in epoch 18 , step 12720 : 0.244867\n",
      "loss in epoch 18 , step 12740 : 1.680070\n",
      "loss in epoch 18 , step 12760 : 0.010643\n",
      "loss in epoch 18 , step 12780 : 0.032264\n",
      "loss in epoch 18 , step 12800 : 0.002697\n",
      "loss in epoch 18 , step 12820 : 0.783860\n",
      "loss in epoch 18 , step 12840 : 0.214936\n",
      "loss in epoch 18 , step 12860 : 0.249991\n",
      "loss in epoch 18 , step 12880 : 0.049481\n",
      "loss in epoch 18 , step 12900 : 0.677126\n",
      "loss in epoch 18 , step 12920 : 0.002107\n",
      "loss in epoch 18 , step 12940 : 0.559873\n",
      "loss in epoch 18 , step 12960 : 0.244499\n",
      "loss in epoch 18 , step 12980 : 0.181344\n",
      "loss in epoch 18 , step 13000 : 0.467380\n",
      "loss in epoch 18 , step 13020 : 0.094955\n",
      "loss in epoch 18 , step 13040 : 2.860617\n",
      "loss in epoch 18 , step 13060 : 1.154483\n",
      "loss in epoch 18 , step 13080 : 0.372668\n",
      "loss in epoch 18 , step 13100 : 0.417238\n",
      "loss in epoch 18 , step 13120 : 0.250125\n",
      "loss in epoch 18 , step 13140 : 0.253365\n",
      "loss in epoch 18 , step 13160 : 0.226562\n",
      "loss in epoch 18 , step 13180 : 0.327658\n",
      "loss in epoch 18 , step 13200 : 1.603210\n",
      "loss in epoch 18 , step 13220 : 0.167855\n",
      "loss in epoch 18 , step 13240 : 1.695694\n",
      "loss in epoch 18 , step 13260 : 2.602438\n",
      "loss in epoch 18 , step 13280 : 1.380008\n",
      "loss in epoch 18 , step 13300 : 0.062431\n",
      "loss in epoch 18 , step 13320 : 0.443659\n",
      "loss in epoch 18 , step 13340 : 0.030953\n",
      "loss in epoch 18 , step 13360 : 0.041262\n",
      "loss in epoch 18 , step 13380 : 2.048367\n",
      "loss in epoch 18 , step 13400 : 1.486751\n",
      "loss in epoch 18 , step 13420 : 1.551182\n",
      "loss in epoch 18 , step 13440 : 0.014120\n",
      "loss in epoch 18 , step 13460 : 0.718996\n",
      "loss in epoch 18 , step 13480 : 0.259550\n",
      "loss in epoch 18 , step 13500 : 0.199573\n",
      "loss in epoch 18 , step 13520 : 0.402034\n",
      "loss in epoch 18 , step 13540 : 0.447587\n",
      "loss in epoch 18 , step 13560 : 1.587427\n",
      "loss in epoch 18 , step 13580 : 0.043530\n",
      "loss in epoch 18 , step 13600 : 1.013343\n",
      "loss in epoch 18 , step 13620 : 0.002302\n",
      "loss in epoch 18 , step 13640 : 0.612108\n",
      "loss in epoch 18 , step 13660 : 0.286628\n",
      "loss in epoch 18 , step 13680 : 0.219209\n",
      "loss in epoch 18 , step 13700 : 0.817328\n",
      "loss in epoch 18 , step 13720 : 3.828163\n",
      "loss in epoch 18 , step 13740 : 2.271020\n",
      "loss in epoch 18 , step 13760 : 1.229709\n",
      "loss in epoch 18 , step 13780 : 1.211446\n",
      "loss in epoch 18 , step 13800 : 1.210309\n",
      "loss in epoch 18 , step 13820 : 0.930515\n",
      "loss in epoch 18 , step 13840 : 0.001230\n",
      "loss in epoch 18 , step 13860 : 0.577397\n",
      "loss in epoch 18 , step 13880 : 0.005245\n",
      "loss in epoch 18 , step 13900 : 0.205573\n",
      "loss in epoch 18 , step 13920 : 0.038827\n",
      "loss in epoch 18 , step 13940 : 0.228039\n",
      "loss in epoch 18 , step 13960 : 0.111282\n",
      "loss in epoch 18 , step 13980 : 0.859505\n",
      "loss in epoch 18 , step 14000 : 0.950198\n",
      "loss in epoch 18 , step 14020 : 0.571098\n",
      "loss in epoch 18 , step 14040 : 0.163285\n",
      "loss in epoch 18 , step 14060 : 0.266140\n",
      "loss in epoch 18 , step 14080 : 1.397233\n",
      "loss in epoch 18 , step 14100 : 0.815117\n",
      "loss in epoch 18 , step 14120 : 1.847685\n",
      "loss in epoch 18 , step 14140 : 1.775886\n",
      "loss in epoch 18 , step 14160 : 2.344707\n",
      "loss in epoch 18 , step 14180 : 0.886559\n",
      "loss in epoch 18 , step 14200 : 0.132243\n",
      "loss in epoch 18 , step 14220 : 0.901796\n",
      "loss in epoch 18 , step 14240 : 1.001841\n",
      "loss in epoch 18 , step 14260 : 0.355024\n",
      "loss in epoch 18 , step 14280 : 0.525389\n",
      "loss in epoch 18 , step 14300 : 0.090614\n",
      "loss in epoch 18 , step 14320 : 0.002404\n",
      "loss in epoch 18 , step 14340 : 0.874582\n",
      "loss in epoch 18 , step 14360 : 0.001865\n",
      "loss in epoch 18 , step 14380 : 0.033210\n",
      "loss in epoch 18 , step 14400 : 0.024680\n",
      "loss in epoch 18 , step 14420 : 0.034072\n",
      "loss in epoch 18 , step 14440 : 0.330478\n",
      "loss in epoch 18 , step 14460 : 0.107462\n",
      "loss in epoch 18 , step 14480 : 1.562300\n",
      "loss in epoch 18 , step 14500 : 0.721633\n",
      "loss in epoch 18 , step 14520 : 0.004676\n",
      "loss in epoch 18 , step 14540 : 0.259876\n",
      "loss in epoch 18 , step 14560 : 1.109974\n",
      "loss in epoch 18 , step 14580 : 0.132880\n",
      "loss in epoch 18 , step 14600 : 0.098792\n",
      "loss in epoch 18 , step 14620 : 0.343687\n",
      "loss in epoch 18 , step 14640 : 0.002553\n",
      "loss in epoch 18 , step 14660 : 0.001263\n",
      "loss in epoch 18 , step 14680 : 3.714120\n",
      "loss in epoch 18 , step 14700 : 0.554187\n",
      "loss in epoch 18 , step 14720 : 1.445899\n",
      "loss in epoch 18 , step 14740 : 0.866933\n",
      "loss in epoch 18 , step 14760 : 0.534036\n",
      "loss in epoch 18 , step 14780 : 1.788486\n",
      "loss in epoch 18 , step 14800 : 0.192376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 18 , step 14820 : 0.003184\n",
      "loss in epoch 18 , step 14840 : 1.269646\n",
      "loss in epoch 18 , step 14860 : 1.737085\n",
      "loss in epoch 18 , step 14880 : 1.232152\n",
      "loss in epoch 18 , step 14900 : 0.706196\n",
      "loss in epoch 18 , step 14920 : 1.050942\n",
      "loss in epoch 18 , step 14940 : 0.497400\n",
      "loss in epoch 18 , step 14960 : 0.023687\n",
      "loss in epoch 18 , step 14980 : 0.112452\n",
      "loss in epoch 18 , step 15000 : 0.616158\n",
      "loss in epoch 18 , step 15020 : 2.500704\n",
      "loss in epoch 18 , step 15040 : 2.251035\n",
      "loss in epoch 18 , step 15060 : 0.043119\n",
      "loss in epoch 18 , step 15080 : 0.006229\n",
      "loss in epoch 18 , step 15100 : 0.444108\n",
      "loss in epoch 18 , step 15120 : 0.364425\n",
      "loss in epoch 18 , step 15140 : 1.748956\n",
      "loss in epoch 18 , step 15160 : 0.089491\n",
      "loss in epoch 18 , step 15180 : 0.707096\n",
      "loss in epoch 18 , step 15200 : 1.086838\n",
      "loss in epoch 18 , step 15220 : 0.450697\n",
      "loss in epoch 18 , step 15240 : 0.391417\n",
      "loss in epoch 18 , step 15260 : 0.008455\n",
      "loss in epoch 18 , step 15280 : 0.309422\n",
      "loss in epoch 18 , step 15300 : 0.009340\n",
      "loss in epoch 18 , step 15320 : 0.026106\n",
      "loss in epoch 18 , step 15340 : 0.026231\n",
      "loss in epoch 18 , step 15360 : 0.003658\n",
      "loss in epoch 18 , step 15380 : 0.031869\n",
      "loss in epoch 18 , step 15400 : 1.042663\n",
      "loss in epoch 18 , step 15420 : 0.169921\n",
      "loss in epoch 18 , step 15440 : 0.066163\n",
      "loss in epoch 18 , step 15460 : 0.412972\n",
      "loss in epoch 18 , step 15480 : 0.062795\n",
      "loss in epoch 18 , step 15500 : 0.006128\n",
      "loss in epoch 18 , step 15520 : 0.159105\n",
      "loss in epoch 18 , step 15540 : 0.006029\n",
      "loss in epoch 18 , step 15560 : 1.490165\n",
      "loss in epoch 18 , step 15580 : 0.112476\n",
      "loss in epoch 18 , step 15600 : 0.389391\n",
      "loss in epoch 18 , step 15620 : 0.103272\n",
      "loss in epoch 18 , step 15640 : 0.362427\n",
      "loss in epoch 18 , step 15660 : 0.032373\n",
      "loss in epoch 18 , step 15680 : 0.472825\n",
      "loss in epoch 18 , step 15700 : 0.649468\n",
      "loss in epoch 18 , step 15720 : 0.053941\n",
      "loss in epoch 18 , step 15740 : 0.570287\n",
      "loss in epoch 18 , step 15760 : 1.319890\n",
      "loss in epoch 18 , step 15780 : 0.467970\n",
      "loss in epoch 18 , step 15800 : 1.458419\n",
      "loss in epoch 18 , step 15820 : 0.983218\n",
      "loss in epoch 18 , step 15840 : 0.006563\n",
      "loss in epoch 18 , step 15860 : 1.367699\n",
      "loss in epoch 18 , step 15880 : 0.174548\n",
      "loss in epoch 18 , step 15900 : 1.183592\n",
      "loss in epoch 18 , step 15920 : 0.004875\n",
      "loss in epoch 18 , step 15940 : 1.105852\n",
      "loss in epoch 18 , step 15960 : 0.363585\n",
      "loss in epoch 18 , step 15980 : 0.877669\n",
      "loss in epoch 18 , step 16000 : 1.859221\n",
      "loss in epoch 18 , step 16020 : 0.428478\n",
      "loss in epoch 18 , step 16040 : 0.269254\n",
      "loss in epoch 18 , step 16060 : 0.646468\n",
      "loss in epoch 18 , step 16080 : 0.225995\n",
      "loss in epoch 18 , step 16100 : 0.072848\n",
      "loss in epoch 18 , step 16120 : 0.769180\n",
      "loss in epoch 18 , step 16140 : 0.024029\n",
      "loss in epoch 18 , step 16160 : 0.018296\n",
      "loss in epoch 18 , step 16180 : 0.365294\n",
      "loss in epoch 18 , step 16200 : 0.001890\n",
      "loss in epoch 18 , step 16220 : 1.418299\n",
      "loss in epoch 18 , step 16240 : 1.294892\n",
      "loss in epoch 18 , step 16260 : 1.880211\n",
      "loss in epoch 18 , step 16280 : 0.431434\n",
      "loss in epoch 18 , step 16300 : 3.253571\n",
      "loss in epoch 18 , step 16320 : 0.243747\n",
      "loss in epoch 18 , step 16340 : 0.002344\n",
      "loss in epoch 18 , step 16360 : 1.115081\n",
      "loss in epoch 18 , step 16380 : 0.392685\n",
      "loss in epoch 18 , step 16400 : 1.549879\n",
      "loss in epoch 18 , step 16420 : 0.053872\n",
      "loss in epoch 18 , step 16440 : 0.161484\n",
      "loss in epoch 18 , step 16460 : 1.602569\n",
      "loss in epoch 18 , step 16480 : 0.423466\n",
      "loss in epoch 18 , step 16500 : 0.001064\n",
      "loss in epoch 18 , step 16520 : 0.275730\n",
      "loss in epoch 18 , step 16540 : 1.049191\n",
      "loss in epoch 18 , step 16560 : 0.077294\n",
      "loss in epoch 18 , step 16580 : 1.095727\n",
      "loss in epoch 18 , step 16600 : 0.070739\n",
      "loss in epoch 18 , step 16620 : 0.223196\n",
      "loss in epoch 18 , step 16640 : 0.097288\n",
      "loss in epoch 18 , step 16660 : 1.851072\n",
      "loss in epoch 18 , step 16680 : 0.036354\n",
      "loss in epoch 18 , step 16700 : 1.154330\n",
      "loss in epoch 18 , step 16720 : 1.225674\n",
      "loss in epoch 18 , step 16740 : 0.886844\n",
      "loss in epoch 18 , step 16760 : 0.354967\n",
      "loss in epoch 18 , step 16780 : 0.761670\n",
      "loss in epoch 18 , step 16800 : 0.049258\n",
      "loss in epoch 18 , step 16820 : 1.074484\n",
      "loss in epoch 18 , step 16840 : 0.010389\n",
      "loss in epoch 18 , step 16860 : 1.668217\n",
      "loss in epoch 18 , step 16880 : 0.752963\n",
      "loss in epoch 18 , step 16900 : 0.407422\n",
      "loss in epoch 18 , step 16920 : 0.650707\n",
      "loss in epoch 18 , step 16940 : 0.002757\n",
      "loss in epoch 18 , step 16960 : 0.842836\n",
      "loss in epoch 18 , step 16980 : 0.158504\n",
      "loss in epoch 18 , step 17000 : 1.482964\n",
      "loss in epoch 18 , step 17020 : 0.661820\n",
      "loss in epoch 18 , step 17040 : 0.803695\n",
      "loss in epoch 18 , step 17060 : 0.021120\n",
      "loss in epoch 18 , step 17080 : 0.173409\n",
      "loss in epoch 18 , step 17100 : 0.279441\n",
      "loss in epoch 18 , step 17120 : 0.233694\n",
      "loss in epoch 18 , step 17140 : 0.221914\n",
      "loss in epoch 18 , step 17160 : 0.116431\n",
      "loss in epoch 18 , step 17180 : 2.210735\n",
      "loss in epoch 18 , step 17200 : 0.820767\n",
      "loss in epoch 18 , step 17220 : 0.546363\n",
      "loss in epoch 18 , step 17240 : 0.463115\n",
      "loss in epoch 18 , step 17260 : 0.005931\n",
      "loss in epoch 18 , step 17280 : 1.093262\n",
      "loss in epoch 18 , step 17300 : 0.082343\n",
      "loss in epoch 18 , step 17320 : 0.002228\n",
      "loss in epoch 18 , step 17340 : 0.001026\n",
      "loss in epoch 18 , step 17360 : 0.002264\n",
      "loss in epoch 18 , step 17380 : 1.180077\n",
      "loss in epoch 18 , step 17400 : 1.416925\n",
      "loss in epoch 18 , step 17420 : 0.688998\n",
      "loss in epoch 18 , step 17440 : 0.359439\n",
      "loss in epoch 18 , step 17460 : 0.104633\n",
      "loss in epoch 18 , step 17480 : 0.853432\n",
      "loss in epoch 18 , step 17500 : 0.583752\n",
      "loss in epoch 18 , step 17520 : 1.066499\n",
      "loss in epoch 18 , step 17540 : 0.002103\n",
      "loss in epoch 18 , step 17560 : 0.556061\n",
      "loss in epoch 18 , step 17580 : 4.062179\n",
      "loss in epoch 18 , step 17600 : 0.043925\n",
      "loss in epoch 18 , step 17620 : 0.245633\n",
      "loss in epoch 18 , step 17640 : 2.027196\n",
      "loss in epoch 18 , step 17660 : 0.063119\n",
      "loss in epoch 18 , step 17680 : 0.948479\n",
      "loss in epoch 18 , step 17700 : 0.061117\n",
      "loss in epoch 18 , step 17720 : 0.586687\n",
      "loss in epoch 18 , step 17740 : 0.419121\n",
      "loss in epoch 18 , step 17760 : 0.842495\n",
      "loss in epoch 18 , step 17780 : 0.213324\n",
      "loss in epoch 18 , step 17800 : 0.536858\n",
      "loss in epoch 18 , step 17820 : 0.180075\n",
      "loss in epoch 18 , step 17840 : 1.078491\n",
      "loss in epoch 18 , step 17860 : 0.001583\n",
      "loss in epoch 18 , step 17880 : 1.496964\n",
      "loss in epoch 18 , step 17900 : 0.687953\n",
      "loss in epoch 18 , step 17920 : 0.138409\n",
      "loss in epoch 18 , step 17940 : 0.543882\n",
      "loss in epoch 18 , step 17960 : 0.330328\n",
      "loss in epoch 18 , step 17980 : 0.492189\n",
      "loss in epoch 18 , step 18000 : 0.471278\n",
      "loss in epoch 18 , step 18020 : 0.654403\n",
      "loss in epoch 18 , step 18040 : 1.475380\n",
      "loss in epoch 18 , step 18060 : 0.016114\n",
      "loss in epoch 18 , step 18080 : 1.768908\n",
      "loss in epoch 18 , step 18100 : 0.627733\n",
      "loss in epoch 18 , step 18120 : 1.731791\n",
      "loss in epoch 18 , step 18140 : 0.177389\n",
      "loss in epoch 18 , step 18160 : 0.001387\n",
      "loss in epoch 18 , step 18180 : 0.206512\n",
      "loss in epoch 18 , step 18200 : 0.538911\n",
      "loss in epoch 18 , step 18220 : 0.004293\n",
      "loss in epoch 18 , step 18240 : 0.039395\n",
      "loss in epoch 18 , step 18260 : 0.249868\n",
      "loss in epoch 18 , step 18280 : 0.892609\n",
      "loss in epoch 18 , step 18300 : 2.123672\n",
      "loss in epoch 18 , step 18320 : 1.056228\n",
      "loss in epoch 18 , step 18340 : 0.319327\n",
      "loss in epoch 18 , step 18360 : 0.102888\n",
      "loss in epoch 18 , step 18380 : 0.854522\n",
      "loss in epoch 18 , step 18400 : 0.226006\n",
      "loss in epoch 18 , step 18420 : 0.951425\n",
      "loss in epoch 18 , step 18440 : 0.032083\n",
      "loss in epoch 18 , step 18460 : 0.001922\n",
      "loss in epoch 18 , step 18480 : 0.008055\n",
      "loss in epoch 18 , step 18500 : 1.651206\n",
      "loss in epoch 18 , step 18520 : 0.511738\n",
      "loss in epoch 18 , step 18540 : 0.234668\n",
      "loss in epoch 18 , step 18560 : 0.607359\n",
      "loss in epoch 18 , step 18580 : 1.471631\n",
      "loss in epoch 18 , step 18600 : 2.723041\n",
      "loss in epoch 18 , step 18620 : 0.343406\n",
      "loss in epoch 18 , step 18640 : 0.361257\n",
      "loss in epoch 18 , step 18660 : 0.321116\n",
      "loss in epoch 18 , step 18680 : 0.617985\n",
      "loss in epoch 18 , step 18700 : 1.146948\n",
      "loss in epoch 18 , step 18720 : 0.200035\n",
      "loss in epoch 18 , step 18740 : 0.002177\n",
      "loss in epoch 18 , step 18760 : 1.850021\n",
      "loss in epoch 18 , step 18780 : 1.164490\n",
      "loss in epoch 18 , step 18800 : 0.017761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 18 , step 18820 : 0.252596\n",
      "loss in epoch 18 , step 18840 : 0.893474\n",
      "loss in epoch 18 , step 18860 : 1.145959\n",
      "loss in epoch 18 , step 18880 : 0.672071\n",
      "loss in epoch 18 , step 18900 : 0.539037\n",
      "loss in epoch 18 , step 18920 : 0.691735\n",
      "loss in epoch 18 , step 18940 : 0.095934\n",
      "loss in epoch 18 , step 18960 : 0.026698\n",
      "loss in epoch 18 , step 18980 : 1.652398\n",
      "loss in epoch 18 , step 19000 : 0.889207\n",
      "loss in epoch 18 , step 19020 : 0.796043\n",
      "loss in epoch 18 , step 19040 : 0.066154\n",
      "loss in epoch 18 , step 19060 : 0.012193\n",
      "loss in epoch 18 , step 19080 : 1.054310\n",
      "loss in epoch 18 , step 19100 : 0.870567\n",
      "loss in epoch 18 , step 19120 : 1.020963\n",
      "loss in epoch 18 , step 19140 : 0.649573\n",
      "loss in epoch 18 , step 19160 : 1.093011\n",
      "loss in epoch 18 , step 19180 : 0.206815\n",
      "loss in epoch 18 , step 19200 : 0.536377\n",
      "loss in epoch 18 , step 19220 : 0.007880\n",
      "loss in epoch 18 , step 19240 : 0.311098\n",
      "loss in epoch 18 , step 19260 : 0.035096\n",
      "loss in epoch 18 , step 19280 : 0.396218\n",
      "loss in epoch 18 , step 19300 : 0.377171\n",
      "loss in epoch 18 , step 19320 : 0.206002\n",
      "loss in epoch 18 , step 19340 : 0.373609\n",
      "loss in epoch 18 , step 19360 : 0.194970\n",
      "loss in epoch 18 , step 19380 : 0.820738\n",
      "loss in epoch 18 , step 19400 : 0.060882\n",
      "loss in epoch 18 , step 19420 : 0.379971\n",
      "loss in epoch 18 , step 19440 : 0.034371\n",
      "loss in epoch 18 , step 19460 : 1.775116\n",
      "loss in epoch 18 , step 19480 : 0.490687\n",
      "loss in epoch 18 , step 19500 : 0.515614\n",
      "loss in epoch 18 , step 19520 : 0.001800\n",
      "loss in epoch 18 , step 19540 : 0.540776\n",
      "loss in epoch 18 , step 19560 : 0.668464\n",
      "loss in epoch 18 , step 19580 : 1.292978\n",
      "loss in epoch 18 , step 19600 : 0.859453\n",
      "loss in epoch 18 , step 19620 : 0.540116\n",
      "loss in epoch 18 , step 19640 : 0.325264\n",
      "loss in epoch 18 , step 19660 : 0.271785\n",
      "loss in epoch 18 , step 19680 : 0.014503\n",
      "loss in epoch 18 , step 19700 : 1.190545\n",
      "loss in epoch 18 , step 19720 : 1.777017\n",
      "loss in epoch 18 , step 19740 : 0.009605\n",
      "loss in epoch 18 , step 19760 : 0.511372\n",
      "loss in epoch 18 , step 19780 : 0.211151\n",
      "loss in epoch 18 , step 19800 : 0.089734\n",
      "loss in epoch 18 , step 19820 : 0.467033\n",
      "loss in epoch 18 , step 19840 : 0.325729\n",
      "loss in epoch 18 , step 19860 : 0.447999\n",
      "loss in epoch 18 , step 19880 : 0.002880\n",
      "loss in epoch 18 , step 19900 : 0.145380\n",
      "loss in epoch 18 , step 19920 : 1.300962\n",
      "loss in epoch 18 , step 19940 : 0.182230\n",
      "Accuracy in epoch 18 : 31.246840\n",
      "loss in epoch 19 , step 0 : 0.094705\n",
      "loss in epoch 19 , step 20 : 0.006659\n",
      "loss in epoch 19 , step 40 : 1.768761\n",
      "loss in epoch 19 , step 60 : 0.518158\n",
      "loss in epoch 19 , step 80 : 0.000987\n",
      "loss in epoch 19 , step 100 : 0.067109\n",
      "loss in epoch 19 , step 120 : 0.299073\n",
      "loss in epoch 19 , step 140 : 0.341770\n",
      "loss in epoch 19 , step 160 : 0.645219\n",
      "loss in epoch 19 , step 180 : 2.734356\n",
      "loss in epoch 19 , step 200 : 0.435281\n",
      "loss in epoch 19 , step 220 : 0.157737\n",
      "loss in epoch 19 , step 240 : 0.061721\n",
      "loss in epoch 19 , step 260 : 1.339342\n",
      "loss in epoch 19 , step 280 : 0.019150\n",
      "loss in epoch 19 , step 300 : 0.015303\n",
      "loss in epoch 19 , step 320 : 0.687804\n",
      "loss in epoch 19 , step 340 : 0.059798\n",
      "loss in epoch 19 , step 360 : 0.005979\n",
      "loss in epoch 19 , step 380 : 0.498980\n",
      "loss in epoch 19 , step 400 : 0.938484\n",
      "loss in epoch 19 , step 420 : 0.005483\n",
      "loss in epoch 19 , step 440 : 0.881229\n",
      "loss in epoch 19 , step 460 : 0.112060\n",
      "loss in epoch 19 , step 480 : 1.047845\n",
      "loss in epoch 19 , step 500 : 0.309362\n",
      "loss in epoch 19 , step 520 : 0.276035\n",
      "loss in epoch 19 , step 540 : 0.731220\n",
      "loss in epoch 19 , step 560 : 0.586876\n",
      "loss in epoch 19 , step 580 : 0.533428\n",
      "loss in epoch 19 , step 600 : 0.794151\n",
      "loss in epoch 19 , step 620 : 1.373119\n",
      "loss in epoch 19 , step 640 : 0.286039\n",
      "loss in epoch 19 , step 660 : 0.007760\n",
      "loss in epoch 19 , step 680 : 0.104316\n",
      "loss in epoch 19 , step 700 : 0.075919\n",
      "loss in epoch 19 , step 720 : 0.270781\n",
      "loss in epoch 19 , step 740 : 0.795952\n",
      "loss in epoch 19 , step 760 : 0.001863\n",
      "loss in epoch 19 , step 780 : 0.952464\n",
      "loss in epoch 19 , step 800 : 1.092407\n",
      "loss in epoch 19 , step 820 : 0.478903\n",
      "loss in epoch 19 , step 840 : 0.984505\n",
      "loss in epoch 19 , step 860 : 0.013630\n",
      "loss in epoch 19 , step 880 : 0.022344\n",
      "loss in epoch 19 , step 900 : 0.001668\n",
      "loss in epoch 19 , step 920 : 1.656654\n",
      "loss in epoch 19 , step 940 : 0.944329\n",
      "loss in epoch 19 , step 960 : 1.187539\n",
      "loss in epoch 19 , step 980 : 0.098922\n",
      "loss in epoch 19 , step 1000 : 0.169125\n",
      "loss in epoch 19 , step 1020 : 0.645230\n",
      "loss in epoch 19 , step 1040 : 0.622369\n",
      "loss in epoch 19 , step 1060 : 0.034334\n",
      "loss in epoch 19 , step 1080 : 1.287237\n",
      "loss in epoch 19 , step 1100 : 0.760908\n",
      "loss in epoch 19 , step 1120 : 0.456188\n",
      "loss in epoch 19 , step 1140 : 0.015756\n",
      "loss in epoch 19 , step 1160 : 0.241052\n",
      "loss in epoch 19 , step 1180 : 0.465896\n",
      "loss in epoch 19 , step 1200 : 0.682702\n",
      "loss in epoch 19 , step 1220 : 0.000416\n",
      "loss in epoch 19 , step 1240 : 0.672303\n",
      "loss in epoch 19 , step 1260 : 0.427227\n",
      "loss in epoch 19 , step 1280 : 0.005434\n",
      "loss in epoch 19 , step 1300 : 0.091983\n",
      "loss in epoch 19 , step 1320 : 0.658222\n",
      "loss in epoch 19 , step 1340 : 0.018416\n",
      "loss in epoch 19 , step 1360 : 1.424932\n",
      "loss in epoch 19 , step 1380 : 0.460056\n",
      "loss in epoch 19 , step 1400 : 0.746576\n",
      "loss in epoch 19 , step 1420 : 0.338230\n",
      "loss in epoch 19 , step 1440 : 0.267601\n",
      "loss in epoch 19 , step 1460 : 0.001104\n",
      "loss in epoch 19 , step 1480 : 0.534353\n",
      "loss in epoch 19 , step 1500 : 0.026950\n",
      "loss in epoch 19 , step 1520 : 0.042478\n",
      "loss in epoch 19 , step 1540 : 0.129982\n",
      "loss in epoch 19 , step 1560 : 0.078562\n",
      "loss in epoch 19 , step 1580 : 0.655632\n",
      "loss in epoch 19 , step 1600 : 0.071468\n",
      "loss in epoch 19 , step 1620 : 0.768884\n",
      "loss in epoch 19 , step 1640 : 3.224607\n",
      "loss in epoch 19 , step 1660 : 0.073764\n",
      "loss in epoch 19 , step 1680 : 1.195702\n",
      "loss in epoch 19 , step 1700 : 1.257671\n",
      "loss in epoch 19 , step 1720 : 0.358181\n",
      "loss in epoch 19 , step 1740 : 0.499509\n",
      "loss in epoch 19 , step 1760 : 0.442491\n",
      "loss in epoch 19 , step 1780 : 0.831746\n",
      "loss in epoch 19 , step 1800 : 0.014484\n",
      "loss in epoch 19 , step 1820 : 0.031467\n",
      "loss in epoch 19 , step 1840 : 0.012560\n",
      "loss in epoch 19 , step 1860 : 0.476845\n",
      "loss in epoch 19 , step 1880 : 0.239862\n",
      "loss in epoch 19 , step 1900 : 0.002854\n",
      "loss in epoch 19 , step 1920 : 0.147579\n",
      "loss in epoch 19 , step 1940 : 0.261762\n",
      "loss in epoch 19 , step 1960 : 1.600479\n",
      "loss in epoch 19 , step 1980 : 0.349359\n",
      "loss in epoch 19 , step 2000 : 0.127087\n",
      "loss in epoch 19 , step 2020 : 0.831388\n",
      "loss in epoch 19 , step 2040 : 0.001695\n",
      "loss in epoch 19 , step 2060 : 0.129906\n",
      "loss in epoch 19 , step 2080 : 0.001787\n",
      "loss in epoch 19 , step 2100 : 1.037192\n",
      "loss in epoch 19 , step 2120 : 0.770527\n",
      "loss in epoch 19 , step 2140 : 0.774835\n",
      "loss in epoch 19 , step 2160 : 0.054854\n",
      "loss in epoch 19 , step 2180 : 0.114307\n",
      "loss in epoch 19 , step 2200 : 1.640058\n",
      "loss in epoch 19 , step 2220 : 0.295464\n",
      "loss in epoch 19 , step 2240 : 0.008265\n",
      "loss in epoch 19 , step 2260 : 0.002540\n",
      "loss in epoch 19 , step 2280 : 0.013145\n",
      "loss in epoch 19 , step 2300 : 0.540171\n",
      "loss in epoch 19 , step 2320 : 0.628732\n",
      "loss in epoch 19 , step 2340 : 0.138987\n",
      "loss in epoch 19 , step 2360 : 0.018725\n",
      "loss in epoch 19 , step 2380 : 0.652328\n",
      "loss in epoch 19 , step 2400 : 1.053180\n",
      "loss in epoch 19 , step 2420 : 0.012724\n",
      "loss in epoch 19 , step 2440 : 0.006521\n",
      "loss in epoch 19 , step 2460 : 0.630449\n",
      "loss in epoch 19 , step 2480 : 0.472546\n",
      "loss in epoch 19 , step 2500 : 0.168705\n",
      "loss in epoch 19 , step 2520 : 0.107732\n",
      "loss in epoch 19 , step 2540 : 0.217980\n",
      "loss in epoch 19 , step 2560 : 0.687034\n",
      "loss in epoch 19 , step 2580 : 0.184243\n",
      "loss in epoch 19 , step 2600 : 0.003395\n",
      "loss in epoch 19 , step 2620 : 1.491078\n",
      "loss in epoch 19 , step 2640 : 1.068080\n",
      "loss in epoch 19 , step 2660 : 0.005014\n",
      "loss in epoch 19 , step 2680 : 1.769339\n",
      "loss in epoch 19 , step 2700 : 0.127135\n",
      "loss in epoch 19 , step 2720 : 0.436972\n",
      "loss in epoch 19 , step 2740 : 0.556992\n",
      "loss in epoch 19 , step 2760 : 0.191705\n",
      "loss in epoch 19 , step 2780 : 0.537998\n",
      "loss in epoch 19 , step 2800 : 0.479566\n",
      "loss in epoch 19 , step 2820 : 0.360159\n",
      "loss in epoch 19 , step 2840 : 1.071029\n",
      "loss in epoch 19 , step 2860 : 1.177912\n",
      "loss in epoch 19 , step 2880 : 0.097784\n",
      "loss in epoch 19 , step 2900 : 0.263085\n",
      "loss in epoch 19 , step 2920 : 0.016453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 19 , step 2940 : 0.129703\n",
      "loss in epoch 19 , step 2960 : 0.001369\n",
      "loss in epoch 19 , step 2980 : 0.008468\n",
      "loss in epoch 19 , step 3000 : 0.054071\n",
      "loss in epoch 19 , step 3020 : 0.302688\n",
      "loss in epoch 19 , step 3040 : 0.211903\n",
      "loss in epoch 19 , step 3060 : 0.016949\n",
      "loss in epoch 19 , step 3080 : 0.981890\n",
      "loss in epoch 19 , step 3100 : 0.676655\n",
      "loss in epoch 19 , step 3120 : 1.094550\n",
      "loss in epoch 19 , step 3140 : 0.916684\n",
      "loss in epoch 19 , step 3160 : 1.048631\n",
      "loss in epoch 19 , step 3180 : 0.954886\n",
      "loss in epoch 19 , step 3200 : 0.720416\n",
      "loss in epoch 19 , step 3220 : 0.106756\n",
      "loss in epoch 19 , step 3240 : 0.003082\n",
      "loss in epoch 19 , step 3260 : 1.702002\n",
      "loss in epoch 19 , step 3280 : 0.294137\n",
      "loss in epoch 19 , step 3300 : 0.579592\n",
      "loss in epoch 19 , step 3320 : 0.002368\n",
      "loss in epoch 19 , step 3340 : 0.251294\n",
      "loss in epoch 19 , step 3360 : 0.003570\n",
      "loss in epoch 19 , step 3380 : 1.176739\n",
      "loss in epoch 19 , step 3400 : 0.531553\n",
      "loss in epoch 19 , step 3420 : 1.201952\n",
      "loss in epoch 19 , step 3440 : 0.890051\n",
      "loss in epoch 19 , step 3460 : 0.336207\n",
      "loss in epoch 19 , step 3480 : 0.312829\n",
      "loss in epoch 19 , step 3500 : 0.020725\n",
      "loss in epoch 19 , step 3520 : 0.313951\n",
      "loss in epoch 19 , step 3540 : 0.747576\n",
      "loss in epoch 19 , step 3560 : 0.009763\n",
      "loss in epoch 19 , step 3580 : 0.209632\n",
      "loss in epoch 19 , step 3600 : 0.588036\n",
      "loss in epoch 19 , step 3620 : 0.194932\n",
      "loss in epoch 19 , step 3640 : 0.140851\n",
      "loss in epoch 19 , step 3660 : 1.724512\n",
      "loss in epoch 19 , step 3680 : 0.064497\n",
      "loss in epoch 19 , step 3700 : 0.303168\n",
      "loss in epoch 19 , step 3720 : 0.001810\n",
      "loss in epoch 19 , step 3740 : 0.853032\n",
      "loss in epoch 19 , step 3760 : 2.081892\n",
      "loss in epoch 19 , step 3780 : 1.278015\n",
      "loss in epoch 19 , step 3800 : 0.296445\n",
      "loss in epoch 19 , step 3820 : 0.003749\n",
      "loss in epoch 19 , step 3840 : 0.077888\n",
      "loss in epoch 19 , step 3860 : 1.524057\n",
      "loss in epoch 19 , step 3880 : 0.050205\n",
      "loss in epoch 19 , step 3900 : 0.008599\n",
      "loss in epoch 19 , step 3920 : 0.194785\n",
      "loss in epoch 19 , step 3940 : 1.342979\n",
      "loss in epoch 19 , step 3960 : 0.344557\n",
      "loss in epoch 19 , step 3980 : 0.013194\n",
      "loss in epoch 19 , step 4000 : 3.398724\n",
      "loss in epoch 19 , step 4020 : 0.394718\n",
      "loss in epoch 19 , step 4040 : 0.832755\n",
      "loss in epoch 19 , step 4060 : 0.528731\n",
      "loss in epoch 19 , step 4080 : 0.348618\n",
      "loss in epoch 19 , step 4100 : 0.031738\n",
      "loss in epoch 19 , step 4120 : 0.444757\n",
      "loss in epoch 19 , step 4140 : 0.782836\n",
      "loss in epoch 19 , step 4160 : 0.097434\n",
      "loss in epoch 19 , step 4180 : 0.443651\n",
      "loss in epoch 19 , step 4200 : 0.000399\n",
      "loss in epoch 19 , step 4220 : 0.323520\n",
      "loss in epoch 19 , step 4240 : 0.004588\n",
      "loss in epoch 19 , step 4260 : 0.449016\n",
      "loss in epoch 19 , step 4280 : 0.377355\n",
      "loss in epoch 19 , step 4300 : 0.239845\n",
      "loss in epoch 19 , step 4320 : 0.248306\n",
      "loss in epoch 19 , step 4340 : 0.004565\n",
      "loss in epoch 19 , step 4360 : 0.117309\n",
      "loss in epoch 19 , step 4380 : 0.989163\n",
      "loss in epoch 19 , step 4400 : 0.681084\n",
      "loss in epoch 19 , step 4420 : 0.708744\n",
      "loss in epoch 19 , step 4440 : 0.459736\n",
      "loss in epoch 19 , step 4460 : 0.566097\n",
      "loss in epoch 19 , step 4480 : 0.214183\n",
      "loss in epoch 19 , step 4500 : 0.022242\n",
      "loss in epoch 19 , step 4520 : 0.012636\n",
      "loss in epoch 19 , step 4540 : 0.028015\n",
      "loss in epoch 19 , step 4560 : 0.003311\n",
      "loss in epoch 19 , step 4580 : 0.128954\n",
      "loss in epoch 19 , step 4600 : 0.930035\n",
      "loss in epoch 19 , step 4620 : 0.473879\n",
      "loss in epoch 19 , step 4640 : 0.048507\n",
      "loss in epoch 19 , step 4660 : 0.701119\n",
      "loss in epoch 19 , step 4680 : 0.013237\n",
      "loss in epoch 19 , step 4700 : 1.181901\n",
      "loss in epoch 19 , step 4720 : 0.145973\n",
      "loss in epoch 19 , step 4740 : 2.461056\n",
      "loss in epoch 19 , step 4760 : 0.665433\n",
      "loss in epoch 19 , step 4780 : 0.589505\n",
      "loss in epoch 19 , step 4800 : 0.530504\n",
      "loss in epoch 19 , step 4820 : 0.032577\n",
      "loss in epoch 19 , step 4840 : 1.243787\n",
      "loss in epoch 19 , step 4860 : 0.135882\n",
      "loss in epoch 19 , step 4880 : 0.098899\n",
      "loss in epoch 19 , step 4900 : 0.524580\n",
      "loss in epoch 19 , step 4920 : 0.931240\n",
      "loss in epoch 19 , step 4940 : 0.870202\n",
      "loss in epoch 19 , step 4960 : 0.115457\n",
      "loss in epoch 19 , step 4980 : 0.495416\n",
      "loss in epoch 19 , step 5000 : 0.253409\n",
      "loss in epoch 19 , step 5020 : 0.261019\n",
      "loss in epoch 19 , step 5040 : 0.018638\n",
      "loss in epoch 19 , step 5060 : 0.566928\n",
      "loss in epoch 19 , step 5080 : 0.172621\n",
      "loss in epoch 19 , step 5100 : 0.049136\n",
      "loss in epoch 19 , step 5120 : 0.010740\n",
      "loss in epoch 19 , step 5140 : 0.160412\n",
      "loss in epoch 19 , step 5160 : 0.182238\n",
      "loss in epoch 19 , step 5180 : 0.353631\n",
      "loss in epoch 19 , step 5200 : 0.714970\n",
      "loss in epoch 19 , step 5220 : 0.224260\n",
      "loss in epoch 19 , step 5240 : 0.184024\n",
      "loss in epoch 19 , step 5260 : 0.061446\n",
      "loss in epoch 19 , step 5280 : 0.088407\n",
      "loss in epoch 19 , step 5300 : 0.148534\n",
      "loss in epoch 19 , step 5320 : 0.014625\n",
      "loss in epoch 19 , step 5340 : 0.145049\n",
      "loss in epoch 19 , step 5360 : 0.478398\n",
      "loss in epoch 19 , step 5380 : 0.335128\n",
      "loss in epoch 19 , step 5400 : 0.092406\n",
      "loss in epoch 19 , step 5420 : 0.005179\n",
      "loss in epoch 19 , step 5440 : 2.283481\n",
      "loss in epoch 19 , step 5460 : 0.007853\n",
      "loss in epoch 19 , step 5480 : 0.002126\n",
      "loss in epoch 19 , step 5500 : 0.945712\n",
      "loss in epoch 19 , step 5520 : 0.897820\n",
      "loss in epoch 19 , step 5540 : 0.007357\n",
      "loss in epoch 19 , step 5560 : 0.714214\n",
      "loss in epoch 19 , step 5580 : 0.847797\n",
      "loss in epoch 19 , step 5600 : 0.191803\n",
      "loss in epoch 19 , step 5620 : 0.400027\n",
      "loss in epoch 19 , step 5640 : 0.080285\n",
      "loss in epoch 19 , step 5660 : 0.260991\n",
      "loss in epoch 19 , step 5680 : 0.111072\n",
      "loss in epoch 19 , step 5700 : 0.928432\n",
      "loss in epoch 19 , step 5720 : 0.635255\n",
      "loss in epoch 19 , step 5740 : 0.394375\n",
      "loss in epoch 19 , step 5760 : 0.258368\n",
      "loss in epoch 19 , step 5780 : 0.509590\n",
      "loss in epoch 19 , step 5800 : 0.849469\n",
      "loss in epoch 19 , step 5820 : 0.010986\n",
      "loss in epoch 19 , step 5840 : 0.271037\n",
      "loss in epoch 19 , step 5860 : 0.003927\n",
      "loss in epoch 19 , step 5880 : 0.468198\n",
      "loss in epoch 19 , step 5900 : 0.186496\n",
      "loss in epoch 19 , step 5920 : 0.836771\n",
      "loss in epoch 19 , step 5940 : 0.151155\n",
      "loss in epoch 19 , step 5960 : 1.845970\n",
      "loss in epoch 19 , step 5980 : 0.706259\n",
      "loss in epoch 19 , step 6000 : 0.013902\n",
      "loss in epoch 19 , step 6020 : 0.565046\n",
      "loss in epoch 19 , step 6040 : 0.075052\n",
      "loss in epoch 19 , step 6060 : 0.090429\n",
      "loss in epoch 19 , step 6080 : 0.010539\n",
      "loss in epoch 19 , step 6100 : 0.275009\n",
      "loss in epoch 19 , step 6120 : 0.349322\n",
      "loss in epoch 19 , step 6140 : 0.066121\n",
      "loss in epoch 19 , step 6160 : 0.070076\n",
      "loss in epoch 19 , step 6180 : 1.654243\n",
      "loss in epoch 19 , step 6200 : 0.853071\n",
      "loss in epoch 19 , step 6220 : 0.557351\n",
      "loss in epoch 19 , step 6240 : 0.378969\n",
      "loss in epoch 19 , step 6260 : 1.328933\n",
      "loss in epoch 19 , step 6280 : 0.327091\n",
      "loss in epoch 19 , step 6300 : 0.373951\n",
      "loss in epoch 19 , step 6320 : 0.011532\n",
      "loss in epoch 19 , step 6340 : 0.595849\n",
      "loss in epoch 19 , step 6360 : 0.038242\n",
      "loss in epoch 19 , step 6380 : 0.046196\n",
      "loss in epoch 19 , step 6400 : 0.001209\n",
      "loss in epoch 19 , step 6420 : 0.743184\n",
      "loss in epoch 19 , step 6440 : 0.296879\n",
      "loss in epoch 19 , step 6460 : 0.155423\n",
      "loss in epoch 19 , step 6480 : 0.166331\n",
      "loss in epoch 19 , step 6500 : 0.507976\n",
      "loss in epoch 19 , step 6520 : 0.041807\n",
      "loss in epoch 19 , step 6540 : 0.020668\n",
      "loss in epoch 19 , step 6560 : 0.247943\n",
      "loss in epoch 19 , step 6580 : 1.826510\n",
      "loss in epoch 19 , step 6600 : 0.247587\n",
      "loss in epoch 19 , step 6620 : 0.208597\n",
      "loss in epoch 19 , step 6640 : 0.002053\n",
      "loss in epoch 19 , step 6660 : 1.189908\n",
      "loss in epoch 19 , step 6680 : 1.201824\n",
      "loss in epoch 19 , step 6700 : 0.588459\n",
      "loss in epoch 19 , step 6720 : 0.190661\n",
      "loss in epoch 19 , step 6740 : 0.460860\n",
      "loss in epoch 19 , step 6760 : 0.891641\n",
      "loss in epoch 19 , step 6780 : 1.569340\n",
      "loss in epoch 19 , step 6800 : 0.039436\n",
      "loss in epoch 19 , step 6820 : 0.346152\n",
      "loss in epoch 19 , step 6840 : 0.786091\n",
      "loss in epoch 19 , step 6860 : 0.156306\n",
      "loss in epoch 19 , step 6880 : 0.510167\n",
      "loss in epoch 19 , step 6900 : 0.951323\n",
      "loss in epoch 19 , step 6920 : 0.833629\n",
      "loss in epoch 19 , step 6940 : 1.834724\n",
      "loss in epoch 19 , step 6960 : 0.028582\n",
      "loss in epoch 19 , step 6980 : 0.204446\n",
      "loss in epoch 19 , step 7000 : 1.418449\n",
      "loss in epoch 19 , step 7020 : 0.477913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 19 , step 7040 : 0.131809\n",
      "loss in epoch 19 , step 7060 : 1.269835\n",
      "loss in epoch 19 , step 7080 : 0.544604\n",
      "loss in epoch 19 , step 7100 : 1.392589\n",
      "loss in epoch 19 , step 7120 : 1.102403\n",
      "loss in epoch 19 , step 7140 : 0.317560\n",
      "loss in epoch 19 , step 7160 : 0.885794\n",
      "loss in epoch 19 , step 7180 : 0.820057\n",
      "loss in epoch 19 , step 7200 : 0.294583\n",
      "loss in epoch 19 , step 7220 : 0.007657\n",
      "loss in epoch 19 , step 7240 : 1.714644\n",
      "loss in epoch 19 , step 7260 : 0.424318\n",
      "loss in epoch 19 , step 7280 : 4.339984\n",
      "loss in epoch 19 , step 7300 : 1.018166\n",
      "loss in epoch 19 , step 7320 : 0.517378\n",
      "loss in epoch 19 , step 7340 : 0.087336\n",
      "loss in epoch 19 , step 7360 : 0.002495\n",
      "loss in epoch 19 , step 7380 : 0.001644\n",
      "loss in epoch 19 , step 7400 : 0.594763\n",
      "loss in epoch 19 , step 7420 : 0.455602\n",
      "loss in epoch 19 , step 7440 : 1.233293\n",
      "loss in epoch 19 , step 7460 : 0.598312\n",
      "loss in epoch 19 , step 7480 : 0.102459\n",
      "loss in epoch 19 , step 7500 : 0.707830\n",
      "loss in epoch 19 , step 7520 : 0.685504\n",
      "loss in epoch 19 , step 7540 : 0.222312\n",
      "loss in epoch 19 , step 7560 : 0.004323\n",
      "loss in epoch 19 , step 7580 : 1.533965\n",
      "loss in epoch 19 , step 7600 : 0.301151\n",
      "loss in epoch 19 , step 7620 : 0.003377\n",
      "loss in epoch 19 , step 7640 : 2.163173\n",
      "loss in epoch 19 , step 7660 : 0.019375\n",
      "loss in epoch 19 , step 7680 : 0.821370\n",
      "loss in epoch 19 , step 7700 : 0.506960\n",
      "loss in epoch 19 , step 7720 : 1.279493\n",
      "loss in epoch 19 , step 7740 : 0.100361\n",
      "loss in epoch 19 , step 7760 : 0.731991\n",
      "loss in epoch 19 , step 7780 : 0.372005\n",
      "loss in epoch 19 , step 7800 : 0.096558\n",
      "loss in epoch 19 , step 7820 : 0.049762\n",
      "loss in epoch 19 , step 7840 : 0.227445\n",
      "loss in epoch 19 , step 7860 : 0.022881\n",
      "loss in epoch 19 , step 7880 : 0.536487\n",
      "loss in epoch 19 , step 7900 : 0.265200\n",
      "loss in epoch 19 , step 7920 : 0.726255\n",
      "loss in epoch 19 , step 7940 : 0.055704\n",
      "loss in epoch 19 , step 7960 : 0.544905\n",
      "loss in epoch 19 , step 7980 : 0.259379\n",
      "loss in epoch 19 , step 8000 : 0.860112\n",
      "loss in epoch 19 , step 8020 : 0.415295\n",
      "loss in epoch 19 , step 8040 : 0.209662\n",
      "loss in epoch 19 , step 8060 : 0.074220\n",
      "loss in epoch 19 , step 8080 : 0.000825\n",
      "loss in epoch 19 , step 8100 : 1.220642\n",
      "loss in epoch 19 , step 8120 : 1.119703\n",
      "loss in epoch 19 , step 8140 : 0.031059\n",
      "loss in epoch 19 , step 8160 : 1.355390\n",
      "loss in epoch 19 , step 8180 : 0.062299\n",
      "loss in epoch 19 , step 8200 : 0.722864\n",
      "loss in epoch 19 , step 8220 : 1.028096\n",
      "loss in epoch 19 , step 8240 : 2.352970\n",
      "loss in epoch 19 , step 8260 : 1.534366\n",
      "loss in epoch 19 , step 8280 : 1.964469\n",
      "loss in epoch 19 , step 8300 : 0.036618\n",
      "loss in epoch 19 , step 8320 : 1.026036\n",
      "loss in epoch 19 , step 8340 : 0.089867\n",
      "loss in epoch 19 , step 8360 : 0.997584\n",
      "loss in epoch 19 , step 8380 : 0.318091\n",
      "loss in epoch 19 , step 8400 : 0.548957\n",
      "loss in epoch 19 , step 8420 : 0.128548\n",
      "loss in epoch 19 , step 8440 : 0.021276\n",
      "loss in epoch 19 , step 8460 : 0.475255\n",
      "loss in epoch 19 , step 8480 : 0.881966\n",
      "loss in epoch 19 , step 8500 : 0.549024\n",
      "loss in epoch 19 , step 8520 : 0.216368\n",
      "loss in epoch 19 , step 8540 : 0.232381\n",
      "loss in epoch 19 , step 8560 : 0.584185\n",
      "loss in epoch 19 , step 8580 : 0.008463\n",
      "loss in epoch 19 , step 8600 : 0.727965\n",
      "loss in epoch 19 , step 8620 : 1.183907\n",
      "loss in epoch 19 , step 8640 : 1.050668\n",
      "loss in epoch 19 , step 8660 : 0.481343\n",
      "loss in epoch 19 , step 8680 : 0.049444\n",
      "loss in epoch 19 , step 8700 : 1.209432\n",
      "loss in epoch 19 , step 8720 : 0.000560\n",
      "loss in epoch 19 , step 8740 : 0.635799\n",
      "loss in epoch 19 , step 8760 : 1.078818\n",
      "loss in epoch 19 , step 8780 : 2.452994\n",
      "loss in epoch 19 , step 8800 : 0.243931\n",
      "loss in epoch 19 , step 8820 : 0.964303\n",
      "loss in epoch 19 , step 8840 : 2.482101\n",
      "loss in epoch 19 , step 8860 : 0.010545\n",
      "loss in epoch 19 , step 8880 : 1.209840\n",
      "loss in epoch 19 , step 8900 : 0.018560\n",
      "loss in epoch 19 , step 8920 : 0.755633\n",
      "loss in epoch 19 , step 8940 : 0.058745\n",
      "loss in epoch 19 , step 8960 : 0.565805\n",
      "loss in epoch 19 , step 8980 : 0.260233\n",
      "loss in epoch 19 , step 9000 : 0.121060\n",
      "loss in epoch 19 , step 9020 : 0.107641\n",
      "loss in epoch 19 , step 9040 : 0.422658\n",
      "loss in epoch 19 , step 9060 : 0.165274\n",
      "loss in epoch 19 , step 9080 : 0.112871\n",
      "loss in epoch 19 , step 9100 : 0.027068\n",
      "loss in epoch 19 , step 9120 : 0.129292\n",
      "loss in epoch 19 , step 9140 : 0.080828\n",
      "loss in epoch 19 , step 9160 : 0.472914\n",
      "loss in epoch 19 , step 9180 : 0.079742\n",
      "loss in epoch 19 , step 9200 : 0.003652\n",
      "loss in epoch 19 , step 9220 : 0.384328\n",
      "loss in epoch 19 , step 9240 : 1.848922\n",
      "loss in epoch 19 , step 9260 : 0.183078\n",
      "loss in epoch 19 , step 9280 : 0.270599\n",
      "loss in epoch 19 , step 9300 : 0.541107\n",
      "loss in epoch 19 , step 9320 : 0.188384\n",
      "loss in epoch 19 , step 9340 : 3.214387\n",
      "loss in epoch 19 , step 9360 : 0.906929\n",
      "loss in epoch 19 , step 9380 : 0.009579\n",
      "loss in epoch 19 , step 9400 : 0.002879\n",
      "loss in epoch 19 , step 9420 : 0.584441\n",
      "loss in epoch 19 , step 9440 : 0.992052\n",
      "loss in epoch 19 , step 9460 : 0.836064\n",
      "loss in epoch 19 , step 9480 : 0.362967\n",
      "loss in epoch 19 , step 9500 : 1.069942\n",
      "loss in epoch 19 , step 9520 : 0.252279\n",
      "loss in epoch 19 , step 9540 : 0.303354\n",
      "loss in epoch 19 , step 9560 : 1.641126\n",
      "loss in epoch 19 , step 9580 : 1.174361\n",
      "loss in epoch 19 , step 9600 : 0.083504\n",
      "loss in epoch 19 , step 9620 : 0.222217\n",
      "loss in epoch 19 , step 9640 : 4.099241\n",
      "loss in epoch 19 , step 9660 : 0.388314\n",
      "loss in epoch 19 , step 9680 : 0.046603\n",
      "loss in epoch 19 , step 9700 : 0.030305\n",
      "loss in epoch 19 , step 9720 : 2.810409\n",
      "loss in epoch 19 , step 9740 : 1.224061\n",
      "loss in epoch 19 , step 9760 : 0.286564\n",
      "loss in epoch 19 , step 9780 : 3.291069\n",
      "loss in epoch 19 , step 9800 : 1.050651\n",
      "loss in epoch 19 , step 9820 : 0.488423\n",
      "loss in epoch 19 , step 9840 : 0.006950\n",
      "loss in epoch 19 , step 9860 : 1.727583\n",
      "loss in epoch 19 , step 9880 : 0.449199\n",
      "loss in epoch 19 , step 9900 : 1.581749\n",
      "loss in epoch 19 , step 9920 : 0.184210\n",
      "loss in epoch 19 , step 9940 : 1.190746\n",
      "loss in epoch 19 , step 9960 : 0.120254\n",
      "loss in epoch 19 , step 9980 : 1.108210\n",
      "loss in epoch 19 , step 10000 : 0.019263\n",
      "loss in epoch 19 , step 10020 : 0.087149\n",
      "loss in epoch 19 , step 10040 : 0.797839\n",
      "loss in epoch 19 , step 10060 : 0.561838\n",
      "loss in epoch 19 , step 10080 : 0.202897\n",
      "loss in epoch 19 , step 10100 : 0.069683\n",
      "loss in epoch 19 , step 10120 : 0.259323\n",
      "loss in epoch 19 , step 10140 : 0.312971\n",
      "loss in epoch 19 , step 10160 : 3.078928\n",
      "loss in epoch 19 , step 10180 : 0.543391\n",
      "loss in epoch 19 , step 10200 : 0.019604\n",
      "loss in epoch 19 , step 10220 : 0.088663\n",
      "loss in epoch 19 , step 10240 : 0.272786\n",
      "loss in epoch 19 , step 10260 : 0.009515\n",
      "loss in epoch 19 , step 10280 : 0.738447\n",
      "loss in epoch 19 , step 10300 : 0.338523\n",
      "loss in epoch 19 , step 10320 : 0.290251\n",
      "loss in epoch 19 , step 10340 : 0.151650\n",
      "loss in epoch 19 , step 10360 : 0.052160\n",
      "loss in epoch 19 , step 10380 : 2.189222\n",
      "loss in epoch 19 , step 10400 : 1.438068\n",
      "loss in epoch 19 , step 10420 : 0.253726\n",
      "loss in epoch 19 , step 10440 : 0.633446\n",
      "loss in epoch 19 , step 10460 : 0.002668\n",
      "loss in epoch 19 , step 10480 : 0.177343\n",
      "loss in epoch 19 , step 10500 : 0.096009\n",
      "loss in epoch 19 , step 10520 : 0.080934\n",
      "loss in epoch 19 , step 10540 : 0.198195\n",
      "loss in epoch 19 , step 10560 : 0.601171\n",
      "loss in epoch 19 , step 10580 : 0.178832\n",
      "loss in epoch 19 , step 10600 : 0.099568\n",
      "loss in epoch 19 , step 10620 : 1.522642\n",
      "loss in epoch 19 , step 10640 : 0.416241\n",
      "loss in epoch 19 , step 10660 : 0.005282\n",
      "loss in epoch 19 , step 10680 : 0.225328\n",
      "loss in epoch 19 , step 10700 : 0.801435\n",
      "loss in epoch 19 , step 10720 : 0.503962\n",
      "loss in epoch 19 , step 10740 : 0.227102\n",
      "loss in epoch 19 , step 10760 : 0.869659\n",
      "loss in epoch 19 , step 10780 : 0.000417\n",
      "loss in epoch 19 , step 10800 : 0.050945\n",
      "loss in epoch 19 , step 10820 : 0.444191\n",
      "loss in epoch 19 , step 10840 : 0.003773\n",
      "loss in epoch 19 , step 10860 : 0.061656\n",
      "loss in epoch 19 , step 10880 : 0.023130\n",
      "loss in epoch 19 , step 10900 : 0.218982\n",
      "loss in epoch 19 , step 10920 : 0.401269\n",
      "loss in epoch 19 , step 10940 : 1.246068\n",
      "loss in epoch 19 , step 10960 : 0.424080\n",
      "loss in epoch 19 , step 10980 : 0.333920\n",
      "loss in epoch 19 , step 11000 : 0.750625\n",
      "loss in epoch 19 , step 11020 : 0.114196\n",
      "loss in epoch 19 , step 11040 : 0.177749\n",
      "loss in epoch 19 , step 11060 : 0.012668\n",
      "loss in epoch 19 , step 11080 : 0.049635\n",
      "loss in epoch 19 , step 11100 : 2.213852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 19 , step 11120 : 0.024566\n",
      "loss in epoch 19 , step 11140 : 0.592081\n",
      "loss in epoch 19 , step 11160 : 0.417193\n",
      "loss in epoch 19 , step 11180 : 0.055134\n",
      "loss in epoch 19 , step 11200 : 0.819430\n",
      "loss in epoch 19 , step 11220 : 0.492540\n",
      "loss in epoch 19 , step 11240 : 0.374793\n",
      "loss in epoch 19 , step 11260 : 3.125659\n",
      "loss in epoch 19 , step 11280 : 0.363252\n",
      "loss in epoch 19 , step 11300 : 0.071743\n",
      "loss in epoch 19 , step 11320 : 1.420865\n",
      "loss in epoch 19 , step 11340 : 0.162019\n",
      "loss in epoch 19 , step 11360 : 0.009471\n",
      "loss in epoch 19 , step 11380 : 0.043908\n",
      "loss in epoch 19 , step 11400 : 0.122302\n",
      "loss in epoch 19 , step 11420 : 0.609596\n",
      "loss in epoch 19 , step 11440 : 0.001812\n",
      "loss in epoch 19 , step 11460 : 0.420109\n",
      "loss in epoch 19 , step 11480 : 0.002579\n",
      "loss in epoch 19 , step 11500 : 1.961496\n",
      "loss in epoch 19 , step 11520 : 1.151798\n",
      "loss in epoch 19 , step 11540 : 0.169963\n",
      "loss in epoch 19 , step 11560 : 0.038762\n",
      "loss in epoch 19 , step 11580 : 0.205918\n",
      "loss in epoch 19 , step 11600 : 0.082370\n",
      "loss in epoch 19 , step 11620 : 0.189049\n",
      "loss in epoch 19 , step 11640 : 0.552479\n",
      "loss in epoch 19 , step 11660 : 0.015185\n",
      "loss in epoch 19 , step 11680 : 0.016774\n",
      "loss in epoch 19 , step 11700 : 0.597968\n",
      "loss in epoch 19 , step 11720 : 0.405975\n",
      "loss in epoch 19 , step 11740 : 0.357958\n",
      "loss in epoch 19 , step 11760 : 0.005163\n",
      "loss in epoch 19 , step 11780 : 0.647143\n",
      "loss in epoch 19 , step 11800 : 0.177096\n",
      "loss in epoch 19 , step 11820 : 1.232424\n",
      "loss in epoch 19 , step 11840 : 0.514068\n",
      "loss in epoch 19 , step 11860 : 0.640009\n",
      "loss in epoch 19 , step 11880 : 0.503722\n",
      "loss in epoch 19 , step 11900 : 0.200776\n",
      "loss in epoch 19 , step 11920 : 0.058793\n",
      "loss in epoch 19 , step 11940 : 0.777549\n",
      "loss in epoch 19 , step 11960 : 1.196252\n",
      "loss in epoch 19 , step 11980 : 0.866413\n",
      "loss in epoch 19 , step 12000 : 1.436095\n",
      "loss in epoch 19 , step 12020 : 0.083517\n",
      "loss in epoch 19 , step 12040 : 0.614821\n",
      "loss in epoch 19 , step 12060 : 0.305347\n",
      "loss in epoch 19 , step 12080 : 0.677521\n",
      "loss in epoch 19 , step 12100 : 1.092649\n",
      "loss in epoch 19 , step 12120 : 0.141127\n",
      "loss in epoch 19 , step 12140 : 0.131033\n",
      "loss in epoch 19 , step 12160 : 1.217470\n",
      "loss in epoch 19 , step 12180 : 0.089756\n",
      "loss in epoch 19 , step 12200 : 0.259378\n",
      "loss in epoch 19 , step 12220 : 0.035615\n",
      "loss in epoch 19 , step 12240 : 1.168314\n",
      "loss in epoch 19 , step 12260 : 0.000597\n",
      "loss in epoch 19 , step 12280 : 0.178768\n",
      "loss in epoch 19 , step 12300 : 0.349366\n",
      "loss in epoch 19 , step 12320 : 0.684908\n",
      "loss in epoch 19 , step 12340 : 1.752163\n",
      "loss in epoch 19 , step 12360 : 1.152475\n",
      "loss in epoch 19 , step 12380 : 0.113796\n",
      "loss in epoch 19 , step 12400 : 0.233892\n",
      "loss in epoch 19 , step 12420 : 0.363363\n",
      "loss in epoch 19 , step 12440 : 0.550130\n",
      "loss in epoch 19 , step 12460 : 0.696449\n",
      "loss in epoch 19 , step 12480 : 0.429865\n",
      "loss in epoch 19 , step 12500 : 1.101774\n",
      "loss in epoch 19 , step 12520 : 0.056723\n",
      "loss in epoch 19 , step 12540 : 5.441468\n",
      "loss in epoch 19 , step 12560 : 0.008947\n",
      "loss in epoch 19 , step 12580 : 0.402484\n",
      "loss in epoch 19 , step 12600 : 0.052621\n",
      "loss in epoch 19 , step 12620 : 1.914654\n",
      "loss in epoch 19 , step 12640 : 0.174130\n",
      "loss in epoch 19 , step 12660 : 0.401989\n",
      "loss in epoch 19 , step 12680 : 0.316125\n",
      "loss in epoch 19 , step 12700 : 0.286017\n",
      "loss in epoch 19 , step 12720 : 0.592594\n",
      "loss in epoch 19 , step 12740 : 1.392736\n",
      "loss in epoch 19 , step 12760 : 0.528560\n",
      "loss in epoch 19 , step 12780 : 0.101460\n",
      "loss in epoch 19 , step 12800 : 1.650063\n",
      "loss in epoch 19 , step 12820 : 0.025393\n",
      "loss in epoch 19 , step 12840 : 1.373683\n",
      "loss in epoch 19 , step 12860 : 0.140922\n",
      "loss in epoch 19 , step 12880 : 1.578938\n",
      "loss in epoch 19 , step 12900 : 0.459628\n",
      "loss in epoch 19 , step 12920 : 0.212435\n",
      "loss in epoch 19 , step 12940 : 0.083002\n",
      "loss in epoch 19 , step 12960 : 0.293073\n",
      "loss in epoch 19 , step 12980 : 0.064535\n",
      "loss in epoch 19 , step 13000 : 1.041661\n",
      "loss in epoch 19 , step 13020 : 1.556966\n",
      "loss in epoch 19 , step 13040 : 0.150144\n",
      "loss in epoch 19 , step 13060 : 0.325069\n",
      "loss in epoch 19 , step 13080 : 2.408029\n",
      "loss in epoch 19 , step 13100 : 0.756093\n",
      "loss in epoch 19 , step 13120 : 0.127118\n",
      "loss in epoch 19 , step 13140 : 3.134870\n",
      "loss in epoch 19 , step 13160 : 0.439977\n",
      "loss in epoch 19 , step 13180 : 0.203327\n",
      "loss in epoch 19 , step 13200 : 0.006409\n",
      "loss in epoch 19 , step 13220 : 0.017596\n",
      "loss in epoch 19 , step 13240 : 0.265332\n",
      "loss in epoch 19 , step 13260 : 0.095870\n",
      "loss in epoch 19 , step 13280 : 0.001546\n",
      "loss in epoch 19 , step 13300 : 4.385020\n",
      "loss in epoch 19 , step 13320 : 0.895079\n",
      "loss in epoch 19 , step 13340 : 0.118938\n",
      "loss in epoch 19 , step 13360 : 0.226136\n",
      "loss in epoch 19 , step 13380 : 0.132180\n",
      "loss in epoch 19 , step 13400 : 0.334926\n",
      "loss in epoch 19 , step 13420 : 0.614022\n",
      "loss in epoch 19 , step 13440 : 0.422414\n",
      "loss in epoch 19 , step 13460 : 2.485693\n",
      "loss in epoch 19 , step 13480 : 1.254101\n",
      "loss in epoch 19 , step 13500 : 0.408651\n",
      "loss in epoch 19 , step 13520 : 0.366157\n",
      "loss in epoch 19 , step 13540 : 0.198721\n",
      "loss in epoch 19 , step 13560 : 0.001787\n",
      "loss in epoch 19 , step 13580 : 1.495767\n",
      "loss in epoch 19 , step 13600 : 0.041941\n",
      "loss in epoch 19 , step 13620 : 0.560409\n",
      "loss in epoch 19 , step 13640 : 0.180284\n",
      "loss in epoch 19 , step 13660 : 0.090022\n",
      "loss in epoch 19 , step 13680 : 0.569580\n",
      "loss in epoch 19 , step 13700 : 0.003144\n",
      "loss in epoch 19 , step 13720 : 0.014239\n",
      "loss in epoch 19 , step 13740 : 0.258683\n",
      "loss in epoch 19 , step 13760 : 0.027794\n",
      "loss in epoch 19 , step 13780 : 0.659124\n",
      "loss in epoch 19 , step 13800 : 0.745831\n",
      "loss in epoch 19 , step 13820 : 0.247023\n",
      "loss in epoch 19 , step 13840 : 0.040684\n",
      "loss in epoch 19 , step 13860 : 0.483270\n",
      "loss in epoch 19 , step 13880 : 0.855099\n",
      "loss in epoch 19 , step 13900 : 0.155472\n",
      "loss in epoch 19 , step 13920 : 1.126909\n",
      "loss in epoch 19 , step 13940 : 0.001457\n",
      "loss in epoch 19 , step 13960 : 0.029218\n",
      "loss in epoch 19 , step 13980 : 0.055702\n",
      "loss in epoch 19 , step 14000 : 1.407272\n",
      "loss in epoch 19 , step 14020 : 0.607028\n",
      "loss in epoch 19 , step 14040 : 0.984211\n",
      "loss in epoch 19 , step 14060 : 0.533891\n",
      "loss in epoch 19 , step 14080 : 0.137224\n",
      "loss in epoch 19 , step 14100 : 0.548486\n",
      "loss in epoch 19 , step 14120 : 0.025815\n",
      "loss in epoch 19 , step 14140 : 0.765869\n",
      "loss in epoch 19 , step 14160 : 0.557183\n",
      "loss in epoch 19 , step 14180 : 0.426105\n",
      "loss in epoch 19 , step 14200 : 0.211994\n",
      "loss in epoch 19 , step 14220 : 0.819287\n",
      "loss in epoch 19 , step 14240 : 0.013618\n",
      "loss in epoch 19 , step 14260 : 1.586442\n",
      "loss in epoch 19 , step 14280 : 0.324524\n",
      "loss in epoch 19 , step 14300 : 0.755847\n",
      "loss in epoch 19 , step 14320 : 0.077494\n",
      "loss in epoch 19 , step 14340 : 0.509076\n",
      "loss in epoch 19 , step 14360 : 0.985610\n",
      "loss in epoch 19 , step 14380 : 0.640619\n",
      "loss in epoch 19 , step 14400 : 0.004795\n",
      "loss in epoch 19 , step 14420 : 0.544751\n",
      "loss in epoch 19 , step 14440 : 0.030335\n",
      "loss in epoch 19 , step 14460 : 0.457512\n",
      "loss in epoch 19 , step 14480 : 0.480039\n",
      "loss in epoch 19 , step 14500 : 0.001333\n",
      "loss in epoch 19 , step 14520 : 0.109534\n",
      "loss in epoch 19 , step 14540 : 0.446014\n",
      "loss in epoch 19 , step 14560 : 0.047257\n",
      "loss in epoch 19 , step 14580 : 0.870537\n",
      "loss in epoch 19 , step 14600 : 0.626250\n",
      "loss in epoch 19 , step 14620 : 1.190756\n",
      "loss in epoch 19 , step 14640 : 0.388690\n",
      "loss in epoch 19 , step 14660 : 0.280627\n",
      "loss in epoch 19 , step 14680 : 0.166029\n",
      "loss in epoch 19 , step 14700 : 0.544702\n",
      "loss in epoch 19 , step 14720 : 0.107799\n",
      "loss in epoch 19 , step 14740 : 0.205561\n",
      "loss in epoch 19 , step 14760 : 1.042682\n",
      "loss in epoch 19 , step 14780 : 0.196565\n",
      "loss in epoch 19 , step 14800 : 1.045919\n",
      "loss in epoch 19 , step 14820 : 1.708037\n",
      "loss in epoch 19 , step 14840 : 0.771826\n",
      "loss in epoch 19 , step 14860 : 0.504559\n",
      "loss in epoch 19 , step 14880 : 0.007952\n",
      "loss in epoch 19 , step 14900 : 1.038530\n",
      "loss in epoch 19 , step 14920 : 0.141510\n",
      "loss in epoch 19 , step 14940 : 0.560332\n",
      "loss in epoch 19 , step 14960 : 2.772650\n",
      "loss in epoch 19 , step 14980 : 2.319940\n",
      "loss in epoch 19 , step 15000 : 0.388580\n",
      "loss in epoch 19 , step 15020 : 0.239889\n",
      "loss in epoch 19 , step 15040 : 0.008680\n",
      "loss in epoch 19 , step 15060 : 0.036742\n",
      "loss in epoch 19 , step 15080 : 0.703823\n",
      "loss in epoch 19 , step 15100 : 1.246891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 19 , step 15120 : 0.086273\n",
      "loss in epoch 19 , step 15140 : 0.040868\n",
      "loss in epoch 19 , step 15160 : 0.386529\n",
      "loss in epoch 19 , step 15180 : 0.024914\n",
      "loss in epoch 19 , step 15200 : 0.308475\n",
      "loss in epoch 19 , step 15220 : 0.330141\n",
      "loss in epoch 19 , step 15240 : 0.811707\n",
      "loss in epoch 19 , step 15260 : 0.003733\n",
      "loss in epoch 19 , step 15280 : 1.184353\n",
      "loss in epoch 19 , step 15300 : 0.288367\n",
      "loss in epoch 19 , step 15320 : 0.001496\n",
      "loss in epoch 19 , step 15340 : 0.087918\n",
      "loss in epoch 19 , step 15360 : 0.314797\n",
      "loss in epoch 19 , step 15380 : 0.010443\n",
      "loss in epoch 19 , step 15400 : 0.637841\n",
      "loss in epoch 19 , step 15420 : 0.421270\n",
      "loss in epoch 19 , step 15440 : 0.102399\n",
      "loss in epoch 19 , step 15460 : 0.619668\n",
      "loss in epoch 19 , step 15480 : 1.904956\n",
      "loss in epoch 19 , step 15500 : 0.046707\n",
      "loss in epoch 19 , step 15520 : 0.010742\n",
      "loss in epoch 19 , step 15540 : 0.438839\n",
      "loss in epoch 19 , step 15560 : 1.515450\n",
      "loss in epoch 19 , step 15580 : 0.013798\n",
      "loss in epoch 19 , step 15600 : 0.872900\n",
      "loss in epoch 19 , step 15620 : 0.040838\n",
      "loss in epoch 19 , step 15640 : 0.193714\n",
      "loss in epoch 19 , step 15660 : 1.456668\n",
      "loss in epoch 19 , step 15680 : 0.151670\n",
      "loss in epoch 19 , step 15700 : 0.237406\n",
      "loss in epoch 19 , step 15720 : 0.908506\n",
      "loss in epoch 19 , step 15740 : 0.406754\n",
      "loss in epoch 19 , step 15760 : 0.242420\n",
      "loss in epoch 19 , step 15780 : 0.320463\n",
      "loss in epoch 19 , step 15800 : 0.003106\n",
      "loss in epoch 19 , step 15820 : 0.061769\n",
      "loss in epoch 19 , step 15840 : 0.940035\n",
      "loss in epoch 19 , step 15860 : 0.287130\n",
      "loss in epoch 19 , step 15880 : 0.761728\n",
      "loss in epoch 19 , step 15900 : 0.075362\n",
      "loss in epoch 19 , step 15920 : 0.025170\n",
      "loss in epoch 19 , step 15940 : 1.148932\n",
      "loss in epoch 19 , step 15960 : 0.188405\n",
      "loss in epoch 19 , step 15980 : 0.357474\n",
      "loss in epoch 19 , step 16000 : 0.000880\n",
      "loss in epoch 19 , step 16020 : 0.130033\n",
      "loss in epoch 19 , step 16040 : 0.557303\n",
      "loss in epoch 19 , step 16060 : 0.004213\n",
      "loss in epoch 19 , step 16080 : 0.074421\n",
      "loss in epoch 19 , step 16100 : 1.135141\n",
      "loss in epoch 19 , step 16120 : 0.689209\n",
      "loss in epoch 19 , step 16140 : 2.033069\n",
      "loss in epoch 19 , step 16160 : 0.243823\n",
      "loss in epoch 19 , step 16180 : 0.010607\n",
      "loss in epoch 19 , step 16200 : 1.034441\n",
      "loss in epoch 19 , step 16220 : 1.746267\n",
      "loss in epoch 19 , step 16240 : 0.195725\n",
      "loss in epoch 19 , step 16260 : 0.013861\n",
      "loss in epoch 19 , step 16280 : 1.402689\n",
      "loss in epoch 19 , step 16300 : 0.106203\n",
      "loss in epoch 19 , step 16320 : 0.233629\n",
      "loss in epoch 19 , step 16340 : 0.082669\n",
      "loss in epoch 19 , step 16360 : 0.041358\n",
      "loss in epoch 19 , step 16380 : 0.038624\n",
      "loss in epoch 19 , step 16400 : 0.354498\n",
      "loss in epoch 19 , step 16420 : 0.049096\n",
      "loss in epoch 19 , step 16440 : 1.000833\n",
      "loss in epoch 19 , step 16460 : 0.512992\n",
      "loss in epoch 19 , step 16480 : 1.438054\n",
      "loss in epoch 19 , step 16500 : 2.753392\n",
      "loss in epoch 19 , step 16520 : 0.005880\n",
      "loss in epoch 19 , step 16540 : 0.008098\n",
      "loss in epoch 19 , step 16560 : 0.127880\n",
      "loss in epoch 19 , step 16580 : 0.111181\n",
      "loss in epoch 19 , step 16600 : 0.060201\n",
      "loss in epoch 19 , step 16620 : 0.052157\n",
      "loss in epoch 19 , step 16640 : 0.004670\n",
      "loss in epoch 19 , step 16660 : 1.044052\n",
      "loss in epoch 19 , step 16680 : 0.604479\n",
      "loss in epoch 19 , step 16700 : 0.341841\n",
      "loss in epoch 19 , step 16720 : 0.114736\n",
      "loss in epoch 19 , step 16740 : 1.105642\n",
      "loss in epoch 19 , step 16760 : 0.038794\n",
      "loss in epoch 19 , step 16780 : 1.816571\n",
      "loss in epoch 19 , step 16800 : 0.734027\n",
      "loss in epoch 19 , step 16820 : 0.657760\n",
      "loss in epoch 19 , step 16840 : 0.376141\n",
      "loss in epoch 19 , step 16860 : 0.543632\n",
      "loss in epoch 19 , step 16880 : 0.337211\n",
      "loss in epoch 19 , step 16900 : 0.102891\n",
      "loss in epoch 19 , step 16920 : 1.286365\n",
      "loss in epoch 19 , step 16940 : 0.098612\n",
      "loss in epoch 19 , step 16960 : 0.402499\n",
      "loss in epoch 19 , step 16980 : 0.968599\n",
      "loss in epoch 19 , step 17000 : 0.431434\n",
      "loss in epoch 19 , step 17020 : 0.235159\n",
      "loss in epoch 19 , step 17040 : 0.095185\n",
      "loss in epoch 19 , step 17060 : 1.025478\n",
      "loss in epoch 19 , step 17080 : 0.286187\n",
      "loss in epoch 19 , step 17100 : 0.298607\n",
      "loss in epoch 19 , step 17120 : 0.040198\n",
      "loss in epoch 19 , step 17140 : 0.838877\n",
      "loss in epoch 19 , step 17160 : 0.157790\n",
      "loss in epoch 19 , step 17180 : 0.054746\n",
      "loss in epoch 19 , step 17200 : 0.452294\n",
      "loss in epoch 19 , step 17220 : 2.533898\n",
      "loss in epoch 19 , step 17240 : 0.080983\n",
      "loss in epoch 19 , step 17260 : 0.856605\n",
      "loss in epoch 19 , step 17280 : 1.293975\n",
      "loss in epoch 19 , step 17300 : 0.232545\n",
      "loss in epoch 19 , step 17320 : 0.016769\n",
      "loss in epoch 19 , step 17340 : 0.073426\n",
      "loss in epoch 19 , step 17360 : 1.107443\n",
      "loss in epoch 19 , step 17380 : 0.052586\n",
      "loss in epoch 19 , step 17400 : 0.000921\n",
      "loss in epoch 19 , step 17420 : 2.614946\n",
      "loss in epoch 19 , step 17440 : 0.511588\n",
      "loss in epoch 19 , step 17460 : 0.058307\n",
      "loss in epoch 19 , step 17480 : 0.733216\n",
      "loss in epoch 19 , step 17500 : 0.294692\n",
      "loss in epoch 19 , step 17520 : 0.570822\n",
      "loss in epoch 19 , step 17540 : 0.159141\n",
      "loss in epoch 19 , step 17560 : 0.020587\n",
      "loss in epoch 19 , step 17580 : 0.326500\n",
      "loss in epoch 19 , step 17600 : 0.001886\n",
      "loss in epoch 19 , step 17620 : 0.695429\n",
      "loss in epoch 19 , step 17640 : 0.306196\n",
      "loss in epoch 19 , step 17660 : 3.328686\n",
      "loss in epoch 19 , step 17680 : 0.003754\n",
      "loss in epoch 19 , step 17700 : 0.072690\n",
      "loss in epoch 19 , step 17720 : 0.533166\n",
      "loss in epoch 19 , step 17740 : 0.520717\n",
      "loss in epoch 19 , step 17760 : 0.432969\n",
      "loss in epoch 19 , step 17780 : 0.215879\n",
      "loss in epoch 19 , step 17800 : 0.001096\n",
      "loss in epoch 19 , step 17820 : 0.873236\n",
      "loss in epoch 19 , step 17840 : 0.001429\n",
      "loss in epoch 19 , step 17860 : 0.411315\n",
      "loss in epoch 19 , step 17880 : 1.398636\n",
      "loss in epoch 19 , step 17900 : 0.039475\n",
      "loss in epoch 19 , step 17920 : 0.152933\n",
      "loss in epoch 19 , step 17940 : 0.552004\n",
      "loss in epoch 19 , step 17960 : 0.645440\n",
      "loss in epoch 19 , step 17980 : 0.136377\n",
      "loss in epoch 19 , step 18000 : 1.087069\n",
      "loss in epoch 19 , step 18020 : 0.004985\n",
      "loss in epoch 19 , step 18040 : 0.002034\n",
      "loss in epoch 19 , step 18060 : 0.009147\n",
      "loss in epoch 19 , step 18080 : 0.009103\n",
      "loss in epoch 19 , step 18100 : 0.655557\n",
      "loss in epoch 19 , step 18120 : 0.904245\n",
      "loss in epoch 19 , step 18140 : 1.241581\n",
      "loss in epoch 19 , step 18160 : 0.386311\n",
      "loss in epoch 19 , step 18180 : 0.047863\n",
      "loss in epoch 19 , step 18200 : 0.897453\n",
      "loss in epoch 19 , step 18220 : 0.418898\n",
      "loss in epoch 19 , step 18240 : 1.128317\n",
      "loss in epoch 19 , step 18260 : 0.022203\n",
      "loss in epoch 19 , step 18280 : 0.068259\n",
      "loss in epoch 19 , step 18300 : 0.397050\n",
      "loss in epoch 19 , step 18320 : 1.179068\n",
      "loss in epoch 19 , step 18340 : 0.072091\n",
      "loss in epoch 19 , step 18360 : 0.036866\n",
      "loss in epoch 19 , step 18380 : 0.005394\n",
      "loss in epoch 19 , step 18400 : 0.001580\n",
      "loss in epoch 19 , step 18420 : 0.025418\n",
      "loss in epoch 19 , step 18440 : 0.529157\n",
      "loss in epoch 19 , step 18460 : 0.325637\n",
      "loss in epoch 19 , step 18480 : 1.039679\n",
      "loss in epoch 19 , step 18500 : 0.709440\n",
      "loss in epoch 19 , step 18520 : 0.873369\n",
      "loss in epoch 19 , step 18540 : 0.047114\n",
      "loss in epoch 19 , step 18560 : 0.021378\n",
      "loss in epoch 19 , step 18580 : 0.718294\n",
      "loss in epoch 19 , step 18600 : 0.388140\n",
      "loss in epoch 19 , step 18620 : 0.630655\n",
      "loss in epoch 19 , step 18640 : 0.004993\n",
      "loss in epoch 19 , step 18660 : 0.103088\n",
      "loss in epoch 19 , step 18680 : 1.302210\n",
      "loss in epoch 19 , step 18700 : 0.542770\n",
      "loss in epoch 19 , step 18720 : 0.384646\n",
      "loss in epoch 19 , step 18740 : 0.000547\n",
      "loss in epoch 19 , step 18760 : 0.140772\n",
      "loss in epoch 19 , step 18780 : 0.015752\n",
      "loss in epoch 19 , step 18800 : 1.246709\n",
      "loss in epoch 19 , step 18820 : 0.039165\n",
      "loss in epoch 19 , step 18840 : 0.000642\n",
      "loss in epoch 19 , step 18860 : 0.014717\n",
      "loss in epoch 19 , step 18880 : 2.073403\n",
      "loss in epoch 19 , step 18900 : 0.159811\n",
      "loss in epoch 19 , step 18920 : 0.151418\n",
      "loss in epoch 19 , step 18940 : 1.006668\n",
      "loss in epoch 19 , step 18960 : 1.311903\n",
      "loss in epoch 19 , step 18980 : 0.033577\n",
      "loss in epoch 19 , step 19000 : 0.051579\n",
      "loss in epoch 19 , step 19020 : 2.143405\n",
      "loss in epoch 19 , step 19040 : 0.127947\n",
      "loss in epoch 19 , step 19060 : 0.013180\n",
      "loss in epoch 19 , step 19080 : 1.918212\n",
      "loss in epoch 19 , step 19100 : 7.921350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 19 , step 19120 : 0.855044\n",
      "loss in epoch 19 , step 19140 : 0.901919\n",
      "loss in epoch 19 , step 19160 : 0.657588\n",
      "loss in epoch 19 , step 19180 : 0.177249\n",
      "loss in epoch 19 , step 19200 : 0.395846\n",
      "loss in epoch 19 , step 19220 : 0.449737\n",
      "loss in epoch 19 , step 19240 : 0.980237\n",
      "loss in epoch 19 , step 19260 : 0.002712\n",
      "loss in epoch 19 , step 19280 : 0.650371\n",
      "loss in epoch 19 , step 19300 : 0.509988\n",
      "loss in epoch 19 , step 19320 : 0.998402\n",
      "loss in epoch 19 , step 19340 : 0.207888\n",
      "loss in epoch 19 , step 19360 : 0.005243\n",
      "loss in epoch 19 , step 19380 : 0.373271\n",
      "loss in epoch 19 , step 19400 : 0.260087\n",
      "loss in epoch 19 , step 19420 : 4.195141\n",
      "loss in epoch 19 , step 19440 : 0.424148\n",
      "loss in epoch 19 , step 19460 : 1.287143\n",
      "loss in epoch 19 , step 19480 : 0.993193\n",
      "loss in epoch 19 , step 19500 : 0.159482\n",
      "loss in epoch 19 , step 19520 : 1.962710\n",
      "loss in epoch 19 , step 19540 : 0.006078\n",
      "loss in epoch 19 , step 19560 : 1.200392\n",
      "loss in epoch 19 , step 19580 : 0.819504\n",
      "loss in epoch 19 , step 19600 : 0.106208\n",
      "loss in epoch 19 , step 19620 : 0.124304\n",
      "loss in epoch 19 , step 19640 : 0.855897\n",
      "loss in epoch 19 , step 19660 : 1.096646\n",
      "loss in epoch 19 , step 19680 : 0.092188\n",
      "loss in epoch 19 , step 19700 : 0.391084\n",
      "loss in epoch 19 , step 19720 : 0.521557\n",
      "loss in epoch 19 , step 19740 : 0.977908\n",
      "loss in epoch 19 , step 19760 : 2.081841\n",
      "loss in epoch 19 , step 19780 : 0.093858\n",
      "loss in epoch 19 , step 19800 : 0.764544\n",
      "loss in epoch 19 , step 19820 : 0.528576\n",
      "loss in epoch 19 , step 19840 : 0.072798\n",
      "loss in epoch 19 , step 19860 : 0.723530\n",
      "loss in epoch 19 , step 19880 : 1.366667\n",
      "loss in epoch 19 , step 19900 : 1.063113\n",
      "loss in epoch 19 , step 19920 : 0.003618\n",
      "loss in epoch 19 , step 19940 : 0.947538\n",
      "Accuracy in epoch 19 : 31.929691\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,20):\n",
    "    adjust_lr(optimizer,epoch,learning_rate)\n",
    "    train(train_loader,model,criterion,optimizer,epoch)\n",
    "    test(test_loader,model,criterion,epoch)\n",
    "    # ... after training, save your model \n",
    "    torch.save(model, 'DenseNetModelSave.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7314d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. to load your previously training model:\n",
    "model = torch.load('DenseNetModelSave.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b844c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fc82675fa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f877e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
